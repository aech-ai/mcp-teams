## Tree for 
```
├── database/
│   ├── postgres_client.py
│   ├── user_admin.py
│   ├── __init__.py
│   ├── test_authenticated_client.py
│   ├── authenticated_postgres_client.py
│   ├── test_database_client.py
│   └── test_user_admin.py
├── llm/
│   ├── model_providers.py
│   ├── base_provider.py
│   ├── test_llm.py
│   ├── provider.py
│   ├── add_new_model.py
│   ├── test_function_calling.py
│   ├── __init__.py
│   ├── demo_function_calling/
│   │   ├── weather_report.py
│   │   ├── weather_joker.py
│   │   ├── demo_nested_function_calls.py
│   │   ├── weather.py
│   │   ├── demo_simple_function_call.py
│   │   ├── demo_binary_objects.py
│   │   └── try_arg_types.py
│   ├── README.md
│   ├── openai_provider.py
│   └── llm_function_extractor.py
├── app/
│   ├── ticket_ingester.py
│   ├── test_ticket_database.py
│   ├── ticket_annotator.py
│   ├── ticket_poller.py
│   ├── Dockerfile
│   ├── ticket_image_processor.py
│   ├── ticket_pdf_writer.py
│   ├── run_poller.py
│   ├── utils/
│   │   ├── generate_annotation_examples.py
│   │   ├── generate_note_examples.py
│   │   ├── aech_test_ticket_operations.py
│   │   ├── ingest_tickets.py
│   │   └── get_active_tsi_dict.py
│   ├── models/
│   │   ├── ticket.py
│   │   ├── ticket_annotation.py
│   │   └── __init__.py
│   ├── api.py
│   ├── ticket_database.py
│   ├── test_ticket_ingester.py
│   ├── data/
│   │   ├── tsi_dict.json
│   │   ├── test/
│   │   │   ├── 1036301.json
│   │   │   └── 1036301.md
│   │   ├── ticket_with_images.json
│   │   ├── statuses.json
│   │   ├── tsi_dict_active.json
│   │   ├── tickets.json
│   │   └── time_entries.json
│   ├── test_ticket_image_processor.py
│   ├── test_ticket_annotator.py
│   └── test_connectwise_api.py
├── requirements.txt
├── pyproject.toml
├── __init__.py
├── README.md
├── .dockerignore
├── retrieval/
│   ├── ingestion.py
│   ├── transcription.py
│   ├── test_transcription.py
│   ├── __init__.py
│   ├── test_hybrid_retriever.py
│   ├── test_ingestion.py
│   └── hybrid_retriever.py
├── .gitignore
├── experiment/
│   ├── analysis_updated.ipynb
│   └── ticket_annotation_experiment.py
├── docker-compose.yml
├── postgres_setup/
│   ├── pgdump_20250409/
│   │   ├── essential_data.sql
│   │   ├── schema.sql
│   │   └── roles_permissions.sql
│   ├── init-db.sh
│   ├── Dockerfile
│   ├── pgdump_20250415/
│   │   ├── essential_data.sql
│   │   ├── schema.sql
│   │   └── roles_permissions.sql
│   ├── README.md
│   ├── postgresql.conf
│   └── backup_db.sh
└── analysis.ipynb
```

## File: requirements.txt
```
aiofiles==24.1.0
aiohttp==3.11.16
asyncio==3.4.3
asyncpg==0.30.0
beautifulsoup4==4.12.3
httpx==0.28.1
langchain-text-splitters==0.3.4
openai==1.72.0
Pillow==10.4.0
pgvector[psycopg]>=0.3.6
psycopg[binary]>=3.2.3
psycopg-pool==3.2.4
pydantic==2.10.4
pydantic[email]==2.10.4
python-dotenv==1.0.1
python-multipart==0.0.20
pytz==2024.2
requests==2.32.3
rich==13.9.4
textblob==0.18.0.post0

fastapi==0.110.0
uvicorn==0.29.0
python-dateutil==2.8.2 
weasyprint==62.3
pdf2image==1.17.0
```
## File: pyproject.toml
```
[build-system]
requires = ["setuptools>=64", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "scout-helpdesk"
version = "0.1.0"
description = "Helpdesk Automation Library"
authors = [{name = "Trevor Kinsey"}]
readme = "README.md"
requires-python = ">=3.10"

[tool.setuptools]
packages = [
    "app",
    "database",
    "llm",
    "retrieval"
]
```
## File: README.md
```markdown
# Scout Helpdesk Core

This repository contains the core functionality of the Scout Helpdesk application, focused on automated ticket ingestion, classification, and retrieval using Retrieval-Augmented Generation (RAG).

## Features

- Polls the Scout API for new and updated tickets
- Automatically classifies new tickets (type, subtype, item, priority)
- Suggests solutions for IT technicians based on similar historical tickets
- Ingests resolved tickets into a PostgreSQL database with vector embeddings
- Tracks open tickets with skeleton entries, and fully ingests them upon closure
- Supports hybrid search (full-text and semantic) for ticket retrieval

## How It Works

The core logic is in the `app/` folder, primarily in `ticket_poller.py` and `run_poller.py`:

1. **Polling**: The app continuously polls the Scout API for new tickets and for tickets that have recently been closed.
2. **Annotation**: New open tickets are classified and annotated. The app suggests solutions and creates a minimal (skeleton) database entry for tracking.
3. **Ingestion**: When a ticket is closed, its full content is ingested into the database, updating or creating a complete record.
4. **Notes**: Optionally, the app can add notes to tickets in Scout, including post-closure analysis.

The polling interval, company identifiers, and other parameters are controlled via environment variables.

## Architecture

The application is containerized using Docker and consists of:

- **App Container**: Runs the polling and processing logic (see `app/run_poller.py`)
- **PostgreSQL Container**: Stores tickets and vector embeddings

## Prerequisites

- Docker and Docker Compose
- Scout API credentials
- OpenAI API key (for LLM-based classification and search)

## Setup

1. Clone this repository:
   ```
   git clone <repository-url>
   cd scout-helpdesk-core
   ```

2. Create a `.env` file with your configuration:
   ```
   # Database configuration
   POSTGRES_USER=postgres
   POSTGRES_PASSWORD=your_secure_password
   POSTGRES_DB=scout_db
   POSTGRES_HOST=postgres
   POSTGRES_PORT=5432

   # OpenAI API configuration
   OPENAI_API_KEY=your_openai_api_key

   # Scout API configuration
   CONNECTWISE_API_BASE_URL=your_connectwise_api_base_url
   CONNECTWISE_CLIENT_ID=your_connectwise_client_id
   CONNECTWISE_API_PUBLIC_KEY=your_connectwise_api_public_key
   CONNECTWISE_API_PRIVATE_KEY=your_connectwise_api_private_key
   CONNECTWISE_COMPANY_ID=your_connectwise_company_id

   # App configuration
   COMPANY_IDENTIFIERS=company1,company2
   POLLING_INTERVAL_SECONDS=60
   PAGE_SIZE=25
   MAX_TICKETS=100
   SIMULTANEOUS_REQUESTS=5
   TSI_DICT_PATH=path/to/tsi_dict.json
   ```

3. Create the PostgreSQL setup directory:
   ```
   mkdir -p postgres_setup
   ```

4. Create the initialization script for PostgreSQL:
   ```
   touch postgres_setup/init.sql
   ```

## Running the Application

Start the application using Docker Compose:

```
docker-compose up -d
```

The main entrypoint is `app/run_poller.py`, which initializes the database client and starts the `TicketPoller`. The poller will:
- Monitor for new tickets at the configured interval
- For open tickets: classify, suggest solutions, and create skeleton DB entries
- For newly closed tickets: fully ingest ticket content into the database

## Development

To run the application in development mode (with logs in the foreground):

```
docker-compose up
```

Or, to run the poller directly (ensure your environment variables are set):

```
python -m app.run_poller
```

## Environment Variables

- `COMPANY_IDENTIFIERS`: Comma-separated list of company identifiers to monitor
- `POLLING_INTERVAL_SECONDS`: How often to poll for new tickets (default: 60)
- `PAGE_SIZE`, `MAX_TICKETS`, `SIMULTANEOUS_REQUESTS`: Control batching and concurrency
- `TSI_DICT_PATH`: Path to the TSI dictionary JSON file

## Bulk Ingestion of Historical Tickets

To ingest large batches of historical tickets (for example, when initializing the database with past data), use the script at `app/utils/ingest_tickets.py`.

### What it does
- Fetches all ticket IDs for specified companies after a given start date (or loads them from a file)
- Identifies which tickets have not yet been ingested into the database
- Ingests those tickets concurrently, saving their data and logging progress

### Configuration
- The companies to ingest are specified via the `COMPANY_IDENTIFIERS` environment variable (comma-separated)
- Adjust `--start-date` to control how far back to fetch tickets
- Set `--max-concurrent` to control how many tickets are ingested in parallel
- The script uses environment variables for database and API credentials (see setup above)

### Running the script
From the project root, run:

```
python -m app.utils.ingest_tickets --start-date 2023-01-01 --fetch
```

The script will:
- Fetch relevant ticket IDs from API or from disk (if already fetched)
- Ingest tickets that are not already in the database
- Save ticket data as JSON files (for debugging/auditing)
- Log a summary of successes and failures

You can limit the number of tickets ingested by uncommenting the relevant lines in the script.

#### Usage Example

Set the `COMPANY_IDENTIFIERS` environment variable (comma-separated) either in your .env file or at the command line,  then run the script with your desired options:

```bash
# Optionally set company identifiers at command line
export COMPANY_IDENTIFIERS="Elim,AACB,CrisisCentre"
python -m app.utils.ingest_tickets --start-date 2023-01-01 --max-concurrent 5 --data_folder ticket_data/new --fetch
```

**Arguments:**
- `--start-date YYYY-MM-DD` (required): The earliest ticket date to ingest.
- `--max-concurrent N` (optional): Maximum number of tickets to ingest in parallel (default: 10).
- `--data_folder PATH` (optional): Where to save ticket data and intermediate files (default: `ticket_data/all`).
- `--fetch` (optional): If present, fetch ticket IDs from the API; if omitted, load from file.

**Environment:**
- `COMPANY_IDENTIFIERS`: Comma-separated list of company identifiers to ingest.

**Examples:**

- Fetch and ingest tickets for 3 companies, starting from Jan 1, 2023, with 8 concurrent workers, saving data in a custom folder:
  ```bash
  export COMPANY_IDENTIFIERS="Elim,AACB,CrisisCentre"
  python -m app.utils.ingest_tickets --start-date 2023-01-01 --max-concurrent 8 --data_folder ticket_data/batch1 --fetch
  ```

- Ingest tickets using previously fetched ticket IDs (no API call), using defaults:
  ```bash
  export COMPANY_IDENTIFIERS="Elim,AACB"
  python -m app.utils.ingest_tickets --start-date 2022-01-01
  ```
```
## File: .dockerignore
```
# Version control
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
scout_helpdesk.egg-info/
*.egg-info/

# Data directories
ticket_data/
postgres_setup/
app/data/annotated_tickets/

# Environment
.env
.venv
env/
venv/
ENV/


# Docker
.dockerignore
docker-compose*.yml

# Logs
*.log
```
## File: .gitignore
```
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST




# UV
uv.lock


# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# ipython stuff
.DS_Store
.ipynb_checkpoints/

###########################

# data files
ticket_data/
app/data/annotated_tickets/

# postgres
postgres_setup/*/non_essential_data.dump*
```
## File: docker-compose.yml
```yaml
services:
  ticket-poller:
    build: 
      context: ./
      dockerfile: app/Dockerfile
    container_name: "ticket_poller"
    volumes:
      - ./app:/app/app
      - ./.env:/app/.env
      - ./app/data:/app/app/data
    environment:
      - MAX_WORKERS=4
    restart: unless-stopped
    env_file:
      - .env
    depends_on:
      - postgres
    

  postgres:
    build: 
      context: ./postgres_setup
    container_name: scout_postgres
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres_setup:/postgres_setup
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```
## File: analysis.ipynb
```markdown
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "import os\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = \"app/data/2025-02-01_2025-03-01\"\n",
    "# files = os.listdir(data_folder)\n",
    "# print(f\"{len(files)} ticket files loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_file(file_name, folder = data_folder):\n",
    "#     with open(os.path.join(folder, file_name), 'r') as f:\n",
    "#         return json.load(f)\n",
    "\n",
    "# data = load_file(files[1])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_flatten_json_files(folder=data_folder):\n",
    "#     \"\"\"\n",
    "#     Load all JSON files in the specified folder and flatten them into a DataFrame\n",
    "#     with no nested columns by prepending parent keys to child keys.\n",
    "    \n",
    "#     Args:\n",
    "#         folder (str): Path to the folder containing JSON files\n",
    "        \n",
    "#     Returns:\n",
    "#         pd.DataFrame: Flattened DataFrame with all data\n",
    "#     \"\"\"\n",
    "#     # Get all JSON files in the folder\n",
    "#     files = [f for f in os.listdir(folder) if f.endswith('.json')]\n",
    "    \n",
    "#     all_data = []\n",
    "    \n",
    "#     for file in files:\n",
    "#         with open(os.path.join(folder, file), 'r') as f:\n",
    "#             data = json.load(f)\n",
    "#         keys = list(data.keys())\n",
    "#         for key in keys:\n",
    "#             if data[key] is None:\n",
    "#                 del data[key]\n",
    "#         flattened_data = {\n",
    "#             \"ticket_id\": data[\"ticket_id\"],\n",
    "#             \"user_history\": data.get(\"user_history\", {}).get(\"overview\"),\n",
    "#             \"user_similar_tickets\": data.get(\"user_history\", {}).get(\"similar_tickets\"),\n",
    "#             \"query\": data.get(\"query\"),\n",
    "#             \"suggested_type\": data.get(\"predicted\", {}).get(\"type\"),\n",
    "#             \"suggested_subtype\": data.get(\"predicted\", {}).get(\"subtype\"),\n",
    "#             \"suggested_item\": data.get(\"predicted\", {}).get(\"item\"),\n",
    "#             \"suggested_solution\": data.get(\"predicted\", {}).get(\"suggested_solution\"),\n",
    "#             \"actual_type\": data.get(\"actual\", {}).get(\"type\"),\n",
    "#             \"actual_subtype\": data.get(\"actual\", {}).get(\"subtype\"),\n",
    "#             \"actual_item\": data.get(\"actual\", {}).get(\"item\"),\n",
    "#             \"actual_solution\": data.get(\"actual\", {}).get(\"solution\"),\n",
    "#             \"solution_score\": data.get(\"evaluation\", {}).get(\"helpfulness_score\"),\n",
    "#             \"solution_analysis\": data.get(\"evaluation\", {}).get(\"analysis\"),\n",
    "#         }\n",
    "        \n",
    "        \n",
    "        \n",
    "#         all_data.append(flattened_data)\n",
    "    \n",
    "#     # Convert the list of flattened dictionaries to DataFrame\n",
    "#     df = pd.DataFrame(all_data)\n",
    "#     for column in [\"suggested_type\",\"suggested_subtype\",\"suggested_item\"]:\n",
    "#         df[column] = df[column].replace(\"Unknown\", None)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df = load_and_flatten_json_files()\n",
    "# print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1270, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>user_history</th>\n",
       "      <th>user_similar_tickets</th>\n",
       "      <th>query</th>\n",
       "      <th>suggested_type</th>\n",
       "      <th>suggested_subtype</th>\n",
       "      <th>suggested_item</th>\n",
       "      <th>suggested_solution</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>actual_subtype</th>\n",
       "      <th>actual_item</th>\n",
       "      <th>actual_solution</th>\n",
       "      <th>solution_score</th>\n",
       "      <th>solution_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978178</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td># Worxhub Cache In History - Hoping There Is A...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>Update</td>\n",
       "      <td>Suggested steps: Implement a scheduled task or...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>The issue involved users experiencing problems...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>The suggested solution of implementing a sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978181</td>\n",
       "      <td>Sally Ali typically experiences issues related...</td>\n",
       "      <td>[791485, 718599, 631756, 626917]</td>\n",
       "      <td># Black screen</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>OS</td>\n",
       "      <td>Problem</td>\n",
       "      <td>Suggested steps: Attempt to restart the workst...</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The issue reported was a black screen on the u...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>The suggested solution provided a reasonable a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978183</td>\n",
       "      <td>Gabriel Mutch typically encounters issues rela...</td>\n",
       "      <td>[974891, 968771, 961682, 910891, 875428]</td>\n",
       "      <td># Update dsstaff@ Mailing List\\n\\n## On 2024-0...</td>\n",
       "      <td>User</td>\n",
       "      <td>Group Membership</td>\n",
       "      <td>None</td>\n",
       "      <td>Suggested steps: The IT team can update the ds...</td>\n",
       "      <td>Group</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The actual problem was a request to update the...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>The suggested solution effectively identifies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978201</td>\n",
       "      <td>Lynnelle Friesen typically experiences issues ...</td>\n",
       "      <td>[929129, 843615, 914729, 854533, 811986]</td>\n",
       "      <td># Check If This Is Legit - Scout Request For A...</td>\n",
       "      <td>Application</td>\n",
       "      <td>MS - Teams (No Voice)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Network</td>\n",
       "      <td>E-mail/Spam</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>The actual problem was a request from the Scou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannot evaluate due to missing solution data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978204</td>\n",
       "      <td>Judy Slutsky typically experiences issues rela...</td>\n",
       "      <td>[951475, 951473, 928456, 916379, 953596]</td>\n",
       "      <td># Regarding Urban Email</td>\n",
       "      <td>User</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Suggested steps: The IT team should review the...</td>\n",
       "      <td>Application</td>\n",
       "      <td>MS - Outlook</td>\n",
       "      <td>None</td>\n",
       "      <td>The actual problem was related to the Multi-Fa...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>The suggested solution emphasizes the need for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                       user_history  \\\n",
       "0     978178                                               None   \n",
       "1     978181  Sally Ali typically experiences issues related...   \n",
       "2     978183  Gabriel Mutch typically encounters issues rela...   \n",
       "3     978201  Lynnelle Friesen typically experiences issues ...   \n",
       "4     978204  Judy Slutsky typically experiences issues rela...   \n",
       "\n",
       "                       user_similar_tickets  \\\n",
       "0                                      None   \n",
       "1          [791485, 718599, 631756, 626917]   \n",
       "2  [974891, 968771, 961682, 910891, 875428]   \n",
       "3  [929129, 843615, 914729, 854533, 811986]   \n",
       "4  [951475, 951473, 928456, 916379, 953596]   \n",
       "\n",
       "                                               query suggested_type  \\\n",
       "0  # Worxhub Cache In History - Hoping There Is A...    Application   \n",
       "1                                     # Black screen    Workstation   \n",
       "2  # Update dsstaff@ Mailing List\\n\\n## On 2024-0...           User   \n",
       "3  # Check If This Is Legit - Scout Request For A...    Application   \n",
       "4                            # Regarding Urban Email           User   \n",
       "\n",
       "       suggested_subtype suggested_item  \\\n",
       "0                  Other         Update   \n",
       "1                     OS        Problem   \n",
       "2       Group Membership           None   \n",
       "3  MS - Teams (No Voice)           None   \n",
       "4                   None           None   \n",
       "\n",
       "                                  suggested_solution  actual_type  \\\n",
       "0  Suggested steps: Implement a scheduled task or...  Application   \n",
       "1  Suggested steps: Attempt to restart the workst...  Workstation   \n",
       "2  Suggested steps: The IT team can update the ds...        Group   \n",
       "3                                               None      Network   \n",
       "4  Suggested steps: The IT team should review the...  Application   \n",
       "\n",
       "  actual_subtype actual_item  \\\n",
       "0          Other        None   \n",
       "1           None        None   \n",
       "2           None        None   \n",
       "3    E-mail/Spam    Phishing   \n",
       "4   MS - Outlook        None   \n",
       "\n",
       "                                     actual_solution  solution_score  \\\n",
       "0  The issue involved users experiencing problems...            50.0   \n",
       "1  The issue reported was a black screen on the u...            61.0   \n",
       "2  The actual problem was a request to update the...            81.0   \n",
       "3  The actual problem was a request from the Scou...             NaN   \n",
       "4  The actual problem was related to the Multi-Fa...            41.0   \n",
       "\n",
       "                                   solution_analysis  \n",
       "0  The suggested solution of implementing a sched...  \n",
       "1  The suggested solution provided a reasonable a...  \n",
       "2  The suggested solution effectively identifies ...  \n",
       "3       Cannot evaluate due to missing solution data  \n",
       "4  The suggested solution emphasizes the need for...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_flatten_big_json_file(path):\n",
    "    \"\"\"\n",
    "    Load all JSON files in the specified folder and flatten them into a DataFrame\n",
    "    with no nested columns by prepending parent keys to child keys.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): Path to the folder containing JSON files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Flattened DataFrame with all data\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    flattened_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        \n",
    "        keys = list(item.keys())\n",
    "        for key in keys:\n",
    "            if item[key] is None:\n",
    "                del item[key]\n",
    "        flattened_item = {\n",
    "            \"ticket_id\": item[\"ticket_id\"],\n",
    "            \"user_history\": item.get(\"user_history\", {}).get(\"overview\"),\n",
    "            \"user_similar_tickets\": item.get(\"user_history\", {}).get(\"similar_tickets\"),\n",
    "            \"query\": item.get(\"query\"),\n",
    "            \"suggested_type\": item.get(\"predicted\", {}).get(\"type\"),\n",
    "            \"suggested_subtype\": item.get(\"predicted\", {}).get(\"subtype\"),\n",
    "            \"suggested_item\": item.get(\"predicted\", {}).get(\"item\"),\n",
    "            \"suggested_solution\": item.get(\"predicted\", {}).get(\"suggested_solution\"),\n",
    "            \"actual_type\": item.get(\"actual\", {}).get(\"type\"),\n",
    "            \"actual_subtype\": item.get(\"actual\", {}).get(\"subtype\"),\n",
    "            \"actual_item\": item.get(\"actual\", {}).get(\"item\"),\n",
    "            \"actual_solution\": item.get(\"actual\", {}).get(\"solution\"),\n",
    "            \"solution_score\": item.get(\"evaluation\", {}).get(\"helpfulness_score\"),\n",
    "            \"solution_analysis\": item.get(\"evaluation\", {}).get(\"analysis\"),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        flattened_data.append(flattened_item)\n",
    "    \n",
    "    # Convert the list of flattened dictionaries to DataFrame\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "    for column in [\"suggested_type\",\"suggested_subtype\",\"suggested_item\"]:\n",
    "        df[column] = df[column].replace(\"Unknown\", None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "path = \"app/data/all_results_feb2025.json\"\n",
    "df = load_and_flatten_big_json_file(path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ticket_data/experiment_old.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = pio.templates[\"seaborn\"].layout.colorway\n",
    "PLOT_WIDTH=700\n",
    "PLOT_HEIGHT=500\n",
    "TEMPLATE=\"seaborn\"\n",
    "\n",
    "style_settings = {\n",
    "    \"width\": PLOT_HEIGHT, \n",
    "    \"height\": PLOT_HEIGHT, \n",
    "    \"template\": TEMPLATE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSI prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Actual Null Count</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Suggested Null Count</th>\n",
       "      <th>Suggested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtype</td>\n",
       "      <td>252</td>\n",
       "      <td>19.8</td>\n",
       "      <td>133</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item</td>\n",
       "      <td>1029</td>\n",
       "      <td>81.0</td>\n",
       "      <td>369</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Field  Actual Null Count  Actual  Suggested Null Count  Suggested\n",
       "0     type                  0     0.0                     0        0.0\n",
       "1  subtype                252    19.8                   133       10.5\n",
       "2     item               1029    81.0                   369       29.1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame showing null counts and fractions for type, subtype, and item\n",
    "comparison_data = []\n",
    "total_rows = len(df)\n",
    "\n",
    "for field in ['type', 'subtype', 'item']:\n",
    "    suggested_field = f'suggested_{field}'\n",
    "    actual_field = f'actual_{field}'\n",
    "    \n",
    "    suggested_null_count = df[suggested_field].isna().sum()\n",
    "    actual_null_count = df[actual_field].isna().sum()\n",
    "    \n",
    "    suggested_null_fraction = suggested_null_count / total_rows *100\n",
    "    actual_null_fraction = actual_null_count / total_rows*100\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Field': field,\n",
    "        'Actual Null Count': actual_null_count,\n",
    "        'Actual': actual_null_fraction,\n",
    "        'Suggested Null Count': suggested_null_count,\n",
    "        'Suggested': suggested_null_fraction,\n",
    "        \n",
    "    })\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data).round(1)\n",
    "comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Category=Suggested<br>Classification=%{x}<br>Null Percentage (%)=%{y}<extra></extra>",
         "legendgroup": "Suggested",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Suggested",
         "offsetgroup": "Suggested",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "type",
          "subtype",
          "item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAlQJqZmZmZGT1A",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Category=Actual<br>Classification=%{x}<br>Null Percentage (%)=%{y}<extra></extra>",
         "legendgroup": "Actual",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual",
         "offsetgroup": "Actual",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "type",
          "subtype",
          "item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAAADNzMzMzMwzQAAAAAAAQFRA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 500,
        "legend": {
         "title": {
          "text": ""
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Null TSI Classifications"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Classification"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          89.10000000000001
         ],
         "title": {
          "text": "Null Percentage (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the data for plotting\n",
    "plot_data = pd.melt(\n",
    "    comparison_df, \n",
    "    id_vars=['Field'],\n",
    "    value_vars=['Suggested', 'Actual'],\n",
    "    var_name='Category',\n",
    "    value_name='Null Percentage'\n",
    ")\n",
    "\n",
    "# Create the bar chart with the correct data structure\n",
    "fig = px.bar(\n",
    "    plot_data,\n",
    "    x='Field',\n",
    "    y='Null Percentage',\n",
    "    color='Category',\n",
    "    barmode='group',\n",
    "    title='Null TSI Classifications',\n",
    "    labels={'Field': 'Classification', 'Null Percentage': 'Null Percentage (%)'},\n",
    "    color_discrete_map={\n",
    "        'Suggested': COLORS[1],  # orange\n",
    "        'Actual': COLORS[0]      # blue\n",
    "    },\n",
    "    text_auto='.0f',\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text='',\n",
    "    yaxis_range=[0, max(plot_data['Null Percentage'])*1.1]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "=%{x}<br>Count=%{y}<extra></extra>",
         "legendgroup": "Actual valid type",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid type",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid type"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "9gQ=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "=%{x}<br>Count=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "7QI=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Type suggestion accuracy: 59%",
          "x": 0.5,
          "y": 1333.5
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": ""
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Type Suggestions"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid type",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual valid type</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matching suggestions</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value\n",
       "0     Actual valid type   1270\n",
       "1  Matching suggestions    749"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the match data for types\n",
    "valid_actual_type = df[df['actual_type'].notna()]\n",
    "matches = (valid_actual_type['suggested_type'] == valid_actual_type['actual_type']).sum()\n",
    "total_valid = len(valid_actual_type)\n",
    "match_percentage = (matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results - keep all values as their original types\n",
    "type_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid type', 'Matching suggestions'],\n",
    "    'Value': [total_valid, matches]\n",
    "})\n",
    "\n",
    "\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    type_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Type Suggestions',\n",
    "    labels={'Metric': '', 'Value': 'Count'},\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid type': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Type suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(type_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtype Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Actual valid subtype",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid subtype",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid subtype"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "mQI=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "6gE=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Subtype suggestion accuracy: 74%",
          "x": 0.5,
          "y": 698.25
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Subtype Suggestions (matching <b><i>type</i></b>)"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid subtype",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'].notna())]\n",
    "\n",
    "# Count subtype matches\n",
    "subtype_matches = (valid_rows['suggested_subtype'] == valid_rows['actual_subtype']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (subtype_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "subtype_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid subtype', 'Matching suggestions'],\n",
    "    'Value': [total_valid, subtype_matches]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "subtype_df.round()\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    subtype_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Subtype Suggestions (matching <b><i>type</i></b>)',\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid subtype': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    template=TEMPLATE,\n",
    "    width=PLOT_WIDTH,\n",
    "    height=PLOT_HEIGHT\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Subtype suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(subtype_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a promising, but limited result since so many tickets do not have subtypes defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valid rows (types match &amp; actual_item not null)</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item matches (suggested = actual)</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item match percentage (%)</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Metric  Value\n",
       "0  Valid rows (types match & actual_item not null)  137.0\n",
       "1                Item matches (suggested = actual)  104.0\n",
       "2                        Item match percentage (%)   76.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to rows where:\n",
    "# 1. actual_type is not null\n",
    "# 2. suggested_type matches actual_type\n",
    "# 3. actual_item is not null\n",
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'] == df['suggested_subtype']) &\n",
    "                (df['actual_item'].notna())]\n",
    "\n",
    "# Count item matches\n",
    "item_matches = (valid_rows['suggested_item'] == valid_rows['actual_item']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (item_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "item_match_df = pd.DataFrame({\n",
    "    'Metric': ['Valid rows (types match & actual_item not null)', \n",
    "               'Item matches (suggested = actual)', \n",
    "               'Item match percentage (%)'],\n",
    "    'Value': [total_valid, item_matches, match_percentage]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "item_match_df.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Actual valid item",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid item",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "iQA=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "aA==",
          "dtype": "i1"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Item suggestion accuracy: 76%",
          "x": 0.5,
          "y": 143.85
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Item Suggestions (matching <b><i>type/subtype</i></b>)"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid item",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual valid item</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matching suggestions</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value\n",
       "0     Actual valid item    137\n",
       "1  Matching suggestions    104"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'] == df['suggested_subtype']) &\n",
    "                (df['actual_item'].notna())]\n",
    "\n",
    "# Count subtype matches\n",
    "item_matches = (valid_rows['suggested_item'] == valid_rows['actual_item']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (item_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "subtype_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid item', 'Matching suggestions'],\n",
    "    'Value': [total_valid, item_matches]\n",
    "})\n",
    "\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    subtype_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Item Suggestions (matching <b><i>type/subtype</i></b>)',\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid item': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    template=TEMPLATE,\n",
    "    width=PLOT_WIDTH,\n",
    "    height=PLOT_HEIGHT\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Item suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(subtype_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "subtype_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Solutions\n",
    "\n",
    "These were rated by an LLM, comparing the suggested solution with the one that was implemented.\n",
    "\n",
    "Note that often the suggested solution is based on minimal information, and that the actual solution involves interactions with the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>user_history</th>\n",
       "      <th>user_similar_tickets</th>\n",
       "      <th>query</th>\n",
       "      <th>suggested_type</th>\n",
       "      <th>suggested_subtype</th>\n",
       "      <th>suggested_item</th>\n",
       "      <th>suggested_solution</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>actual_subtype</th>\n",
       "      <th>actual_item</th>\n",
       "      <th>actual_solution</th>\n",
       "      <th>solution_score</th>\n",
       "      <th>solution_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978178</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td># Worxhub Cache In History - Hoping There Is A...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>Update</td>\n",
       "      <td>Suggested steps: Implement a scheduled task or...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>The issue involved users experiencing problems...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>The suggested solution of implementing a sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978181</td>\n",
       "      <td>Sally Ali typically experiences issues related...</td>\n",
       "      <td>[791485, 718599, 631756, 626917]</td>\n",
       "      <td># Black screen</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>OS</td>\n",
       "      <td>Problem</td>\n",
       "      <td>Suggested steps: Attempt to restart the workst...</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The issue reported was a black screen on the u...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>The suggested solution provided a reasonable a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                       user_history  \\\n",
       "0     978178                                               None   \n",
       "1     978181  Sally Ali typically experiences issues related...   \n",
       "\n",
       "               user_similar_tickets  \\\n",
       "0                              None   \n",
       "1  [791485, 718599, 631756, 626917]   \n",
       "\n",
       "                                               query suggested_type  \\\n",
       "0  # Worxhub Cache In History - Hoping There Is A...    Application   \n",
       "1                                     # Black screen    Workstation   \n",
       "\n",
       "  suggested_subtype suggested_item  \\\n",
       "0             Other         Update   \n",
       "1                OS        Problem   \n",
       "\n",
       "                                  suggested_solution  actual_type  \\\n",
       "0  Suggested steps: Implement a scheduled task or...  Application   \n",
       "1  Suggested steps: Attempt to restart the workst...  Workstation   \n",
       "\n",
       "  actual_subtype actual_item  \\\n",
       "0          Other        None   \n",
       "1           None        None   \n",
       "\n",
       "                                     actual_solution  solution_score  \\\n",
       "0  The issue involved users experiencing problems...            50.0   \n",
       "1  The issue reported was a black screen on the u...            61.0   \n",
       "\n",
       "                                   solution_analysis  \n",
       "0  The suggested solution of implementing a sched...  \n",
       "1  The suggested solution provided a reasonable a...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticket_id', 'user_history', 'user_similar_tickets', 'query',\n",
       "       'suggested_type', 'suggested_subtype', 'suggested_item',\n",
       "       'suggested_solution', 'actual_type', 'actual_subtype', 'actual_item',\n",
       "       'actual_solution', 'solution_score', 'solution_analysis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_suggested_solutions:       1180\n",
      "n_tickets:                   1270\n",
      "percent_suggested_solutions: 93\n"
     ]
    }
   ],
   "source": [
    "n_suggested_solutions = df[\"solution_score\"].notnull().sum()\n",
    "n_tickets = df.shape[0]\n",
    "percent_suggested_solutions = n_suggested_solutions/n_tickets * 100\n",
    "percent_suggested_solutions\n",
    "print(f\"n_suggested_solutions:       {n_suggested_solutions}\")\n",
    "print(f\"n_tickets:                   {n_tickets}\")\n",
    "print(f\"percent_suggested_solutions: {percent_suggested_solutions:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean solution score: 55\n",
      "Median solution score: 61\n"
     ]
    }
   ],
   "source": [
    "mean_solution_score =  df[\"solution_score\"].mean()\n",
    "print(f\"Mean solution score: {mean_solution_score:.0f}\")\n",
    "\n",
    "median_solution_score =  df[\"solution_score\"].median()\n",
    "print(f\"Median solution score: {median_solution_score:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "variable=solution_score<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "solution_score",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "solution_score",
         "nbinsx": 10,
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "xbins": {
          "end": 100,
          "size": 10,
          "start": 0
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Mean: 55",
          "x": 54.93050847457627,
          "xanchor": "left",
          "y": 1.05,
          "yref": "paper"
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dash",
           "width": 2
          },
          "type": "line",
          "x0": 54.93050847457627,
          "x1": 54.93050847457627,
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Distribution of Suggested Solution Helpfulness Scores"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Score"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = px.histogram(\n",
    "    df[\"solution_score\"],\n",
    "    title=\"Distribution of Suggested Solution Helpfulness Scores\",\n",
    "    color_discrete_sequence=[COLORS[1]],\n",
    "    nbins=10,\n",
    "    **style_settings\n",
    ")\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"Score\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "# Add vertical line for median with improved visibility\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=mean_solution_score,\n",
    "    y0=0,\n",
    "    x1=mean_solution_score,\n",
    "    y1=1,  # This will be automatically scaled to the y-axis\n",
    "    yref=\"paper\",  # Makes y1=1 refer to 100% of the y-axis height\n",
    "    line=dict(\n",
    "        color=\"black\",\n",
    "        width=2,\n",
    "        dash=\"dash\",\n",
    "    )\n",
    ")\n",
    "# Update the bin configuration\n",
    "fig.update_traces(xbins=dict(\n",
    "    start=0,  # Start at 0\n",
    "    end=100,  # End at 100\n",
    "    size=10   # Bin width of 10\n",
    "))\n",
    "\n",
    "# Add annotation\n",
    "fig.add_annotation(\n",
    "    x=mean_solution_score,\n",
    "    y=1.05,\n",
    "    yref=\"paper\",\n",
    "    text=f\"Mean: {mean_solution_score:.0f}\",\n",
    "    showarrow=False,\n",
    "    xanchor=\"left\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tickets with suggested_helpfulness >= 60: 61.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Type</th>\n",
       "      <th>Percentage ≥ 60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suggested Solution</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score Type  Percentage ≥ 60\n",
       "0  Suggested Solution             61.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For suggested_helpfulness\n",
    "suggested_high_scores = df[df['solution_score'] >= 60].shape[0]\n",
    "total_with_suggested_scores = df['solution_score'].notnull().sum()\n",
    "suggested_high_percentage = (suggested_high_scores / total_with_suggested_scores * 100) if total_with_suggested_scores > 0 else 0\n",
    "\n",
    "\n",
    "print(f\"Percentage of tickets with suggested_helpfulness >= 60: {suggested_high_percentage:.1f}%\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary_df = pd.DataFrame({\n",
    "    'Score Type': ['Suggested Solution'],\n",
    "    'Percentage ≥ 60': [suggested_high_percentage]\n",
    "})\n",
    "\n",
    "summary_df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No solutions\n",
    "what caused there to be no solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 queries with null helpfulness scores\n",
      "\n",
      "Examples:\n",
      "\n",
      "----------------------------------------------------\n",
      "# Check If This Is Legit - Scout Request For Access\n",
      "\n",
      "## On 2024-09-03T19:08:32Z, Lynnelle Friesen wrote a note (2253084):\n",
      "Hello Scout team,\n",
      "\n",
      "Is this request legit?\n",
      "Thanks\n",
      "Lynnelle\n",
      "\n",
      "[Image: A Microsoft Teams notification email. The subject reads: \"A request has been made to join a private team that you own.\" The email is from Microsoft Teams <noreply@email.teams.microsoft.com> to Lynnelle Friesen. The main content states: \"Scout Admin has requested to join 'Home Care Charting'.\" It shows a logo with \"HC\" and the text \"Home Care Charting\" below it. The team has 28 members and is marked as Private. The team name is \"Garrison Crossing Home Care Charting.\" There are buttons to \"Accept or Deny request.\" The footer includes Microsoft Corporation's address and a privacy policy link.]\n",
      "\n",
      "![\\[image\\]](cid:PGVQsFowH0ifhu06n4TFqwEV_Garrison-Crossing_logo_RGB_signature_png)**Lynnelle Friesen**\n",
      "Site Director\n",
      "Garrison Crossing Admin Office\n",
      "45418 Chehalis Drive Chilliwack, BC V2R 6E3\n",
      "**T:** 604.426.0438 **F:** 604.582.5503\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:GjluG0NszEyx8TvoedU7JA9_CWImageFacebook_gif)]([URL removed]) [![\\[image\\]](cid:7A21npSr70Oh3LAr9M5GtA9_CWImageLinkedin_gif)]([URL removed]) [![\\[image\\]](cid:oiaPkpm7dki1luIhLCcF6w9_CWImageInstagram_gif)]([URL removed])\n",
      "\n",
      "----------------------------------------------------\n",
      "# Remove Email Account\n",
      "\n",
      "## On 2024-09-03T21:48:43Z, Daniel Gu wrote a note (2253170):\n",
      "Hi Support,\n",
      "\n",
      "Can AcitveCO's email account be removed right now?\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "**From:** Nicole Laffin <nlaffin@protecdental.com>\n",
      "**Sent:** Tuesday, September 3, 2024 12:26 PM\n",
      "**To:** Scout Admin <scouttg@protecdental.com>\n",
      "**Cc:** Daniel Gu <dgu@protecdental.com>\n",
      "**Subject:** Fw: Not junk:192fc962-5380-44c7-b29e-08dcc96b33c5|info@orthodonticsvictoria.net|\\(Declan Leitch \\(Twinblock Refit\\)\\) 9/3/2024 7:25:32 PM\n",
      "\n",
      "Thank you, \n",
      "***Nicole Laffin,*** \n",
      "\n",
      "*Office Team Supervisor,*\n",
      "Orthodontics Department\n",
      "**PROTEC DENTAL LABORATORIES**\n",
      "38 East 1st Avenue\n",
      "Vancouver, British Columbia\n",
      "Canada, V5T 1A1\n",
      "Tel:  604.873.8000\\(115\\) \n",
      "Toll-Free: 800-663-5488\n",
      "\n",
      "Web: [protecdental.com](URL removed)\n",
      "\n",
      "![\\[image\\]](https://ci4.googleusercontent.com/proxy/RJQ5TKwRINjgtT9q-tIKM3F3zPQ76M4vkN9J5RB9UiPvyF5Alnox0PjQ2rtOnV1tOjWXokyMyUxMsOf424_zMwEycCJkooqdq0bBefhiupuduPqavlRsjHqLZA=s0-d-e1-ft#http://www.protecdental.com/sites/default/files/proteclogosgnaturead.jpg)\n",
      "__NOTICE OF CONFIDENTIALITY__: This material is intended for the use of the individual to whom it is addressed and may contain information that is privileged, proprietary, confidential and exempt from disclosure. If you are not the intended recipient or the person responsible for delivering the material to the intended recipient, you are notified that dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately via e-mail and destroy this message accordingly.\n",
      "\n",
      "**From:** Microsoft Outlook <MicrosoftExchange329e71ec88ae4615bbc36ab6ce41109e@protecdental.com>\n",
      "**Sent:** Tuesday, September 3, 2024 12:25 PM\n",
      "**To:** Office 365 Submissions <activeco@protecdental.com>\n",
      "**Subject:** Undeliverable: Not junk:192fc962-5380-44c7-b29e-08dcc96b33c5|info@orthodonticsvictoria.net|\\(Declan Leitch \\(Twinblock Refit\\)\\) 9/3/2024 7:25:32 PM\n",
      "\n",
      "![\\[image\\]](https://products.office.com/en-us/CMSImages/Office365Logo_Orange.png?version=b8d100a9-0a8b-8e6a-88e1-ef488fee0470)\n",
      "Your message to activeco@protecdental.com couldn't be delivered.\n",
      "activeco wasn't found atprotecdental.com.\n",
      "nlaffin\n",
      "Office 365\n",
      "activeco\n",
      "**Action Required**\n",
      "Recipient\n",
      "\n",
      "Unknown To address\n",
      "\n",
      "How to Fix It\n",
      "The address may be misspelled or may not exist. Try one or more of the following:\n",
      "* Send the message again following these steps: In Outlook, open this non-delivery report \\(NDR\\) and choose**Send Again** from the Report ribbon. In Outlook on the web, select this NDR, then select the link \"**To send this message again, click here.**\" Then delete and retype the entire recipient address. If prompted with an Auto-Complete List suggestion don't select it. After typing the complete address, click **Send**.\n",
      "* Contact the recipient \\(by phone, for example\\) to check that the address exists and is correct.\n",
      "* The recipient may have set up email forwarding to an incorrect address. Ask them to check that any forwarding they've set up is working correctly.\n",
      "* Clear the recipient Auto-Complete List in Outlook or Outlook on the web by following the steps in this article:[Fix email delivery issues for error code 5.1.10 in Office 365](URL removed), and then send the message again. Retype the entire recipient address before selecting**Send**.\n",
      "If the problem continues, forward this message to your email admin. If you're an email admin, refer to the**More Info for Email Admins** section below.\n",
      "\n",
      "*Was this helpful? [Send feedback to Microsoft](URL removed).*\n",
      "\n",
      "More Info for Email Admins\n",
      "*Status code: 550 5.1.10*\n",
      "This error occurs because the sender sent a message to an email address hosted by Office 365 but the address is incorrect or doesn't exist at the destination domain. The error is reported by the recipient domain's email server, but most often it must be fixed by the person who sent the message. If the steps in the **How to Fix It** section above don't fix the problem, and you're the email admin for the recipient, try one or more of the following:\n",
      "**The email address exists and is correct** - Confirm that the recipient address exists, is correct, and is accepting messages.\n",
      "**Synchronize your directories** - If you have a hybrid environment and are using directory synchronization make sure the recipient's email address is synced correctly in both Office 365 and in your on-premises directory.\n",
      "**Errant forwarding rule** - Check for forwarding rules that aren't behaving as expected. Forwarding can be set up by an admin via mail flow rules or mailbox forwarding address settings, or by the recipient via the Inbox Rules feature.\n",
      "**Recipient has a valid license** - Make sure the recipient has an Office 365 license assigned to them. The recipient's email admin can use the Office 365 admin center to assign a license \\(Users > Active Users > select the recipient > Assigned License > Edit\\).\n",
      "**Mail flow settings and MX records are not correct** - Misconfigured mail flow or MX record settings can cause this error. Check your Office 365 mail flow settings to make sure your domain and any mail flow connectors are set up correctly. Also, work with your domain registrar to make sure the MX records for your domain are configured correctly.\n",
      "For more information and additional tips to fix this issue, see [Fix email delivery issues for error code 5.1.10 in Office 365](URL removed).\n",
      "Original Message Details\n",
      "Created Date:\n",
      "9/3/2024 7:25:32 PM\n",
      "Sender Address:\n",
      "nlaffin@protecdental.com\n",
      "Recipient Address:\n",
      "activeco@protecdental.com\n",
      "Subject:\n",
      "\n",
      "Not junk:192fc962-5380-44c7-b29e-08dcc96b33c5|info@orthodonticsvictoria.net|\\(Declan Leitch \\(Twinblock Refit\\)\\) 9/3/2024 7:25:32 PM\n",
      "\n",
      "Error Details\n",
      "Error:\n",
      "*550 5.1.10 RESOLVER.ADR.RecipientNotFound; Recipient activeco@protecdental.com not found by SMTP address lookup*\n",
      "Message rejected by:\n",
      "YQBPR01MB10737.CANPRD01.PROD.OUTLOOK.COM\n",
      "\n",
      "Notification Details\n",
      "Sent by:\n",
      "*YQBPR01MB10737.CANPRD01.PROD.OUTLOOK.COM*\n",
      "\n",
      "Message Hops\n",
      "HOP\n",
      "TIME \\(UTC\\)\n",
      "FROM\n",
      "TO\n",
      "WITH\n",
      "RELAY TIME\n",
      "1\n",
      "9/3/2024\n",
      "7:25:32 PM\n",
      "YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM\n",
      "YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM\n",
      "mapi\n",
      "\\*\n",
      "2\n",
      "9/3/2024\n",
      "7:25:32 PM\n",
      "YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM\n",
      "YQBPR01MB10737.CANPRD01.PROD.OUTLOOK.COM\n",
      "Microsoft SMTP Server \\(version=TLS1\\_2, cipher=TLS\\_ECDHE\\_RSA\\_WITH\\_AES\\_256\\_GCM\\_SHA384\\)\n",
      "\\*\n",
      "\n",
      "Original Message Headers\n",
      "```\n",
      "Authentication-Results: dkim=none (message not signed)\n",
      "\n",
      "header.d=none;dmarc=none action=none header.from=protecdental.com;\n",
      "Received: from YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM (2603:10b6:b01:17::10)\n",
      "\n",
      "by YQBPR01MB10737.CANPRD01.PROD.OUTLOOK.COM (2603:10b6:c01:73::17) with\n",
      "\n",
      "Microsoft SMTP Server (version=TLS1_2,\n",
      "\n",
      "cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7918.25; Tue, 3 Sep\n",
      "\n",
      "2024 19:25:32 +0000\n",
      "Received: from YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM\n",
      "\n",
      "([fe80::fea0:b1d0:4d4a:3376]) by YTBPR01MB3533.CANPRD01.PROD.OUTLOOK.COM\n",
      "\n",
      "([fe80::fea0:b1d0:4d4a:3376%6]) with mapi id 15.20.7918.024; Tue, 3 Sep 2024\n",
      "\n",
      "19:25:32 +0000\n",
      "Content-Type: application/ms-tnef; name=\"winmail.dat\"\n",
      "Content-Transfer-Encoding: binary\n",
      "From: Nicole Laffin <nlaffin@protecdental.com>\n",
      "To: Office 365 Submissions <activeco@protecdental.com>\n",
      "Subject: Not\n",
      "\n",
      "junk:192fc962-5380-44c7-b29e-08dcc96b33c5|info@orthodonticsvictoria.net|(Declan\n",
      "\n",
      "Leitch (Twinblock Refit)) 9/3/2024 7:25:32 PM\n",
      "Thread-Topic: Not\n",
      "\n",
      "junk:192fc962-5380-44c7-b29e-08dcc96b33c5|info@orthodonticsvictoria.net|(Declan\n",
      "\n",
      "Leitch (Twinblock Refit)) 9/3/2024 7:25:32 PM\n",
      "Thread-Index: AQHa/jcLPEADvH3hiEa0mqGzTrvTlw==\n",
      "Date: Tue, 3 Sep 2024 19:25:32 +0000\n",
      "Message-ID: <JMR.192fc962-5380-44c7-b29e-08dcc96b33c5.NotJunk.638609883324982281@microsoft.com>\n",
      "Accept-Language: en-US\n",
      "Content-Language: en-US\n",
      "X-MS-Has-Attach: yes\n",
      "X-MS-TNEF-Correlator: <JMR.192fc962-5380-44c7-b29e-08dcc96b33c5.NotJunk.638609883324982281@microsoft.com>\n",
      "x-ms-exchange-antispam-submitterorganizationid: a31b1070-5d35-4a5d-bbf9-7061ec1b0d10\n",
      "x-ms-exchange-antispam-submitteremail: nlaffin@protecdental.com\n",
      "x-ms-exchange-antispam-submissionids: d34e31ec-60cf-4941-448c-08dccc4e2d63\n",
      "x-ms-exchange-antispam-submitterid: 4681981a-2624-4002-b1f1-f91390c90a46\n",
      "x-ms-exchange-antispam-duplicatemailtocustommailbox: true\n",
      "MIME-Version: 1.0\n",
      "X-MS-PublicTrafficType: Email\n",
      "X-MS-TrafficTypeDiagnostic: YTBPR01MB3533:EE_|YQBPR01MB10737:EE_\n",
      "Return-Path: nlaffin@protecdental.com\n",
      "X-MS-Office365-Filtering-Correlation-Id: 1b73a1aa-f19b-493a-9218-08dccc4e2db0\n",
      "\n",
      "```\n",
      "\n",
      "----------------------------------------------------\n",
      "# Can't log into security cameras\n",
      "\n",
      "----------------------------------------------------\n",
      "# Somehow My Files In The R Drive In The Folder YVR- How Do I Fix Them Back?\n",
      "\n",
      "## On 2024-09-16T15:50:50Z, Cindy Ferrie wrote a note (2260961):\n",
      "Hi\n",
      "Somehow my files in the R drive in the  folder YVR Rfp 3550 Recycling and Waste Management folder:\n",
      "\n",
      "For review by Nicole\n",
      "Changed to thumbnails\n",
      "How do I fix them back so I can see dates?**Cindy Ferrie**\n",
      "Marketing Consultant\n",
      "**C** [604.561.5480 ](tel:604.561.5480)\n",
      "**E** [Cindy.Ferrie@urbanimpact.com](mailto:Cindy.Ferrie@urbanimpact.com)\n",
      "![\\[image\\]](cid:Udpi0kGNEKYZnlasFvgUrbanImpact_BeverageContainerRefundProgram_v09_jpg)\n",
      "\n",
      "## On 2024-09-16T16:30:42Z, Cindy Ferrie Cindy.Ferrie@urbanimpact.com wrote a note (2261006):\n",
      "please cancel ticket- was able to fix \n",
      "\n",
      "**Cindy Ferrie**\n",
      "Marketing Consultant\n",
      "**C** [604.561.5480 ](tel:604.561.5480)\n",
      "**E** [Cindy.Ferrie@urbanimpact.com](mailto:Cindy.Ferrie@urbanimpact.com)\n",
      "![\\[image\\]](cid:Udpi0kGNEKYZnlasFvgUrbanImpact_BeverageContainerRefundProgram_v09_jpg)\n",
      "\n",
      "On Sep 16, 2024, at 8:54 AM, Scout Help Desk <Scout.Help.Desk@scouttg.com> wrote:\n",
      "\n",
      "----------------------------------------------------\n",
      "# Nurse phone screen not working\n",
      "\n",
      "----------------------------------------------------\n",
      "# List of Staff Who Are Allowed to View and Make Changes on the R Drive\n",
      "\n",
      "## On 2024-09-19T16:24:07Z, Nicole Stefenelli wrote a note (2263551):\n",
      "Can I please get a summary of staff who are allowed to view and make changes on the R Drive please.\n",
      "**Nicole Stefenelli**\n",
      "Founder / CEO\n",
      "**C** [604.834.1468 ](tel:604.834.1468)\n",
      "**E** [Nicole.Stefenelli@urbanimpact.com](mailto:Nicole.Stefenelli@urbanimpact.com)\n",
      "Did you know you can manage your account online? [**Log in**](URL removed) to our online portal to pay bills, schedule pick up and much more!  Need help with the portal? Follow this **[easy how-to-guide](URL removed).**\n",
      "\n",
      "## On 2024-09-19T20:54:00Z, Alberto Rincon wrote a time_entry (984910):\n",
      "Hello Nicole\n",
      "\n",
      "Here is the user list that has permission to the R Drive\n",
      "[Image: Advanced Security Settings for RFPs\n",
      "\n",
      "Name: D:\\RFPs\n",
      "Owner: Administrators (RECYCLING\\Administrators) Change\n",
      "\n",
      "Permissions | Share | Auditing | Effective Access\n",
      "\n",
      "For additional information, double-click a permission entry. To modify a permission entry, select the entry and click Edit (if available).\n",
      "\n",
      "Permission entries:\n",
      "\n",
      "Type | Principal | Access | Inherited from | Applies to\n",
      "Allow | CREATOR OWNER | Full control | None | Subfolders and files only\n",
      "Allow | SYSTEM | Full control | None | This folder, subfolders and files\n",
      "Allow | Grp-Sec-RFPs (RECYCLING\\Gr... | Full control | None | This folder, subfolders and files\n",
      "Allow | Domain Admins (RECYCLING\\... | Full control | None | This folder, subfolders and files\n",
      "Allow | Louise Roxby (Louise.Roxby@... | Modify | None | This folder, subfolders and files\n",
      "Allow | Scout Admin (ScoutTG@urban... | Full control | None | This folder, subfolders and files\n",
      "\n",
      "[Add] [Remove] [View] [Edit]\n",
      "\n",
      "Enable inheritance\n",
      "\n",
      "Replace all child object permission entries with inheritable permission entries from this object\n",
      "\n",
      "[OK] [Cancel] [Apply] ]\n",
      "\n",
      "The group that is in the list\n",
      "[Image: Grp-Sec-RFPs Properties\n",
      "\n",
      "General | Members | Member Of | Managed By | Object | Security\n",
      "\n",
      "Members:\n",
      "\n",
      "Name | Active Directory Domain Services Folder\n",
      "Cindy Ferrie | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Jeff Ward | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Jesse Sist | recycling.local/UrbanImpact/Disabled Users\n",
      "Louise Roxby | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Melissa Ward | recycling.local/UrbanImpact/Users/MobileStaff\n",
      "Mitch Brown | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Nicole Stefenelli | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Rebecca M... | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "Rod Nicolas | recycling.local/UrbanImpact/Users/Azure_ADSy...\n",
      "\n",
      "[Add] [Remove]]\n",
      "\n",
      "Please let me know if you have any questions\n",
      "\n",
      "Thank you\n",
      "\n",
      "**ALBERTO RINCON**\n",
      "Systems Administrator\n",
      "604\\.424\\.4398 - Direct\n",
      "========================\n",
      "\n",
      "----------------------------------------------------\n",
      "# Issues Loggin into Accounts\n",
      "\n",
      "----------------------------------------------------\n",
      "# FW: New Voicemail from 16045615480 - Kris:Cindy Ferrie\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unable To Get Back Of The Server\n",
      "\n",
      "## On 2024-09-23T16:17:47Z, Kurtis Johnson wrote a note (2266195):\n",
      "-----Original Message-----\n",
      "From: Scout Do Not Reply <do_not_reply@scouttg.com> \n",
      "Sent: Monday, September 23, 2024 09:11\n",
      "To: Kurtis Johnson <Kurtis@scouttg.com>\n",
      "Subject: New Voicemail from 16045615480 - Kurtis:Cindy Ferrie\n",
      "\n",
      "You have received a new voice mail from \"16045615480 - Kurtis:Cindy Ferrie\"\n",
      "\n",
      "From: 16045615480 \n",
      "To: \"1009\" - \"Kurtis\" \"Johnson\"\n",
      "Received:\"Monday, September 23, 2024 9:10:18 AM\"\n",
      "Duration:\"00:00:21\"\t\n",
      "File:\"vmail_16045615480_1009_20240923161018\"\n",
      "\n",
      "Transcription:\n",
      "Hey Curtis, Cindy Ferry calling. Hey I had issues with.\n",
      "\n",
      "Crashing out of the bonfire thing and then not being able to get back in on the server on Saturday. Luckily. I was able to use Nicole's computer. But anyway, maybe we can get to the bottom of this. Thanks 604 5615480. Thanks.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unifi Access - Will Not Display Anything\n",
      "\n",
      "## On 2024-09-24T17:41:09Z, Daniel Gu wrote a note (2266984):\n",
      "Hi Scout,\n",
      "\n",
      "My login to the Unifi dashboard will not display anything. Do you know what happened? \n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unable to Connect to Page\n",
      "\n",
      "----------------------------------------------------\n",
      "# Teams Showing Incorrect Times\n",
      "\n",
      "## On 2024-10-04T23:37:10Z, Elaine McBride wrote a note (2276329):\n",
      "Hi there, two issues.  See screens below.\n",
      "\n",
      "1. Cannot contact Scout.\n",
      "\n",
      "<img_place_holder_1>\n",
      "\n",
      "1. Why Teams Meeting invites are showing incorrect times… this is not the first time and Nicole S recommended that I reach out to you for help.\n",
      "\n",
      "<img_place_holder_2>\n",
      "**Elaine McBride**\n",
      "Safety Coordinator\n",
      "\n",
      "[ ](tel:)\n",
      "**E** [elaine.McBride@urbanimpact.com](mailto:elaine.McBride@urbanimpact.com)\n",
      "Did you know you can manage your account online? [**Log in**](URL removed) to our online portal to pay bills, schedule pick up and much more!  Need help with the portal? Follow this **[easy how-to-guide](URL removed).**\n",
      "\n",
      "----------------------------------------------------\n",
      "# Chubb Director assistance\n",
      "\n",
      "----------------------------------------------------\n",
      "# Re: Project - USD functional currency - Dashboard\n",
      "\n",
      "## On 2024-10-08T15:21:39Z, alexander@golikov.onmicrosoft.com wrote a note (2278646):\n",
      "Hi Carmena,\n",
      "\n",
      "I just reached out to Scout to iron out a few things, but I'm hoping to have access today. Once access is granted, I'll get familiar with the environment and reach out if there are any questions.\n",
      "\n",
      "Thank you,\n",
      "Alex.\n",
      "\n",
      "**From:**Carmena Gee <CGee@excellbattery.com>\n",
      "**Date:** Monday, October 7, 2024 at 2:19PM\n",
      "**To:** Alexander Golikov <alexander@golikov.onmicrosoft.com>\n",
      "**Cc:** Mike Neil <mike@arbutusadvisors.com>, 'Casey Callaghan' <casey@umbrellaconsulting.ca>, Scout Help Desk <Scout.Help.Desk@scouttg.com>\n",
      "**Subject:** RE: Project - USD functional currency - Dashboard\n",
      "\n",
      "[Hi Alex](http://)\n",
      "Were you able to get access to our system from Scout?\n",
      "Casey, our Umbrella consultant will have the new company C  - updated tonight and  I will start testing this week\n",
      "I have copied Casey in case you have any technical questions…\n",
      "\n",
      "Best regards\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Alexander Golikov <alexander@golikov.onmicrosoft.com>\n",
      "**Sent:** Friday, August 23, 2024 7:08 AM\n",
      "**To:** Carmena Gee <CGee@excellbattery.com>\n",
      "**Subject:** Re: Project - USD functional currency\n",
      "\n",
      "Absolutely, I'll update the meeting now.\n",
      "\n",
      "**From:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Sent:** Friday, August 23, 2024 10:06:26 AM\n",
      "**To:** Alexander Golikov <[alexander@golikov.onmicrosoft.com](mailto:alexander@golikov.onmicrosoft.com)>\n",
      "**Subject:** RE: Project - USD functional currency\n",
      "\n",
      "Could we start at 9:15 instead?\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Alexander Golikov <[alexander@golikov.onmicrosoft.com](mailto:alexander@golikov.onmicrosoft.com)>\n",
      "**Sent:** Friday, August 23, 2024 6:21 AM\n",
      "**To:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>; Mike Neil <[mike@arbutusadvisors.com](mailto:mike@arbutusadvisors.com)>\n",
      "**Subject:** Re: Project - USD functional currency\n",
      "\n",
      "Hi Carmena,\n",
      "\n",
      "Pleasure to meet you. I just sent an invite for a kick-off meeting this Monday at 9am PST. Let me know if another time works better.\n",
      "\n",
      "Thank you,\n",
      "Alex.\n",
      "\n",
      "**From:**Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Date:** Thursday, August 22, 2024 at 8:12PM\n",
      "**To:** Mike Neil <[mike@arbutusadvisors.com](mailto:mike@arbutusadvisors.com)>, Alexander Golikov <[alexander@golikov.onmicrosoft.com](mailto:alexander@golikov.onmicrosoft.com)>\n",
      "**Subject:** RE: Project - USD functional currency\n",
      "\n",
      "Hi Alex\n",
      "I am available  7-3  PST daily..\n",
      "\n",
      "Best regards\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Mike Neil <[mike@arbutusadvisors.com](mailto:mike@arbutusadvisors.com)>\n",
      "**Sent:** Thursday, August 22, 2024 9:07 AM\n",
      "**To:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>; Alexander Golikov <[alexander@golikov.onmicrosoft.com](mailto:alexander@golikov.onmicrosoft.com)>\n",
      "**Cc:** Mike Neil <[mike@arbutusadvisors.com](mailto:mike@arbutusadvisors.com)>\n",
      "**Subject:** FW: Project - USD functional currency\n",
      "\n",
      "Hi Carmena,\n",
      "\n",
      "Looping Alex into this conversation….can't recall if I officially made the intro previously.\n",
      "\n",
      "Carmena – Alex will take the lead on this project\n",
      "\n",
      "Alex – please meet Carmena and vice versa.  Can you please establish a kick off meeting for this project?\n",
      "\n",
      "Thanks  and looking forward to doing our part on this.\n",
      "\n",
      "Regards,\n",
      "Mike\n",
      "\n",
      "**From:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Sent:** Monday, August 19, 2024 9:14 AM\n",
      "**To:** Mike Neil <[mike@arbutusadvisors.com](mailto:mike@arbutusadvisors.com)>\n",
      "**Subject:** FW: Project - USD functional currency\n",
      "\n",
      "[Hi Mike](http://)\n",
      "Casey is proceeding with changing Canada to USD functional currency.\n",
      "Attached is his timeline.\n",
      "He will be setting up a new company C – directly from currently Company X   that will be in USD and we will test before we go live Jan 1\n",
      "Can we set up a quick meeting to brainstorm on the dashboards and how they can  be adjusted?\n",
      "\n",
      "Hope you are having a great summer…\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Casey Callaghan <[casey@umbrellaconsulting.ca](mailto:casey@umbrellaconsulting.ca)>\n",
      "**Sent:** Monday, August 19, 2024 8:46 AM\n",
      "**To:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Subject:** RE: Project\n",
      "\n",
      "Hi Carmena:\n",
      "Attached is the project plan we had gone through in our call last week – apologies for not sending sooner. Aiming to get first round of company C in place by end of this month if still okay with you in terms of timing.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "**Casey Callaghan**| Senior Consultant\n",
      "604.910.4696|[**Umbrella Consulting**](URL removed)\n",
      "\n",
      "**From:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Sent:** Friday, August 16, 2024 11:16 AM\n",
      "**To:** Casey Callaghan <[casey@umbrellaconsulting.ca](mailto:casey@umbrellaconsulting.ca)>\n",
      "**Subject:** Project\n",
      "\n",
      "Hi Casey\n",
      "Please forward the preliminary timeline when available\n",
      "I have approved the quote on the Auto Fx currency program\n",
      "I don't know if this will impact anything but remember you put a plug on my fx so it would only convert one way…\n",
      "\n",
      "Thanks\n",
      "\n",
      "Carmena\n",
      "\n",
      "----------------------------------------------------\n",
      "# Update for Alder\n",
      "\n",
      "## On 2024-10-08T21:25:39Z, Neda Shadbakht wrote a note (2278857):\n",
      "Hi Alder - just spoke with Shanon and just wanted to let you know, the topic about the calendar visibility can be on pause for now and we don't need to go through with making the changes just yet, they just wanted to know what was possible. You can definitely go ahead and make those department groupings you mentioned but I think they're still deciding if they want to make organizational wide calendar changes fully yet.\n",
      "Thanks!\n",
      "\n",
      "Neda\n",
      "\n",
      "Neda Shadbakht\n",
      "Coordinator, Strategic Partnerships\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "\n",
      "E:[nshadbakht@crisiscentre.bc.ca](mailto:nshadbakht@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/86b492a3-8b6d-4519-a6f2-e1e4f0a11046 \"Facebook\")](URL removed)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/4dcbcbb8-9896-4a11-9c67-3aa6adf0a91b \"Twitter\")](URL removed)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/33ff4394-d5de-4074-95bd-398f3ebfd018 \"LinkedIn\")](URL removed)\n",
      "\n",
      "[Instagram icon](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f42597c1-ae2e-46e1-ae66-0588523c8e86 \"https://crisiscentre.bc.ca\")](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Another phone issue - 334\n",
      "\n",
      "## On 2024-10-09T19:15:51Z, Tamara Guyon wrote a note (2281473):\n",
      "Hello everyone,  I tried calling the business line and 334 extension and got first, the hold \"music\" but it was news and should not be, then it routed to the voice mail box of the greater vancouver distress line and seniors line voice mail automated message which is not correct either.  I think 334 is not a proper staff extension number  - from my recollection, staff extensions all started with the number 2, not 3.  So, two issues - one is the hold music \\(I think there's a radio in the phone equipment room upstairs that is set to the station it should be on but I'm sorry, a past DS Director dealt with that and I'm not sure\\). Maybe Alain knows?  and two is Melissa's extension - I don't think it should be 334 - Scout, can you help? I don't know how to help Melissa with this fix if she's followed the instructions on the post we have re: set up  [http://my.crisiscentre.local/askb/avaya-voicemail-see-below/](URL removed)\n",
      "Also, I don't know if her having the phone that was in the accounting office is the right phone for her to have as I think it had all of the phone lines on it as it was my old phone and had everything - do we have any other phones in the office that are not crackly? that could also be a part of the problem, I'm not sure - see if that helps too having a different phone that is not my old one?  \n",
      "Tamara Guyon\n",
      "Manager, Administration\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "T:[604-872-1811 x221](tel:604-872-1811%20x221)\n",
      "E:[tguyon@crisiscentre.bc.ca](mailto:tguyon@crisiscentre.bc.ca)\n",
      "\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/dd66dfca-ad17-4d5d-883b-9c54d6839c73 \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429046811%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=8iQvlG%2BfCfHL2l%2Fln3Cjdcnfc5zTF8b53pAP%2F%2FjPaCk%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/6b0d789a-3570-440a-aa73-5a26721ab19c \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429064811%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=kBBxaT7%2FMflA7znuFX249NdqpWd37uyTSOxbi2tCJJg%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/9fdf8374-19db-49c0-923d-57d454c8007b \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429086060%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=aHFvJ7M4GT7RN2VTMGal4s1GMHGQMURbDqib3WPcyT4%3D&amp;reserved=0)\n",
      "[Instagram icon](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/9ee3a787-5ac9-476c-8c1a-0fc64f4b24fe \"https://crisiscentre.bc.ca\")]([URL removed]%2F&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429119888%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=JL4Vew%2BVznLTH5P2pbsJ%2BFbr2iN7WznF1AFwfhI6MI8%3D&amp;reserved=0)\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: **Melissa Van Dyk** <[melissa.vandyk@crisiscentre.bc.ca](mailto:melissa.vandyk@crisiscentre.bc.ca)>\n",
      "Date: Tue, Oct 8, 2024 at 5:31 PM\n",
      "Subject: Another phone issue\n",
      "To: Samantha Fogel <[admin@crisiscentre.bc.ca](mailto:admin@crisiscentre.bc.ca)>\n",
      "\n",
      "Hi Samantha,\n",
      "\n",
      "I need your help again with the phone - please!  \n",
      "\n",
      "1. I don't know how to change the settings so that my phone audibly rings when a call is coming in. A green light starts flashing \\(in that \"do not use\" section\\) but there is no noise.\n",
      "\n",
      "2. If I dial the number 604.872.1811 and then type my extension 334 and don't pick up, it goes to an odd voicemail box that is not mine. \\(And I have set up my voicemail with my name and a personal message.\\) \n",
      "\n",
      "3. Also - is our hold \"music\" a radio station?\n",
      "\n",
      "Thanks!\n",
      "\n",
      "Melissa\n",
      "\n",
      "--\n",
      "\n",
      "Melissa Van Dyk \\(She/Her\\)Director, Program Operations\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "T:604-872-1811 x334\n",
      "E:[melissa.vandyk@crisiscentre.bc.ca](mailto:melissa.vandyk@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]]( \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429160281%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=rSBaggnhCbWonoUHUoUJ3V24821Q%2Fpn4LhUg5KfE240%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]]( \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429179726%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=RPY0ljTAlhst8CuBQHt%2BM9pEnCce2IEC%2BgGzSGRWxaw%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]]( \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429200315%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=IemTQgzH9aK9GXjAQB9CNpOGtF5x3yLPG%2BxqS5kva28%3D&amp;reserved=0)\n",
      "[![\\[image\\]]()]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429222855%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=nZSde7%2B%2BxtV%2FRJtbYmHaBriyYOSz2ML0jx6N8ueQ7rY%3D&amp;reserved=0)\n",
      "\n",
      "[![\\[https://crisiscentre.bc.ca\\]]( \"https://crisiscentre.bc.ca\")]([URL removed]%2F&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429243548%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=Ow8qNBJwbgTHZ0vYmTpmGFiEJf2gOCQ%2FSVze5XbkhAc%3D&amp;reserved=0)\n",
      "\n",
      "Melissa Van Dyk\n",
      "Director, Program Operations\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "\n",
      "E:[melissa.vandyk@crisiscentre.bc.ca](mailto:melissa.vandyk@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/a8291a67-effb-49e4-8559-2930d73cbe82 \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429275650%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=3a99geuKXz%2BRg8%2BWNBPVa2N4URoOaYx1CfSL0uppLcI%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/6e26922f-9af3-43ef-87fd-fb67a799e962 \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429291286%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=TanF%2BTb8BndTNIqV98j1Q94tY82AsKLArxuSJLGpfgg%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/d78e953e-9cd8-4dcb-a057-22c18d296ce3 \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429305674%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=T1NgFed%2F%2FYWqz%2B4nlTwGhvx%2Fi5FTaflAe30yQ0jU2Vs%3D&amp;reserved=0)\n",
      "[Instagram icon](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/da736d42-3843-4909-b795-08769f77a87b \"https://crisiscentre.bc.ca\")]([URL removed]%2F&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce26cea5a1a3b4f4bd8fa08dce896c2fb%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638640981429336395%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=UDihrdrvP72%2Fem5wc7LmMTVv97oHRRHkmKp2RjIfJpk%3D&amp;reserved=0)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Deletion Of Shadow Copy On 22-093L Expected?\n",
      "\n",
      "## On 2024-10-11T16:29:41Z, Darren Truong wrote a note (2283256):\n",
      "Hello,\n",
      "\n",
      "We have observed the deletion of a shadow copy on the host \"22-093L\". Attackers will frequently delete shadow copies prior to the deployment of ransomware to prevent recovery.\n",
      "\n",
      "Date/Time: 2024-10-11 15:33:20 UTC\n",
      "User: NT AUTHORITY\\SYSTEM\n",
      "Host: 22-093L\n",
      "\n",
      "Process tree: ScreenConnect.WindowsBackstageShell.exe > PowerShell.exe > vssadmin.exe\n",
      "\n",
      "Processes:\n",
      "C:\\Program Files \\(x86\\)\\ScreenConnect Client \\(8c9d71f3290a6fc1\\)\\ScreenConnect.WindowsBackstageShell.exe\n",
      "\"C:\\WINDOWS\\system32\\windowspowershell\\v1.0\\PowerShell.exe\"\n",
      "\"C:\\WINDOWS\\system32\\vssadmin.exe\" list shadows\n",
      "\"C:\\WINDOWS\\system32\\vssadmin.exe\" Resize ShadowStorage /For=C: /On=C: /MaxSize=300MB\n",
      "\"C:\\WINDOWS\\system32\\vssadmin.exe\" Resize ShadowStorage /For=C: /On=C: /MaxSize=2%\n",
      "\"C:\\WINDOWS\\system32\\vssadmin.exe\" delete shadows /For=C: /all /quiet\n",
      "\n",
      "Upon review, we can see PowerShell spawning through a ScreenConnect session, followed by various commands attempting to list shadow copies, resize the storage limits, and remove existing copies on \"C:/\".\n",
      "\n",
      "This is likely benign administrative activity to free up disk space as previously seen in INC#3141319. An attacker would typically wipe all shadow copies instead of adjusting limits.\n",
      "\n",
      "Whilst no other suspicious activity was found in the surrounding logs, we would like to confirm whether this was authorized.\n",
      "Remediation Advice\n",
      "\n",
      "Please confirm if the deletion of shadow copies on this host was expected/authorized.\n",
      "\n",
      "Thanks,\n",
      "Darren Truong | Information Technology | Ultralife Corporation | Office 315-359-6211 | [darren.truong@ulbi.com](mailto:darren.truong@ulbi.com) | [ultralifecorp.com](URL removed)\n",
      "\n",
      "This message contains confidential information and is intended only for the individual\\(s\\) addressed in the message. If you are not the named addressee, you should not disseminate, distribute, or copy this e-mail. If you are not the intended recipient, you are notified that disclosing, distributing, or copying this e-mail is strictly prohibited.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Meeting Reminder - Unable To Remove\n",
      "\n",
      "## On 2024-10-15T20:23:12Z, Lynn Juillet wrote a note (2284489):\n",
      "Hello,\n",
      "\n",
      "I am unable to get rid of this meeting reminder.\n",
      "\n",
      "Is there something you can do from you end?\n",
      "\n",
      "Thank you,\n",
      "Lynn\n",
      "\n",
      "[Image: A screenshot of a Microsoft Teams Meeting reminder window. The reminder is for an \"Exit Interview\" scheduled at 1:30 PM on Friday, June 28, 2024. The reminder indicates that the meeting is 15 weeks overdue. There are options to \"Dismiss\" or \"Snooze\" the reminder, with a dropdown to select snooze duration, currently set to 5 minutes.]\n",
      "\n",
      "![\\[image\\]](cid:S54egtvES1SWeWPT64QEV_logo_RGB_signature_png)**Lynn Juillet,**  CPHR\n",
      "Director of Human Resources\n",
      "Elim Village Administration\n",
      "9067 160 Street Surrey, BC V4N 2X7\n",
      "**T:** 604.583.3546 ext. 4029 **F:** 604.587.8998\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:Q5gjIDvlkuPbG4eoMmXwQ988_CWImageFacebook_gif)]([URL removed]) [![\\[image\\]](cid:7E5sR4KBHEunMB052uu3Vw988_CWImageLinkedin_gif)]([URL removed]) [![\\[image\\]](cid:VcGuAbsrdEqrb6W3OW6ZXQ988_CWImageInstagram_gif)]([URL removed])\n",
      "\n",
      "----------------------------------------------------\n",
      "# Login Issues - Existing Ticket for Kurt Munari\n",
      "\n",
      "## On 2024-10-15T22:44:50Z, Thomas Maloney wrote a note (2284569):\n",
      "Howdy y'all,\n",
      "\n",
      "Just wanted to check in and see about the progress for the ticket \\(likely logged by Zack Macdonald\\) about his remote login woes.\n",
      "\n",
      "If there's any chance I could get an update or be kept in the loop about the progress of it, that would be much appreciated - I'm not party to any more details of the issue so I can't provide additional details, but did want to see if it can be expedited.\n",
      "\n",
      "Thanks very much,\n",
      "\n",
      "Thomas Maloney\n",
      "Operations Manager, Distress Services\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "\n",
      "E:[tmaloney@crisiscentre.bc.ca](mailto:tmaloney@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/13baebbf-0a41-43a7-9c3c-ad558c9cfbb0 \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Cdba1189d45404164d25308dced6af290%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638646290803094755%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=nyFb2Ii5tVtahby%2BJQo01ivFEWW0dt1KS4VLyIY%2Bdj4%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/3a15f2f1-2603-4019-9bec-b4abccc6be2c \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Cdba1189d45404164d25308dced6af290%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638646290803113314%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=jdgimsk0GRtS2aFCGFobelO1nnbXWQrJZ%2BZnpgZA7Fg%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/377d7fd9-da3b-46a4-bdcf-ed2a9fde576b \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Cdba1189d45404164d25308dced6af290%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638646290803127906%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=2nktuGIvmzZcCIkDDbM8ASkOpEXB%2FDyFbzJ1rOeIqYo%3D&amp;reserved=0)\n",
      "[Instagram icon](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/417bda44-af76-484c-8128-11034a474faa \"https://crisiscentre.bc.ca\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Cdba1189d45404164d25308dced6af290%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638646290803155728%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=84LwKfiOli0RqKor84LrvgGsSCcyi2ug3mHtxDgpHfU%3D&amp;reserved=0)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Payment Approvals Not Coming into Process Street\n",
      "\n",
      "----------------------------------------------------\n",
      "# Station 2 Keeps Restarting And Dropping Calls So No One Is Able To Use It\n",
      "\n",
      "## On 2024-10-16T17:22:39Z, Claudia Winterton wrote a note (2285397):\n",
      "#### How many people is this affecting?\n",
      "* Group of users\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What time are you working till?\n",
      "6pm\n",
      "\n",
      "#### Preferred method of contact\n",
      "priority line\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Station 2 keeps restarting and dropping calls\n",
      "\n",
      "## On 2024-10-16T17:22:39Z, Claudia Winterton wrote a note (2285398):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: Cwinterton\n",
      "- machine name: DELL3060-19-01\n",
      "    - host name: DELL3060-19-01\n",
      "    - address: fe80::71e6:133d:db27:75b6%11; 192.168.1.79\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16048722444 - Crisis Centre Priority Line\n",
      "\n",
      "## On 2024-10-19T05:56:19Z, Scout Voicemail wrote a note (2286692):\n",
      "You have received a new voice mail from \"16048722444 - Crisis Centre Priority Line\"\n",
      "\n",
      "From: 16048722444 \n",
      "To: \"9798\" - \"Emergency\" \"VM\"\n",
      "Received:\"Friday, October 18, 2024 10:54:34 PM\"\n",
      "Duration:\"00:01:00\"\t\n",
      "File:\"vmail_16048722444_9798_20241019055434\"\n",
      "\n",
      "Transcription:\n",
      "Hi. I'm calling from the BC, crisis center. I'm calling about. I made an after-hours ticket and they closed my\n",
      "\n",
      "ticket without helping, or fixing the whole issue that I was looking for. I'm looking for a port source, which I got, but I need a port destination Source IP and destination IP for a chat that happened. Just because we are calling intervention for this person which was a while ago and the police still need more information to be able to locate and find the person.\n",
      "\n",
      "Who is killing themself. So I would love if you guys can give me a call back. My number you can call is six zero four.\n",
      "\n",
      "Eight. Seven, two.\n",
      "\n",
      "Two, four, four, that 604.\n",
      "\n",
      "87224 or 4. Thank you.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unable to Authenticate on Computer\n",
      "\n",
      "----------------------------------------------------\n",
      "# Lab Web Service Not Working\n",
      "\n",
      "----------------------------------------------------\n",
      "# Block the email from AMM fastmarket\n",
      "\n",
      "## On 2024-10-21T17:58:01Z, Jin Ma wrote a note (2287471):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* Yes, This Has Happened Before\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "I need to reset the password for AMM Fastmarket and they sent me the link, but it seems that Scout blocked the email. By the time, I received the feedback and release the email, the link to reset the password got expired already.\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Phone\n",
      "\n",
      "#### What is the best number to reach you at?\n",
      "604-788-7598\n",
      "\n",
      "## On 2024-10-21T17:58:01Z, Jin Ma wrote a note (2287472):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Program Files\\DeskDirector\\DeskDirector Portal\n",
      "- user name: jin.ma\n",
      "- machine name: 23-152L\n",
      "    - host name: 23-152L\n",
      "    - address: fe80::e8bf:fe13:fd81:cad5%3; 10.48.2.57\n",
      "\n",
      "----------------------------------------------------\n",
      "# Ronnie Deol - Home Directory not Mapped After Reboot\n",
      "\n",
      "## On 2024-10-21T18:59:55Z, Michael McQuigge wrote a note (2287500):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* Yes, This Has Happened Before\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Hello Support,\n",
      "Ronnie has rebooted Win-PC-056 and her home directories (Desktop) are no longer mapping correctly and appear empty. \n",
      "\n",
      "Thank you,\n",
      "Michael\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Email\n",
      "\n",
      "## On 2024-10-21T19:17:28Z, Michael McQuigge wrote a note (2287515):\n",
      "Issue remedied itself according to user.\n",
      "\n",
      "----------\n",
      "Ticket was closed by Michael McQuigge(mmcquigge@aacb.com)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Need Assistance to Connect to Projector\n",
      "\n",
      "----------------------------------------------------\n",
      "# Net Extender Error message\n",
      "\n",
      "## On 2024-10-25T22:20:22Z, Melissa Van Dyk wrote a note (2289600):\n",
      "Hello,\n",
      "\n",
      "The past few times I have tried to work remotely I've received an error message from Net Extender that doesn't allow me to connect.  The first few times I remotely this wasn't an issue. I'm wondering what I need to do to resolve this. I've included the screenshot below.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Melissa\n",
      "\n",
      "[Image: The image shows a NetExtender error message window with the SonicWALL logo. The error message reads: \"Error: Service is not responding!\" There is a \"Close\" button at the bottom right of the message box.]\n",
      "\n",
      "--\n",
      "\n",
      "Melissa Van Dyk \\(She/Her\\)\n",
      "Director, Program Operations\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "T:604-872-1811 x334\n",
      "E:[melissa.vandyk@crisiscentre.bc.ca](mailto:melissa.vandyk@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage830410.png@09BA6F6B.33B6C150 \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139823581%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=wkK2bTpklyOn11g%2FzgYGiVEveJVnQ%2B02IIOg0zzb10g%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage122410.png@8BB67F13.5094A936 \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139838295%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=vyGoqGCj4X1%2ByVkxq88nYftTqSV40PlQGUnkvflhUIY%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage417983.png@FA3D58B4.AF4A7301 \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139852697%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=IAC3c9XWmSDiU3WtgzyD68cy4KHy2PNGa64tLsVHri8%3D&amp;reserved=0)\n",
      "[![\\[image\\]]([URL removed]\n",
      "\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage621900.png@5AA92B5F.EBE8B43E \"https://crisiscentre.bc.ca\")](URL removed)\n",
      "\n",
      "Melissa Van Dyk\n",
      "Director, Program Operations\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "\n",
      "E:[melissa.vandyk@crisiscentre.bc.ca](mailto:melissa.vandyk@crisiscentre.bc.ca)\n",
      "W: [www.crisiscentre.bc.ca](URL removed)\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage609306.png@24DFE7E7.3BD1F62E \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139908888%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=TjbqXx%2FOPVGGvFJzF3psnoNVS%2FvWyqA4ChzXX0wL%2Fo4%3D&amp;reserved=0)\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage590319.png@449AF7B2.84D7F045 \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139922970%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=5ukPu9s4QXmXanneGzb7IXENgsPBziQJgqtSfLHEAPU%3D&amp;reserved=0)\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage500810.png@01E3B058.AE612CC2 \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7C1e35edd5e917485a32b508dcf5432d79%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638654916139937108%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=kLnBoYt%2B7DWzKx1EXxYIaHFOx%2FPViQTO0NpbY4lXlQY%3D&amp;reserved=0)\n",
      "[![\\[image\\]]([URL removed]\n",
      "\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/f71bc2a8-0ea6-460b-9c99-fd8fbecaedfcimage872524.png@A0E07D5B.6EEC27C4 \"https://crisiscentre.bc.ca\")](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 14168945575 - MONICA FERNEYHO\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 13604414316 - Washington\n",
      "\n",
      "----------------------------------------------------\n",
      "# Enrique Serpa | Create TAP to Access Email for Apple Account Recovery\n",
      "\n",
      "## On 2024-11-03T16:59:41Z, Enrique Serpa wrote a note (2295560):\n",
      "#### Afterhours Emergency Support\n",
      "Please note our office is open from Monday - Friday 7:30AM - 5:00PM Pacific time Excluding Statutory Holidays.\n",
      "If you are unable to work and it is outside these hours or during a holiday, please submit this ticket. \n",
      "**Please do not use this during regular business hours**\n",
      "\n",
      "This will immediately trigger emergency escalation to our after hours on-call team. \n",
      "If this is during late night hours, they will be woken up.\n",
      "\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "now\n",
      "\n",
      "#### What is the best phone number to reach you at?\n",
      "6049619175\n",
      "\n",
      "## On 2024-11-03T16:59:42Z, Enrique Serpa wrote a note (2295561):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Program Files\\DeskDirector\\DeskDirector Portal\n",
      "- user name: Enrique.Serpa\n",
      "- machine name: 23-153L\n",
      "    - host name: 23-153L\n",
      "    - address: fe80::2daf:24d1:9393:5cac%3; 2001:569:702f:bd00:f480:53ef:f769:299a; 2001:569:702f:bd00:bad1:5eb3:2086:8e98; 192.168.1.75\n",
      "\n",
      "----------------------------------------------------\n",
      "# Power Outage at Surrey Office\n",
      "\n",
      "## On 2024-11-04T16:32:29Z, Carmena Gee wrote a note (2295862):\n",
      "Get [Outlook for iOS](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Problems When Joined Into Domain\n",
      "\n",
      "## On 2024-11-04T19:05:38Z, Daniel Gu wrote a note (2296038):\n",
      "Hi Scout,\n",
      "\n",
      "I noticed an issue when a new laptop was trying to join the domain. It was failed when join through the WIFI \\(Fishbowl\\). But, when I connected laptop with a network cable, it worked.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "## On 2024-11-04T19:08:51Z, Daniel Gu dgu@protecdental.com wrote a note (2296041):\n",
      "Sorry, I forgot to mention the problem was found in Ontario St. office.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "## On 2024-11-04T19:55:07Z, Daniel Gu dgu@protecdental.com wrote a note (2296104):\n",
      "Sorry, I found the problem. It was connected to Guest WIFI. But, the new laptop was only filled the password with Fishbowl WIFI before. When I opened the WIFI properties, it has all 3 company WIFI profiles. Might imported from Microsoft account in the cloud.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "----------------------------------------------------\n",
      "# Reports Are No Longer Arriving Daily – Not since 10/2 - auto.reports@COLEINTL.COM\n",
      "\n",
      "## On 2024-11-06T16:08:15Z, Carmena Gee wrote a note (2297680):\n",
      "I have not received any cole reports since October 2 - I will also check with IT to ensure they are not blocking.\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Dorothy Ferreira-Colliss <Dorothy.Ferreira-Colliss@coleintl.com>\n",
      "**Sent:** Friday, October 25, 2024 11:00 AM\n",
      "**To:** Carmena Gee <CGee@excellbattery.com>\n",
      "**Subject:** RE: Daily reports from auto.reports@COLEINTL.COM\n",
      "\n",
      "Strange.  I will check.\n",
      "\n",
      "Did you receive your SOA today ?\n",
      "\n",
      "**Dorothy Ferreira-Colliss** CCS\n",
      "Account Management\n",
      "Vancouver Branch\n",
      "[Cole International logo]\n",
      "220, 3820 Cessna Drive, Richmond, British Columbia  |  V7B 0A2  |  Canada\n",
      "604-998-1756     604-240-3712[![\\[Social - Email signature (400x100 px).png\\]](cid:social-emailsignature(400x100px)_5d6920cc-b7f1-4d06-9f22-55362a1c7ec7.png)](URL removed)\n",
      "[Dorothy.Ferreira-Colliss@coleintl.com](mailto:%7BE-mail%7D)  |  [coleintl.com](URL removed)\n",
      "[Image: Importers start PAYING CBSA directly October 31st. CONFIRM YOUR CCP ACCOUNT BALANCE.](URL removed)\n",
      "\n",
      "Get [CARM ready](URL removed)     [Online Portal](URL removed)     [Incoterms Calculator](URL removed)               [Stay Connected](URL removed)\n",
      "\n",
      "Business undertaken subject to: [Cole International Inc. / Cole International USA Inc. Terms and Conditions.](URL removed)\n",
      "\n",
      "**From:** Carmena Gee <CGee@excellbattery.com>\n",
      "**Sent:** October 24, 2024 9:50 AM\n",
      "**To:** Dorothy Ferreira-Colliss <Dorothy.Ferreira-Colliss@coleintl.com>\n",
      "**Subject:** Daily reports from auto.reports@COLEINTL.COM\n",
      "\n",
      "[Hi Dorothy](http://)\n",
      "These reports are no longer are arriving daily – Not since  10/2   can you have someone check and  get them emailed again especially the CBSA Importer statements..\n",
      "\n",
      "Thanks\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "----------------------------------------------------\n",
      "# RE: Daily reports from auto.reports@COLEINTL.COM\n",
      "\n",
      "## On 2024-11-06T16:28:37Z, Dorothy.Ferreira-Colliss@coleintl.com wrote a note (2297692):\n",
      "Hi Carmena\n",
      "\n",
      "I will check on my end as well.\n",
      "\n",
      "**Dorothy Ferreira-Colliss** CCS\n",
      "Account Management\n",
      "Vancouver Branch\n",
      "[Cole International logo]\n",
      "220, 3820 Cessna Drive, Richmond, British Columbia  |  V7B 0A2  |  Canada\n",
      "604-998-1756     604-240-3712[![\\[Social - Email signature (400x100 px).png\\]](cid:social-emailsignature(400x100px)_5d6920cc-b7f1-4d06-9f22-55362a1c7ec7.png)](URL removed)\n",
      "[Dorothy.Ferreira-Colliss@coleintl.com](mailto:%7BE-mail%7D)  |  [coleintl.com](URL removed)\n",
      "[Image: Importers start PAYING CBSA directly October 31st. CONFIRM YOUR CCP ACCOUNT BALANCE](URL removed)\n",
      "\n",
      "Get [CARM ready](URL removed)     [Online Portal](URL removed)     [Incoterms Calculator](URL removed)               [Stay Connected](URL removed)\n",
      "\n",
      "Business undertaken subject to: [Cole International Inc. / Cole International USA Inc. Terms and Conditions.](URL removed)\n",
      "\n",
      "**From:** Carmena Gee <CGee@excellbattery.com>\n",
      "**Sent:** November 6, 2024 8:07 AM\n",
      "**To:** Dorothy Ferreira-Colliss <Dorothy.Ferreira-Colliss@coleintl.com>\n",
      "**Cc:** Scout Help Desk <Scout.Help.Desk@scouttg.com>\n",
      "**Subject:** Re: Daily reports from auto.reports@COLEINTL.COM\n",
      "\n",
      "I have not received any cole reports since October 2 - I will also check with IT to ensure they are not blocking.\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "**From:** Dorothy Ferreira-Colliss <[Dorothy.Ferreira-Colliss@coleintl.com](mailto:Dorothy.Ferreira-Colliss@coleintl.com)>\n",
      "**Sent:** Friday, October 25, 2024 11:00 AM\n",
      "**To:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Subject:** RE: Daily reports from [auto.reports@COLEINTL.COM](mailto:auto.reports@COLEINTL.COM)\n",
      "\n",
      "Strange.  I will check.\n",
      "\n",
      "Did you receive your SOA today ?\n",
      "\n",
      "**Dorothy Ferreira-Colliss** CCS\n",
      "Account Management\n",
      "**Vancouver Branch**\n",
      "[Cole International logo]\n",
      "220, 3820 Cessna Drive, Richmond, British Columbia  |  V7B 0A2  |  Canada\n",
      "604-998-1756     604-240-3712\n",
      "[Social media icons](URL removed)\n",
      "[Dorothy.Ferreira-Colliss@coleintl.com](mailto:%7BE-mail%7D)  |  [coleintl.com](URL removed)\n",
      "[Image: Importers start PAYING CBSA directly October 31st. CONFIRM YOUR CCP ACCOUNT BALANCE](URL removed)\n",
      "\n",
      "Get [CARM ready](URL removed)\n",
      "[Online Portal](URL removed)\n",
      "[Incoterms Calculator](URL removed)\n",
      "[Stay Connected](URL removed)\n",
      "Business undertaken subject to: [Cole International Inc. / Cole International USA Inc. Terms and Conditions.](URL removed)\n",
      "\n",
      "**From:** Carmena Gee <[CGee@excellbattery.com](mailto:CGee@excellbattery.com)>\n",
      "**Sent:** October 24, 2024 9:50 AM\n",
      "**To:** Dorothy Ferreira-Colliss <[Dorothy.Ferreira-Colliss@coleintl.com](mailto:Dorothy.Ferreira-Colliss@coleintl.com)>\n",
      "**Subject:** Daily reports from [auto.reports@COLEINTL.COM](mailto:auto.reports@COLEINTL.COM)\n",
      "\n",
      "[Hi Dorothy](http://)\n",
      "These reports are no longer are arriving daily – Not since  10/2   can you have someone check and  get them emailed again especially the CBSA Importer statements..\n",
      "\n",
      "Thanks\n",
      "\n",
      "**Carmena Gee**\n",
      "Controller / HR Manager\n",
      "Excell Battery Company\n",
      "\n",
      "[Phone icon]\n",
      "778-617-2086\n",
      "[Email icon]\n",
      "[cgee@excellbattery.com](mailto:cgee@excellbattery.com)\n",
      "[Link icon]\n",
      "[URL removed](URL removed)\n",
      "[Excell Battery logo]\n",
      "\n",
      "----------------------------------------------------\n",
      "# Outlook Calendar To Be Shared On Our Website\n",
      "\n",
      "## On 2024-11-06T20:51:38Z, Scout Voicemail wrote a note (2297855):\n",
      "You have received a new voice mail from \"16045005489 - Daniel Gu\"\n",
      "\n",
      "From: 16045005489 \n",
      "To: \"1003\" - \"Support\" \"VM\"\n",
      "Received:\"Wednesday, November 6, 2024 12:50:09 PM\"\n",
      "Duration:\"00:00:47\"\t\n",
      "File:\"vmail_16045005489_1003_20241106205009\"\n",
      "\n",
      "Transcription:\n",
      "Hey hello, this is Daniel from product Dental. I'm calling just checking to see if you're familiar with some kind of Outlook calendar to be shared on our website so people can make a schedule on reservation on the open, the calendar like so they can make appointment with our technician and yeah, just give me a call if possible if 604 500 5489 again 6045005489 this is Daniel from protect dental lab. Thank you.\n",
      "\n",
      "----------------------------------------------------\n",
      "# My Account/Desktop Is Not Syncing With The HW Admin Boardroom Computer\n",
      "\n",
      "## On 2024-11-07T21:20:27Z, Sheldon Loeppky wrote a note (2298377):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "- my laptop required an updated password\n",
      "-  The HW Admin Boardroom computer/windows does not recognize my new password, though I can log in with my old one\n",
      "- The HW Admin Boardroom computer/desktop does not sync with what's on my laptop\n",
      "- No access to EHS/OneDrive from HW Admin Boardroom\n",
      "- Something is not syncing properly...\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Phone\n",
      "\n",
      "#### What is the best number to reach you at?\n",
      "6046161203\n",
      "\n",
      "## On 2024-11-07T21:20:27Z, Sheldon Loeppky wrote a note (2298378):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Windows\\system32\n",
      "- user name: sloeppky\n",
      "- machine name: 24-007L\n",
      "    - host name: 24-007L\n",
      "    - address: fe80::77b9:cc7a:cad8:9cb3%20; 10.10.30.161; fd91:938e:b78:842:a407:8496:6974:9bb0; fd8d:9a42:f22c:6e11:a407:8496:6974:9bb0; fd91:938e:b78:842:4d0:61ed:fb19:e392; fd8d:9a42:f22c:6e11:7559:5c64:3003:3122\n",
      "\n",
      "----------------------------------------------------\n",
      "# iCarol is not recognizing my email to reset my password\n",
      "\n",
      "## On 2024-11-13T02:06:06Z, Samantha Bush wrote a note (2302074):\n",
      "#### Afterhours Emergency Support\n",
      "Please note our office is open from Monday - Friday 7:30AM - 5:00PM Pacific time Excluding Statutory Holidays.\n",
      "If you are unable to work and it is outside these hours or during a holiday, please submit this ticket. \n",
      "**Please do not use this during regular business hours**\n",
      "\n",
      "This will immediately trigger emergency escalation to our after hours on-call team. \n",
      "If this is during late night hours, they will be woken up.\n",
      "\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What is the best phone number to reach you at?\n",
      "435-659-0225\n",
      "\n",
      "## On 2024-11-13T02:06:08Z, Samantha Bush wrote a note (2302075):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: sbush\n",
      "- machine name: 21-234D\n",
      "    - host name: 21-234D\n",
      "    - address: fe80::f433:55bf:b82c:92ee%13; 192.168.1.83\n",
      "\n",
      "----------------------------------------------------\n",
      "# Payment Receipt for PO - 12083 - Created Afterhours\n",
      "\n",
      "----------------------------------------------------\n",
      "# PO #12083 has shipped from Wesco - Created Afterhours\n",
      "\n",
      "----------------------------------------------------\n",
      "# Missing program for shipping\n",
      "\n",
      "## On 2024-11-25T15:41:53Z, Aldwin Tajan wrote a note (2309219):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "When change my unit\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Chat\n",
      "\n",
      "## On 2024-11-25T15:41:53Z, Aldwin Tajan wrote a note (2309220):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Windows\\System32\n",
      "- user name: Surrey-Ship-Rec\n",
      "- machine name: 24-173D\n",
      "    - host name: 24-173D\n",
      "    - address: fe80::1e85:80ad:3d1d:6041%15; 192.168.10.100\n",
      "\n",
      "## On 2024-11-25T16:05:31Z, Aldwin Tajan wrote a note (2309241):\n",
      "Cancel the request please its done\n",
      "\n",
      "----------------------------------------------------\n",
      "# 988 Genesys Login Issue and Icarol Account\n",
      "\n",
      "## On 2024-11-25T21:17:00Z, Tim Martiniuk wrote a note (2309466):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What time are you working till?\n",
      "5 pm\n",
      "\n",
      "#### Preferred method of contact\n",
      "Cell- 250-485-3196\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Hi there, \n",
      "\n",
      "One of our responders- Keely O'Brien- is unable to authenticate when logging into 988 Genesys (it does not recognize her address,) and I'm wondering if it may have something to do with her Microsoft crisis centre account (we had a similar problem with Meaghan Chenosky). Would it be possible to reset this?\n",
      "\n",
      "I've also noticed that iCarol will not send welcome emails to Keely's current crisis centre address- it says that it does not exist when I use a test function. She hasn't received some other correspondence. Not sure if this could be related. I can be the contact for her since she works late evenings once per week. Feel free to call me if it's easier.\n",
      "\n",
      "Thanks!\n",
      "Tim\n",
      "\n",
      "----------------------------------------------------\n",
      "# Laptop Login Issues\n",
      "\n",
      "## On 2024-11-27T13:41:20Z, Monica Ferneyhough wrote a note (2310283):\n",
      "Hi there,\n",
      "\n",
      "I am having issues logging into my laptop. I am travelling in the US if that makes a difference. \n",
      "\n",
      "Thanks in advance!\n",
      "\n",
      "Monica Ferneyhough\n",
      "\n",
      "----------------------------------------------------\n",
      "# Long Distance Call Reports\n",
      "\n",
      "## On 2024-11-28T20:46:07Z, Justin Manaois wrote a note (2312661):\n",
      "Hi team,\n",
      "\n",
      "May someone please send us the long distance call reports from August to October? Our accounting team is processing our month end billing and we really need these reports.\n",
      "\n",
      "Thanks!\n",
      "\n",
      "Justin\n",
      "\n",
      "![\\[image\\]](cid:P2SLpwNDf0SMauX185REegEV_logo_RGB_signature_png)**Justin Manaois,**  PMP\n",
      "Operations Manager\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 5T6\n",
      "**C:** 778.788.5387 **T:** 604.583.3546 ext. 4045 **F:** 604.587.6464\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:qxic4BE0SUeIyvRGUnM7hg672_CWImageFacebook_gif)](URL removed) [![\\[image\\]](cid:Rb7X5LMMHkqVq7p5BXIsCA672_CWImageLinkedin_gif)](URL removed) [![\\[image\\]](cid:nICPILl7aUCeDlHxwcRSWQ672_CWImageInstagram_gif)](URL removed)\n",
      "\n",
      " Thank you.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Microsoft Azure Payment - Just Wanted To Confirm If Any Action Is Required\n",
      "\n",
      "## On 2024-12-06T22:52:27Z, Laura Vasquez wrote a note (2316876):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What time are you working till?\n",
      "Monday to Friday from 8:00am to 4:00pm\n",
      "\n",
      "#### Preferred method of contact\n",
      "Email and Cell Phone 6047002796\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "I received an invoice from Microsoft Azure on November 18, but I have not seen the corresponding charge on my credit card as I have in previous months. I just wanted to confirm if any action is required on my part, or if this is an issue that will be resolved automatically.\n",
      "\n",
      "Thank you for your assistance.\n",
      "\n",
      "## On 2024-12-06T22:52:27Z, Laura Vasquez wrote a note (2316877):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: lvasquez\n",
      "- machine name: 21-114L\n",
      "    - host name: 21-114L\n",
      "    - address: fe80::1c9c:75a0:71fd:19c6%14; 2604:3d08:6982:8500:b968:ba42:7636:8cc1; 2604:3d08:6982:8500::e973; 2604:3d08:6982:8500:391c:c6ae:8ad8:ef42; 10.0.0.180\n",
      "\n",
      "----------------------------------------------------\n",
      "# Was Expecting Approximately 11 Emails That I Have Not Received.\n",
      "\n",
      "## On 2024-12-12T17:24:45Z, Amanda Dietz wrote a note (2319846):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "I am looking to confirm if emails I was expecting have been blocked from the server or if it is an issue on the senders end.  I was expecting 10 e-gift cards and a purchase confirmation for a place called \"Blue Frog\".\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Email\n",
      "\n",
      "## On 2024-12-12T17:24:45Z, Amanda Dietz wrote a note (2319847):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: adietz\n",
      "- machine name: 23-056L\n",
      "    - host name: 23-056L\n",
      "    - address: fe80::448d:5530:1ecf:6958%5; 10.10.30.150\n",
      "\n",
      "----------------------------------------------------\n",
      "# Weird Access Issues Cloudfare with Yardi and Onboard\n",
      "\n",
      "## On 2024-12-13T21:36:45Z, Justin Manaois wrote a note (2320480):\n",
      "Hi team,\n",
      "\n",
      "We had a weird network blip with Yardi and Onboard this morning. It didn't let us login for a bit and an error message from Cloudflare showed up. Do you know why this happened?\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Justin\n",
      "\n",
      "![\\[image\\]](cid:vcdr4a9yEicIDpinXWVygEV_logo_RGB_signature_png)**Justin Manaois,**  PMP\n",
      "Operations Manager\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 5T6\n",
      "**C:** 778.788.5387 **T:** 604.583.3546 ext. 4045 **F:** 604.587.6464\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:xoT7xwDw5keBLqzbQt1Fg286_CWImageFacebook_gif)](URL removed) [![\\[image\\]](cid:fflviPgR1UC0G0xOZwv64w286_CWImageLinkedin_gif)](URL removed) [![\\[image\\]](cid:Q7840A0xHE22SNjpwjNahA286_CWImageInstagram_gif)](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Question Regarding Account\n",
      "\n",
      "----------------------------------------------------\n",
      "# Postage Meter - It Gives Me A Message That It Is Not Connected To The Internet\n",
      "\n",
      "## On 2024-12-24T21:47:41Z, Helen Vandenberg wrote a note (2324735):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "I'm trying to refill our Pitney Bowes postage meter.  It gives me a message that it is not connected to the internet, but when i check the network it shows that it's connected by wifi to elim devices.  Not sure if this is something that you can help me with.  I'm off until Dec 30, so i'm in no hurry.\n",
      "\n",
      "## On 2024-12-24T21:47:42Z, Helen Vandenberg wrote a note (2324736):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: hvandenberg\n",
      "- machine name: 20-146D\n",
      "    - host name: 20-146D\n",
      "    - address: fe80::5435:a96c:69c0:578c%3; 10.10.30.151; fd8d:9a42:f22c:6e11:456b:7ff1:b38d:bafc; fd8d:9a42:f22c:6e11:5afb:f1c1:1adc:9562\n",
      "\n",
      "## On 2024-12-24T22:26:55Z, Helen Vandenberg hvandenberg@elimvillage.com wrote a note (2324743):\n",
      "Sorry, just got it fixed.  You can close this ticket.  Thanks   helen\n",
      "\n",
      "![\\[image\\]](cid:0ECxSk3u0WQWckj0HyswEV_Fleetwood_logo_rgb_signature_png)**Helen Vandenberg**\n",
      "Receptionist & Admin Assistant\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 5T6\n",
      "**T:** 604.587.8999 **F:** 604.587.6464\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:xoT7xwDw5keBLqzbQt1Fg286_CWImageFacebook_gif)]([URL removed]) [![\\[image\\]](cid:fflviPgR1UC0G0xOZwv64w286_CWImageLinkedin_gif)]([URL removed]) [![\\[image\\]](cid:Q7840A0xHE22SNjpwjNahA286_CWImageInstagram_gif)]([URL removed])\n",
      "\n",
      "----------------------------------------------------\n",
      "# Temas missing\n",
      "\n",
      "----------------------------------------------------\n",
      "# Laura Unable To Log In\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16043544877 - Brit. Columbia\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16043544877 - Brit. Columbia\n",
      "\n",
      "----------------------------------------------------\n",
      "# Abdullah Ali - Access to F Drive\n",
      "\n",
      "## On 2025-01-02T17:26:09Z, Andrew Le wrote a note (2329044):\n",
      "Hello,\n",
      "\n",
      "Could you please give Abdullah Ali access to the Training Computers in the Safety Offices at NW Plant through this email?\n",
      "\n",
      "Can you please organize him as a user and ensure he has access to his email/Outlook on that computer?\n",
      "\n",
      "Also, could you please advise what access Airon Nisperos had previously? The same access should be provided to Abdullah Ali as well\n",
      "\n",
      "It would be great if you can complete this request as your earliest convenience.\n",
      "\n",
      "Thank you,\n",
      "Andrew\n",
      "\n",
      "**Andrew Le**\n",
      "Senior Financial Analyst\n",
      "**D** [778.234.0363 ](tel:778.234.0363)\n",
      "**E** [andrew.le@urbanimpact.com](mailto:andrew.le@urbanimpact.com)\n",
      "Did you know you can manage your account online? [**Log in**](URL removed) to our online portal to pay bills, schedule pick up and much more!  Need help with the portal? Follow this **[easy how-to-guide](URL removed).**\n",
      "\n",
      "## On 2025-01-02T17:35:00Z, Florinda Coj Sulugui wrote a time_entry (1018069):\n",
      "Good morning Louise,\n",
      "\n",
      "I hope you are doing well, We got this request from Andrew Le to give Abdullah Ali access to the Training Computers in the Safety Offices at NW Plant through this email. Also access to F Drive and the same access that Airon Nisperos has.\n",
      "\n",
      "Are we okay to proceed with this request? \n",
      "\n",
      "Regards, \n",
      "\n",
      "**FLORINDA COJ SULUGUI**\n",
      "Support Coordinator\n",
      "236\\.200\\.5765 - Direct\n",
      "========================\n",
      "\n",
      "----------------------------------------------------\n",
      "# Doesn't Recognize New User on the Domain Controller \n",
      "\n",
      "## On 2025-01-03T19:05:31Z, Scout Voicemail wrote a note (2329570):\n",
      "You have received a new voice mail from \"16045005489 - Noah:Daniel Gu\"\n",
      "\n",
      "From: 16045005489 \n",
      "To: \"9797\" - \"Support P1\" \"VM\"\n",
      "Received:\"Friday, January 3, 2025 11:03:20 AM\"\n",
      "Duration:\"00:01:11\"\t\n",
      "File:\"vmail_16045005489_9797_20250103190320\"\n",
      "\n",
      "Transcription:\n",
      "Hey, hello. This is Daniel calling from protect dental lab and I had an issue. I just need to create a new user in domain controller, and also said this user with the local admin rights,\n",
      "\n",
      "But somehow after user was created and if I added the user into the local admin accounts and sorry administrator groups, it doesn't recognize this user showing with a weird like some kind of random number with some kind of looks like unrecognized domain account.\n",
      "\n",
      "So that only happens after we turned off the older domain controller. And so just wonder if something wrong with a new domain controller,\n",
      "\n",
      "So would you mind give me a call to really urgent? I need to set when you are.\n",
      "\n",
      "My return number is 604-500-5489. This is Daniel from protect dental lab. Thank you.\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16045005489 - Daniel Gu\n",
      "\n",
      "## On 2025-01-04T04:45:19Z, Scout Voicemail wrote a note (2329852):\n",
      "You have received a new voice mail from \"16045005489 - Daniel Gu\"\n",
      "\n",
      "From: 16045005489 \n",
      "To: \"9798\" - \"Emergency\" \"VM\"\n",
      "Received:\"Friday, January 3, 2025 8:43:55 PM\"\n",
      "Duration:\"00:00:45\"\t\n",
      "File:\"vmail_16045005489_9798_20250104044355\"\n",
      "\n",
      "Transcription:\n",
      "Hello. This is the Danielle calling from protect dental lab and I just noticed all the server and devices disappeared.\n",
      "\n",
      "From the network and just about 10-15 minutes ago.\n",
      "\n",
      "Not sure what is happening.\n",
      "\n",
      "if you aware of the issue and we can maybe just a repair\n",
      "\n",
      "Tomorrow, if you need me to go on site, just please let me know early. And I can meet you over there and try to resolve all this issues before next Monday or business starts.\n",
      "\n",
      "Thank you very much, bye.\n",
      "\n",
      "## On 2025-01-04T04:45:45Z, OpsGenie wrote a note (2329853):\n",
      "[OpsGenie] Alexander Ross acknowledged alert: \"Ticket#1009892/Scout Technology Guides/New Voicemail from 16045005489 - Daniel Gu\" [URL removed]\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 18327820275 - Texas\n",
      "\n",
      "----------------------------------------------------\n",
      "# Laptop Returned (21-131) - Does Scout Need To Do Anything With The Laptop Remotely?\n",
      "\n",
      "## On 2025-01-07T23:53:15Z, Samantha Fogel wrote a note (2331443):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* Yes, This Has Happened Before\n",
      "\n",
      "#### What time are you working till?\n",
      "9-4:30 every day this week.\n",
      "\n",
      "#### Preferred method of contact\n",
      "email\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Neda Shadbakht recently returned her laptop (21-131) and I forget if I need to submit a ticket about this or not. Does Scout need to do anything with the laptop remotely before it can go in storage, to eventually be reassigned to someone else? Thanks!\n",
      "\n",
      "## On 2025-01-07T23:53:15Z, Samantha Fogel wrote a note (2331444):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: sfogel\n",
      "- machine name: DELL3050-18-01\n",
      "    - host name: Dell3050-18-01\n",
      "    - address: ::1; 192.168.1.117\n",
      "\n",
      "----------------------------------------------------\n",
      "# Drive Mapping Incorrect And System Unstable\n",
      "\n",
      "## On 2025-01-09T16:47:46Z, Michael McQuigge wrote a note (2333038):\n",
      "#### Office Hours Emergency Support\n",
      "Please note our office is open from Monday - Friday 7:30AM - 5:00PM Pacific time.\n",
      "\n",
      "If you submit this ticket outside these hours we will not see it until the next business day.\n",
      "\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Please urgently contact Namita Murti.\n",
      "After signing in this morning, her user profile is showing old data from the past and the wrong contents of her desktop. The system is also showing overall instability. Applications (Front, Slack)  fail to open.\n",
      "\n",
      "Thank you.\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Chat\n",
      "\n",
      "----------------------------------------------------\n",
      "# Automatic reply: Scout Firewall Update Notification\n",
      "\n",
      "## On 2025-01-09T19:53:30Z, Justin Manaois wrote a note (2333197):\n",
      "Hi there,\n",
      "\n",
      "I will be away from my office from December 30th, 2004 to January 24th, 2025. If you have any inquires please leave me a detailed message and I will get back to you, if it's an emergency please contact the administration office at 604-583-3546. If you are working with me on a project, please kindly send me an email with the project title in the subject line and I will try my best to respond ASAP.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "Justin\n",
      "\n",
      "----------------------------------------------------\n",
      "# Park Feature of Yealink Phone System Doesn't Work\n",
      "\n",
      "## On 2025-01-09T21:22:10Z, Vanessa Schumacher wrote a note (2333249):\n",
      "#### How many people is this affecting?\n",
      "* Group of users\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Park Feature of phone system doesn't seem to be working. When I place someone on Park, light does not come on to indicate link on hold and just now, I placed someone on hold and they disappeared.\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Phone\n",
      "\n",
      "#### What is the best number to reach you at?\n",
      "604.583.3546\n",
      "\n",
      "## On 2025-01-09T21:22:11Z, Vanessa Schumacher wrote a note (2333250):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: vschumacher\n",
      "- machine name: 20-146D\n",
      "    - host name: 20-146D\n",
      "    - address: fe80::5435:a96c:69c0:578c%3; 10.10.30.151; fd8d:9a42:f22c:6e11:b:8462:608c:32f1; fd8d:9a42:f22c:6e11:5afb:f1c1:1adc:9562\n",
      "\n",
      "----------------------------------------------------\n",
      "# Rexall Medication Computer at Harrison Has Blacked Out\n",
      "\n",
      "## On 2025-01-09T23:53:25Z, Scout Voicemail wrote a note (2333326):\n",
      "You have received a new voice mail from \"16045833546 - Justin Manaois\"\n",
      "\n",
      "From: 16045833546 \n",
      "To: \"1003\" - \"Support\" \"VM\"\n",
      "Received:\"Thursday, January 9, 2025 3:50:47 PM\"\n",
      "Duration:\"00:01:38\"\t\n",
      "File:\"vmail\\_16045833546\\_1003\\_20250109235047\"\n",
      "\n",
      "Transcription:\n",
      "Hello. This is an Earth Paul Kim from elim Villages. The Union number is the one East Side. We have medic the Medicaid computer for the email that the computer actually is a blackout. It's out of order now.\n",
      "\n",
      "and,\n",
      "\n",
      "the morning nurse told me that it was not working this morning and when I came in for the evening,\n",
      "\n",
      "even though I changed the batteries, the battery is full in the charge.\n",
      "\n",
      "When he put in the system, it actually no power at all.\n",
      "\n",
      "So and when I checked the connection connectors, the adapter something wrong, it's not really connected properly. So I think the computer itself was something out of order now.\n",
      "\n",
      "So, please call me back.\n",
      "\n",
      "Picture of Paul.\n",
      "Not physically.\n",
      "\n",
      "I will give you write number.\n",
      "\n",
      "Actually, my extension is 40070.\n",
      "\n",
      "Nurses phone number extension, 4070. In Ellen Village.\n",
      "\n",
      "Okay. Yeah, 6045878999 extension. 4070, this is not support. Please call me back. Thank you. Bye.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Assistance with Adding Two Displays\n",
      "\n",
      "----------------------------------------------------\n",
      "# Vacation 21-22\n",
      "\n",
      "## On 2025-01-17T21:20:23Z, Daniel Gu wrote a note (2340870):\n",
      "Hi Staff,\n",
      "\n",
      "I will take a short vacation early next week\\(Tuesday & Wednesday\\) for 2 days. If you have any issues, please submit the service ticket in Scout. I will either dispatch it to Scout or fix it after I come back.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "----------------------------------------------------\n",
      "# Memory Leak on Home PC - 24-178D\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16047256196 - PAUL GORRE - Created Afterhours\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 17789689094 - Jennifer Ladesma\n",
      "\n",
      "## On 2025-01-18T18:38:39Z, Scout Voicemail wrote a note (2341123):\n",
      "You have received a new voice mail from \"17789689094 - Jennifer Ladesma\"\n",
      "\n",
      "From: 17789689094 \n",
      "To: \"1001\" - \"Scout After Hours\" \"VM\"\n",
      "Received:\"Saturday, January 18, 2025 10:37:23 AM\"\n",
      "Duration:\"00:00:38\"\t\n",
      "File:\"vmail_17789689094_1001_20250118183723\"\n",
      "\n",
      "Transcription:\n",
      "Oh hello. This is Jennifer Ledesma director of Care at the Harrison at elim Village. Just wanted to talk with someone in regards to\n",
      "\n",
      "An incident with the phone lines and the call Bell lines. That went out at 3:30 early this morning and then came back at 8:00. Yeah, somebody could call me\n",
      "\n",
      "About that.\n",
      "\n",
      "Greatly appreciate it. My numbers is 778. 968 980 94. Thank you. Bye.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Duplicate Signatures in Replies\n",
      "\n",
      "## On 2025-01-22T17:45:56Z, Shannon Magnuson wrote a note (2342730):\n",
      "Hello,\n",
      "\n",
      "I am noticing that my signature comes up in duplicate when I reply to emails \\(sample below\\). It seems to occur after I send.\n",
      "Kind regards,\n",
      "Shannon\n",
      "\n",
      "![\\[image\\]](cid:0ECxSk3u0WQWckj0HyswEV_Fleetwood_logo_rgb_signature_png)**Shannon Magnuson**\n",
      "HR Administrator\n",
      "Elim Village Administration\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 2X7\n",
      "**T:** 604-583-3546 **F:**\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:xoT7xwDw5keBLqzbQt1Fg286_CWImageFacebook_gif)](URL removed) [![\\[image\\]](cid:fflviPgR1UC0G0xOZwv64w286_CWImageLinkedin_gif)](URL removed) [![\\[image\\]](cid:Q7840A0xHE22SNjpwjNahA286_CWImageInstagram_gif)](URL removed)\n",
      "\n",
      "**From:** Shannon Magnuson <smagnuson@elimvillage.com>\n",
      "**Sent:** Wednesday, January 22, 2025 9:43 AM\n",
      "**To:** Shannon Magnuson <smagnuson@elimvillage.com>\n",
      "**Subject:** RE: Campus Pastor postings\n",
      "\n",
      "test\n",
      "\n",
      "[Elim Village Fleetwood logo]\n",
      "**Shannon Magnuson**\n",
      "Human Resources Administrator\n",
      "The Harrison West Building\n",
      "9067 - 160 Street Surrey, BC V4N 2X7\n",
      "**T:** 604.583.3546 ext. 2301**F:** 604-587-8998\n",
      "[www.elimvillage.com](URL removed)\n",
      "[Facebook icon](URL removed) [LinkedIn icon](URL removed) [Instagram icon](URL removed)\n",
      "\n",
      "[Elim Village Fleetwood logo]\n",
      "**Shannon Magnuson**\n",
      "HR Administrator\n",
      "Elim Village Administration\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 2X7\n",
      "**T:** 604-583-3546**F:**\n",
      "[www.elimvillage.com](URL removed)\n",
      "[Facebook icon](URL removed) [LinkedIn icon](URL removed) [Instagram icon](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# - [##824505##] Your ticket has been Assigned\n",
      "\n",
      "----------------------------------------------------\n",
      "# - [##824505##] Your ticket has been Assigned\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16045833546 - Justin Manaois\n",
      "\n",
      "## On 2025-01-23T12:47:06Z, Scout Voicemail wrote a note (2343039):\n",
      "You have received a new voice mail from \"16045833546 - Justin Manaois\"\n",
      "\n",
      "From: 16045833546 \n",
      "To: \"9798\" - \"Emergency\" \"VM\"\n",
      "Received:\"Thursday, January 23, 2025 4:46:03 AM\"\n",
      "Duration:\"00:00:31\"\t\n",
      "File:\"vmail_16045833546_9798_20250123124603\"\n",
      "\n",
      "Transcription:\n",
      "Hi dear. This is navneet Eren calling from Harrison West. Just to inform you that residents call Bell from third West Floor are not working. Not going to 3 West RCS phone instead. It's going on four West Floor. Could you please call me back at 604-587-8999 extension 8824? So father I can explain you. Thank you.\n",
      "\n",
      "## On 2025-01-23T12:47:50Z, OpsGenie wrote a note (2343040):\n",
      "[OpsGenie] Demetrios Georgeadis acknowledged alert: \"Ticket#1015334/Elim Housing Society/New Voicemail from 16045833546 - Justin Manaois\" [URL removed]\n",
      "\n",
      "----------------------------------------------------\n",
      "# Bhavana Dahiya - Gmail Access\n",
      "\n",
      "## On 2025-01-23T22:41:15Z, Jeffrey Preiss wrote a note (2343423):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What time are you working till?\n",
      "Business Hours.\n",
      "\n",
      "#### Preferred method of contact\n",
      "G chat or phone\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Hey there,\n",
      "\n",
      "Bhavana Dahiya is not able to access her work Gmail any longer. She needs access to continue working today.\n",
      "\n",
      "## On 2025-01-23T22:41:16Z, Jeffrey Preiss wrote a note (2343424):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Windows\\system32\n",
      "- user name: jpreiss\n",
      "- machine name: 23-136D\n",
      "    - host name: 23-136D\n",
      "    - address: fe80::c1dd:f503:d681:f301%14; 192.168.1.62\n",
      "\n",
      "## On 2025-01-23T22:50:01Z, Jeffrey Preiss wrote a note (2343428):\n",
      "I have just been told she is in now. No need to fix. Close the ticket\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unable to Login Remotely\n",
      "\n",
      "----------------------------------------------------\n",
      "# Email Server Error and Monitor Issues\n",
      "\n",
      "## On 2025-01-30T19:49:16Z, Shannon Magnuson wrote a note (2347953):\n",
      "Hi,\n",
      "\n",
      "I just received the following error message:\n",
      "\n",
      "[Image: Outlook Send/Receive Progress dialog box showing an error message:\n",
      "\n",
      "\"0 of 1 Tasks have completed successfully\"\n",
      "\n",
      "Error tab selected with the following message:\n",
      "\n",
      "\"Task 'smagnuson@elimvillage.com - Sending' reported error (0x80040115): 'We can't complete this because we can't contact the server right now. Please try again later.'\"]\n",
      "\n",
      "Also, the icons and display on one of my monitors randomly increased to a very large size…\n",
      "\n",
      "![\\[image\\]](cid:Q6PHqTqd06CzkmC9afpPgEV_Fleetwood_logo_rgb_signature_png)**Shannon Magnuson**\n",
      "HR Administrator\n",
      "Elim Village Administration\n",
      "9025 160 Street Surrey, BC V4N 2X7\n",
      "**T:** 604-583-3546 **F:**\n",
      "www.elimvillage.com\n",
      "[![\\[image\\]](cid:qxic4BE0SUeIyvRGUnM7hg672_CWImageFacebook_gif)]([URL removed])\n",
      "\n",
      "## On 2025-01-30T19:55:25Z, Shannon Magnuson wrote a note (2347956):\n",
      "Please disregard - with a restart - things seem to have resolved.\n",
      "\n",
      "----------------------------------------------------\n",
      "# Cannot Login\n",
      "\n",
      "----------------------------------------------------\n",
      "# Help with Monitor Placement\n",
      "\n",
      "----------------------------------------------------\n",
      "# [Ticket# CAS-20193-D3K6R5 ] | RE: Ticket#1017288/UrbanImpact/Temporarily update Urban Impact Email F\n",
      "\n",
      "----------------------------------------------------\n",
      "# [Ticket# CAS-20206-D5C8V3 ] | RE: Ticket#1017288/UrbanImpact/Temporarily update Urban Impact Email F\n",
      "\n",
      "----------------------------------------------------\n",
      "# [Ticket# CAS-20231-X1X1V6 ] | RE: Ticket#1017288/UrbanImpact/Temporarily update Urban Impact Email F\n",
      "\n",
      "----------------------------------------------------\n",
      "# Rest Password - Max Chowdhury\n",
      "\n",
      "## On 2025-02-06T16:43:31Z, John McGrath wrote a note (2353900):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "need so he can access computer and email.\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Email\n",
      "\n",
      "## On 2025-02-06T16:43:31Z, John McGrath wrote a note (2353901):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: jmcgrath\n",
      "- machine name: 21-266L\n",
      "    - host name: 21-266L\n",
      "    - address: fe80::abb6:bdb5:c8a7:ecc3%12; 10.22.70.113\n",
      "\n",
      "----------------------------------------------------\n",
      "# Unable to Login to Account\n",
      "\n",
      "----------------------------------------------------\n",
      "# Need Help Closing a File Left Open on Remote Server Asap\n",
      "\n",
      "----------------------------------------------------\n",
      "# Fw: Leave at 10:30 and off tomorrow\n",
      "\n",
      "## On 2025-02-13T18:27:27Z, Daniel Gu wrote a note (2359400):\n",
      "Sorry, forgot to CC you.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "**From:** Daniel Gu <dgu@protecdental.com>\n",
      "**Sent:** Thursday, February 13, 2025 9:53 AM\n",
      "**To:** Protec Dental <staff@protecdental.com>\n",
      "**Subject:** Leave at 10:30 and off tomorrow\n",
      "\n",
      "Hi Staff,\n",
      "\n",
      "I have to leave early and may not be able to come into the office either tomorrow. Feel sick, need some time for the recovery.\n",
      "\n",
      "Miner issues, please create the Scout ticket and leave it aside, after the long weekend I will help you. For critical issues that affect your ability to work, please contact me with my cell phone and I will dispatch to Scout for a immediate service.\n",
      "\n",
      "**Best Regards,**\n",
      "\n",
      "**DANIEL GU**\n",
      "*IT Support*\n",
      "****PROTEC DENTAL LABORATORIES**\n",
      "1880 Ontario Street\n",
      "Vancouver, BC\n",
      "V5T 2W6\n",
      "Email:  [itsupport@protecdental.com](mailto:itsupport@protecdental.com)\n",
      "Phone: 604.500.5489\n",
      "Fax: 604.873.8527\n",
      "\n",
      "----------------------------------------------------\n",
      "# Mailing List Addition - Cancellation List\n",
      "\n",
      "## On 2025-02-14T19:02:39Z, Tim Martiniuk wrote a note (2360038):\n",
      "Hi there, \n",
      "\n",
      "Could you please add Paul Carter to the Cancellation list? \n",
      "\n",
      "Thanks and have a good long weekend!\n",
      "Tim\n",
      "\n",
      "-- \n",
      "\n",
      "Tim Martiniuk\n",
      "Operations Manager \\(People\\)\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway, Vancouver, BC \n",
      "V5T 1X8\n",
      "\n",
      "Tim Martiniuk\n",
      "Operations Manager \\(People\\), Distress Services\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway\n",
      ",\n",
      "Vancouver\n",
      ",\n",
      "BC\n",
      "\n",
      "V5T 1X8\n",
      "\n",
      "E:\n",
      "[tmartiniuk@crisiscentre.bc.ca](mailto:tmartiniuk@crisiscentre.bc.ca)\n",
      "W:\n",
      "[www.crisiscentre.bc.ca](URL removed)\n",
      "\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/3e07e00a-354d-4c82-87a2-c98bb0d051c9 \"Facebook\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce65ad2d8bd584572bab408dd4d2a20d4%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638751565543793604%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=Jew34EYoqwXtu8oNsMsWuFgRpzJHantmaNC1n9XqadU%3D&amp;reserved=0)\n",
      "\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/749213d7-9d0d-4607-b848-3b6932922b51 \"Twitter\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce65ad2d8bd584572bab408dd4d2a20d4%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638751565543807274%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=6ezy2q8e71VsT%2BXGw5cQloIjocptoyzFdzuLV2oSO98%3D&amp;reserved=0)\n",
      "\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/0fc65d4b-494a-4999-9d43-04fe5d5a0528 \"LinkedIn\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce65ad2d8bd584572bab408dd4d2a20d4%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638751565543820633%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=2WNcWx%2BCDfXp6x90xclgtbM1Y3KTt2cojFFWKAAdxXA%3D&amp;reserved=0)\n",
      "\n",
      "[Instagram logo](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/a57de215-2be8-47af-bfeb-e755c24045dc \"https://crisiscentre.bc.ca\")]([URL removed]&amp;data=05%7C02%7Cscout.help.desk%40scouttg.com%7Ce65ad2d8bd584572bab408dd4d2a20d4%7Cbbe6c771d94b42a0bf8496bcabb430c4%7C1%7C0%7C638751565543845548%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=8dmEbuu9HqssTVNtON2jRtaJ1HbcSy1O6egKSpWlLPE%3D&amp;reserved=0)\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16046129908 - Brit. Columbia\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16046129908 - Brit. Columbia\n",
      "\n",
      "----------------------------------------------------\n",
      "# Trying To Connect To SonicWall Mobile Connect - Getting An \"Incorrect Username/Password\" Message\n",
      "\n",
      "## On 2025-02-18T18:14:22Z, Adam Shillington wrote a note (2360992):\n",
      "Hi,\n",
      "I'm trying to log onto the remote desktop server and was unable to log in on my usual way through the Microsoft remote desktop. I saw that there are new instructions to use Sonic Wall mobile connect. I followed the instructions but I am getting an \"incorrect username/password\" message when I try to log in. Hoping to have some support in logging in\n",
      "\n",
      "I'm using a Mac \\(I followed the mac instructions\\)\n",
      "\n",
      "Thanks Adam\n",
      "\n",
      "Adam Shillington\n",
      "\n",
      "\\(\n",
      "He/Him\n",
      "\\)\n",
      "Clinical Specialist, Distress Services\n",
      "Crisis Intervention & Suicide Prevention Centre of BC\n",
      "Musqueam, Squamish, and Tsleil‑Waututh Territory\n",
      "763 East Broadway\n",
      ",\n",
      "Vancouver\n",
      ",\n",
      "BC\n",
      "\n",
      "V5T 1X8\n",
      "\n",
      "T:\n",
      "604-872-1811\n",
      "E:\n",
      "[ashillington@crisiscentre.bc.ca](mailto:ashillington@crisiscentre.bc.ca)\n",
      "W:\n",
      "[www.crisiscentre.bc.ca](URL removed)\n",
      "\n",
      "[![\\[Facebook\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/55b63cbf-4362-4065-a60e-74f52c23f7af \"Facebook\")](URL removed)\n",
      "\n",
      "[![\\[Twitter\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/e3eaee5b-5a2b-477f-9cd3-5533f0940489 \"Twitter\")](URL removed)\n",
      "\n",
      "[![\\[LinkedIn\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/a4a3eeaa-ec94-409f-9a00-3feb191eb807 \"LinkedIn\")](URL removed)\n",
      "\n",
      "[Instagram logo](URL removed)\n",
      "[![\\[https://crisiscentre.bc.ca\\]](https://manage.scouttg.com/v4_6_release/api/inlineimages/scout/50510856-7d8c-4dae-9ff9-8cc935619f6a \"https://crisiscentre.bc.ca\")](URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Need To Access My Account In Computer #24-099D\n",
      "\n",
      "## On 2025-02-21T00:07:09Z, Weng Magrata wrote a note (2363209):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* No, First Time This Has Happened\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Phone\n",
      "\n",
      "#### What is the best number to reach you at?\n",
      "604-830-1255\n",
      "\n",
      "## On 2025-02-21T00:07:10Z, Weng Magrata wrote a note (2363210):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.22631.0\n",
      "- portal dir: C:\\Windows\\System32\n",
      "- user name: wmagrata\n",
      "- machine name: 24-099D\n",
      "    - host name: 24-099D\n",
      "    - address: fe80::539d:8f07:5cfc:3ffe%9; 10.48.2.60\n",
      "\n",
      "----------------------------------------------------\n",
      "# Jessica Grant | Help Conrad with Getting Her Signed into her Account\n",
      "\n",
      "----------------------------------------------------\n",
      "# Delete \"Calendar - Human Resources\"\n",
      "\n",
      "## On 2025-02-28T00:27:29Z, Davina Cooper wrote a note (2367567):\n",
      "#### Specific details about the problem/question?\n",
      "please delete \"Calendar - Human Resources\"\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Chat\n",
      "\n",
      "## On 2025-02-28T00:27:29Z, Davina Cooper wrote a note (2367568):\n",
      "> Information recorded by desktop portal client-portal/5.3.1.0.\n",
      "\n",
      "- operation system: Win32NT/10.0.19045.0\n",
      "- portal dir: C:\\WINDOWS\\system32\n",
      "- user name: dcooper\n",
      "- machine name: 19-077L\n",
      "    - host name: 19-077L\n",
      "    - address: fe80::2544:2db0:a99b:ca0b%12; 10.10.30.146\n"
     ]
    }
   ],
   "source": [
    "null_score_queries = df[df['solution_score'].isna()]['query'].tolist()\n",
    "\n",
    "# Print the number of queries found and display some examples\n",
    "print(f\"Found {len(null_score_queries)} queries with null helpfulness scores\")\n",
    "if len(null_score_queries) > 0:\n",
    "    print(\"\\nExamples:\")\n",
    "    for query in null_score_queries:  \n",
    "        print(f\"\\n----------------------------------------------------\\n{query}\")\n",
    "\n",
    "# Return the list for further processing if needed\n",
    "# null_score_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
```
## File: database/postgres_client.py
```python
"""
Asynchronous PostgreSQL client module providing a high-level interface for database operations.
Includes classes for building queries, executing database operations, and managing connections.
"""
import os
import logging
import traceback
from datetime import datetime, date
from typing import Dict, List, Any, Optional, Union
from uuid import UUID
import json
import asyncio

import asyncpg
from dotenv import load_dotenv


load_dotenv()

logger = logging.getLogger(__name__)



class PostgresClient:
    """
    An asynchronous PostgreSQL client that manages database connections and operations.
    
    Provides methods for executing queries and managing database connections using connection pooling.
    Supports both raw SQL queries and a builder pattern interface similar to Supabase.
    
    Can be used as an async context manager:
    
    async with PostgresClient() as client:
        result = await client.table("users").select("*").execute()
    
    Attributes:
        db_params (dict): Database connection parameters
        pool (Pool): Connection pool for managing database connections
    """
    def __init__(self, role: str = "postgres"):
        """Initialize PostgreSQL client."""
        if role == "postgres":
            password = os.getenv("POSTGRES_PASSWORD")
        elif role == "app_user":
            password = os.getenv("POSTGRES_APP_USER_PASSWORD")
        else:
            raise ValueError(f"Invalid role: '{role}'")

        self.db_params = {
            "database": os.getenv("POSTGRES_DB"),
            "user": role,
            "password": password,
            "host": os.getenv("POSTGRES_HOST"),
            "port": os.getenv("POSTGRES_PORT"),
            # Add explicit connection limits
            "min_size": 1,
            "max_size": 50
        }
        self.pool = None

    def _format_row(self, row: dict) -> dict:
        """Format database row values to appropriate Python types"""
        if not row:
            return row
            
        formatted = {}
        for key, value in row.items():
            if isinstance(value, UUID):
                formatted[key] = str(value)
            elif isinstance(value, str) and value.startswith('{') and value.endswith('}'):
                try:
                    formatted[key] = json.loads(value)
                except json.JSONDecodeError:
                    formatted[key] = value
            else:
                formatted[key] = value
        return formatted

    async def initialize(self):
        """Initialize the connection pool if not already initialized"""
        if not self.pool:
            self.pool = await asyncpg.create_pool(**self.db_params)
        return self

    async def close(self):
        """Close the connection pool"""
        if self.pool:
            await self.pool.close()
            self.pool = None

    async def acquire(self):
        """Acquire a connection from the pool"""
        if not self.pool:
            await self.initialize()
        return await self.pool.acquire()

    async def execute(self, query: str, params=None, max_retries=3, retry_delay=1):
        """
        Execute a database query with retry logic.
        
        Args:
            query (str): SQL query to execute
            params (dict | list, optional): Query parameters. Can be dict for named params or list for positional.
            max_retries (int): Maximum number of retry attempts. Defaults to 3.
            retry_delay (int): Delay between retries in seconds. Defaults to 1.
            
        Returns:
            Response: Query results wrapped in Response object containing:
                - data: List of query results as dicts
                - count: Number of rows returned
            
        Raises:
            asyncpg.exceptions.PostgresError: If database operation fails after all retries
            Exception: For other database errors
        """
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    logger.debug(f"Executing query: {query} with params: {params}")
                    
                    # Execute the query with the appropriate parameters
                    rows = await conn.fetch(query, *(params or []))
                    
                    # Format the results
                    results = [self._format_row(dict(row)) for row in rows]
                    
                    return results
                
            except asyncpg.exceptions.PostgresError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"Database operation failed, retrying in {retry_delay}s: {e}")
                await asyncio.sleep(retry_delay)
                
            except Exception as e:
                logger.error(f"Error executing query: {e}")
                raise

    async def __aenter__(self):
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()

    def table(self, table_name):
        """
        Create a query builder for the specified table.
        
        Args:
            table_name (str): Name of the database table
            
        Returns:
            AsyncTableQuery: Query builder instance for the specified table
        """
        return AsyncTableQuery(self, table_name)

    def rpc(self, function_name, params=None):
        """
        Call a stored procedure/function in the database.
        
        Args:
            function_name (str): Name of the function to call
            params (dict, optional): Parameters to pass to the function
            
        Returns:
            AsyncRPCQuery: Query builder for the stored procedure call
        """
        debug_params = {k: v if k != 'p_query_embedding' else f'<Vector of length {len(v)}>' 
                        for k, v in (params or {}).items()}
        logger.debug(f"RPC call to {function_name} with params: {debug_params}")
        return AsyncRPCQuery(self, function_name, params)

    async def raw_query(self, query, params=None):
        """
        Execute a raw SQL query with parameters.
        
        Args:
            query (str): SQL query string with parameter placeholders
            params (dict, optional): Query parameters
            
        Returns:
            Response: Query results wrapped in Response object
            
        Example:
            await client.raw_query(
                "SELECT * FROM users WHERE role = $1 LIMIT $2",
                ["admin", 10]
            )
        """
        return await self.execute(query, params)

    def _format_output(self, row: dict) -> dict:
        """
        Format database output values to their string representations where needed.
        
        Args:
            row (dict): Database row as dictionary
            
        Returns:
            dict: Formatted row with converted values
        """
        return {
            key: (
                str(value) if isinstance(value, UUID) else value
            )
            for key, value in row.items()
        }

    def _prepare_query_params(self, params: Union[List[Any], Dict[str, Any], None]) -> Union[List[Any], Dict[str, Any], None]:
        """
        Prepare query parameters by converting Python types to PostgreSQL-compatible types.
        """
        if params is None:
            return None

        def convert_value(value: Any) -> Any:
            if isinstance(value, dict):
                return json.dumps(value)
            if isinstance(value, list):
                return [convert_value(v) for v in value]
            return value

        if isinstance(params, dict):
            return {k: convert_value(v) for k, v in params.items()}
        if isinstance(params, list):
            return [convert_value(v) for v in params]
        return params

    def _serialize_values(self, value: Dict) -> Dict:
        """
        Process values for database insertion by converting Python types to PostgreSQL compatible formats.
        
        Args:
            value (dict): Dictionary of values to serialize
            
        Returns:
            dict: Processed values ready for database insertion
        """
        try:
            processed = {}
            for key, val in value.items():
                if key == 'embedding' and isinstance(val, (list)):
                    processed[key] = f"[{','.join(str(x) for x in val)}]"  
                elif isinstance(val, list):
                    # If the list contains complex types (dict or list), convert to JSON string
                    if any(isinstance(item, (dict, list)) for item in val):
                        processed[key] = json.dumps(val)
                    else:
                        processed[key] = val
                elif isinstance(val, dict):
                    # Convert dictionary values to JSON string
                    processed[key] = json.dumps(val)
                elif isinstance(val, (datetime, date)):
                    processed[key] = val  # asyncpg handles datetime objects
                else:
                    processed[key] = val  # pass through all other values unchanged
            
            return processed
        
        except Exception as e:
            logger.error(f"Error serializing values: {e}")
            raise

    async def fetch(self, query: str, params=None, max_retries=3, retry_delay=1):
        """
        Execute a query and return all rows with retry logic.
        
        Args:
            query (str): SQL query to execute
            params (dict | list, optional): Query parameters
            max_retries (int): Maximum number of retry attempts
            retry_delay (int): Delay between retries in seconds
            
        Returns:
            list: Query results as rows
        """
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    return await conn.fetch(query, *(params or []))
                
            except asyncpg.exceptions.PostgresError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"Database operation failed, retrying in {retry_delay}s: {e}")
                await asyncio.sleep(retry_delay)
                
            except Exception as e:
                logger.error(f"Error executing fetch: {e}")
                raise

    async def fetchrow(self, query: str, params=None, max_retries=3, retry_delay=1):
        """
        Execute a query and return the first row with retry logic.
        
        Args:
            query (str): SQL query to execute
            params (dict | list, optional): Query parameters
            max_retries (int): Maximum number of retry attempts
            retry_delay (int): Delay between retries in seconds
            
        Returns:
            dict: First row of query results
        """
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    return await conn.fetchrow(query, *(params or []))
                
            except asyncpg.exceptions.PostgresError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"Database operation failed, retrying in {retry_delay}s: {e}")
                await asyncio.sleep(retry_delay)
                
            except Exception as e:
                logger.error(f"Error executing fetchrow: {e}")
                raise


class AsyncTableQuery:
    """
    Asynchronous query builder for table operations using method chaining.
    
    Provides methods for building SELECT, INSERT, UPDATE and DELETE queries
    with support for conditions, ordering, and limits.
    
    Example:
        await client.table('users')
            .select('id', 'name')
            .eq('active', True)
            .order_by('created_at', ascending=False)
            .limit(10)
            .execute()
    
    Attributes:
        client (PostgresClient): Database client instance
        table_name (str): Name of the target table
    """
    def __init__(self, client, table_name):
        self.client = client
        self.table_name = table_name
        self._select_cols = "*"
        self._where_clauses = []
        self._where_params = []
        self._order_by = None
        self._limit = None
        self._offset = None
        self._query = None  # Store the built query
        self._insert_values = None  # New attribute for insert values
        self._param_index = 1  # For generating $1, $2, etc.

    def select(self, *columns):
        """
        Specify columns to select.
        
        Args:
            *columns: Column names to select
            
        Returns:
            AsyncTableQuery: Self for method chaining
        """
        self._select_cols = ", ".join(columns) if columns else "*"
        return self

    def eq(self, column, value):
        self._where_clauses.append(f"{column} = ${self._param_index}")
        self._where_params.append(value)
        self._param_index += 1
        return self

    def neq(self, column, value):
        self._where_clauses.append(f"{column} != ${self._param_index}")
        self._where_params.append(value)
        self._param_index += 1
        return self

    def gt(self, column, value):
        self._where_clauses.append(f"{column} > ${self._param_index}")
        self._where_params.append(value)
        self._param_index += 1
        return self

    def lt(self, column, value):
        self._where_clauses.append(f"{column} < ${self._param_index}")
        self._where_params.append(value)
        self._param_index += 1
        return self

    def order_by(self, column, ascending=True):
        self._order_by = f"ORDER BY {column} {'ASC' if ascending else 'DESC'}"
        return self

    def limit(self, n):
        self._limit = f"LIMIT {n}"
        return self

    def offset(self, n):
        self._offset = f"OFFSET {n}"
        return self

    def insert(self, values):
        """
        Build insert query for a single dict or a list of dicts.
        
        Example:
            await client.table('users').insert({'name': 'John', 'created_at': datetime.now()}).execute()
            await client.table('users').insert([{'name': 'John'}, {'name': 'Jane'}]).execute()
        """
        if isinstance(values, list):  # Check if values is a list
            return self._insert_multiple(values)  # Handle multiple dict insertion
        elif isinstance(values, dict):  # Check if values is a single dict
            return self._insert_single(values)  # Handle single dict insertion
        else:
            raise ValueError("Values must be a dictionary or a list of dictionaries.")

    def _insert_single(self, value: dict):
        try:
            logger.debug(f"Original values: {value}")
            
            processed_value = self.client._serialize_values(value)
            # logger.info(f"Processed value: {processed_value}")
            columns = ', '.join(processed_value.keys())
            placeholders = ', '.join([f'${i}' for i in range(1, len(processed_value) + 1)])
            # logger.info(f"Columns: {columns}")
            # logger.info(f"Placeholders: {placeholders}")
            self._query = f"INSERT INTO {self.table_name} ({columns}) VALUES ({placeholders})"
            self._insert_values = list(processed_value.values())
            
            # Debug logging
            logger.debug(f"Generated query: {self._query}")
            logger.debug(f"Insert values: {self._insert_values}")
            
            return self
        
        except Exception as e:
            logger.error(f"Error in _insert_single: {e}")
            raise

    def _insert_multiple(self, values: list):
        try:
            processed_values = [self.client._serialize_values(value) for value in values]
            
            # Ensure all dictionaries have the same keys
            all_keys = set()
            for value in processed_values:
                all_keys.update(value.keys())
            
            # Create a list of columns that will be used for all rows
            columns = list(all_keys)
            columns_str = ', '.join(columns)
            
            # Create placeholders and values list
            placeholders_list = []
            flat_values = []
            param_index = 1
            
            for value_dict in processed_values:
                row_placeholders = []
                for col in columns:
                    if col in value_dict:
                        row_placeholders.append(f'${param_index}')
                        flat_values.append(value_dict[col])
                        param_index += 1
                    else:
                        row_placeholders.append('NULL')
                
                placeholders_list.append(f"({', '.join(row_placeholders)})")
            
            placeholders_str = ', '.join(placeholders_list)
            self._query = f"INSERT INTO {self.table_name} ({columns_str}) VALUES {placeholders_str}"
            self._insert_values = flat_values
            
            return self
        
        except Exception as e:
            logger.error(f"Error in _insert_multiple: {e}")
            raise

    def delete(self):
        """
        Build delete query.
        
        Example:
            await client.table('documents').delete().match({"source": source}).execute()
        """
        # Reset where clauses and params to ensure clean state
        self._where_clauses = []
        self._where_params = []
        self._param_index = 1
        self._query = f"DELETE FROM {self.table_name}"
        return self

    async def execute(self):
        if self._query:  # For INSERT, DELETE, UPDATE
            if self._insert_values is not None:
                # Single insert or update
                if self._where_clauses:  # Add WHERE clause for UPDATE
                    self._query += " WHERE " + " AND ".join(self._where_clauses)
                    # Add RETURNING * after WHERE clause
                    self._query += " RETURNING *"
                    params = self._insert_values + self._where_params
                else:
                    # For inserts or updates without WHERE
                    self._query += " RETURNING *"
                    params = self._insert_values
                return await self.client.execute(self._query, params)
            else:
                # DELETE query - add WHERE clause if it exists
                if self._where_clauses:
                    self._query += " WHERE " + " AND ".join(self._where_clauses)
                return await self.client.execute(self._query, self._where_params)
        else:  # For SELECT
            query = f"SELECT {self._select_cols} FROM {self.table_name}"
            if self._where_clauses:
                query += " WHERE " + " AND ".join(self._where_clauses)
            if self._order_by:
                query += " " + self._order_by
            if self._limit:
                query += " " + self._limit
            if self._offset:
                query += " " + self._offset
            return await self.client.execute(query, self._where_params)

    def match(self, conditions: dict):
        """
        Add equality conditions using a dictionary.
        
        Example:
            await client.table('documents').delete().match({"source": source, "group_id": group_id})
        """
        for column, value in conditions.items():
            self._where_clauses.append(f"{column} = ${self._param_index}")
            self._where_params.append(value)
            self._param_index += 1
        return self

    def in_(self, column, values):
        """
        Add IN condition using a list of values.
        
        Example:
            await client.table('users').in_('id', [1, 2, 3]).execute()
        """
        placeholders = ', '.join([f'${self._param_index + i}' for i in range(len(values))])
        self._where_clauses.append(f"{column} IN ({placeholders})")
        self._where_params.extend(values)
        self._param_index += len(values)
        return self

    def update(self, values):
        """
        Build update query.
        
        Example:
            await client.table('users').update({'name': 'John'}).match({'id': 1}).execute()
        """
        processed = self.client._serialize_values(values)
        set_clauses = [f"{k} = ${i}" for i, k in enumerate(processed.keys(), 1)]
        self._query = f"UPDATE {self.table_name} SET {', '.join(set_clauses)}"
        self._insert_values = list(processed.values())
        self._param_index = len(processed) + 1
        return self


class AsyncRPCQuery:
    """
    Asynchronous query builder for stored procedure/function calls.
    
    Handles parameter validation and execution of database functions.
    
    Attributes:
        client (PostgresClient): Database client instance
        function_name (str): Name of the function to call
        params (dict): Function parameters
    """
    def __init__(self, client, function_name, params=None):
        self.client = client
        self.function_name = function_name
        self.params = params or {}
        self.function_params = []

    async def _get_function_params(self):
        """Fetch function parameter information from PostgreSQL."""
        query = """
            SELECT 
                p.proname,
                pg_get_function_arguments(p.oid) as args
            FROM pg_proc p
            JOIN pg_namespace n ON p.pronamespace = n.oid
            WHERE p.proname = $1
            AND n.nspname NOT IN ('pg_catalog', 'information_schema');
        """
        result = await self.client.execute(query, [self.function_name])
        
        if result:
            func_info = result[0]
            args = func_info['args']
            
            param_list = [arg.strip() for arg in args.split(',') if arg.strip()]
            self.function_params = []
            
            for i, param in enumerate(param_list):
                parts = param.split(' DEFAULT ')
                param_parts = parts[0].split(' ')
                param_name = param_parts[0]
                data_type = ' '.join(param_parts[1:])
                is_required = len(parts) == 1
                
                self.function_params.append({
                    'parameter_name': param_name,
                    'parameter_mode': 'IN',
                    'data_type': data_type,
                    'ordinal_position': i + 1,
                    'is_required': is_required
                })
            
            # Validate that we have all required parameters
            if self.params:
                missing_params = [
                    p['parameter_name'] for p in self.function_params 
                    if p['is_required'] and p['parameter_name'] not in self.params
                ]
                if missing_params:
                    raise ValueError(f"Missing required parameters: {missing_params}")
        else:
            self.function_params = []

    def _serialize_param(self, value: Any, data_type: str) -> Any:
        """Serialize a parameter value based on its PostgreSQL data type."""
        if value is None:
            return None
            
        if data_type == 'vector':
            # Convert vector (list of floats) to PostgreSQL array string format
            if isinstance(value, list):
                return f"[{','.join(str(x) for x in value)}]"
            return value
        elif data_type.endswith('[]'):
            if not isinstance(value, list):
                return [value]
            return value  # asyncpg will handle array types
        elif data_type == 'jsonb' or data_type == 'json':
            if isinstance(value, (dict, list)):
                return json.dumps(value)
            return value
        elif data_type.startswith('timestamp'):
            if isinstance(value, str):
                return datetime.fromisoformat(value.replace('Z', '+00:00'))
            return value
        return value

    async def execute(self):
        await self._get_function_params()
        
        # Initialize param_values as an ordered list
        param_values = []
        
        if not self.function_params:
            query = f"SELECT * FROM {self.function_name}()"
        else:
            # Build parameter placeholders based on function definition order
            param_placeholders = []
            
            # Build ordered parameter list based on function definition
            for param in self.function_params:
                param_name = param['parameter_name']
                param_value = self.params.get(param_name)
                data_type = param['data_type']
                
                # Serialize the parameter value based on its type
                serialized_value = self._serialize_param(param_value, data_type)
                param_values.append(serialized_value)
                param_placeholders.append(f"${len(param_values)}")
            
            # Construct query with positional parameters
            query = f"SELECT * FROM {self.function_name}({', '.join(param_placeholders)})"
            
        logger.debug(f"Executing query: {query}")
        response = await self.client.execute(query, param_values)
        
        # Return the plain value if the value is a single item with the function name as the key
        if len(response) == 1 and list(response[0].keys()) == [self.function_name]:
            response = response[0][self.function_name]

        return response
```
## File: database/user_admin.py
```python
import os
import logging
from typing import List, Optional, Dict
from database import PostgresClient
import json
from dotenv import load_dotenv
import traceback

load_dotenv()

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class UserAdmin:
    def __init__(self, postgres: PostgresClient):
        """Initialize with PostgresClient as postgres superuser"""
        self.postgres = postgres

    async def get_user_info(self, username: str | None = None, user_id: str | None = None,
                      first_name: str | None = None, last_name: str | None = None) -> Dict:
        """
        Retrieve user information by username, user ID, or first and last name.

        Args:
            username (str | None): The username of the user.
            user_id (str | None): The ID of the user.
            first_name (str | None): The first name of the user.
            last_name (str | None): The last name of the user.

        Returns:
            Dict: User details including id, username, first_name, last_name, settings, groups, and apps.

        Raises:
            ValueError: If no search criteria provided or if user not found.
        """
        if user_id:
            user = await self.postgres.table("users").select().eq("id", user_id).limit(1).execute()
            if not user:
                raise ValueError(f"User with ID {user_id} not found.")
            username = user[0].get('username')
        
        elif username:
            user = await self.postgres.table("users").select().eq("username", username).limit(1).execute()
            if not user:
                raise ValueError(f"User with email {username} not found.")
            user_id = user[0].get('id')
        
        elif first_name and last_name:
            user = await self.postgres.table("users").select().eq("first_name", first_name).eq("last_name", last_name).limit(1).execute()
            if not user:
                raise ValueError(f"User with first name {first_name} and last name {last_name} not found.")
            user_id = user[0].get('id')    
        else:
            raise ValueError("Error: Either user_email, user_id, or first_name and last_name must be provided.")
        
        try:
            user_info = {
                "id": user_id,
                "username": username,
                "first_name": user[0].get('first_name'),
                "last_name": user[0].get('last_name'),
                "settings": user[0].get('settings')
            }

            groups_response = await self.postgres.rpc('get_user_groups', {'p_user_id': user_info["id"]}).execute()
            if groups_response:
                user_info["groups"] = [{"id": item['group_id'], "name": item['group_name']} for item in groups_response]
                logger.debug(f"User {user_id}, groups: {user_info['groups']}")

            return user_info # if user_info.id and user_info.name else None
        
        except Exception as e:
            raise ValueError(f"Error getting user info: {str(e)}")

    async def create_user(self, username: str, first_name: str, last_name: str, settings: Optional[Dict] = {}, 
                     default_group: str = "users", groups: Optional[List[str]] = None) -> Dict:
        """
        Add a new user to the system and optionally assign them to groups.

        Args:
            username (str): The username (email) of the new user.
            first_name (str): The first name of the new user.
            last_name (str): The last name of the new user.
            settings (Optional[Dict]): User settings dictionary. Defaults to {}.
            default_group (str): Default group to add user to. Defaults to "users".
            groups (Optional[List[str]]): Additional group names to add the user to.

        Returns:
            Dict: The newly created user record containing id, username, first_name, last_name, and settings.

        Raises:
            ValueError: If user already exists, required data is missing, or if there's an error during creation.
        """
        # Validate required parameters
        if any(param is None for param in [username, first_name, last_name]):
            msg = "Error: username, first_name, and last_name must all be provided."
            logger.error(msg)
            raise ValueError(msg)

        # Check if user already exists
        existing_user = await self.postgres.table("users").select().eq("username", username).execute()
        if len(existing_user) > 0:
            msg = f"User {username} already exists."
            logger.warning(msg)
            raise ValueError(msg)

        try:
            # Create new user
            user_response = await self.postgres.table("users").insert({
                "username": username,
                "first_name": first_name,
                "last_name": last_name,
                "settings": json.dumps(settings)
            }).execute()

            # Add user to specified groups
            groups = [default_group] + groups if groups else [default_group]
            groups_response = await self.add_user_to_groups(username, groups)
            logger.info(f"groups_response = {groups_response}")
            logger.info(f"Added user {username} to groups: {groups}")

            response = {
                "id": user_response[0]['id'],
                "username": user_response[0]['username'],
                "first_name": user_response[0]['first_name'],
                "last_name": user_response[0]['last_name'],
                "settings": user_response[0]['settings'],
                "groups": groups_response[0]['group_names']
            }

            return response
        
        except Exception as e:
            logger.error(f"Error creating user: {str(e)}")
            logger.error(traceback.format_exc())
            return None

    async def delete_user(self, username: str | None = None, user_id: str | None = None) -> Dict:
        """
        Delete a user from the system by username or user ID.

        Args:
            username (str | None): The username of the user to delete.
            user_id (str | None): The ID of the user to delete.

        Returns:
            Dict: Deletion confirmation containing id, username, and deleted status.

        Raises:
            ValueError: If neither username nor user_id is provided, user not found, or if there's an error during deletion.
        """
        
        if user_id:
            user = await self.postgres.table("users").select("username").eq("id", user_id).execute()
            if not user:
                raise ValueError(f"User with ID {user_id} not found.")
            username = user[0]['username']
        
        elif username:
            user = await self.postgres.table("users").select("id").eq("username", username).execute()
            if not user:
                raise ValueError(f"User with email {username} not found.")
            user_id = user[0]['id']
        else:
            raise ValueError("Error: Either user_email or user_id must be provided.")
        
        try:
            # Delete user from the users table
            await self.postgres.table("users").delete().eq("id", user_id).execute()
            deletion_data = {
                "id": user_id,
                "username": username,
                "deleted": True
            }
            logger.info(f"Deleted user '{username}' with id={user_id}")
            return deletion_data

        except Exception as e:
            logger.error(f"Error deleting user: {str(e)}")
            raise ValueError(f"Error deleting user: {str(e)}")
        

    async def list_users(self) -> List[Dict]:
        """
        List all users in the system.

        Returns:
            List[Dict]: A list of dictionaries containing user details (id, username, first_name, last_name).
            Returns empty list if no users found.
        """
        
        users = await self.postgres.table("users").select("id, username, first_name, last_name").execute()
        if not users:
            logger.warning("Nou users found in the system.")
            return []
        return [{'id': user['id'], 'username': user['username'], 'first_name': user['first_name'], 'last_name': user['last_name']} for user in users]
        
        
    async def add_user_to_groups(self, username: str, groups: List[str]) -> List[Dict]:
        """
        Add a user to specified groups.

        Args:
            username (str): The username of the user to add to groups.
            groups (List[str]): A list of group names to add the user to.

        Returns:
            List[Dict]: A list of dictionaries containing group information for each added group.
                       Each dictionary contains 'group_id', 'group_name', and 'group_description'.

        Raises:
            ValueError: If user not found or if there's an error adding the user to groups.
        """
        # ensure groups exist
        for group in groups:
            response = await self.postgres.table("groups").select("id").eq("name", group).execute()
            if not response:
                raise ValueError(f"Group {group} does not exist.")
        # ensure user exists
        response = await self.postgres.table("users").select("id").eq("username", username).execute()
        if not response:
            raise ValueError(f"User {username} does not exist.")    
        
        try:
            response = await self.postgres.rpc(
                'add_user_to_groups', 
                {'p_username': username, 'p_group_names': groups}
                ).execute()
            data = response[0]
            logger.info(f"rpc('add_user_to_groups') response = {response}")
            logger.info(f"Added user {data['username']} to groups: {data['group_names']}")
            return response
        except Exception as e:
            logger.error(f"Error adding user to groups: {str(e)}")
            raise ValueError(f"Error adding user to groups: {str(e)}")
        
    async def add_users_to_group(self, users: List[str], group_name: str) -> Dict:
        """
        Add a list of users to a specified group.

        Args:
            users (List[str]): A list of usernames to add to the group.
            group_name (str): The name of the group to add the users to.

        Returns:
            Dict: A dictionary containing the number of users added to the group.
        """
        # ensure group exists
        response = await self.postgres.table("groups").select("id").eq("name", group_name).execute()
        if not response:
            raise ValueError(f"Group {group_name} does not exist.")
        

        data = []
        for user in users:
            # ensure user exists
            response = await self.postgres.table("users").select("id").eq("username", user).execute()
            if not response:
                logger.warning(f"User {user} does not exist.")
                continue
            response = await self.add_user_to_groups(user, [group_name])
            data.extend(response)
        return data

    async def remove_user_from_groups(self, username: str, groups: List[str]) -> Dict:
        """
        Remove a user from specified groups.

        Args:
            username (str): The username of the user to remove from groups.
            groups (List[str]): A list of group names to remove the user from.

        Returns:
            int: The number of groups the user was removed from.
        """
        try:
            result = await self.postgres.rpc('remove_user_from_groups', 
                                       {'p_username': username, 'p_group_names': groups}).execute()
        
            logger.info(f"Removed user {username} from {len(result)} group(s)")
            return result
        except Exception as e:
            logger.error(f"Error removing user from groups: {str(e)}")
            logger.error(traceback.format_exc())
            return 0

    async def create_group(self, name: str, description: str) -> Dict:
        """
        Create a new group in the system.

        Args:
            name (str): The name of the new group.
            description (str): The description of the new group.

        Returns:
            Dict: The newly created group record containing id, name, and description.

        Raises:
            ValueError: If group already exists or if there's an error during creation.
        """
        try:
            # Check if group already exists
            existing_group = await self.postgres.table("groups").select("id").eq("name", name).execute()
            if existing_group:
                logger.warning(f"Group {name} already exists.")
                raise ValueError(f"Group {name} already exists.")

            # Create new group
            new_group = await self.postgres.table("groups").insert(
                {"name": name, "description": description}
                ).execute()
            group_id = new_group[0]['id']
            logger.info(f"Created new group {name} with ID: {group_id}")

            if 'created_at' in new_group[0]:
                del new_group[0]['created_at']

            return new_group[0]
        
        except Exception as e:
            logger.error(f"Error creating group: {str(e)}")
            logger.error(traceback.format_exc())
            raise ValueError(f"Error creating group: {str(e)}")
        

    async def delete_group(self, group_name: str) -> Dict:
        """
        Delete a group from the system by its name.

        Args:
            group_name (str): The name of the group to delete.

        Returns:
            Dict: The deleted group record containing:
                - id (str): The ID of the deleted group
                - name (str): The name of the deleted group
                - deleted (bool): Always True if successful

        Raises:
            ValueError: If group doesn't exist or if there's an error during deletion.
        """
        try:
            # Check if the group exists
            group = await self.postgres.table("groups").select("id").eq("name", group_name).execute()
            group_id = group[0]['id']

            # Delete the group
            await self.postgres.table("groups").delete().eq("id", group_id).execute()
            logger.info(f"Group '{group_name}' with ID {group_id} has been deleted.")
            
            
            return {
                "id": group_id,
                "name": group_name,
                "deleted": True
            }
    
        except Exception as e:
            logger.error(f"Error deleting group: {str(e)}")
            logger.error(traceback.format_exc())
            raise ValueError(f"Error deleting group: {str(e)}")
        
    async def list_groups(self) -> List[Dict]:
        """
        List all groups in the system.

        Args:
            

        Returns:
            List[Dict]: A list of dictionaries containing group details (id, name, description).
                       
        """
        try:
            groups = await self.postgres.table("groups").select("id, name, description").execute()
            if not groups:
                raise ValueError("No groups found in the system.")
            
            return [{'id': group['id'], 'name': group['name'], 'description': group['description']} for group in groups]
        except Exception as e:
            logger.error(f"Error listing groups: {str(e)}")
            logger.error(traceback.format_exc())
            return []

    async def list_users_in_group(self, group_name: str|None = None, group_id: str|None = None) -> List[Dict]:
        """
        List all users in a specified group specified by group_name OR group_id.
        Either group_name or group_id must be provided. If both are provided, group_id takes precedence.

        Args:
            group_name (str | None): The name of the group to list users from.
            group_id (str | None): The ID of the group to list users from.
                              

        Returns:
            List[Dict]: A list of dictionaries containing user details for users in the specified group.
                   Each dictionary contains user information including id, username, first_name, and last_name.

        Raises:
            ValueError: If neither group_name nor group_id is provided, specified group doesn't exist,
                   or if there's an error retrieving the users.
        """
        # first check that group exists
        if group_id:
            group_name = await self.postgres.table("groups").select("name").eq("id", group_id).execute()
            if not group_name:
                raise ValueError(f"Group with ID {group_id} not found.")
            group_name = group_name[0]['name']
        elif group_name:
            group_id = await self.postgres.table("groups").select("id").eq("name", group_name).execute()
            if not group_id:
                raise ValueError(f"Group with name {group_name} not found.")
            group_id = group_id[0]['id']


        try:
            if group_id:

                users = await self.postgres.rpc('get_users_in_group', {'p_group_id': group_id}).execute()
            elif group_name:
                users = await self.postgres.rpc('get_users_in_group', {'p_group_name': group_name}).execute()
            else:
                raise ValueError("Either group_name or group_id must be provided.")

            logger.info(f"Users in group: {users}")
            return users

        except Exception as e:
            raise ValueError(f"Error listing users in group: {str(e)}")
```
## File: database/__init__.py
```python
from .postgres_client import PostgresClient
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from database.user_admin import UserAdmin

__all__ = [
    PostgresClient,
    AuthenticatedPostgresClient,
    UserAdmin
]
```
## File: database/test_authenticated_client.py
```python
import json
import asyncio
from dotenv import load_dotenv
from database.authenticated_postgres_client import AuthenticatedPostgresClient
import os

    

async def main():
    load_dotenv()
    os.environ["POSTGRES_PORT"] = "5432"
    os.environ["POSTGRES_HOST"] = "localhost"
    
    user_email = "helpdesk_agent"
    # user_email = "trevor@aech.ai"

    async with AuthenticatedPostgresClient(user_email) as client:
        print(f"user info: {client.user_info}")
        user_id = client.user_info.id
        print(f"user {user_email} ({user_id})")
        
        # Now use the authenticated client
        users = await client.table("users").select("id", "username").execute()
        print(f"Found {len(users)} users: {json.dumps(users, indent=4)}")

        # test RLS on groups table
        groups = await client.table("groups").select("id", "name", "description").execute()
        print(f"Found {len(groups)} groups: {json.dumps(groups, indent=4)}")

        # # test RLS on parent_documents table
        # group_name = "test_group"
        # # group_id = await client.rpc("get_group_id", {"p_group_name": group_name}).execute()
        # # group_id = "0cb2fab7-1163-4531-bf28-1eccfb796d15" # test_group
        # group_id = "84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b" # users
        # parent_doc_data = {
        #     "summary": "test_parent_document",
        #     "group_id": group_id,
        #     "created_by": user_id
        # }
        # parent_documents = await client.table("parent_documents").insert(parent_doc_data).execute()
        # # print(f"parent_documents response: {json.dumps(parent_documents, indent=4)}")
        # print(f"parent_documents response: {parent_documents}")

    

if __name__ == "__main__":
    import asyncio
    # Run the async main function
    asyncio.run(main())
```
## File: database/authenticated_postgres_client.py
```python
import os
from contextlib import asynccontextmanager
from database import PostgresClient
import logging
from pydantic import BaseModel, Field
from typing import Optional

logger = logging.getLogger(__name__)

class UserInfo(BaseModel):
    id: str = Field(..., description="uuid of the user")
    username: str = Field(..., description="email of the user")
    first_name: str = Field(..., description="first name of the user")
    last_name: str = Field(..., description="last name of the user")
    settings: dict = Field(..., description="settings of the user")
    groups: list[dict] = Field(..., description="groups the user is a member of")
    timezone: Optional[str] = Field(default=None, description="timezone of the user")


class AuthenticatedPostgresClient(PostgresClient):
    def __init__(self, username: str):
        self.username = username
        super().__init__(role="app_user")
        self.user_info = None

    @classmethod
    async def create(cls, username: str):
        """Create and initialize an authenticated client instance"""
        try:
            client = cls(username)
            await client.initialize()
            client.user_info = await client.get_user_info()
            return client
        except Exception as e:
            logger.error(f"Error creating authenticated client for {username}: {e}")
            if hasattr(client, 'pool'):
                await client.close()
            return None

    @asynccontextmanager
    async def connection(self):
        """Get an authenticated connection"""
        async with super().connection() as conn:
            # First set role to app_user explicitly
            await conn.execute("SET ROLE app_user")
            # Then set the user context
            await conn.execute("SELECT connect_as_user($1)", self.username)
            yield conn

    async def get_user_info(self):
        """Fetch user information"""
        try:
            fields = "id, username, first_name, last_name, settings"
            users = await self.execute(
                f"SELECT {fields} FROM users WHERE username = $1",
                [self.username]
            )
            
            if not users:
                raise Exception("User not found")
            
            user = users[0]

            groups = await self.execute("SELECT id, name, description FROM groups")

            return UserInfo(**user, groups=groups)
            
        except Exception as e:
            logger.error(f"Error getting user info: {e}")
            raise

    async def execute(self, query: str, params: list = None):
        async with self.pool.acquire() as conn:
            # First set role to app_user explicitly
            await conn.execute("SET ROLE app_user")
            # Then set the user context
            await conn.execute("SELECT connect_as_user($1)", self.username)
            rows = await conn.fetch(query, *(params or []))
            return [self._format_row(dict(row)) for row in rows]

    async def fetch(self, query: str, params: list = None):
        conn = await self.acquire()
        try:
            return await conn.fetch(query, *(params or []))
        finally:
            await self.pool.release(conn)

    async def fetchrow(self, query: str, params: list = None):
        conn = await self.acquire()
        try:
            return await conn.fetchrow(query, *(params or []))
        finally:
            await self.pool.release(conn)

    async def initialize(self):
        """Initialize client and load user info"""
        await super().initialize()
        if self.user_info is None:
            self.user_info = await self.get_user_info()
        return self

    # Context manager methods to ensure user info is loaded
    async def __aenter__(self):
        if self.pool is None:
            await self.initialize()
        if self.user_info is None:
            self.user_info = await self.get_user_info()
        return self
```
## File: database/test_database_client.py
```python
import asyncio
import importlib
import database.postgres_client
importlib.reload(database.postgres_client)
from database.postgres_client import PostgresClient
from dotenv import load_dotenv
import os
import logging
import json
logger = logging.getLogger(__name__)

async def main():
    load_dotenv()
    os.environ["POSTGRES_PORT"] = "5432"
    os.environ["POSTGRES_HOST"] = "localhost"
    
    # # Method 1: Using the create class method
    # logger.info("--------------------------------")
    # client = PostgresClient()
    # await client.initialize()
    # try:
    #     users = await client.table("users").select("id", "username").execute()
        
    # finally:        
    #     await client.close()
    # logger.info(users)
    # logger.info(f"Found {len(users)} users")
    
    
    # role = "app_user"
    role = "postgres"


    # Method 2: Using context manager
    logger.info("--------------------------------")
    async with PostgresClient(role) as client:
        groups = await client.table("groups").select("id", "name", "description").execute()
    logger.info(f"Found {len(groups)} groups")
    print(json.dumps(groups, indent=4))

    
    # # Testing the RPC call
    # logger.info("get_group_id()--------------------------------")
    # async with PostgresClient(role) as client:
    #     result = await client.rpc("get_group_id", {"p_group_name": "test_group"}).execute()
    # logger.info("RPC result:")
    # logger.info(result)

    # logger.info("document_fts_search() --------------------------------")
    # async with PostgresClient(role) as client:
    #     result = await client.rpc(
    #         "document_fts_search", 
    #         params={
    #         "p_query_text": "Remove from Slack Channel?",
    #         "p_similarity_threshold": 0.0,
    #         "p_match_count": 2,
    #         "p_max_terms": 50
    #     }).execute()





if __name__ == "__main__":
    asyncio.run(main())
```
## File: database/test_user_admin.py
```python
# This is for futzing with the user admin

import json
from typing import List, Optional, Dict
from dotenv import load_dotenv
from database import UserAdmin
import os
from database import PostgresClient
import asyncio


load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

def get_user_groups(username: str) -> List[str]:
    user_admin = UserAdmin()
    user_info = user_admin.get_user_info(username=username)
    return [group['name'] for group in user_info.groups] if user_info.groups else []


# ############ Testing #################
async def main():

    async with PostgresClient() as postgres:
        user_admin = UserAdmin(postgres)

        # add new user
        username = "ingestion_agent"
        first_name = "Ingestion"
        last_name = "Agent"
        print(f"\nCreating user: {username} {first_name} {last_name}")
        try:
            response = await user_admin.create_user(username, first_name, last_name)
            print(f"create user response = {json.dumps(response, indent=4)}")
        except Exception as e:
            print(f"Error creating user: {e}")


        # # create groups
        # groups = {
        #     "Elim": "Elim housing Society (3885)",
        #     "AACB": "A&A Contract Customs Brokers Ltd (5187)",
        #     "CrisisCentre": "Crisis Intervention Centre of BC (7016)",
        #     "UrbanImpact": "Urban Impact (6926)",
        #     "Excell": "Excell Battery Company (3221)",
        #     "Protec": "Protec Dental Laboratories (2021) Inc",
        # }
        # for group_name, group_description in groups.items():
        #     print(f"\nCreating group: {group_name}: {group_description}")
        #     try:
        #         response = await user_admin.create_group(group_name, group_description)
        #         print(f"\nCreated group: {response}")
        #         print(f"\ncreate group response = {json.dumps(response, indent=4)}")
        #     except Exception as e:
        #         print(f"\nError creating group: {e}")

        # add user to group
        username = "ingestion_agent"
        group_name = "admins"
        print(f"\nAdding user {username} to group {group_name}")
        try:    
            response = await user_admin.add_user_to_groups(username, [group_name])
            print(f"\nadd user to group response = {json.dumps(response, indent=4)}")
        except Exception as e:
            print(f"\nError adding user to group: {e}")

        # get user info
        username = "ingestion_agent"
        print(f"\nTesting get_user_info for user: ", username)
        try:
            user_info = await user_admin.get_user_info(username=username)
            print(user_info)
            print(f"user_info: {json.dumps(user_info, indent=2)}")
        except Exception as e:
            print(f"\nError getting user info: {e}")
        

        # # list users in group
        # group_name = "test_group"
        # print(f"\nListing users in group: {group_name}")
        # try:
        #     response = await user_admin.list_users_in_group(group_name=group_name)
        #     print(f"list users in group response = {json.dumps(response, indent=4)}")
        # except Exception as e:
        #     print(f"\nError listing users in group: {e}")
        
        # # delete user
        # username = "chip@aech.ai"
        # print(f"\nDeleting user: {username}")
        # try:
        #     response = await user_admin.delete_user(username)
        #     print(f"\ndelete user response = {json.dumps(response, indent=4)}")
        # except Exception as e:
        #     print(f"\nError deleting user: {e}")

        
        # response = await user_admin.list_groups()
        # print(f"list groups response = {json.dumps(response, indent=4)}")

        # try:
        #     for group_name in new_group_names:
        #         response = await user_admin.delete_group(group_name)
        #         print(f"\ndelete group response = {json.dumps(response, indent=4)}")
        # except Exception as e:
        #     print(f"\nError deleting group: {e}")

        # response = await user_admin.list_groups()
        # print(f"list groups response = {json.dumps(response, indent=4)}")

        # try:
        #     response = await user_admin.list_users_in_group(group_name="managers")
        #     # response = user_admin.list_users_in_group(group_id="17dd16eb-3f2d-4fff-a398-bce997273ed6")
        #     print(f"\nlist users in group response = {response}")
        # except Exception as e:
        #     print(f"\nError listing users in group: {e}")

        # response = user_admin.add_user_to_groups(username="victor@aech.ai", groups=["hosers"])
        # print(f"add user to groups response = {json.dumps(response, indent=4)}")



if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/model_providers.py
```python
MODEL_PROVIDERS = {
    "gpt-4o": "openai",
    "gpt-4o-latest": "openai",
    "gpt-4o-2024-11-20": "openai",
    "gpt-4o-2024-08-06": "openai",
    "gpt-4o-mini": "openai",
    "gpt-4o-mini-2024-07-18": "openai",
    "gpt-4o-search-preview": "openai",
    "gpt-4.1-2025-04-14": "openai",
    "gpt-4.1-mini-2025-04-14": "openai",
    "gpt-4.1-nano=2025-04-14": "openai",
    "gpt-4.5-preview": "openai",
    "gpt-4.5-preview-2025-02-27": "openai",
    "o1": "openai",
    "o1-mini": "openai",
    "o1-mini-2024-09-12": "openai",
    "o1-preview": "openai",
    "o1-preview-2024-09-12": "openai",
    "o1-preview-2024-09-12": "openai",
    "o3-mini": "openai",
    "o3-mini-2025-01-31": "openai"
}

DEFAULT_PROVIDER_MODELS = {
    "openai": "gpt-4o-2024-11-20",
}
```
## File: llm/base_provider.py
```python
import os
from typing import Dict, Any, List, Union, Optional, Type
from PIL import Image
import base64
import io
import logging
from pydantic import BaseModel
from database import PostgresClient
import datetime
import asyncio
import uuid
import json
import contextvars
from contextlib import contextmanager

logger = logging.getLogger(__name__)

class LLMProvider:
    """Base class for Language Model Providers.
    
    Provides common functionality for handling text and image inputs
    across different LLM providers.
    
    Args:
        client_type (str): The type of LLM provider to initialize ("openai", "anthropic", or "cerebras")
    """

    # Class-level context variable for nesting
    nesting_level_var = contextvars.ContextVar("nesting_level", default=0)

    def __init__(self, client_type: str, default_model: str, azure: Union[bool, str, None] = None, database_client: Optional[Any] = None):
        """Initialize the LLM provider.
        
        Args:
            client_type (str): The type of LLM provider
            default_model (str): The default model to use
            azure (bool|str|None): Whether to use Azure OpenAI, used only to override the USE_AZURE_OPENAI env variable.
                                    (only applies to OpenAI providers)
            database_client (Optional[Any]): Optional database client to use for logging LLM calls.
                                           If provided, will use this client instead of creating a new one.
        """
        self.default_model = default_model
        self.database_client = database_client  # Store the provided database client
        
        if client_type == "openai":
            # If azure param not provided, use environment variable
            azure = os.environ.get("USE_AZURE_OPENAI", "false") if azure is None else azure
            use_azure = azure if isinstance(azure, bool) else azure.lower() == "true" # Convert to boolean if string
            if use_azure == True:
                from openai import AsyncAzureOpenAI
                self.client = AsyncAzureOpenAI(api_key=os.getenv("AZURE_OPENAI_API_KEY"))
            else:
                from openai import AsyncOpenAI
                self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        logger.debug(f"Initializing llm provider with client: {type(self.client)}")

    @contextmanager
    def _nesting_context(self):
        """Context manager to track nesting level of function calls.
        
        Used by providers to track the depth of nested function calls
        for logging and debugging purposes.
        """
        token = self.nesting_level_var.set(self.nesting_level_var.get() + 1)
        try:
            yield
        finally:
            self.nesting_level_var.reset(token)

    async def get_response(self, 
            user: Union[str, List[Union[str, Image.Image]]], 
            config: Optional[Dict[str, Any]], 
            system: Optional[str],
            response_format: Optional[Union[dict, Type[BaseModel]]] = None,
            observability_info: Optional[Dict[str, str]] = None) -> Union[str, dict, BaseModel]:
        """Get response from the language model."""
        raise NotImplementedError
    
    def _convert_image_to_base64(self, image: Image.Image) -> str:
        """Convert a PIL Image to base64 encoded string."""
        logger.debug(f"Converting {image.mode} image of size {image.size} to base64")
        if image.mode in ('RGBA', 'LA') or (image.mode == 'P' and 'transparency' in image.info):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1])
            image = background
        elif image.mode != 'RGB':
            image = image.convert('RGB')
        
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG", quality=95)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def _process_user_input(self, user_input: Union[str, List[Union[str, Image.Image]], List[Dict]]) -> List[Dict]:
        """Process user prompts and images into a format suitable for LLM API calls.
        
        Args:
            user_input: Either a string prompt, a list containing strings and/or PIL Images,
                       or a list of message dictionaries for function calling
            
        Returns:
            List[Dict]: A list of dictionaries, each containing either text content or processed image data
        """
        logger.debug(f"Processing user input of type: {type(user_input)}")
        
        # If input is already a list of message dictionaries (for function calling)
        if isinstance(user_input, list) and all(isinstance(x, dict) for x in user_input):
            return user_input
        
        # Handle string input
        if isinstance(user_input, str):
            return [{"type": "text", "text": user_input}]
        
        # Handle list of strings/images
        content = []
        for item in user_input:
            if isinstance(item, str):
                content.append({"type": "text", "text": item})
            elif isinstance(item, Image.Image):
                content.append(self._process_image(self._convert_image_to_base64(item)))
        return content

    def _process_image(self, base64_image: str) -> Dict:
        """Process a base64 encoded image into provider-specific format.
        
        Args:
            base64_image: Base64 encoded string of the image
            
        Returns:
            Dict: Provider-specific formatted image data
            
        Raises:
            NotImplementedError: This method must be implemented by provider-specific subclasses
        """
        raise NotImplementedError

    async def _log_llm_call(self, observability_info: dict, model: str, prompt: str, 
                      response: Any,  usage: Any, message_id: str = None) -> None:
        """Log LLM call details to the database.
        
        Args:
            observability_info: Dictionary containing {"ticket_id": <int>}
            model: Name of the model used
            prompt: The input prompt(s)
            response: The model's response
            usage: Token usage statistics from the API call
        """
        if message_id:
            logger.warning(f"Please use `observability_info` instead of `message_id` for logging LLM calls")
            return
        
        usage = self._format_usage(usage)
        
        # Convert response to JSON-serializable format
        if isinstance(response, BaseModel):
            response = repr(response)
        elif hasattr(response, '__dict__'):
            response = response.__dict__
        
        # Convert prompt to string if it's a list (for image inputs)
        if isinstance(prompt, list):
            prompt = str(prompt)
        
        max_prompt_length = 10000

        data = {
            "ticket_id": observability_info.get('ticket_id'),
            "model": model,
            "prompt": prompt[:max_prompt_length],
            "response": response,
            "input_tokens": usage["input_tokens"],
            "output_tokens": usage["output_tokens"],
        }
        data = {k: v for k, v in data.items() if v is not None}
        
        try:
            if self.database_client:
                # Use the provided database client directly
                await self.database_client.table("llm_calls").insert(data).execute()
            else:
                # Create a new connection if none was provided
                async with PostgresClient("postgres") as client:
                    await client.table("llm_calls").insert(data).execute()
        except Exception as e:
            logger.error(f"Error logging LLM call: {e}")
        return

    def _format_usage(self, usage: Any) -> Dict:
        """Format usage statistics into a standardized format.
        
        Args:
            usage: Provider-specific usage statistics
            
        Returns:
            Dict: Standardized usage statistics with 'input_tokens' and 'output_tokens'
            
        Raises:
            NotImplementedError: This method must be implemented by provider-specific subclasses
        """
        raise NotImplementedError

    def _serialize_value(self, value: Any) -> Any:
        """Serialize Python objects into JSON-serializable formats.
        
        Args:
            value: Any Python object that needs to be serialized
            
        Returns:
            Any: JSON-serializable version of the input
        """
        if isinstance(value, dict):
            return {k: self._serialize_value(v) for k, v in value.items()}
        elif isinstance(value, list):
            return [self._serialize_value(item) for item in value]
        elif isinstance(value, datetime.datetime):
            return value.isoformat()
        elif not isinstance(value, (str, int, float, bool, type(None))):
            return str(value)
        return value



# elif hasattr(value, '__dict__'):  # Handle custom objects
        #     return self._serialize_value(value.__dict__)
```
## File: llm/test_llm.py
```python
import asyncio
import logging
from provider import get_llm_provider
from dotenv import load_dotenv
from datetime import datetime
from PIL import Image
from pydantic import BaseModel
import json
import os
# Setup logging
logging.basicConfig(level=logging.INFO)

# Suppress logs from specific libraries
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("anthropic").setLevel(logging.WARNING)
logging.getLogger("cerebras").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)


async def test_single_call(observability_info: dict, prompt: str, provider, response_format=None, config=None):
    """Test a single async call to OpenAI"""
    
    start_time = datetime.now()
    response = await provider.get_response(
        user=prompt,
        observability_info=observability_info,
        response_format=response_format,
        config=config
    )
    end_time = datetime.now()
    time_taken = end_time - start_time
    print(f"Time taken: {time_taken}")
    print(f"Prompt: {prompt}")
    if isinstance(response, dict):
        print(f"Single call response:\n{json.dumps(response, indent=4)}")
    else:
        print(f"Single call response:\n{response}")
    


async def test_multiple_calls(observability_info: dict, prompts: list[str], provider, response_format=None, config=None):
    """Test multiple simultaneous calls to OpenAI"""
    
    tasks = [
        provider.get_response(user=prompt, observability_info=observability_info, response_format=response_format, config=config)
        for i, prompt in enumerate(prompts)
    ]
    
    # Run all tasks concurrently
    start_time = datetime.now()
    responses = await asyncio.gather(*tasks)
    end_time = datetime.now()
    time_taken = end_time - start_time
    print(f"Time taken: {time_taken}")
    

    # Print results
    for i, response in enumerate(responses):
        print(f"\nPrompt {i + 1}: {prompts[i]}")
        print(f"Response {i + 1}:\n{response}\n\n")

async def test_image_call(observability_info: dict, image_path: str, provider, response_format=None, config=None):
    """Test a call with an image"""
    
    # Load and process image
    image = Image.open(image_path)
    
    prompt = [
        "What's in this image?",
        image
    ]
    
    start_time = datetime.now()
    response = await provider.get_response(
        user=prompt,
        observability_info=observability_info,
        response_format=response_format,
        config=config
    )
    end_time = datetime.now()
    time_taken = end_time - start_time
    print(f"Time taken: {time_taken}")
    print(f"Image prompt response:\n{response}")

async def test_web_search(observability_info: dict, prompt: str, provider, response_format=None, config=None, web_search_options=None):
    """Test web search functionality"""
    
    start_time = datetime.now()
    response = await provider.get_response(
        user=prompt,
        observability_info=observability_info,
        response_format=response_format,
        config=config,
        web_search_options=web_search_options
    )
    end_time = datetime.now()
    time_taken = end_time - start_time
    print(f"Time taken: {time_taken}")
    print(f"Prompt: {prompt}")
    if isinstance(response, dict):
        print(f"Web search response:\n{json.dumps(response, indent=4)}")
    else:
        print(f"Web search response:\n{response}")
    
    # Check for annotations if response is a dict
    if isinstance(response, dict) and '_annotations' in response:
        print(f"\nCitations from web search:")
        for annotation in response['_annotations']:
            print(f"- {annotation.get('title', 'Untitled')} ({annotation.get('url', 'No URL')})")


async def run_basic_response_format_tests(prompt, provider, observability_info, config=None):
    """Test different response formats with a basic joke prompt"""
    print("\n---------Testing Basic Response Formats---------")
    
    
    
    class Joke(BaseModel):
        setup: str
        punchline: str
        
    json_response_format = {
        "setup": "the joke's setup",
        "punchline": "the joke's punchline"
    }

    response_formats = {
        "None": None,
        "Pydantic": Joke,
        "JSON": json_response_format
    }

    # Test single call with each response format
    for response_format in response_formats:
        print(f"\n***response format: {response_format}***")
        await test_single_call(
            observability_info=observability_info, 
            prompt=prompt, 
            provider=provider, 
            response_format=response_formats[response_format],
            config=config or {}
        )
        
async def run_web_search_tests(prompt, provider, observability_info, config=None):
    """Test web search functionality with different response formats"""
    print("\n---------Testing Web Search Functionality---------")
    
    # Define web search options
    web_search_options = {
        "search_context_size": "medium",  # Options: "low", "medium", "high"
        "user_location": {
            "type": "approximate",
            "approximate": {
                "country": "CA",
                "city": "Vancouver",
                "region": "British Columbia",
            }
        }
    }

    # Test with text response
    print("\n***Web search with plain text response***")
    await test_web_search(
        observability_info=observability_info,
        prompt=prompt,
        provider=provider,
        response_format=None,
        config=config or {},
        web_search_options=web_search_options
    )
    
    # Test with Pydantic response model
    print("\n***Web search with Pydantic model***")
    class NewsItem(BaseModel):
        headline: str
        summary: str
        source: str
        
    class NewsItems(BaseModel):
        items: list[NewsItem]
        
    try:
        await test_web_search(
            observability_info=observability_info,
            prompt=prompt,
            provider=provider,
            response_format=NewsItems,
            config=config or {},
            web_search_options=web_search_options
        )
    except ValueError as e:
        print(f"Error with Pydantic model and web search: {e}")

    # Test with JSON response format
    news_json_format = {
        "items": [
        {
            "headline": "the headline of the news item",
            "summary": "the summary of the news item",
            "source": "the source of the news item"
            }
        ]
    }
    
    print("\n***Web search with JSON response***")
    try:
        await test_web_search(
            observability_info=observability_info,
            prompt=prompt,
            provider=provider,
            response_format=news_json_format,
            config=config or {},
            web_search_options=web_search_options
        )
    except ValueError as e:
        print(f"Error with JSON format and web search: {e}")

async def run_concurrent_request_tests(provider, observability_info, config=None):
    """Test multiple concurrent requests"""
    print("\n---------Testing Multiple Concurrent Requests---------")
    
    prompts = [
        "Tell me a short joke about Python",
        "Tell me a short joke about JavaScript",
        "Tell me a short joke about Java",
        "Tell me a short joke about Rust"
    ]
    
    await test_multiple_calls(
        observability_info=observability_info,
        prompts=prompts,
        provider=provider,
        response_format=None,
        config=config or {}
    )

async def run_image_tests(provider, observability_info, image_path, config=None):
    """Test image-based requests with different response formats"""
    print("\n---------Testing Image Processing---------")
    
    if not os.path.exists(image_path):
        print(f"Image file not found: {image_path}")
        return
        
    class ImageDescription(BaseModel):
        subject: str
        surroundings: str
        
    json_response_format = {
        "subject": "the subject of the image",
        "surroundings": "the surroundings of the image"
    }
    
    response_formats = {
        "None": None,
        "Pydantic": ImageDescription,
        "JSON": json_response_format
    }
    
    for response_format in response_formats:
        print(f"\n***Image with {response_format} response***")
        await test_image_call(
            observability_info=observability_info,
            image_path=image_path,
            provider=provider,
            response_format=response_formats[response_format],
            config=config or {}
        )


async def main():
    # Load environment variables
    load_dotenv()
    os.environ["POSTGRES_HOST"] = "localhost"
    
    # observability_info = {"ticket_id": 1033009}
    observability_info = None
    print(json.dumps(observability_info, indent=4))

    # Choose a model/provider
    # provider_or_model = "openai"
    # provider_or_model = "gpt-4o-2024-11-20"
    provider_or_model = "gpt-4o-search-preview"  # For web search testing
    # provider_or_model = "deepseek-r1-distill-llama-70b"
    # provider_or_model = "llama-3.2-90b-vision-preview"
    
    provider = get_llm_provider(provider_or_model)
    
    # Common config
    config = {}
    
    
    # Image path for image tests
    image_path = r"/path/to/your/image.jpg"  # Update this path
    
    # prompt = "Tell me a short joke about dogs"
    # await run_basic_response_format_tests(prompt, provider, observability_info, config)

    prompt = "What's the weather tomorrow in Vancouver?"
    await run_web_search_tests(prompt, provider, observability_info, config)


    # await run_concurrent_request_tests(provider, observability_info, config)  
    # await run_image_tests(provider, observability_info, image_path, config)


if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/provider.py
```python
import os
from llm.model_providers import MODEL_PROVIDERS, DEFAULT_PROVIDER_MODELS
from llm.openai_provider import OpenAIProvider
import logging
from typing import Union
from database import PostgresClient
logger = logging.getLogger(__name__)

def get_llm_provider(provider_or_model: str, database_client: Union[PostgresClient, None] = None):
    """Factory function to create appropriate LLM provider instance.
    
    This function accepts either a provider name or a specific model name and returns
    the corresponding LLM provider instance. It checks against registered providers
    and models to determine the appropriate provider class to instantiate.
    
    Args:
        provider_or_model (str): Either a provider name (e.g., "openai", "anthropic")
            or a specific model identifier (e.g., "gpt-4o-2024-08-06", "claude-3-5-sonnet-20241022").
        
    Returns:
        LLMProvider: An instance of the appropriate provider class (OpenAIProvider,
            AnthropicProvider, or CerebrasProvider) initialized with the default model.
    
    Raises:
        ValueError: If the provided provider_or_model string is not recognized as a
            supported provider or model name.
    
    Examples:
        >>> provider = get_llm_provider("openai")
        >>> provider = get_llm_provider("gpt-4o-2024-08-06")
        >>> provider = get_llm_provider("anthropic")
    """
    registered_providers = DEFAULT_PROVIDER_MODELS.keys()
    registered_models = MODEL_PROVIDERS.keys()

    


    logger.debug(f"provider_or_model: {provider_or_model}")
    logger.debug(f"registered_providers: {registered_providers}")
    logger.debug(f"registered_models: {registered_models}")

    if provider_or_model in registered_models:
        provider = MODEL_PROVIDERS[provider_or_model]
        default_model = provider_or_model
    elif provider_or_model in registered_providers:
        provider = provider_or_model
        default_model = DEFAULT_PROVIDER_MODELS[provider]
    else:
        raise ValueError(f"Unsupported LLM provider or model: {provider_or_model}")
    
    logger.debug(f"Creating LLM provider instance for: {provider} with default model: {default_model}")
    if provider == "openai":
        return OpenAIProvider(default_model=default_model, database_client=database_client)
    # elif provider == "anthropic":
    #     return AnthropicProvider(default_model=default_model)
    # elif provider == "cerebras":
    #     return CerebrasProvider(default_model=default_model)
    # elif provider == "groq":
    #     return GroqProvider(default_model=default_model)
    else:
        raise ValueError(f"Unsupported LLM provider: {provider}")
```
## File: llm/add_new_model.py
```python
from database import PostgresClient
from dotenv import load_dotenv
import os
import json
import asyncio
load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"


async def add_new_model(model_data: dict):
    async with PostgresClient() as db:
        query = """
            INSERT INTO llms 
            (name, input_token_cost, output_token_cost)
            VALUES ($1, $2, $3)
            RETURNING id
        """
        params = (model_data["name"], model_data["input_token_cost"], model_data["output_token_cost"])
        response = await db.raw_query(query, params)
        return response

async def main():
    model_data = {
        "name": "gpt-4.1-nano",
        "input_token_cost": 0.1 / 1e6,
        "output_token_cost": 0.4 / 1e6
    }
    response = await add_new_model(model_data)
    print(f"Added new model: {json.dumps(response, indent=4)}")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/test_function_calling.py
```python
import asyncio
from llm.openai_provider import OpenAIProvider
from dotenv import load_dotenv
from llm import get_llm_provider
import os
import json
from database import PostgresClient, Conversation
from datetime import datetime
from pydantic import BaseModel, Field
# Load environment variables
load_dotenv(override=True)
os.environ["POSTGRES_PORT"] = "5433"
os.environ["POSTGRES_HOST"] = "localhost"
os.environ["USE_AZURE_OPENAI"] = "True"

def get_observability_info(message_id: str):
    
    postgres_client = PostgresClient()
    conversation = Conversation(postgres_client)

    user_id = "88a28dd0-3294-4780-b9c7-874cd4e4654d" # trevor
    conversation_id = "dummy_conversation"
    message_id = "dummy_message"
    message_content = "test_message"
    app_id = None
    conversation_id = conversation.create_conversation(conversation_id=conversation_id, user_id=user_id)

    id = conversation.create_message(
        conversation_id=conversation_id, 
        message_id=message_id,
        sender="user",
        content=message_content,
        app_id=app_id,
        message_type="email"
        )
    return {"source_id": id, "source_type": "message"}

async def get_weather(location: str, date: str) -> str:
    """
    A sample function to get current weather.
    For demonstration purposes, this function returns a fixed value.
    In a real application, you could integrate with a weather API.
    """
    weather_info = {
        "Boston": f"WEATHER = On {date}, the weather in Boston is sunny, 75°F",
        "San Francisco": f"WEATHER = On {date}, the weather in San Francisco is foggy, 60°F",
        "New York": f"WEATHER = On {date}, the weather in New York is cloudy, 70°F"
    }
    try:
        response = weather_info[location]
    except Exception as e:
        raise Exception(f"Weather data is not available for the city: {e}")
    
    return response

def get_today_date() -> str:
    return datetime.now().strftime("%Y-%m-%d")

def convert_farenheight_to_celsius(farenheight: float) -> float:
    return round((farenheight - 32) * 5/9, 1)

FUNCTIONS = [
    {
        "schema": {
            "name": "get_weather",
            "description": "Get the current weather in a given location.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city name, e.g. Boston"
                    },
                    "date": {
                        "type": "string",
                        "description": "The date, e.g. 2025-02-10"
                    }
                },
                "required": ["location", "date"]
            }
        },
        "bound_method": get_weather
    },
    {
        "schema": {
            "name": "get_today_date",
            "description": "Get the current date.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        },
        "bound_method": get_today_date
    },
    {
        "schema": {
            "name": "convert_farenheight_to_celsius",
            "description": "Convert a temperature from farenheight to celsius.",
            "parameters": {
                "type": "object",
                "properties": {
                    "farenheight": {
                        "type": "number",
                        "description": "The temperature in farenheight"
                    }
                },
                "required": ["farenheight"]
            }
        },
        "bound_method": convert_farenheight_to_celsius
    }
]

async def test_function_calling(prompt, provider, format_types = ["None", "dict", "pydantic"]):    
    class WeatherInfo(BaseModel):
        location: str = Field(description="The city name, e.g. Boston")
        date: str = Field(description="The date, e.g. 2025-02-10")
        weather: str = Field(description="The weather in the city")
        temperature: str = Field(description="The temperature in the city")
    weather_info_dict = {
        "location": "<location of weather forecast>",
        "date": "<date of weather forecast>",
        "weather": "<weather forecast>",
        "temperature": "<temperature forecast>"
    }
    response_formats = {
        "None": None, 
        "dict": weather_info_dict,
        "pydantic": WeatherInfo, 
    }
    for format_type in format_types:
        print(f"\n\n{'-'*25}Using '{provider.default_model}' with response format: {format_type}{'-'*25}")
        
        
        response = await provider.get_response(
            prompt,
            config={},
            functions=FUNCTIONS,
            function_call="auto",
            response_format=response_formats[format_type],
            max_function_iterations=20
        )
        print(f"\nFinal Response:\n{response}\n")


async def main():
    # prompt = "What's the weather in New York in 7 days?. Please tell me the date too. I want the temperature in celsius"
    # prompt = "I want to travel to the city with the nicest weather in 2 days. Should I go to Boston or San Francisco? Please use celsius for all temperatures"
    prompt = "What is the weather in Boston tomorrow?"
    models = [
            "gpt-4o", 
            # "claude-3-5-sonnet-20241022"
        ]
    
    format_types = [
        "None", 
        # "dict", 
        # "pydantic"
    ]

    for model in models:
        print(f"\n\n\n{'#'*80}\nTesting with model: {model}\n{'#'*80}")
        provider = get_llm_provider(model, azure=os.environ.get("USE_AZURE_OPENAI"))
        await test_function_calling(prompt, provider, format_types)

if __name__ == "__main__":

    asyncio.run(main())
```
## File: llm/__init__.py
```python
from llm.provider import get_llm_provider
from llm.openai_provider import OpenAIProvider
from llm.base_provider import LLMProvider
from llm.llm_function_extractor import LLMFunctionExtractor

all = [
    get_llm_provider,
    OpenAIProvider,
    LLMProvider,
    LLMFunctionExtractor
]
```
## File: llm/README.md
```markdown
# LLM Provider

This package provides a unified interface for interacting with various Language Model providers (OpenAI, Anthropic, etc.). It supports text generation, structured outputs, and function calling capabilities.

## Environment Variables


Set up your environment variables in the root `.env` file.

**To use AzureOpenAI**, set the environment variable`USE_AZURE_OPENAI=True`. This will automatically use the AzureOpenAI API with the `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT` environment variables.

```bash
# .env file

# For vanilla OpenAI
OPENAI_API_KEY=your_openai_key

# Or for Azure OpenAI
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
USE_AZURE_OPENAI=True

# Or other providers
ANTHROPIC_API_KEY=your_anthropic_key
```


## Basic Usage

### Instantiating a Provider

Instantiate a provider using the factory function.


```python
# Using factory function that loads the default model for the provider 
from llm import get_llm_provider
model_or_provider = "gpt-4o" # or "openai", or "anthropic", or "claude-3-opus-20240229"
provider = get_llm_provider(model_or_provider)  
```

### Simple Text Generation (`response_format=None`)

```python
response = await provider.get_response(
    user="Tell me a joke about dogs",
    config={
        "temperature": 0.7,
        "max_tokens": 150
    }
)
print(response)

# Response:
# Why did the dog sit in the shade?
# Because he didn't want to be a hot dog!
```

### JSON Output (`response_format={"some_key": "some_value", etc}`)

You can request responses in specific JSON formats by using the `response_format` parameter.

```python
json_format = {
    "setup": "the joke's setup",
    "punchline": "the joke's punchline"
}

response = await provider.get_response(
    user="Tell me a joke about programming",
    config={"temperature": 0.2},
    response_format=json_format
)
print(response)  # Returns a dictionary matching the format

# {'setup': 'Why did the dog sit in the shade?', 'punchline': 'Because he didn't want to be a hot dog!'}
```

### Structured Output (`response_format=PydanticModel`)

For type-safe responses, use Pydantic models by passing a Pydantic model to the `response_format` parameter.

```python
from pydantic import BaseModel, Field

class Joke(BaseModel):
    setup: str = Field(description="The setup of the joke")
    punchline: str = Field(description="The punchline of the joke")

response = await provider.get_response(
    user="Tell me a joke about dogs",
    config={"temperature": 0.7},
    response_format=Joke
)
print(response)

# Joke(setup='Why did the dog sit in the shade?', punchline="Because he didn't want to be a hot dog!")
```

## Multimodal inputs

The `user` parameter can be a a simple string or a list of text strings and PIL images. These can be combined in any order. It is best not to exceed 5-10 images because the latency increases dramatically.

```python
from PIL import Image

image = Image.open("path/to/your/image.jpg")

response = await provider.get_response(
    user=["what is in this image?", image]
)
print(response)

# This is a picture of dogs playing poker. Some are smoking cigars and some are drinking. 
```

## Configuration Options

These are specified by the optional `config` parameter. Common configuration options include:

```python
config = {
    "temperature": 0.3,  # Controls randomness (0.0 to 1.0)
    "max_tokens": 750,   # Maximum length of response
    "model": "gpt-4"     # Override default model
}

response = await provider.get_response(
    user="What is a semaphore?",
    config=config,
    
)
```

## System Messages

You can provide system messages to guide the model's behavior:

```python
response = await provider.get_response(
    user="Tell me a joke",
    system="You are a French comedian who only responds in French"
)
print(response)

# Pourquoi les chiens ont-ils joué au poker ?
# Parce qu'ils ont besoin de gagner des cadeaux !   
```

## Observability

Track LLM calls with observability info:

```python
response = await provider.get_response(
    user="Your prompt",
    observability_info={
        "source_id": "message_uuid", # the uuid of the message in the 'messages' table
        "source_type": "message"     # the type of the source (e.g. "message", "email", typically "message")
    }
)
```

## Function Calling

The providers support function calling that can initiate a series of function calls with a single prompt. It works like this:

- send prompt to llm with function definitions
- if the LLM decides it needs to call a function:
  - llm responds with a function request, including the function name and argument values
  - we call the function with the provided args then send the result back to the llm
  - the llm decides to call another function or not
- this process continues until the LLM decides it has enough information to formulate a final response.


To use function calling, we just need to pass a `functions` parameter to the `get_response` method. Optionally, we can specify the `max_function_iterations` parameter to limit the number of function calls for safety.


### The `functions` parameter

This contains all the information the LLMProvider needs to execute function calls. It is a list of dictionaries with a `schema` and a `bound_method`.

- `schema` is used to inform the llm about what the function does and what are its input parameters
- `bound_method`  is the actual function that will be called when the LLM responds with a function call message

```python
# simple example using functions
def get_weather(location: str, date: str) -> str:
    """
    Get the current weather in a given location.

    Args:
        location (str): The city name
        date (str): The date (YYYY-MM-DD)
        
    Returns:
        str: The weather for the location and date
    """
    # NOTE: This is just a dummy function for demonstration purposes
    return f"The weather in {location} on {date} is sunny and 21°C"

def get_today_date() -> str:
    return datetime.now().strftime("%Y-%m-%d")

functions = [
    {
        "schema": {
            "name": "get_weather",
            "description": "Get the current weather in a given location./n/nReturns str: The weather for the location and date",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city name, e.g. Boston"
                    },
                    "date": {
                        "type": "string",
                        "description": "The date, e.g. 2025-02-10"
                    }
                },
                "required": ["location", "date"]
            }
        },
        "bound_method": get_weather
    },
    {
        "schema": {
            "name": "get_today_date",
            "description": "Get the current date.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        },
        "bound_method": get_today_date
    }
]

response = await provider.get_response(
    user="What's the weather in Boston tomorrow?",
    functions=functions,
    max_function_iterations=20,
    response_format=None # Can specify response format like JSON or Pydantic
)
print(f"Final Response:\n{response}")
```

This will begin a tool calling chain. You can see the function calls and the results in the logs:

```bash
INFO:llm.openai_provider:Starting level 1 function calling sequence with 2 functions
INFO:llm.openai_provider:Available functions: ['get_weather', 'get_today_date']
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 1/20 ----------
INFO:llm.openai_provider:calling 'get_today_date' with args: {}
INFO:llm.openai_provider:'get_today_date' returned: 2025-02-20
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 2/20 ----------
INFO:llm.openai_provider:calling 'get_weather' with args: {"location":"Boston","date":"2025-02-21"}
INFO:llm.openai_provider:'get_weather' returned: The weather in Boston on 2025-02-21 is sunny and 21°C
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 3/20 ----------
INFO:llm.openai_provider:Level 1 function call sequence complete

Final Response:
The weather in Boston on 2025-02-21 is sunny and 21°C
```

### Building the `functions` object with `LLMFunctionExtractor`

To build the `functions` object for the functions in a python class, we can use the `LLMFunctionExtractor` class. This will extract the functions from a the class.

**IMPORTANT** The JSON schema for the functions is generated from the docstrings of the functions. So make sure to include detailed docstrings for the functions you want to be able to call.

```python
from llm import get_llm_provider
from llm.function_extractor.llm_function_extractor import LLMFunctionExtractor

# Load functions from a Python file
script_path = "path/to/your/script.py"
python_object = YourClass()  # Instance of the class containing the methods
functions = LLMFunctionExtractor(script_path).get_functions(
    python_object,        # the instatiated class object
    skip_underscored=True # skip functions that start with an underscore (default is True)
)

# Pass functions to get_response
provider = get_llm_provider("gpt-4")
response = await provider.get_response(
    user="Your prompt here",
    functions=functions,  # List of function definitions with bound methods
    function_call="auto",  # Let the model choose which function to call
    max_function_iterations=20  # Maximum number of nested function calls
)
```

For a simple example of function calling, see `llm/demo_function_calling/demo_simple_function_call.py` in the repository.

### Note on Function Argument Data Types

Since the LLM only outputs text, all function arguments and return values are handled as text. This raises some issues with arguments with data types:

- **dictionary**:  cannot be passed as dictionaries,  *they must be passed as JSON strings*. Any function that expects a dict should also accept a JSON string, eg `dict_arg: dict|str`.
- **datetime**: cannot be passed as datetime objects, *they must be passed as ISO date strings*. This means that any function that expects a datetime object should also accept an ISO date string, eg `dt_arg: datetime|str`.


This means that the functions args must be overloaded to accept the string serialization of the data type as well as the data type itself, then the function must parse the string as needed. See the example below:

```python
import json
from datetime import datetime

def some_function(dict_arg: dict|str, datetime_arg: datetime|str) -> str:

    # convert JSON string to dict
    dict_arg = json.loads(dict_arg) if isinstance(dict_arg, str) else dict_arg

    # convert ISO date string to datetime object
    dt_arg = datetime.fromisoformat(dt_arg) if isinstance(dt_arg, str) else dt_arg

    # do something with the args
    return "result"
```

#### Concrete example of handling dictionary arguments

In the example below, the `get_weather_data` function returns a dict, so we must ensure the `write_weather_report` function expects a JSON string. This is done by overloading the `weather_data: str|dict` argument and parsing the JSON string as needed with `json.loads(weather_data)`. Important: the type hint must be `str|dict` not `dict|str` because the `LLMFunctionExtractor` will only apply the first type hint. See `LLMFunctionExtractor` below:

```python
import json
from datetime import datetime

# Example of a function that returns a dict
def get_current_weather_data(location: str) -> dict:
    """
    Get the weather data for a location and date

    Args:
        location (str): The city name
        date (datetime|str): The date (YYYY-MM-DD)
        
    Returns:
        dict: The weather data for the location and date
    """
    return {
        "location": location,
        "date": datetime.now().strftime("%Y-%m-%d"),
        "weather": "sunny",
        "temperature": 21
    }
    

# Example of a function that expects a dict
def write_weather_report(weather_data: str|dict) -> str:
    """
    Write a weather report for the given weather data

    Args:
        weather_data (str|dict): The weather data for the location and date
        
    Returns:
        str: The weather report
    """
    ##### If the weather_data is a JSON string, parse it into a dict as needed #####
    weather_data = json.loads(weather_data) if isinstance(weather_data, str) else weather_data

    return f"The weather in {weather_data['location']} on {weather_data['date']} is {weather_data['weather']} and {weather_data['temperature']}°C"
```

For a complete implementation example of handling dictionary arguments, see `llm/demo_function_calling/demo_nested_function_calls.py` in the repository.


### Handling Binary Objects and File Operations

Often we need to call functions that create files or handle binary objects. This is a bit tricky because the LLM function calling can't return a file object. So we need to do it this way:

1. Use the `tempfile` module to create a temporary directory defined within the context manager where the llm call is made. (e.g. `with tempfile.TemporaryDirectory() as temp_dir:`)
2. The llm call will return file paths as strings (since binary data cannot be passed directly)
3. Handle the files within the context manager
4. The temporary directory and its contents are automatically cleaned up when the context manager is exited.

Here's an example of creating a weather report PDF:

```python
import tempfile
import shutil
import os

async def create_weather_report(query: str, output_folder: str) -> str:
    """Creates a weather report based on the user query.
    
    Args:
        query (str): The query describing what weather report to create
        output_folder (str): Folder where the report should be saved
        
    Returns:
        str: Path to the generated report
    """
    # Function implementation that creates and saves 'report.pdf' in the output_folder
    output_path = f"{output_folder}/report.pdf"
    return output_path

async def main():
    query = "Please prepare a 7-day weather report for Fort Worth TX"
    os.makedirs(output_folder, exist_ok=True)
    
    # Use a temporary output_folder for file operations
    with tempfile.TemporaryDirectory() as output_folder:
        # Generate the report in the temp directory
        temp_path = await create_weather_report(query, output_folder)
        
        # Process the temp file as needed (e.g. send it to the user)
        print(f"Processing file: {temp_path}")
        
        
    # Outside the context manager, the temporary directory and its contents are automatically cleaned up
    print(f"The temp directory has been cleaned up")
```

**Important Notes for File Operations:**

- Use the `tempfile.TemporaryDirectory()` folder as the `output_folder` parameter for the functions that create files
- Functions that create files should 
  - have an `output_folder` parameter 
  - return the path to the file as a string
- Handle file processing outside the function calling chain, but within the context manager

For a complete implementation example, see `llm/demo_function_calling/demo_binar

## Nested Function Calling

It is possible to have nested calls, where an LLM call with functions is made with functions that invoke another LLM call with functions. The LLMProvider will handle this automatically to any nesting depth.

For an example, see `llm/demo_function_calling/demo_nested_function_calls.py` in the repository (note that you need an `OWM_API_KEY` in your .env file to run it).

In it we make an LLM call (nest level 1) with the `WeatherJoker` class' functions to make a funny weather forecast. The `WeatherJoker.get_weather` method then makes another LLM call (nest level 2) with the `Weather` class' functions to get the lat,lon coordinates and current weather for a given location. Then it goes back to nest level 1 and uses the weather data to create a funny weather forecast with the `WeatherJoker.get_funny_forecast` method.

In this example, the prompt is *"Give me a funny weather forecast for New Westminster"*. You can see in the logs that the nesting levels and iteration number for each function call is displayed.

```text
INFO:llm.openai_provider:Starting level 1 function calling sequence with 3 functions
INFO:llm.openai_provider:Available functions: ['get_weather', 'get_funny_forecast', 'get_funny_comparative_forecast']
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 1/20 ----------
INFO:llm.openai_provider:calling 'get_weather' with args: {"user_prompt":"New Westminster"}
INFO:llm.openai_provider:Starting level 2 function calling sequence with 2 functions
INFO:llm.openai_provider:Available functions: ['get_location', 'get_weather_data']
INFO:llm.openai_provider:---------- Function call: Level 2, Iteration 1/20 ----------
INFO:llm.openai_provider:calling 'get_location' with args: {"prompt":"New Westminster"}
INFO:llm.openai_provider:'get_location' returned: {'lat': 49.2067726, 'lon': -122.9108818, 'location_name': 'New Westminster'}
INFO:llm.openai_provider:---------- Function call: Level 2, Iteration 2/20 ----------
INFO:llm.openai_provider:calling 'get_weather_data' with args: {"lat":49.2067726,"lon":-122.9108818,"location_name":"New Westminster"}
INFO:llm.openai_provider:'get_weather_data' returned: {'current': {'dt': '2025-02-20T12:47:14-08:00', 'sunrise': '2025-02-20T07:10:57-08:00', 'sunset': '2025-02-20T17:40:03-08:00', 'temp': 8.02, 'feels_like': 4.67, 'pressure': 1028, 'humidity': 79, 'dew_point': 4.6, 'uvi': 0.19, 'clouds': 100, 'visibility': 10000, 'wind_speed': 6.17, 'wind_deg': 120, 'wind_gust': 8.75, 'weather': [{'id': 500, 'main': 'Rain', 'description': 'light rain', 'icon': '10d'}], 'rain': {'1h': 0.25}}, 'location': 'New Westminster'}
INFO:llm.openai_provider:---------- Function call: Level 2, Iteration 3/20 ----------
INFO:llm.openai_provider:Level 2 function call sequence complete
INFO:llm.openai_provider:'get_weather' returned: {"current":{"dt":"2025-02-20T12:47:14-08:00","sunrise":"2025-02-20T07:10:57-08:00","sunset":"2025-02-20T17:40:03-08:00","temp":8.02,"feels_like":4.67,"pressure":1028,"humidity":79,"dew_point":4.6,"uvi":0.19,"clouds":100,"visibility":10000,"wind_speed":6.17,"wind_deg":120,"wind_gust":8.75,"weather":[{"id":500,"main":"Rain","description":"light rain","icon":"10d"}],"rain":{"1h":
0.25}},"location":"New Westminster"}
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 2/20 ----------
INFO:llm.openai_provider:calling 'get_funny_forecast' with args: {"weather_data":"{\"current\":{\"dt\":\"2025-02-20T12:47:14-08:00\",\"sunrise\":\"2025-02-20T07:10:57-08:00\",\"sunset\":\"2025-02-20T17:40:03-08:00\",\"temp\":8.02,\"feels_like\":4.67,\"pressure\":1028,\"humidity\":79,\"dew_point\":4.6,\"uvi\":0.19,\"clouds\":100,\"visibility\":10000,\"wind_speed\":6.17,\"wind_deg\":120,\"wind_gust\":8.75,\"weather\":[{\"id\":500,\"main\":\"Rain\",\"description\":\"light rain\",\"icon\":\"10d\"}],\"rain\":{\"1h\":0.25}},\"location\":\"New Westminster\"}"}
INFO:llm.openai_provider:'get_funny_forecast' returned: 
Good day, New Westminster! Or as we locals affectionately call it, "Not Quite Vancouver". Am I right? Let's dive into today's weather, because if there's one thing we love more than our overpriced coffee, it's talking about the weather that drives us to drink it in the first place.

Current conditions are a delightful 8.02°C, which feels like a bone-chilling 4.67°C. That's not just a temperature drop, folks—that's Mother Nature's way of reminding you that you own three separate jackets for a reason. So, layer up like you're an onion trying to hide from a salad.

Speaking of hiding, the skies will be 100% cloudy today, which means you'll have the perfect excuse to avoid awkward eye contact with that neighbor who insists on telling you about their cat's gluten-free diet. And with 79% humidity, your hair can go on an adventure of its own—channeling either a 1980s rock band or a wet mop, depending on your luck.

Expect light rain, or as we call it here, a "mild sprinkle". It's the kind of rain that makes your umbrella feel like that gym membership you bought last January—completely unnecessary but still nice to have. Just 
a light drizzle of 0.25mm per hour to keep your windshield wipers on their toes.

Wind speeds are breezing by at 6.17 meters per second with gusts that might just push that meticulously raked pile of leaves back onto your lawn. So, hold onto your hats—unless it's a Vancouver Canucks hat, in which case, keep it close to your heart and remember there's always next season.

Sunrise was at 7:10 AM, but honestly, who even saw it with all those clouds? Sunset is at 5:40 PM, but in true Pacific Northwest fashion, it'll probably feel like midnight by lunch.

So, bundle up, grab your favorite artisanal brew, and remember: if you don't like the weather in New Westminster, just wait five minutes. Or, better yet, move to Vancouver and complain there instead.
INFO:llm.openai_provider:---------- Function call: Level 1, Iteration 3/20 ----------
INFO:llm.openai_provider:Level 1 function call sequence complete
```


## Supported Providers

- OpenAI
- Anthropic
- Cerebras
- Groq

## Model Lookup

There is a lookup table in `llm/model_providers.py` that maps model names to provider names and sets the default model for each provider. As new models are added, they should be added to the `MODEL_PROVIDERS` dictionary and the `DEFAULT_PROVIDER_MODELS` dictionary.


```python
MODEL_PROVIDERS = {
    "gpt-4o": "openai",
    "gpt-4o-latest": "openai",
    ...
    "claude-3-5-haiku-20241022": "anthropic",
    "claude-3-5-sonnet-20240620": "anthropic",
    "claude-3-5-sonnet-20241022": "anthropic",
    "llama3.1-405b": "cerebras",
    "llama3.3-70b": "cerebras",
    "deepseek-r1-distill-llama-70b": "groq",
    "llama-3.2-90b-vision-preview": "groq",
    "llama-3.3-70b-versatile": "groq"

}
DEFAULT_PROVIDER_MODELS = {
    "openai": "gpt-4o-2024-08-06",
    "anthropic": "claude-3-5-sonnet-20241022",
    "cerebras": "llama3.3-70b",
    "groq": "llama-3.2-90b-vision-preview"
}
AZURE_OPENAI_DEPLOYMENTS = {
    "gpt-4o": "gpt-4o",
    "gpt-4o-latest": "gpt-4o",
    "gpt-4o-2024-11-20": "gpt-4o",
    "gpt-4o-2024-08-06": "gpt-4o",
    "gpt-4o-mini": "gpt-4o-mini",
    "gpt-4o-mini-2024-07-18": "gpt-4o-mini",
}
```

### Note for AzureOpenAI

The deployments (what they call model) are different from the model names. For example, there is no `gpt-4o-2024-08-06` deployment, but there is a `gpt-4o` deployment. As a result if we are using AzureOpenAI, the OpenAIProvider will use the `AZURE_OPENAI_DEPLOYMENTS` dictionary to map the model name to the deployment name.
```
## File: llm/openai_provider.py
```python
import json
import os
import logging
from typing import Dict, Any, List, Union, Optional, Type
from pydantic import BaseModel
from llm.base_provider import LLMProvider
from PIL import Image
from dotenv import load_dotenv
import inspect
import contextvars
load_dotenv()

logger = logging.getLogger(__name__)
# os.environ["OPENAI_API_TYPE"] = "openai"

DEFAULT_MAX_FUNCTION_CALL_ITERATIONS = 20

class OpenAIProvider(LLMProvider):
    """Provider class for OpenAI's language models.
    
    Handles interactions with OpenAI's API, including text generation, JSON responses,
    structured data parsing using Pydantic models, and function calling.

    Args:
        default_model (str): The default OpenAI model to use for requests (e.g., "gpt-4o", "gpt-4o-2024-08-06")
        database_client: Optional database client for additional functionality

    Example:
        ```python
        provider = OpenAIProvider(default_model="gpt-4o")
        ```
    """
    
    def __init__(self, default_model: str, database_client = None):
        logger.debug(f"Initializing OpenAIProvider with default_model={default_model}")
            
        super().__init__("openai", default_model, database_client=database_client)
     

    def _process_image(self, base64_image: str) -> Dict:
        """Convert a base64 encoded image to OpenAI's expected format.
        
        Args:
            base64_image (str): Base64 encoded image string (without the "data:image/jpeg;base64," prefix)
            
        Returns:
            Dict: Image data formatted for OpenAI's API with high detail setting

        Example:
            ```python
            base64_str = "iVBORw0KGgoAAAANSUhEUgAA..."  # Your base64 image string
            image_data = provider._process_image(base64_str)
            ```
        """
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}",
                "detail": "high"
            }
        }
    
    def _format_usage(self, usage: Union[Any, List[Any]]) -> Dict:
        """Format OpenAI's usage statistics into standardized format.
        
        Args:
            usage (Any): Usage data from OpenAI's API response. Can be a single usage object
                        or a list of usage objects from multiple API calls.
            
        Returns:
            Dict: Standardized usage data with input_tokens and output_tokens
        """
        if isinstance(usage, list):
            input_tokens = sum(u.prompt_tokens for u in usage)
            output_tokens = sum(u.completion_tokens for u in usage)
        else:
            input_tokens = usage.prompt_tokens
            output_tokens = usage.completion_tokens
        
        return {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
        }

    async def get_response(self, 
                           user: Union[str, List[Union[str, Image.Image]]], 
                           config: Optional[Dict[str, Any]] = None, 
                           system: Optional[str] = None,
                           response_format: Optional[Union[dict, Type[BaseModel]]] = None,
                           observability_info: Optional[Dict[str, str]] = None,
                           functions: Optional[List[Dict]] = None,
                           function_call: Optional[str] = "auto",
                           max_function_iterations: int = DEFAULT_MAX_FUNCTION_CALL_ITERATIONS,
                           web_search_options: Optional[Dict[str, Any]] = None
                           ) -> Union[str, dict, BaseModel]:
        """Generate a response using OpenAI's API with support for multiple input types and function calling.

        Args:
            user: User input as string, list of strings/images, or message dictionaries
            config: Optional configuration dictionary for the API call (e.g., {"temperature": 0.7, "max_tokens": 150})
            system: Optional system message to guide model behavior
            response_format: Optional format specification (dict schema or Pydantic model)
            observability_info: Optional dict with ticket_id for logging (e.g., {"ticket_id": 456})
            functions: Optional list of available functions with their schemas and bound_methods
            function_call: Optional specification for function calling behavior ("auto" or specific function name)
            max_function_iterations: Maximum number of allowed function call iterations, defaults to 5
            web_search_options: Optional configuration for web search capabilities (e.g., {"search_context_size": "medium", 
                              "user_location": {"type": "approximate", "approximate": {"country": "US"}}})

        Returns:
            Union[str, dict, BaseModel]: Response in the specified format (string, JSON, or Pydantic model)

        Raises:
            ValueError: If response parsing fails
            Exception: For API errors or function execution failures
        """
        config = config or {}
        config['model'] = config.get('model', self.default_model)
        
        logger.debug(f"Generating OpenAI response with model: {config['model']}")
        
        # Add web search options if provided
        if web_search_options is not None:
            config['web_search_options'] = web_search_options
            logger.debug(f"Using web search with options: {web_search_options}")
        
        # Construct initial messages list.
        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        
        # Add user messages.
        user_message_content = self._process_user_input(user)
        messages.append({"role": "user", "content": user_message_content})
        
        # Select the appropriate response method based on response_format.
        if isinstance(response_format, type) and issubclass(response_format, BaseModel):
            response_method = self._get_structured_response
        elif isinstance(response_format, dict):
            response_method = self._get_json_response
        else:
            response_method = self._get_simple_response

        # Delegate to the chosen response method.
        with self._nesting_context():
            response, usage = await response_method(
                messages, 
                config,
                response_format=response_format, 
                functions=functions,
                function_call=function_call,
                max_iterations=max_function_iterations
            )
    
        # Log the call if observability info is provided.
        if observability_info:
            logger.debug(f"Logging LLM call for: {observability_info}")
            await self._log_llm_call(observability_info, config['model'], user, response, usage)

        return response

    async def _execute_function_calls(self,
                                    messages: List[Dict],
                                    config: Dict,
                                    functions: List[Dict],
                                    function_call: str = "auto",
                                    max_iterations: int = DEFAULT_MAX_FUNCTION_CALL_ITERATIONS
                                    ) -> tuple[List[Dict], List]:
        """Execute a series of function calls based on model responses.

        Args:
            messages: List of conversation messages in OpenAI format
            config: API configuration dictionary
            functions: List of available functions with schemas and bound_methods
            function_call: Function calling behavior ("auto" or specific function)
            max_iterations: Maximum number of allowed function call iterations
            

        Example function format:
            
            functions = [{
                "schema": {
                    "name": "get_weather",
                    "description": "Get current weather in a location",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {
                                "type": "string",
                                "description": "City name"
                            }
                        },
                        "required": ["location"]
                    }
                },
                "bound_method": lambda location: {"temp": 72, "condition": "sunny"}
            }]
            

        Returns:
            tuple[List[Dict], List]: Updated message history and accumulated usage statistics
        """
        current_level = self.nesting_level_var.get()
        logger.info(f"Starting level {current_level} function calling sequence with {len(functions)} functions")
        logger.info(f"Available functions: {[f['schema']['name'] for f in functions]}")
        
        # Initialize usage tracking
        function_call_usage = []
        
        # Create function-specific config once
        function_config = config.copy()
        function_config['functions'] = [f["schema"] for f in functions]
        function_config['function_call'] = function_call
        
        # Map function names to their bound_methods for quick lookup
        available_functions = {f["schema"]["name"]: f["bound_method"] for f in functions}
        
        iteration = 1
        while iteration <= max_iterations:
            logger.info(f"---------- Function call: Level {current_level}, Iteration {iteration}/{max_iterations} ----------")

            completion = await self.client.chat.completions.create(
                messages=messages, **function_config
            )
            function_call_usage.append(completion.usage)
            response_obj = completion.choices[0].message
            
            # If no function call is requested, we're done
            if not hasattr(response_obj, "function_call") or response_obj.function_call is None:
                logger.info(f"Level {current_level} function call sequence complete")
                messages.append({"role": "assistant", "content": response_obj.content})
                logger.debug(f"Summary of function call messages:{json.dumps(messages, indent=2)}")
                return messages, function_call_usage
            
            # Process function call
            function_name = response_obj.function_call.name
            args_str = response_obj.function_call.arguments
            
            # Append the assistant's function call message
            messages.append({
                "role": "assistant",
                "content": None,
                "function_call": {"name": function_name, "arguments": args_str}
            })
            
            # Execute the function
            try:
                logger.info(f"calling '{function_name}' with args: {args_str}")
                args = json.loads(args_str)
                
                # Parse any JSON string values that should be objects/arrays
                for key, value in args.items():
                    if isinstance(value, str):
                        try:
                            args[key] = json.loads(value)
                        except json.JSONDecodeError:
                            continue
                
                if function_name not in available_functions:
                    raise ValueError(f"Function '{function_name}' is not available. Available functions are: {', '.join(available_functions.keys())}")
            
                ### HERE IS WHERE WE CALL THE FUNCTION TO DO THE WORK
                func = available_functions[function_name]
                is_async = inspect.iscoroutinefunction(func)
                result = await func(**args) if is_async else func(**args)
                logger.info(f"'{function_name}' returned: {result}")
                    
            except json.JSONDecodeError as e:
                logger.error(f"JSON parsing error: {str(e)}")
                result = f"Error parsing arguments for '{function_name}': {str(e)}"
            except Exception as e:
                logger.error(f"Error in function {function_name}: {str(e)}")
                result = f"Error executing function '{function_name}': {str(e)}"
            
            # Append the function execution result to message history
            messages.append({
                "role": "function",
                "name": function_name,
                "content": json.dumps(self._serialize_value(result)) if isinstance(result, (dict, list)) else str(result)
            })
            
            iteration += 1
        
        logger.warning(f"Reached maximum number of function calling iterations: {max_iterations}")
        return messages, function_call_usage

    async def _get_simple_response(self, 
                                  messages: List[Dict], 
                                  config: Dict, 
                                  response_format: Optional[Any] = None,
                                  functions: Optional[List[Dict]] = None,
                                  function_call: Optional[str] = "auto",
                                  max_iterations: int = DEFAULT_MAX_FUNCTION_CALL_ITERATIONS,
                                  **kwargs) -> tuple[Any, Any]:
        """Generate a simple text response from the model.

        Args:
            messages: List of conversation messages
            config: API configuration dictionary
            response_format: Ignored for simple responses (must be present due to implementation, however)
            functions: Optional list of available functions
            function_call: Optional specification for function calling behavior ("auto" or specific function)
            **kwargs: Additional arguments passed to the API

        Returns:
            tuple[Any, Any]: Tuple of (response_message, usage_statistics)
        """
        if functions:
            messages, usage = await self._execute_function_calls(
                messages, config, functions, function_call,
                max_iterations=max_iterations
            )
            # Get the final message (which is the actual plain text response)
            return messages[-1]['content'], usage
        
        else:
            # Only make API call if no functions were involved
            completion = await self.client.chat.completions.create(messages=messages, **config)
            response_content = completion.choices[0].message.content
            
            # Process annotations for web search if present
            if hasattr(completion.choices[0].message, 'annotations'):
                annotations = completion.choices[0].message.annotations
                logger.debug(f"Response contains {len(annotations)} annotations from web search")
            
            return response_content, completion.usage

    async def _get_json_response(self, 
                                messages: List[Dict], 
                                config: Dict, 
                                response_format: Dict,
                                functions: Optional[List[Dict]] = None,
                                function_call: Optional[str] = "auto",
                                max_iterations: int = DEFAULT_MAX_FUNCTION_CALL_ITERATIONS) -> tuple[Any, Any]:
        """Generate a JSON-formatted response matching the specified schema.

        Args:
            messages: List of conversation messages
            config: API configuration dictionary
            response_format: Expected JSON schema for the response
            functions: Optional list of available functions
            function_call: Optional specification for function calling behavior ("auto" or specific function)
            **kwargs: Additional arguments passed to the API

        Returns:
            tuple[Any, Any]: Tuple of (parsed_json_response, usage_statistics)

        Raises:
            ValueError: If JSON parsing fails
        """
        # Check if web_search_options is being used and raise error - JSON mode not compatible
        if 'web_search_options' in config:
            error_msg = "JSON response format is not supported with web search. Please use plain text responses with web search instead."
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        function_call_usage = None
        # First handle any function calls
        if functions:
            # First get all function calls and final text response
            messages, function_call_usage = await self._execute_function_calls(
                messages, config, functions, function_call,
                max_iterations=max_iterations
            )
        
        # Add system instruction for JSON formatting.
        config['response_format'] = {"type": "json_object"}
        format_instruction = f"You must respond with a valid JSON object in this format: {json.dumps(response_format)}"
        if messages and messages[0]["role"] == "system":
            messages[0]["content"] = f"{messages[0]['content']}\n\n{format_instruction}"
        else:
            messages.insert(0, {"role": "system", "content": format_instruction})
    
        # Make final call using OpenAI's parsing endpoint
        completion = await self.client.chat.completions.create(messages=messages, **config)
        usage = completion.usage if not function_call_usage else function_call_usage + [completion.usage]       
        
        try:
            result = json.loads(completion.choices[0].message.content)
            
            # Add web search annotations if present
            if hasattr(completion.choices[0].message, 'annotations'):
                result['_annotations'] = [
                    {
                        'type': ann.type,
                        'url': ann.url_citation.url if hasattr(ann, 'url_citation') else None,
                        'title': ann.url_citation.title if hasattr(ann, 'url_citation') else None,
                    }
                    for ann in completion.choices[0].message.annotations
                ]
                
            return result, usage
        except Exception as e:
            logger.error(f"Error parsing final JSON response: {e}", exc_info=True)
            raise ValueError(f"Failed to parse final JSON: {completion.choices[0].message.content}")
        


    async def _get_structured_response(self, 
                                      messages: List[Dict], 
                                      config: Dict, 
                                      response_format: Type[BaseModel],
                                      functions: Optional[List[Dict]] = None,
                                      function_call: Optional[str] = "auto",
                                      max_iterations: int = 5) -> tuple[Any, Any]:
        """Generate a response parsed into a Pydantic model.

        Args:
            messages: List of conversation messages
            config: API configuration dictionary
            response_format: Pydantic model class for response parsing
            functions: Optional list of available functions
            function_call: Optional specification for function calling behavior ("auto" or specific function)
            max_iterations: Maximum number of allowed function call iterations, defaults to 5

        Returns:
            tuple[Any, Any]: Tuple of (pydantic_model_instance, usage_statistics)

        Raises:
            ValidationError: If response doesn't match Pydantic model
        """
        function_call_usage = None
        # First handle any function calls
        if functions:
            messages, function_call_usage = await self._execute_function_calls(
                messages, config, functions, function_call,
                max_iterations=max_iterations
            )

        # Make final call using OpenAI's parsing endpoint
        config['response_format'] = response_format   
        completion = await self.client.beta.chat.completions.parse(messages=messages, **config)
        usage = completion.usage if not function_call_usage else function_call_usage + [completion.usage]
        
        # Add annotations to model instance if present and if the model supports it
        if hasattr(completion.choices[0].message, 'annotations'):
            parsed_result = completion.choices[0].message.parsed
            if hasattr(parsed_result, '__dict__'):
                setattr(parsed_result, '_annotations', [
                    {
                        'type': ann.type,
                        'url': ann.url_citation.url if hasattr(ann, 'url_citation') else None,
                        'title': ann.url_citation.title if hasattr(ann, 'url_citation') else None,
                    }
                    for ann in completion.choices[0].message.annotations
                ])
        
        return completion.choices[0].message.parsed, usage
```
## File: llm/llm_function_extractor.py
```python
import re
import ast
import os


class LLMFunctionExtractor:
    def __init__(self, script_path: str):
        self._script_path = None  # Initialize first
        self.script_path = script_path  # This will trigger the setter

    @property
    def script_path(self) -> str:
        return self._script_path

    @script_path.setter
    def script_path(self, value: str):
        if not os.path.exists(value):
            raise FileNotFoundError(f"Script file not found: {value}")
        if not os.path.isfile(value):
            raise ValueError(f"Path is not a file: {value}")
        self._script_path = value
        try:
            self.script_content = self._load_script_content()
        except Exception as e:
            raise ValueError(f"Could not read script file: {e}")

    def get_functions(self, python_object: object, skip_underscored: bool = True) -> list[dict]:
        """Generate function definitions and pair them with their bound_method methods.
        
        Args:
            python_object: Instance of the class containing the bound_method methods
            skip_underscored: Boolean indicating if underscored functions should be skipped
            
        Returns:
            list[dict]: List of dicts containing:
                - schema: OpenAI function definition
                - bound_method: Bound method from the instance
        """
        # Generate OpenAI-style function definition schemas
        function_defs = self._generate_openai_function_defs(skip_underscored=skip_underscored)
        
        # Add bound_methods to the function definitions
        functions_with_bound_methods = []
        
        for func_def in function_defs:
            func_name = func_def["name"]
            if hasattr(python_object, func_name):
                if skip_underscored and func_name.startswith("_"):
                    continue
                method = getattr(python_object, func_name)
                functions_with_bound_methods.append({
                    "schema": func_def,
                    "bound_method": method
                })
        
        return functions_with_bound_methods

    def _load_script_content(self) -> str:
        with open(self.script_path, 'r') as f:
            return f.read()

    def _generate_openai_function_defs(self, skip_underscored: bool = True) -> list[dict]:
        """Generate OpenAI function definitions directly from a Python file.
        
        Parses Python file to extract function definitions including docstrings,
        parameter types, and descriptions in OpenAI function format.
        
        Args:
            skip_underscored (bool): If True, skips functions starting with underscore. Defaults to True.
            
        Returns:
            list[dict]: List of OpenAI function definitions with:
                - name: Function name
                - description: Function docstring
                - parameters: Function parameters schema
        """
        
        function_defs = []
        
        # Parse the file content into an AST
        tree = ast.parse(self.script_content)
        
        def get_type_info(annotation) -> tuple[str, dict]:
            """Helper to parse type annotations into OpenAI schema types"""
            if isinstance(annotation, ast.Subscript):
                if isinstance(annotation.value, ast.Name):
                    container_type = annotation.value.id
                    # Handle Union types
                    if container_type == 'Union':
                        types = []
                        if isinstance(annotation.slice, ast.Tuple):
                            for elt in annotation.slice.elts:
                                type_name, type_schema = get_type_info(elt)
                                types.append(type_schema)  # Use the full schema, not just the type
                        return 'union', {"anyOf": types}
                    # Handle other container types
                    elif container_type in ('List', 'list', 'Sequence', 'Set', 'FrozenSet', 'Collection'):
                        if isinstance(annotation.slice, ast.Name):
                            item_type = get_type_info(annotation.slice)[0]
                        else:
                            item_type = 'string'  # default
                        return 'array', {"type": "array", "items": {"type": item_type}}
                    elif container_type in ('Dict', 'dict', 'Mapping', 'MutableMapping'):
                        return 'object', {"type": "object"}
                    elif container_type == 'Optional':
                        if isinstance(annotation.slice, ast.Tuple):
                            for elt in annotation.slice.elts:
                                if not (isinstance(elt, ast.Name) and elt.id == 'None'):
                                    type_name, type_schema = get_type_info(elt)
                                    return type_name, type_schema
                        else:
                            return get_type_info(annotation.slice)
            elif isinstance(annotation, ast.BinOp):
                # Handle Union types written as X | Y (Python 3.10+)
                if isinstance(annotation.op, ast.BitOr):
                    # Recursively get types from both sides of the |
                    left_type, left_schema = get_type_info(annotation.left)
                    right_type, right_schema = get_type_info(annotation.right)
                    return 'union', {"anyOf": [left_schema, right_schema]}
            elif isinstance(annotation, ast.Name):
                # Simple types - include both built-in and typing versions
                type_mapping = {
                    # Built-in types
                    'str': 'string',
                    'int': 'integer',
                    'float': 'number',
                    'bool': 'boolean',
                    'list': 'array',
                    'dict': 'object',
                    # Typing module equivalents
                    'Text': 'string',
                    'AnyStr': 'string',
                    'Pattern': 'string',
                    'ByteString': 'string',
                    'SupportsInt': 'integer',
                    'SupportsFloat': 'number',
                    'SupportsBytes': 'string',
                    'SupportsAbs': 'number',
                    'SupportsRound': 'number',
                    # Common third-party types
                    'datetime': 'string',
                    'date': 'string',
                    'time': 'string',
                    'timedelta': 'string',
                    'UUID': 'string',
                    'Decimal': 'number',
                    # Any/generic types default to string
                    'Any': 'string',
                    'TypeVar': 'string',
                }
                return type_mapping.get(annotation.id, 'string'), {"type": type_mapping.get(annotation.id, 'string')}
            
            return 'string', {"type": "string"}  # default
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                # Skip private methods if configured to do so
                if skip_underscored and node.name.startswith('_'):
                    continue
                    
                # Get function docstring if it exists
                docstring = ast.get_docstring(node) or ""
                
                # Parse Args section from docstring
                param_descriptions = {}
                if "Args:" in docstring:
                    # Split docstring into main description and args
                    parts = docstring.split("Args:", 1)
                    main_desc = parts[0].strip()
                    args_section = parts[1]
                    
                    # If there are other sections, extract just the Args section
                    for section in ["Returns:", "Raises:", "Examples:"]:
                        if section in args_section:
                            args_section = args_section.split(section)[0]
                    
                    # Parse each argument description
                    current_param = None
                    current_desc = []
                    
                    for line in args_section.strip().split('\n'):
                        line = line.strip()
                        if not line:
                            continue
                            
                        # Check if this line starts a new parameter using regex
                        param_match = re.match(r'^(\w+)\s*(\([^)]+\))?\s*:', line)
                        if param_match:
                            # Save previous parameter if exists
                            if current_param:
                                param_descriptions[current_param] = ' '.join(current_desc).strip()
                            
                            current_param = param_match.group(1)
                            current_desc = [line.split(':', 1)[1].strip()]
                        else:
                            # Continue previous parameter description
                            if current_param:
                                current_desc.append(line)
                    
                    # Save last parameter
                    if current_param:
                        param_descriptions[current_param] = ' '.join(current_desc).strip()
                
                # Get main description and return description
                main_description = docstring.split("Args:")[0].strip() if "Args:" in docstring else docstring
                return_description = ""
                if "Returns:" in docstring:
                    return_section = docstring.split("Returns:", 1)[1].strip()
                    # Clean up any remaining sections
                    for section in ["Args:", "Raises:", "Examples:"]:
                        if section in return_section:
                            return_section = return_section.split(section)[0].strip()
                    return_description = f"\n\nReturns: {return_section}"
                
                # Parse parameters
                params = {}
                required = []
                
                for arg in node.args.args:
                    if arg.arg == 'self' or arg.arg == 'cls':
                        continue
                        
                    # Get type annotation if it exists
                    arg_type = {"type": "string"}  # Default schema
                    if arg.annotation:
                        _, arg_type = get_type_info(arg.annotation)
                    
                    params[arg.arg] = {
                        **arg_type,
                        "description": param_descriptions.get(arg.arg, "")
                    }
                    
                    # Check if parameter has default value
                    if len(node.args.defaults) < len(node.args.args) - node.args.args.index(arg):
                        required.append(arg.arg)
                
                function_def = {
                    "name": node.name,
                    "description": f"{main_description}{return_description}".strip(),
                    "parameters": {
                        "type": "object",
                        "properties": params,
                        "required": required
                    }
                }
                
                # if node.returns:
                #     _, return_schema = get_type_info(node.returns)
                #     function_def["returns"] = return_schema
                
                function_defs.append(function_def)
        
        return function_defs
    

    def print_function_defs(self, function_defs: list[dict]):
        """Print the function definitions in a readable format"""
        import json

        class CustomEncoder(json.JSONEncoder):
            def default(self, obj):
                if hasattr(obj, '__name__'):  # Handle any object with a __name__ attribute
                    return obj.__repr__()
                return super().default(obj)
        print(json.dumps(function_defs, indent=2, cls=CustomEncoder))
```
## File: app/ticket_ingester.py
```python
import logging
import re
import asyncio
from typing import Dict, List, Any, Optional, Union
from app.models.ticket import Ticket
from app.ticket_image_processor import TicketImageProcessor
from database import AuthenticatedPostgresClient

from llm.provider import get_llm_provider
from app.api import ConnectWiseAPI
import json
import os
from retrieval import Ingestion

# Configure logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

INGESTION_MODEL = "gpt-4.1-mini-2025-04-14"
SUMMARY_INSTRUCTIONS = summary_instructions = "This is an IT support ticket. Please summarize the issue, the steps taken to resolve the issue, and the outcome. Do not repeat dates and do not include a preamble, just say what the problem was and how it was closed. Be concise."
AECHAI_FILTER_FROM = ["aechai", "agentaech"]

class TicketIngester:
    """
    Handles the preprocessing of ticket data before analysis.
    
    This class is responsible for:
    1. Cleaning and normalizing ticket text
    2. Processing images in tickets and extracting text
    3. Extracting meaningful user queries
    4. Converting raw data into structured Ticket objects
    
    It works closely with the TicketImageProcessor to handle images 
    in tickets and provides clean, structured data for further analysis.
    """
    
    def __init__(self, db_client: AuthenticatedPostgresClient, username: str = "helpdesk_agent", llm_model_name: str = "gpt-4o-2024-11-20"):
        """
        Initialize the TicketIngester.
        
        Args:
            db_client: Database client for retrieving ticket data
            username: Username for database operations (default: "helpdesk_agent")
            llm_model_name: Name of the LLM model to use for processing
        """
        self.db_client = db_client
        self.username = username
        self.llm_model_name = llm_model_name
        self.llm_provider = get_llm_provider(llm_model_name, database_client=db_client)
        self.connectwise_api= ConnectWiseAPI()
        
        # Initialize the ticket image processor
        self.image_processor = TicketImageProcessor()
        
        # # Initialize the ticket database for retrieving ticket data
        # self.ticket_db = None  # Will be set during initialize()
        
    @classmethod
    async def create(cls, db_client, username: str = "helpdesk_agent", llm_model_name: str = "gpt-4o-2024-11-20"):
        """
        Create and initialize a new TicketIngester instance.
        
        Args:
            db_client: Database client for retrieving ticket data
            username: Username for database operations (default: "helpdesk_agent") 
            llm_model_name: Name of the LLM model to use for processing
            
        Returns:
            TicketIngester: An initialized TicketIngester instance
        """
        instance = cls(db_client, username, llm_model_name)
        await instance.initialize()
        return instance
        
    async def initialize(self):
        """
        Initialize the TicketIngester by setting up its dependencies.
        
        Returns:
            TicketIngester: Self for method chaining
        """
        self.company_group_map = await self._get_company_group_map()
        self.image_processor = TicketImageProcessor(db_client=self.db_client)
        self.user_id = self.db_client.user_info.id
        
        return self
    
    async def _get_company_group_map(self) -> Dict[str, str]:
        """
        Get a map of company names to their corresponding group IDs.
        
        Returns:
            Dict[str, str]: A dictionary mapping company names to group IDs
        """
        data = await self.db_client.table("groups").select("id", "name", "description").execute()
        data = [row for row in data if row["name"] not in ["users", "admins"]]
        # company_group_map = {row["description"]: row["id"] for row in data}

        company_group_map = {row["name"]: row["id"] for row in data}

        # print(f"company_group_map:\n{json.dumps(company_group_map, indent=2)}")
        return company_group_map

    
    async def preprocess_batch(self, ticket_ids: List[int], 
                               max_concurrent: int = 5,
                               save_to_disk: bool = False,
                               folder_path: str = None) -> List[Dict]:
        """
        Preprocess a batch of tickets concurrently with improved error handling.
        
        Args:
            ticket_ids: List of ticket IDs to preprocess
            max_concurrent: Maximum number of concurrent preprocessing tasks
            save_to_disk: Whether to save processed tickets to disk
            folder_path: Path to folder where tickets should be saved (required if save_to_disk is True)
            
        Returns:
            List[Dict]: List of preprocessed ticket data dictionaries
        """
        logger.info(f"Preprocessing batch of {len(ticket_ids)} tickets with max {max_concurrent} concurrent tasks")
        
        # Validate arguments
        if save_to_disk and not folder_path:
            raise ValueError("folder_path must be provided when save_to_disk is True")
        
        if save_to_disk:
            # Ensure the folder exists
            os.makedirs(folder_path, exist_ok=True)
        
        # Create a semaphore to limit concurrency
        semaphore = asyncio.Semaphore(max_concurrent)
        
        # Counter for tracking progress with a lock for thread safety
        counter_lock = asyncio.Lock()
        processed_count = 0
        total_count = len(ticket_ids)
        
        async def preprocess_ticket_with_semaphore(ticket_id):
            """Process a single ticket with semaphore control."""
            nonlocal processed_count
            
            async with semaphore:
                # Get starting count for this task
                async with counter_lock:
                    task_number = processed_count + 1
                
                try:
                    # Log the start of processing with counter
                    ticket_data = await self.preprocess_ticket(ticket_id)
                    
                    # Update counter using the lock
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count
                    
                    if ticket_data:
                        # Save to disk if requested
                        if save_to_disk:
                            self._save_ticket_data(ticket_data, folder_path)
                        
                        # Log success with counter
                        logger.info(f"Successfully processed ticket {ticket_id} ({current_count}/{total_count})")
                        return ticket_data
                    else:
                        logger.warning(f"No data returned for ticket {ticket_id} ({current_count}/{total_count})")
                        return None
                except Exception as e:
                    # Update counter using the lock
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count
                        
                    logger.error(f"Error processing ticket {ticket_id} ({current_count}/{total_count}): {str(e)}")
                    logger.exception("Full traceback:")
                    return None
        
        # Create tasks for each ticket
        tasks = [preprocess_ticket_with_semaphore(ticket_id) for ticket_id in ticket_ids]
        
        # Execute all tasks concurrently and gather results
        results = await asyncio.gather(*tasks)
        
        # Filter out None values (failed tickets)
        processed_tickets = [ticket for ticket in results if ticket]
        
        logger.info(f"Batch processing complete. Successfully processed {len(processed_tickets)}/{total_count} tickets")
        return processed_tickets 

    async def preprocess_ticket(self, 
                    ticket_id: int, 
                    filter_aechai: bool = False
                    ) -> Dict:
        """
        Preprocess a ticket to prepare it for ingestion into the database.
        
        This method:
        1. Retrieves the ticket if an ID is provided
        2. Processes any images in the ticket and cleans messages

        
        Args:
            ticket_id: ID of the ticket to retrieve
            filter_aechai: Whether to filter out AechAI notes from the ticket. Default is False.
        Returns:
            Dict: Processed ticket data in a dictionary format
        """

        try:
            # Step 1: Get the ticket data if an ID is provided
            logger.debug(f"Getting ticket data from Scout API for ticket {ticket_id}")
            ticket_data = await self.connectwise_api.get_ticket_with_messages(ticket_id)

            if filter_aechai:
                ticket_data["messages"] = self.filter_aechai_messages(ticket_data["messages"])
            # Process images in the ticket if needed
            logger.debug(f"Processing ticket images")
            ticket_data = await self._transcribe_and_tidy_messages(ticket_data)

            # format as it will appear in the database
            ticket_data = self.format_ticket_data(ticket_data)

            # step 4: Ensure ticket has the appropriate group_id
            ticket_data["group_id"] = self.company_group_map[ticket_data["company_identifier"]]   
              
            return ticket_data
        
        except Exception as e:
            logger.error(f"Error preprocessing ticket: {str(e)}")
            logger.exception("Full traceback:")
            return None
            
    
    def filter_aechai_messages(self, 
            messages: List[Dict[str, Any]],
            filter_from: List[str] = AECHAI_FILTER_FROM) -> List[Dict[str, Any]]:
        """
        Filter out all AechAI notes from the ticket messages.
        """
        filtered_messages = []
        for m in messages:
            if m.get("from", "").lower() in filter_from:
                continue
            filtered_messages.append(m)
        return filtered_messages
    
        
    async def _transcribe_and_tidy_messages(self, ticket_dict: Dict[str, Any]) -> dict:
        """
        Process any images in the ticket and clean up the ticket content.

        Args:
            ticket_dict (Dict[str, Any]): Raw ticket data that might contain images and messages.

        Returns:
            dict: Updated ticket dictionary with cleaned and transcribed messages.
        """
        cleaned_messages = await self.image_processor.transcribe_ticket_messages(ticket_dict)
                
        for message, cleaned_message in zip(ticket_dict['messages'], cleaned_messages):
            message['text'] = cleaned_message['text']

        for message in ticket_dict['messages']:
            message['text'] = self._clean_ticket_text(message['text'])
        
        return ticket_dict
            

    
    def format_ticket_data(self, ticket_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format a ticket for display and ingestion.
        Uses content already processed by the TicketImageProcessor.
        """
        formatted_ticket = {
            "id": ticket_data.get("id"), 
            "company_name": ticket_data.get("company", {}).get("name", None),
            "company_identifier": ticket_data.get("company", {}).get("identifier", None),
            "contact_name": ticket_data.get("contact", {}).get("name", None),
            "contact_id": ticket_data.get("contact", {}).get("id", None),
            "type": ticket_data.get("type", {}).get("name", None),
            "subtype": ticket_data.get("subType", {}).get("name", None), # note we use subType  not subType
            "item": ticket_data.get("item", {}).get("name", None),
            "date_entered": ticket_data.get("_info", {}).get("dateEntered", None),
            "closed_date": ticket_data.get("closedDate", None),
            "summary": ticket_data.get("summary", None),
            "priority": ticket_data.get("priority", {}).get("name").split("-")[0].strip(),
            "messages": ticket_data.get("messages", None), 
        }
        return formatted_ticket
    
    def _save_ticket_data(self, ticket_data: Dict, folder_path: str) -> None:
        """
        Save the processed ticket data to a JSON file.
        """
        file_path = os.path.join(folder_path, f"{ticket_data['id']}.json")
        with open(file_path, "w") as f:
            json.dump(ticket_data, f, indent=2)
    
    def format_ticket_messages_as_string(self, ticket: Dict) -> str:
        """
        Format all messages from a processed ticket into a single readable string.
        
        This method creates a human-readable representation of the entire ticket by:
        1. Starting with the ticket summary and ID as a header
        2. Adding each message with a clear header showing author, date, and type
        3. Standardizing quotes (replacing curly quotes with straight ones)
        4. Formatting everything with consistent spacing
        
        This is useful for creating a plain text version of the ticket that can be:
        - Displayed in a console or terminal
        - Saved to a text file
        - Used as input for other text-based systems
        
        Args:
            ticket (Dict): Processed ticket dictionary with 'summary' and 'messages' fields
            
        Returns:
            str: A formatted string containing the entire ticket conversation
        """
        if not ticket or 'messages' not in ticket:
            return ""
            
        summary = ticket.get('summary', '')
        
        # Start with the ticket summary if available
        ticket_string = f"# {summary}\n\n" if summary else ""
        
        # Process each message
        for message in ticket.get('messages', []):
            # Extract message metadata
            date = message.get('date', 'Unknown date')
            author = message.get('from', 'Unknown author')
            msg_type = message.get('type', 'Unknown type')
            msg_id = message.get('id', '')
            
            header = f"## On {date}, {author} wrote a {msg_type} ({msg_id}):\n"
            message_text = message.get('text', '')
            ticket_string += header + message_text + "\n\n"
        
        # Apply quote straightening to the entire result
        ticket_string = self._straighten_quotes(ticket_string)
        return ticket_string.strip() 
    
    def _clean_ticket_text(self, text: str) -> str:
        """
        Clean and normalize ticket text by removing noise elements.
        
        Args:
            text: Raw ticket text
            
        Returns:
            str: Cleaned text
        """
        # Remove image tags, URLs, and base64 images
        text = self._filter_image_tags(text)
        text = self._filter_url_tags(text)
        text = self._straighten_quotes(text)
        text = self._filter_base64_images(text)
        return text
    
    def _filter_image_tags(self, content: str) -> str:
        """Remove markdown image tags from text."""
        image_pattern = r'!\[(\\?\[.*?\\?\]|.*?)\]\(.*?\)'
        return re.sub(image_pattern, '<image>', content)
    
    def _filter_url_tags(self, content: str) -> str:
        """Remove markdown URL tags from text."""
        url_pattern = r'\[(\\?\[.*?\\?\]|.*?)\]\(.*?\)'
        return re.sub(url_pattern, '<url>', content)
    
    def _straighten_quotes(self, text: str) -> str:
        """Replace curly/smart quotes with straight quotes."""
        replacements = {
            '\u2018': "'", 
            '\u2019': "'", 
            '\u201C': '"', 
            '\u201D': '"', 
            '\u00a0': ' ',
            '\u2013': '-'
        }
        for curly, straight in replacements.items():
            text = text.replace(curly, straight)
        return text
    
    def _filter_base64_images(self, content: str) -> str:
        """Remove base64-encoded images from content."""
        pattern = r'data:image/([a-zA-Z]+);base64,([^\\)]+)'
        filtered_content = content
        
        matches = re.findall(pattern, content)
        if matches:
            logger.debug(f"Found {len(matches)} base64 patterns")
        
        for image_type, base64_data in matches:
            full_pattern = f'data:image/{image_type};base64,{base64_data}'
            filtered_content = filtered_content.replace(full_pattern, '<base64_image>')
        
        return filtered_content
    
    def _handle_error(self, method_name: str, error: Exception, ticket: Optional[Union[Ticket, int]] = None) -> Dict[str, Any]:
        """
        Standardized error handling for ticket processing methods.
        
        Args:
            method_name: Name of the method where the error occurred
            error: The exception that was raised
            ticket: Optional ticket or ticket ID to include in the error result
            
        Returns:
            Dict[str, Any]: Error result dictionary
        """
        error_msg = f"Error in {method_name}: {str(error)}"
        logger.error(error_msg)
        logger.exception("Full traceback:")
        
        # Create error result
        error_result = {"success": False, "error": str(error)}
        
        if ticket is not None:
            if isinstance(ticket, Ticket):
                error_result["ticket_id"] = ticket.id
            else:
                error_result["ticket_id"] = ticket
        
        return error_result
    
    async def ingest_ticket(self, 
        ticket: Dict, 
        model_name: str = INGESTION_MODEL, 
        summary_instructions: str = SUMMARY_INSTRUCTIONS
        ) -> dict:
        """
        Ingest a ticket into the database.

        Args:
            ticket (Dict): The processed ticket data to ingest.
            model_name (str): The model name to use for ingestion.
            summary_instructions (str): Instructions for summarizing the ticket.

        Returns:
            dict: Ingestion response containing ticket_id, success, and optional error.
        """
        group_id = self.company_group_map[ticket["company_identifier"]]
        source = ticket.get("contact_id", None)
        
        ticket = await self._format_ticket_for_ingestion(ticket)
        logger.debug(f"Ingesting ticket {ticket['id']}")


        async with await Ingestion.create(username=self.username, model_name=model_name) as ingestion:
            ingestion_response = await ingestion.ingest_markdown(
                text=ticket["content"], 
                id=ticket["id"],
                group_id=group_id,
                user_id=self.user_id,
                metadata=ticket["metadata"],
                source = str(source),
                summary_instructions=summary_instructions,
            )
            response = {
                "ticket_id": ticket["id"],
                "success": ingestion_response['success'],
            }
            if ingestion_response.get('error', None):
                response['error'] = ingestion_response['error']
        return response
    
    async def ingest_ticket_batch(self, tickets: List[Dict], max_concurrent: int = 5) -> List[Dict]:
        """
        Ingest a batch of tickets concurrently with improved error handling.
        
        Args:
            tickets: List of ticket dictionaries to ingest
            max_concurrent: Maximum number of concurrent ingestion tasks
            
        Returns:
            List[Dict]: List of ingestion responses
        """
        logger.info(f"Ingesting batch of {len(tickets)} tickets with max {max_concurrent} concurrent tasks")
        
        # Create a semaphore to limit concurrency
        semaphore = asyncio.Semaphore(max_concurrent)
        
        # Counter for tracking progress with a lock for thread safety
        counter_lock = asyncio.Lock()
        processed_count = 0
        total_count = len(tickets)
        
        async def ingest_ticket_with_semaphore(ticket: Dict):
            """Ingest a single ticket with semaphore control."""
            nonlocal processed_count
            
            async with semaphore:
                # Get starting count for this task
                async with counter_lock:
                    task_number = processed_count + 1
                
                try:
                    # Log the start of ingestion with counter
                    ingestion_response = await self.ingest_ticket(ticket)
                    
                    # Update counter using the lock
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count
                    
                    if ingestion_response:
                        # Log success with counter
                        logger.info(f"Successfully ingested ticket {ticket['id']} ({current_count}/{total_count})")
                        return ingestion_response
                    else:
                        logger.warning(f"No response for ticket {ticket['id']} ({current_count}/{total_count})")
                        return None
                except Exception as e:
                    # Update counter using the lock
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count
                        
                    logger.error(f"Error ingesting ticket {ticket['id']} ({current_count}/{total_count}): {str(e)}")
                    logger.exception("Full traceback:")
                    return None
        
        # Create tasks for each ticket
        tasks = [ingest_ticket_with_semaphore(ticket) for ticket in tickets]
        
        # Execute all tasks concurrently and gather results
        results = await asyncio.gather(*tasks)
        
        # Filter out None values (failed tickets)
        processed_tickets = [ticket for ticket in results if ticket]
        
        logger.info(f"Batch ingestion complete. Successfully ingested {len(processed_tickets)}/{total_count} tickets")
        return processed_tickets
    
    async def _format_ticket_for_ingestion(self, ticket: Dict) -> Dict:
        """
        Format a ticket for ingestion into the database.

        Args:
            ticket (Dict): The processed ticket data.

        Returns:
            Dict: Formatted ticket dictionary with id, content, and metadata.
        """
        metadata = {
            "company_name": ticket.get("company_name", None),
            "company_identifier": ticket.get("company_identifier", None),
            "contact_name": ticket.get("contact_name", None),
            "type": ticket.get("type", None),
            "subtype": ticket.get("subtype", None),
            "item": ticket.get("item", None),
            "date_entered": ticket.get("date_entered", None),
            "closed_date": ticket.get("closed_date", None),
            "priority": ticket.get("priority", None),
        }
        content = self.format_ticket_messages_as_string(ticket)
        formatted_ticket = {
            "id": ticket.get("id"), 
            "content": content,
            "metadata": metadata,
        }
        return formatted_ticket
```
## File: app/test_ticket_database.py
```python
import asyncio
import logging
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
import json
from app.ticket_annotator import TicketAnnotator
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from app.ticket_database import TicketDatabase

# Load environment variables
load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
logger.info(f"SSL certificate file set to: {os.environ['SSL_CERT_FILE']}")

# Test data

HELPDESK_USER_ID = "baa90098-5bc6-452b-aa9f-e2de1cf02eaf"


async def test_get_ticket_with_content(ticket_db, ticket_id):
    ticket = await ticket_db.get_ticket_with_content(ticket_id)
    return ticket

async def test_get_user_tickets(ticket_db, user_id):
    response = await ticket_db.get_user_tickets(user_id)
    logger.info(f"Found {len(response)} tickets")
    return response

async def main():
    ticket_id = 978181
    username = "helpdesk_agent"
    async with await AuthenticatedPostgresClient.create(username=username) as db_client:
        # Create ticket database
        ticket_db = await TicketDatabase.create(db_client, username=username)
        ticket_annotator = await TicketAnnotator.create(db_client, username=username)
        
        
        # last_ticket_id = await ticket_db.get_last_ticket_id()
        # print(f"Last ticket ID: {last_ticket_id}")

        ticket_id = 1
        group_id = "d0cfea2a-1756-49dd-a3df-e8d20fc796c3"
        result = await ticket_db.ensure_ticket_skeleton(ticket_id, group_id)
        print(f"Result: {result}")
        
        # ticket = await ticket_db.get_ticket_with_content(ticket_id)
        # print(f"\nTicket: {json.dumps(ticket, indent=4)}")

        # ticket_with_content = await test_get_ticket_with_content(ticket_db, TEST_TICKET_ID)
        # print(f"\nTicket with content: {json.dumps(ticket_with_content, indent=4)}")

        # user_id = ticket["source"]

        # tickets = await ticket_db.get_user_tickets(user_id)
        # ticket_ids = [t['id'] for t in tickets]
        # ticket_ids.sort()
        # print(f"\nUser tickets: {ticket_ids}")

        # threshold_ticket_id = ticket_ids[len(ticket_ids)//2]
        # print(f"Threshold ticket ID: {threshold_ticket_id}")

        # tickets = await ticket_db.get_user_tickets(user_id, max_ticket_id=threshold_ticket_id)
        # ticket_ids = [t['id'] for t in tickets]
        # ticket_ids.sort()
        # print(f"User tickets: {ticket_ids}")

        # threshold_working = all(ticket_id <= threshold_ticket_id for ticket_id in ticket_ids)
        # print(f"Threshold is working: {threshold_working}")

        
        # print(f"\nSearching for similar tickets to {ticket_id} with lookback_only=False") 


        # user_query = ticket_annotator._extract_user_query(ticket)
        # ticket["user_query"] = user_query

        # similar_tickets = await ticket_db.search_similar_tickets(ticket, lookback_only=False)
        # similar_ticket_ids = [t['ticket_id'] for t in similar_tickets]
        # similar_ticket_ids.sort()
        # print(f"Similar tickets: {similar_ticket_ids}")

        
        # print(f"\nSearching for similar tickets to {ticket_id} with lookback_only=True")
        # current_ticket_id = ticket["id"]
        # similar_tickets = await ticket_db.search_similar_tickets(ticket, lookback_only=True)
        # similar_ticket_ids = [t['ticket_id'] for t in similar_tickets]
        # similar_ticket_ids.sort()
        # print(f"Similar tickets: {similar_ticket_ids}")
        # lookback_only_working = all(ticket_id < current_ticket_id for ticket_id in similar_ticket_ids)

        # print(f"Lookback only working: {lookback_only_working}")

        

    


if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/ticket_annotator.py
```python
from datetime import datetime, timezone
import asyncio
import logging
from typing import List, Dict, Any, Optional, Union
import os
import json
from app.api import ConnectWiseAPI
from llm import get_llm_provider
from pydantic import BaseModel, Field
from database.postgres_client import PostgresClient
from app.ticket_database import TicketDatabase
from app.ticket_ingester import TicketIngester
from app.models.ticket import Ticket, Company, Contact, Classification, Message
from app.models.ticket_annotation import TicketAnnotation, ClassificationResult, UserHistory, SimilarTicket, RetrievalQuery, Solutions
import traceback

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# os.environ["POSTGRES_HOST"] = "localhost"

# Authentication details for database access
USERNAME = "helpdesk_agent"
SMART_MODEL = "gpt-4.1-2025-04-14"
DUMB_MODEL = "gpt-4.1-mini-2025-04-14"
WEB_SEARCH_MODEL = "gpt-4o-search-preview"
WEB_SEARCH_OPTIONS = {
    "search_context_size": "medium",
    "user_location": {
        "type": "approximate", "approximate": {"country": "CA", "city": "Vancouver", "region": "British Columbia"}}
}
FAILED_SUGGESTED_SOLUTION = "Unable to generate solution due to classification error."
FAILED_TSI_CATEGORY = "Unknown"

class TicketAnnotator:
    """
    Analyzes support tickets to classify issues, suggest solutions, and evaluate quality.
    
    This class performs advanced analysis on processed ticket content by:
    1. Retrieving tickets from the database based on date ranges and other criteria
    2. Finding similar historical tickets using hybrid semantic/keyword search
    3. Classifying tickets into appropriate service type, subtype, and item categories
    4. Generating suggested solutions based on similar past tickets
    5. Evaluating the quality of suggested solutions against actual resolutions
    6. Analyzing users' ticket history to identify patterns and improve recommendations
    
    Use this class after tickets have been processed and stored in the database when you need to:
    - Automate ticket classification for routing and prioritization
    - Generate solution suggestions to assist support staff
    - Evaluate the effectiveness of suggested solutions
    - Analyze patterns in user support history
    - Add classification and solution notes to tickets in the support system
    
    This component typically works with text-only ticket content that has already been 
    processed by systems like the TicketImageProcessor.
    
    Attributes:
        db_client (PostgresClient): Database client for retrieving ticket data
        username (str): Username for database operations
        simultaneous_requests (int): Number of tickets to process concurrently
        api (ConnectWiseAPI): API client for interacting with the Scout ticketing system
        llm_provider: Provider for LLM services used in classification and solution generation
    """
    def __init__(
        self,
        db_client: PostgresClient = None,
        username: str = USERNAME,
        simultaneous_requests: int = 10,
        model_name: str = SMART_MODEL,
    ):
        """
        Initialize the TicketAnnotator.
        
        Note: This constructor is not meant to be called directly.
        Use the create() class method instead for proper async initialization.
        
        Args:
            db_client (PostgresClient): Database client for retrieving ticket data
            username (str): Username for database operations (default: USERNAME)
            simultaneous_requests (int): Maximum number of concurrent LLM requests
            model_name (str): Model to use for classification
        """
        self.db_client = db_client
        self.username = username
        self.simultaneous_requests = simultaneous_requests
        self.api = ConnectWiseAPI()
        self.tsi_dict = self._load_tsi_dict()
        self.user_id = None
        self.ticket_db = None  # Will be initialized in create() method
        
        # Init LLM provider for ticket processing
        self.llm_provider = get_llm_provider(model_name, database_client=self.db_client)
        
        
    @classmethod
    async def create(
        cls,
        db_client: PostgresClient = None,
        username: str = USERNAME,
        simultaneous_requests: int = 10,
        model_name: str = SMART_MODEL
    ):
        """
        Create and initialize a new TicketAnnotator.
        
        This factory method handles all asynchronous initialization,
        ensuring the TicketAnnotator is fully ready to use when returned.
        
        Args:
            db_client: Database client for retrieving ticket data
            username: Username for database operations (default: USERNAME)
            simultaneous_requests: Maximum number of concurrent LLM requests
            model_name: Model to use for classification
            
        Returns:
            TicketAnnotator: Fully initialized TicketAnnotator instance
        """
        # Create instance with default initialization
        instance = cls(db_client, username, simultaneous_requests, model_name)
        
        # Get user ID for database operations
        user_id = await instance._get_user_id()
        instance.user_id = user_id
        
        # Create and initialize the ticket database
        ticket_db = await TicketDatabase.create(instance.db_client, username)
        instance.ticket_db = ticket_db

        # Create and initialize the ingester    
        ingester = await TicketIngester.create(db_client=instance.db_client, username=username)
        instance.ingester = ingester
        
        return instance

    async def _get_user_id(self):
        """Get the user ID for the current user."""
        result = await self.db_client.table("users").select("id").eq("username", self.username).execute()
        return result[0]['id']

    def _load_tsi_dict(self):
        """Load the TSI dictionary from the file."""
        path = os.getenv("TSI_DICT_PATH")
        with open(path, "r") as f:
            tsi_dict = json.load(f)
        if not tsi_dict:
            logger.error("TSI dictionary not found")
            raise ValueError("TSI dictionary not found")
        return tsi_dict

    
    
    async def _get_ticket(self, ticket_id: int, source: str = "api", filter_aechai: bool = False) -> Ticket:
        """
        Get a ticket by ID and convert it to a standardized Ticket model.
        
        This method handles retrieving tickets from either the API or database
        and ensures they are returned in a consistent format using the Ticket model.
        
        Args:
            ticket_id: ID of the ticket to retrieve
            source: Source of the ticket ("api" or "database")
            filter_aechai: Whether to filter out AechAI notes from the ticket when retrieving from the API. Default is False.
        Returns:
            Ticket: Standardized Ticket model with consistent fields
        """
        try:
            if source == "api":
                # Get raw ticket data from API
                ticket_dict = await self._get_preprocessed_ticket_from_api(ticket_id, 
                                                                           filter_aechai=filter_aechai)
                if not ticket_dict:
                    logger.error(f"Could not retrieve ticket {ticket_id} from API")
                    return None
                
                # Convert API format to standardized Ticket model
                return Ticket.from_api_format(ticket_dict)
    
            elif source == "database":
                # Get raw ticket data from database
                ticket_dict = await self._get_ticket_from_database(ticket_id)
                if not ticket_dict:
                    logger.error(f"Could not retrieve ticket {ticket_id} from database")
                    return None
                
                # Convert database format to standardized Ticket model
                return Ticket.from_database_format(ticket_dict)
            
            else:
                raise ValueError(f"Invalid source: {source}, must be 'api' or 'database'")
                
        except Exception as e:
            logger.error(f"Error retrieving ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return None

    async def _get_preprocessed_ticket_from_api(self, ticket_id: int, filter_aechai: bool = False) -> Dict[str, Any]:
        """
        Get a ticket by ID from the API.

        Args:
            ticket_id (int): ID of the ticket to retrieve
            filter_aechai (bool): Whether to filter out AechAI notes from the ticket. Default is False.
        Returns:
            Dict[str, Any]: The preprocessed ticket dictionary from the API.
        """
        logger.info(f"Getting ticket {ticket_id} from API")
        ticket = await self.ingester.preprocess_ticket(ticket_id, 
                                                       filter_aechai=filter_aechai)

        return ticket
    
    
    async def _get_ticket_from_database(self, ticket_id: int) -> Dict[str, Any]:
        """
        Get a ticket by ID from the database.

        Args:
            ticket_id (int): ID of the ticket to retrieve

        Returns:
            Dict[str, Any]: The ticket dictionary from the database.
        """
        logger.info(f"Getting ticket {ticket_id} from database")
        try:
            # Get raw ticket data from the database
            ticket_data = await self.ticket_db.get_ticket_with_content(ticket_id)
            
            return ticket_data
        
        except Exception as e:
            logger.error(f"Error retrieving ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return None
        



    def _extract_user_query(self, ticket: Ticket, initial_messages_only: bool = False) -> str:
        """
        Extract just the user's original query from the ticket.
        
        Args:
            ticket: Standardized Ticket object
            initial_messages_only: Whether to include only the initial messages or all messages
            
        Returns:
            str: JSON string with the ticket summary and filtered messages
        """
        # If no summary, return empty string
        if not ticket.summary:
            return ""
            
        # Start building the result object
        result = {"summary": ticket.summary}
        
        # If there are no messages, return just the summary
        if not ticket.messages:
            result["messages"] = []
            return json.dumps(result)
            
        # Filter messages if needed
        if initial_messages_only and len(ticket.messages) > 1:
            try:
                first_message = ticket.messages[0]
                ref_time = datetime.fromisoformat(first_message.date.replace('Z', '+00:00'))
                
                # Start with the first message
                filtered_messages = [first_message.model_dump()]
                
                # Only include messages within 30 seconds of the first message
                for message in ticket.messages[1:]:
                    message_time = datetime.fromisoformat(message.date.replace('Z', '+00:00'))
                    time_diff = abs((message_time - ref_time).total_seconds())
                    
                    if time_diff <= 30:
                        filtered_messages.append(message.model_dump())
                    else:
                        # Break once we find a message outside our time window
                        break
                
                result["messages"] = filtered_messages
                
            except (IndexError, ValueError, AttributeError, TypeError) as e:
                # If there's any error parsing dates, fall back to all messages
                logger.warning(f"Error filtering messages by time: {str(e)}. Using all available messages.")
                result["messages"] = [message.model_dump() for message in ticket.messages]
        else:
            # Include all messages if not filtering
            result["messages"] = [message.model_dump() for message in ticket.messages]
                
        return json.dumps(result)

    async def _get_user_tickets(self, 
                              contact_id: str, 
                              max_ticket_id: int = None) -> List[Dict[str, Any]]:
        """
        Get previous tickets for a specific user from the database.
        
        Args:
            contact_id: ID of the contact to find tickets for
            max_ticket_id: Optional maximum ticket ID to consider
            
        Returns:
            List[Dict[str, Any]]: List of tickets associated with the contact
        """
        try:
            # Get raw database tickets
            db_tickets = await self.ticket_db.get_user_tickets(
                contact_id, 
                max_ticket_id=max_ticket_id
            )
            # Convert to standardized tickets 
            tickets = [Ticket.from_database_format(ticket) for ticket in db_tickets]
            return tickets
            
        except Exception as e:
            logger.error(f"Error getting user tickets for {contact_id}: {str(e)}")
            return []
    
    async def _prepare_user_history(self, 
                            ticket: Ticket, 
                            retrieval_query: str,
                            user_tickets: List[Ticket], 
                            observability_info: Dict[str, Any],
                            n_user_history_tickets: int = 2) -> UserHistory:
        """
        Generate a summary of a user's ticket history using LLM, as it pertains to the current ticket
        
        Args:
            ticket: The current ticket
            retrieval_query: The query used for retrieving similar tickets
            user_tickets: List of tickets associated with the user
            observability_info: Observability information for logging
            n_user_history_tickets: Number of similar tickets to include in the user history
            
        Returns:
            UserHistory: Summary of the user's ticket history
        """
        # Get the contact name from the ticket
        username = ticket.contact.name
        total_user_tickets = len(user_tickets)

        max_tickets_in_context = 100
        if total_user_tickets > max_tickets_in_context:
            logger.warning(f"User {username} has {total_user_tickets} previous tickets, which is more than the maximum of {max_tickets_in_context} to send to llm. Limiting to {max_tickets_in_context}.")
            user_tickets = user_tickets[:max_tickets_in_context]


        if not user_tickets or len(user_tickets) == 0:
            return UserHistory(
                overview=f"The user {username} has no previous tickets",
                similar_ticket_ids=[],
                similar_tickets=[],
                recurring_issue=False,
                recurring_issue_cause=None
            )
        
        try:
            logger.debug(f"Generating summary for {len(user_tickets)} user tickets")
            
            # Extract key information from each ticket
            prompt_tickets = []
            for user_ticket in user_tickets:
                prompt_tickets.append({
                    "id": user_ticket.id,
                    "summary": user_ticket.llm_summary or "No summary available",
                })
            
            # maximum number of similar ticket_ids to include in the user history
            n_similar_ticket_ids = 5 + n_user_history_tickets 
            prompt = f"""
You are an IT support expert analyzing a user's ticket history to assist the IT tech workers. Below are summaries of previous tickets from this user.
Please provide:
1. A brief overview of the types of issues this user typically has
2. A list of up to {n_similar_ticket_ids} tickets that are most similar to the current ticket. It is ok if there are fewer than {n_similar_ticket_ids} tickets, just ensure they are relevant
3. Is this related to an recurring issue? If so, what is the underlying cause?

User's name: {username}
Today's date: {datetime.now().strftime("%Y-%m-%d")}.

<current_ticket>
{retrieval_query}
</current_ticket>

<ticket_history>
{json.dumps(prompt_tickets, indent=2)}
</ticket_history>
"""
            class UserSummary(BaseModel):
                overview: str = Field(description="Brief overview of the user's typical issues")
                similar_ticket_ids: List[int] = Field(default_factory=list, description=f"A list of ticket IDs that are most similar to the current ticket, in order of relevance (maximum {n_similar_ticket_ids})")
                recurring_issue: bool = Field(description="Is the current ticket related to a recurring issue that is present in the ticket history?")
                recurring_issue_cause: Optional[str] = Field(default=None, description="If there is a recurring issue related to the current ticket, what is its underlying cause? If not, return None.")

            # Use the UserHistory class directly as the response format
            response = await self.llm_provider.get_response(
                prompt,
                config = {"temperature": 0.1, "model": DUMB_MODEL},
                response_format = UserSummary,
                observability_info = observability_info
            )


            logger.debug(f"Reduced to {len(response.similar_ticket_ids)} similar user tickets")
            similar_tickets = []
            for similar_ticket_id in response.similar_ticket_ids:
                for prompt_ticket in prompt_tickets:
                    if prompt_ticket["id"] == similar_ticket_id:
                        similar_ticket = SimilarTicket(
                            id=prompt_ticket["id"], 
                            summary = prompt_ticket["summary"]
                        )
                        similar_tickets.append(similar_ticket)
            
            # ensure we have the correct number of similar tickets
            if len(similar_tickets) > n_user_history_tickets:
                similar_tickets = similar_tickets[:n_user_history_tickets]

            user_history = UserHistory(
                overview=response.overview,
                similar_ticket_ids=response.similar_ticket_ids,
                similar_tickets=similar_tickets,
                recurring_issue=response.recurring_issue,
                recurring_issue_cause=response.recurring_issue_cause
            )
            
            # Add additional context to the overview
            user_history.overview += f" The user has {total_user_tickets} previous tickets."
            
            return user_history
            
        except Exception as e:
            logger.error(f"Error generating user summary: {str(e)}")
            logger.exception(f"Full traceback: {traceback.format_exc()}")
            return UserHistory(
                overview="Unable to generate user summary due to an error.",
                similar_tickets=[],
                recurring_issue=False,
                recurring_issue_cause=None
            )

    async def _convert_to_ticket(self, 
                             ticket_input: Union[int, Dict[str, Any], Ticket], 
                             source: str = "api") -> Optional[Ticket]:
        """
        Convert various ticket input formats into a standardized Ticket object.
        
        Args:
            ticket_input: Either a ticket ID (int), a ticket dictionary, or a Ticket object
            source: Whether to retrieve the ticket from "api" or "database"
            
        Returns:
            Optional[Ticket]: The converted Ticket object or None if conversion failed
        """
        try:
            # Convert input to standardized Ticket object
            if isinstance(ticket_input, int):
                # Get ticket by ID
                ticket_id = ticket_input
                return await self._get_ticket(ticket_id, source)
            
            elif isinstance(ticket_input, dict):
                ticket_id = ticket_input.get('id') or ticket_input.get('ticket_id', 0)
                # Convert dictionary to Ticket object
                if source == "api":
                    return Ticket.from_api_format(ticket_input)
                else:
                    return Ticket.from_database_format(ticket_input)
            
            elif isinstance(ticket_input, Ticket):
                # Already a Ticket object
                return ticket_input
            
            else:
                # Invalid input type
                logger.error(f"Invalid ticket input type: {type(ticket_input)}")
                return None
        
        except Exception as e:
            # Handle any exceptions during conversion
            logger.error(f"Error converting ticket input for ticket {ticket_id}: {str(e)}")
            return None

    async def annotate_ticket(self, 
                          ticket_input: Union[int, Dict[str, Any], Ticket], 
                          add_note: bool = False, 
                          save_folder: str = None,
                          initial_messages_only: bool = False,
                          lookback_only: bool = False,
                          source: str = "api",
                          n_matches: int = 20, 
                          n_user_history_tickets: int = 2,
                          ) -> TicketAnnotation:
        """
        Process a single ticket.
        
        This method:
        1. Finds similar tickets using hybrid retrieval
        2. Classifies the ticket (type/subtype/item)
        3. Generates a suggested solution
        4. Optionally adds a note to the ticket in Scout system
        5. Optionally saves the result to a file
        
        Args:
            ticket_input: Either a ticket ID (int), a ticket dictionary, or a Ticket object
            add_note: Whether to add notes to the ticket with results
            save_folder: Folder to save results in (if None, results are not saved)
            initial_messages_only: Whether to only use the initial messages of the ticket containing the user query (used for validation)
            lookback_only: Whether to only look back at the user's previous tickets (used for validation)
            source: Whether to retrieve the ticket from "api" or "database"
            n_matches: Number of similar tickets to retrieve from the database
            n_user_history_tickets: Number of tickets to include in the user history
            
        Returns:
            TicketAnnotation: Result of processing the ticket
        """
        
            
        try:
            # Convert input to standardized Ticket object
            ticket = await self._convert_to_ticket(ticket_input, source)
            
            # Return early if conversion failed
            if not ticket:
                return TicketAnnotation(
                    ticket_id=ticket_id,
                    group_id=ticket.group_id,
                    success=False,
                    error="Failed to convert ticket input to Ticket object"
                )
            
            # Use the resolved ticket_id from the ticket
            ticket_id = ticket.id
            observability_info = {"ticket_id": ticket_id}
            
            logger.debug(f"Annotating ticket {ticket_id}")
            # logger.info(f"Ticket.model_dump(): {ticket.model_dump_json(indent=4)}")
            
            # Prepare annotation object
            annotation = TicketAnnotation(
                ticket_id=ticket_id, 
                group_id=ticket.group_id
            )
            
            # Extract user query based on settings
            user_query = self._extract_user_query(ticket, initial_messages_only=initial_messages_only)
            
            if not user_query:
                annotation.success = False
                annotation.error = "Could not extract user query"
                return annotation
            
            # Generate retrieval query
            retrieval_query = await self._write_ticket_retrieval_query(user_query, ticket_id)
            # Store the retrieval query in the annotation object
            annotation.retrieval_query = retrieval_query
            
            retrieval_query_text = retrieval_query.query
            if retrieval_query.system_information:
                retrieval_query_text += "\n\nSystem information: " + retrieval_query.system_information
            # logger.info(f"Retrieval query:\n{retrieval_query_text}\n\n")
            
            # Create async tasks for operations that can run concurrently
            tasks = []
            
            ######### Task 1: Get user history (if contact_id exists)
            user_history_task = None
            contact_id = str(ticket.contact.id) if ticket.contact else None
            if contact_id:
                async def get_user_history():
                    user_tickets = await self._get_user_tickets(
                        contact_id, 
                        max_ticket_id = ticket_id if lookback_only else None
                    )
                    if user_tickets and len(user_tickets) > 0:
                        return await self._prepare_user_history(
                            ticket, 
                            retrieval_query_text,
                            user_tickets, 
                            observability_info,
                            n_user_history_tickets
                        )
                    return None
                
                user_history_task = asyncio.create_task(get_user_history())
                tasks.append(user_history_task)
            
            ######### Task 2: Get similar tickets, filter relevant ones, and classify
            async def classify_ticket():
                # Get similar tickets in dictionary format
                similar_tickets = await self._retrieve_similar_tickets(
                    ticket, 
                    retrieval_query_text,
                    n_matches,
                    lookback_only = lookback_only
                )
                logger.debug(f"Found {len(similar_tickets)} similar tickets")
                
                # Filter relevant tickets
                if similar_tickets and len(similar_tickets) > 0:
                    relevant_tickets = await self._filter_relevant_tickets(
                        ticket, 
                        user_query,
                        similar_tickets, 
                        observability_info,
                        n_relevant_tickets = 5
                    )
                    logger.debug(f"Filtered to {len(relevant_tickets)} relevant tickets")
                else:
                    relevant_tickets = []
                
                # Classify the ticket
                classification = await self._classify_ticket_suggest_solution(
                    user_query, 
                    relevant_tickets, 
                    observability_info
                )
                logger.debug(f"Classification: {classification}")
                
                return {
                    "classification": classification,
                    "suggested_solution": classification["suggested_solution"],
                    "relevant_tickets": relevant_tickets
                }
            
            classification_task = asyncio.create_task(classify_ticket())
            tasks.append(classification_task)
            
            ######### Task 3: Web search for solution
            web_search_task = asyncio.create_task(
                self._llm_web_search_solution(user_query, observability_info)
            )
            tasks.append(web_search_task)
            
            # Wait for all tasks to complete
            await asyncio.gather(*tasks)
            
            # Get results from completed tasks
            user_history = await user_history_task if user_history_task else None
            classification_result = await classification_task 
            web_search_solution = await web_search_task

            # Store relevant ticket IDs (not dictionaries)
            ticket_ids = []
            relevant_tickets = classification_result.get('relevant_tickets', [])
            for relevant_ticket in relevant_tickets:
                if isinstance(relevant_ticket, dict) and relevant_ticket.get('ticket_id'):
                    ticket_ids.append(relevant_ticket.get('ticket_id'))
            
            annotation.relevant_ticket_ids = ticket_ids
            
            # Create classification result
            classification_data = classification_result["classification"]
            annotation.classification = ClassificationResult(
                service_type=classification_data.get("service_type", "Unknown"),
                subtype=classification_data.get("subtype", "Unknown"),
                item=classification_data.get("item", "Unknown"),
                priority=classification_data.get("priority", "Unknown"),
            )
            
            # Set solutions
            annotation.solutions = Solutions(
                historical=classification_data.get("suggested_solution"),
                web_search=web_search_solution
            )
            
            # Set user history if available
            if user_history:
                annotation.user_history = user_history

            # compose annotation note
            logger.debug(f"Composing note for ticket {ticket_id}")
            annotation.note_content = self._compose_note(ticket, annotation)
                
            # Add note to the ticket if requested
            if add_note:
                try:
                    logger.info(f"Adding AgentAech note to ticket {ticket_id}")
                    note_response = await self.api.add_note_to_ticket(
                        ticket_id, 
                        annotation.note_content
                    )
                    if note_response.get("ticketId") == ticket_id:
                        annotation.note_added = True
                    else:
                        annotation.note_added = False
                        annotation.error = f"Error adding note, response: {note_response}"
                except Exception as e:
                    logger.error(f"Error adding note to ticket {ticket_id}: {str(e)}")
                    annotation.note_added = False
                    annotation.error = f"Error adding note: {str(e)}"
            
            # Mark annotation as successful since all processing completed
            annotation.success = True
            
            # Save result to disk if requested
            if save_folder:
                try:
                    # Convert annotation to dictionary for saving
                    result_dict = annotation.to_dict()
                    save_path = self.save_ticket(result_dict, save_folder)
                    annotation.saved_to = save_path
                except Exception as e:
                    logger.error(f"Error saving ticket result to disk: {str(e)}")
                    annotation.error = f"Error saving result: {str(e)}"
                    
            return annotation
                
        except Exception as e:
            if isinstance(ticket_input, int):
                ticket_id = ticket_input
            elif isinstance(ticket_input, dict):
                ticket_id = ticket_input.get('id') or ticket_input.get('ticket_id', 0)
            elif isinstance(ticket_input, Ticket):
                ticket_id = ticket_input.id
            logger.error(f"Error processing ticket {ticket_id}: {str(e)}")
            logger.exception(f"Full traceback: {traceback.format_exc()}")
            return TicketAnnotation(
                ticket_id=ticket_id,
                success=False,
                error=str(e)
            )

    async def _write_ticket_retrieval_query(self, user_query: str, ticket_id: int, max_length: int = 200) -> RetrievalQuery:
        """
        Use LLM to generate a concise, searchable query from the ticket's details that will be
        used to find similar tickets in the database.
        
        Args:
            user_query (str): The user's query text, which may be the entire ticket content
                              or just the initial message
            ticket_id (int): The ID of the ticket being processed
            max_length (int): Maximum length of the summary in words
            
        Returns:
            RetrievalQuery: Generated search query with title and summary fields.
        """
        # Truncate user query if it's very long to avoid token limits
        max_chars = 20000
        if len(user_query) > max_chars:
            logger.debug(f"Truncating user query from {len(user_query)} to {max_chars} characters")
            user_query = user_query[:max_chars] + "...[TRUNCATED]"

        prompt = f"""
You are an IT support expert. Your task is to summarize a user IT request. 
These will be used to search for tickets that have similar issues in our helpdesk database. The search will be done using a hybrid retrieval system that combines vector search and keyword search, so ensure the query contains important keywords that will help in the retrieval process.

Here is the user request:
<request>
{user_query}
</request>

Analyze the request carefully and identify the IT issue.
"""
        class Issue(BaseModel):
            title: str = Field(description="A clear title of the issue")
            summary: str = Field(description=f"A short summary of the issue (<{max_length} words)")
            system_information: Optional[str] = Field(description="Any relevant system information included in the request")
        
        logger.debug(f"Generating search query for ticket {ticket_id}")
        response = await self.llm_provider.get_response(
            prompt,
            config = {"temperature": 0.1},
            response_format = Issue,
            observability_info = {"ticket_id": ticket_id}
        )
            
        retrieval_query = RetrievalQuery(
            query = response.title + ":\n" + response.summary,
            system_information = response.system_information
        )
        return retrieval_query
    

    def _compose_note(self, ticket: Ticket, annotation: TicketAnnotation) -> str:
        """
        Compose a note for a ticket that will be added to the connectwise system.
        """
        company_name = ticket.company.name
        user_name = ticket.contact.name

        note_text = ""
        # note_text += f"**Overview:**\n\n{annotation.retrieval_query.query}"
        # if annotation.retrieval_query.system_information:
        #     note_text += f" ({annotation.retrieval_query.system_information})"

        if annotation.classification:
            note_text += ("**Suggested Classification:**\n"
                          f"\n- Type: {annotation.classification.service_type}"
                          f"\n- Subtype: {annotation.classification.subtype}"
                          f"\n- Item: {annotation.classification.item}"
                          f"\n- Priority: {annotation.classification.priority}")

        note_text += f"\n\n**User Information:** {user_name}"
        if annotation.user_history:
            if annotation.user_history.overview:
                note_text += f"\n\n{annotation.user_history.overview}"
            if annotation.user_history.recurring_issue_cause:
                note_text += f"\n\n*Possible recurring issue:* {annotation.user_history.recurring_issue_cause}\n"
            if len(annotation.user_history.similar_tickets) > 0:
                note_text += "\n\n*Similar tickets from this user:* "
                user_ticket_items = [f"- #{ticket.id}: {ticket.summary}" for ticket in annotation.user_history.similar_tickets]
                user_ticket_items_str = "\n".join(user_ticket_items)
                note_text += f"\n{user_ticket_items_str}\n"
            if annotation.user_history.similar_ticket_ids:
                
                ticket_ids_already_listed = [ticket.id for ticket in annotation.user_history.similar_tickets]
                other_user_ticket_ids = [ticket_id for ticket_id in annotation.user_history.similar_ticket_ids if ticket_id not in ticket_ids_already_listed]
                if len(other_user_ticket_ids) > 0:
                    other_user_ticket_ids_str = ", ".join(f"#{ticket_id}" for ticket_id in other_user_ticket_ids)
                    note_text += f"\n\n*Other related tickets from {user_name}:* {other_user_ticket_ids_str}"
            
        else:
            note_text += "\n\nThis user has no previous tickets."
        
        
        
        if annotation.solutions:
            if annotation.solutions.historical:
                note_text += f"\n\n**Suggested Solution based on historical tickets:**\n\n{annotation.solutions.historical}"
                note_text += "\n\n"
                if annotation.relevant_ticket_ids:
                    relevant_tickets_str = ", ".join(f"#{ticket}" for ticket in annotation.relevant_ticket_ids)
                    note_text += f"\n\n*Similar tickets from other users at {ticket.company.name}:* {relevant_tickets_str}\n"
                
            if annotation.solutions.web_search:
                note_text += f"\n\n**Suggested Solution based on web search:**\n\n{annotation.solutions.web_search}"

        return note_text



    async def _retrieve_similar_tickets(self, 
                                       ticket: Ticket,
                                       retrieval_query: str,
                                       n_matches: int = 10, 
                                       lookback_only=False):
        """
        Search for tickets similar to the provided ticket.
        
        Args:
            ticket: Ticket object containing ticket data
            retrieval_query: The query used for retrieving similar tickets
            n_matches: Maximum number of matches to return
            lookback_only: If True, only consider tickets with IDs less than the current ticket
            
        Returns:
            List[Dict[str, Any]]: List of similar tickets
        """
        try:
            # Create a ticket-like object for search
            search_dict = {
                "id": ticket.id,
                "user_query": retrieval_query,
                "group_id": ticket.group_id
            }
            
            # Use ticket database to search for similar tickets
            similar_tickets = await self.ticket_db.search_similar_tickets(
                search_dict, 
                match_count=n_matches,
                lookback_only = lookback_only
            )
            
            return self._deduplicate_tickets(similar_tickets)
                
        except Exception as e:
            logger.error(f"Error searching similar tickets: {str(e)}")
            logger.exception("Full traceback:")
            return []
    
    def _deduplicate_tickets(self, retrieved_tickets: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Remove duplicate tickets from retrieved results based on ticket_id.
        
        Args:
            retrieved_tickets: List of retrieved ticket dictionaries
            
        Returns:
            List[Dict[str, Any]]: Deduplicated list of tickets
        """
        seen = set()
        unique_tickets = []
        
        for ticket in retrieved_tickets:
            ticket_id = ticket.get('ticket_id')
            if ticket_id and ticket_id not in seen:
                seen.add(ticket_id)
                unique_tickets.append(ticket)
                
        return unique_tickets
    
    async def _filter_relevant_tickets(self, 
                    ticket: Ticket, 
                    user_query: str,
                    tickets: List[Dict[str, Any]], 
                    observability_info: Dict[str, Any],
                    n_relevant_tickets: int = 5) -> List[Dict[str, Any]]:
        """
        Select the most relevant tickets from the set of similar tickets.
        
        Uses LLM to determine which retrieved tickets are most relevant to the
        current issue, improving classification and solution accuracy.
        
        Args:
            ticket: Ticket object containing current ticket data
            user_query: The user's query for the ticket
            tickets: List of similar tickets from search
            observability_info: Dictionary with observability info for logging
            n_relevant_tickets: Number of relevant tickets to return

        Returns:
            List[Dict]: Filtered list containing only the most relevant tickets
        """
        if not tickets:
            return []

        # Add ticket IDs to the display format for each ticket
        tickets_display = [
            {
                "index": i,
                "id": ticket["ticket_id"],
                "type": ticket.get("type"),
                "subtype": ticket.get("subtype"),
                "item": ticket.get("item"),
                "messages": ticket.get("messages")
            }
            for i, ticket in enumerate(tickets)
        ]

        prompt = f"""
You are an IT support expert. We have retrieved some tickets from our knowledge base that may be relevant to the user's issue. 
Your task is to select the index(es) of the tickets(s) that are most relevant to the user's issue.
There may be many tickets that are relevant to the user's issue or there may be none. Either situation is fine.

<user_issue>
{user_query}
</user_issue>

<retrieved_tickets>
{json.dumps(tickets_display, indent=2)}
</retrieved_tickets>

Analyze the tickets carefully and select the ticket IDs that are most relevant to the user's issue.
Return ONLY the ticket IDs of relevant tickets. If no tickets are relevant, return an empty list.
"""
        class RerankResult(BaseModel):
            indeces: list[int] = Field(description=f"The index of the tickets that are relevant to the user message up to a limit of {n_relevant_tickets} tickets. Return empty list if none are relevant.")
        
        logger.debug(f"Invoking {DUMB_MODEL} to select the relevant tickets")
        response = await self.llm_provider.get_response(
            prompt,
            config = {"temperature": 0.1, "model": DUMB_MODEL},
            response_format = RerankResult,
            observability_info = observability_info
        )
        
        # Get the indices of relevant tickets
        indices = response.indeces
        logger.debug(f"Relevant ticket indices: {indices}")
        
        # Select the relevant tickets
        selected_tickets = [tickets[i] for i in indices if i < len(tickets)]
        return selected_tickets
    
    async def _classify_ticket_suggest_solution(self, 
                    issue_description: str, 
                    relevant_tickets: List[Dict[str, Any]], 
                    observability_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Perform the complete ticket classification process.
        
        Orchestrates the classification pipeline:
        1. Determine service type
        2. Determine subtype within that service type
        3. Determine item within that subtype
        4. Generate a suggested solution
        
        Args:
            issue_description (str): Description of the ticket issue
            relevant_tickets (List[Dict]): Similar tickets to guide classification
            observability_info (Dict[str, Any]): Observability information for logging
            
        Returns:
            dict: Complete classification with service_type, subtype, item and suggested_solution
        """
        
        try:
            # Get all types, subtypes, and items from the TSI dictionary
            type_subtype_dict = {k: list(v.keys()) for k, v in self.tsi_dict.items()}
            
            # Step 1: Classify service type
            service_type = await self._classify_service_type(issue_description, relevant_tickets, observability_info)
            
            try:
                # Step 2: Classify subtype
                subtype, priority = await self._classify_subtype_priority(
                    issue_description, 
                    relevant_tickets, 
                    service_type,
                    observability_info
                )
                
                try:
                    # Step 3: Classify item and suggest solution
                    response = await self._classify_item_suggest_solution(
                        issue_description, 
                        relevant_tickets, 
                        service_type, 
                        subtype,
                        observability_info
                    )
                    item = response["item"]
                    suggested_solution = response["suggested_solution"]
                    relevant_tickets_ids = response["relevant_tickets_ids"]
                    
                except Exception as e:
                    logger.error(f"Error classifying item for issue '{issue_description[:50]}': {e}")
                    logger.exception("Full traceback:")
                    item = None
                    priority = None
                    suggested_solution = None
                    
            except Exception as e:
                logger.error(f"Error classifying subtype for issue '{issue_description[:50]}': {e}")
                logger.exception("Full traceback:")
                subtype = None
                item = None
                suggested_solution = None
                
        except Exception as e:
            logger.error(f"Error classifying service type for issue '{issue_description[:50]}': {e}")
            logger.exception(f"Full traceback: {traceback.format_exc()}")
            subtype = None
            item = None
            suggested_solution = None
            similar_ticket_ids = []
                
        
        # Add the classification to the list
        return {
            "service_type": service_type,
            "subtype": subtype,
            "item": item,
            "priority": priority,
            "suggested_solution": suggested_solution
        }

        
    async def _classify_service_type(self, issue_description: str, relevant_tickets: List[Dict[str, Any]], observability_info: Dict[str, Any]) -> str:
        """
        Determine the appropriate service type for a ticket.
        
        Uses LLM to classify the service type based on the issue description
        and similar tickets, matching against the organization's type/subtype dictionary.
        
        Args:
            issue_description (str): Description of the issue
            relevant_tickets (List[Dict]): Similar tickets to use as examples
            observability_info (Dict[str, Any]): Observability information for logging
            
        Returns:
            str: The classified service type
        """
        # Create a dict with just the service types and subtypes
        type_subtype_dict = {k: list(v.keys()) for k, v in self.tsi_dict.items()}
        types_list = list(type_subtype_dict.keys())
        types_list.append(FAILED_TSI_CATEGORY)
        
        prompt = f"""
You are an IT support expert. Your task is to identify the most appropriate service type for a user issue.
<issue>
{issue_description}
</issue>

Here are some retrieved tickets from our knowledge base that are relevant to the user's issue:
<retrieved_tickets>
{json.dumps(relevant_tickets, indent=2)}
</retrieved_tickets>

Here are the valid service types:
<service_types>
{types_list}
</service_types>

Analyze the issue carefully and identify the single most appropriate service type.
The retrieved tickets are meant as a guide to help you classify the service type, but may not be relevant.
"""
        
        # print(f"\n_classify_service_type prompt: {prompt}")
        class ServiceType(BaseModel):
            service_type: str = Field(description=f"The service type name that applies to the issue. Select from {types_list}")

        response = await self.llm_provider.get_response(
            prompt,
            config = {"temperature": 0.1, "model": SMART_MODEL},
            response_format = ServiceType,
            observability_info = observability_info
        )
        return response.service_type

    async def _classify_subtype_priority(self, 
                                issue_description: str, 
                                relevant_tickets: List[Dict[str, Any]], 
                                service_type: str,
                                observability_info: Dict[str, Any]) -> tuple:
        """
        Determine the appropriate subtype for a ticket within its service type.
        
        Uses LLM to classify the subtype based on the issue description, similar tickets,
        and the previously determined service type. If no appropriate subtype can be determined,
        returns "Unknown".
        
        Args:
            issue_description (str): Description of the issue
            relevant_tickets (List[Dict]): Similar tickets to use as examples
            service_type (str): The previously classified service type
            observability_info (Dict[str, Any]): Observability information for logging
            
        Returns:
            tuple: (subtype (str), priority (str))
        """
        
        # Get valid subtypes for this service type
        subtype_item_dict = {k: v for k, v in self.tsi_dict[service_type].items()}
        subtypes_list = list(subtype_item_dict.keys())
        subtypes_list.append(FAILED_TSI_CATEGORY)
        
        prompt = f"""
You are an IT support expert. Your tasks are to
- identify the most appropriate service subtype for a user issue
- assign a priority to the ticket.

<issue>
{issue_description}
</issue>

The service type has been determined to be: {service_type}

Here are some retrieved tickets from our knowledge base that are relevant to the user's issue:
These are meant as a guide to help you classify the subtype. 
If the current issue does not match the examples, select the best subtype from the list of valid subtypes.
<example_tickets>
{json.dumps(relevant_tickets, indent=2)}
</example_tickets>

Here are the valid subtypes for this service type:
<subtypes>
{subtypes_list}
</subtypes>

Analyze the issue carefully and identify the single most appropriate subtype from the list. If none of the specific subtypes seem to apply, select "Unknown".

Ticket Priorities are based on:
- impact(number of people affected) 
- severity (how much it affects job)

| | High Urgency | Medium Urgency | Low Urgency |
|---|---|---|---|
| High Impact | P1 | P2 | P3 |
| Medium Impact | P2 | P3 | P3 |
| Low Impact | P3 | P4 | P4 |

Low Urgency : "One user or a small group of users is affected"
High Impact : "Critical - Major business processes are stopped"""
        # print(f"\n_classify_subtype_priority prompt: {prompt}")
        class SubtypeResponse(BaseModel):
            subtype: str = Field(description=f"The subtype name that applies to the issue. Select from {subtypes_list}")
            priority: str = Field(description="The priority of the ticket. Select from [P1, P2, P3, P4]. If unsure, assign P3")
            
        response = await self.llm_provider.get_response(
            prompt,
            config = {"temperature": 0.1, "model": SMART_MODEL},
            response_format = SubtypeResponse,
            observability_info = observability_info
        )
        return response.subtype, response.priority

    async def _classify_item_suggest_solution(self, 
                                             issue_description: str,
                                             relevant_tickets: List[Dict[str, Any]],
                                             service_type: str,
                                             subtype: str,
                                             observability_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Determine the specific item for a ticket and suggest a solution.
        
        Uses LLM to classify the item (the most specific categorization level)
        and generate a suggested solution based on similar tickets.
        
        Args:
            issue_description (str): Description of the issue
            relevant_tickets (List[Dict]): Similar tickets to use as examples
            service_type (str): The previously classified service type
            subtype (str): The previously classified subtype
            observability_info (Dict[str, Any]): Observability information for logging
            
        Returns:
            dict: Contains 'item', 'suggested_solution', and 'relevant_tickets_ids' keys.
        """

        try:
            service_subtypes = self.tsi_dict.get(service_type, {})   
            items = service_subtypes.get(subtype, [])
            items.append(FAILED_TSI_CATEGORY)
            
            prompt = f"""
You are an IT support expert. Your task is to identify the most appropriate service item for a user issue.
<issue>
{issue_description}
</issue>

Here are some tickets that are relevant to the user's issue that have been retrieved from our knowledge base. 
Use them as examples to help classify the item and suggest a possible solution. 
These are meant as a guide to help you classify the item. If the current issue does not match the examples, select the best item from the list of valid items.
<retrieved_tickets>
{json.dumps(relevant_tickets, indent=2)}
</retrieved_tickets>

The service type is: {service_type}
The subtype is: {subtype}
Here are the valid items for this combination:
<items>
{items}
</items>

Analyze the issue carefully and identify the single most appropriate item from the list. If none of the specific items seem to apply, select "Unknown".
Also provide a short suggested solution for how the IT team can help the user resolve their issue. Use only the information provided in the retrieved tickets for this. Get straight to the point with no preamble. If there is no clear solution for the IT team in the tickets, return None.
"""
            class ItemEntry(BaseModel):
                item: str = Field(description=f"The item name that applies to the issue. Select from {items}")
                suggested_solution: Optional[str] = Field(..., description="A suggestion for how the IT team can help the user resolve their issue, based on the retrieved tickets. If no solution is shown in the retrieved tickets, return None. Start with 'Steps: ...' . Use point form if appropriate.")
                relevant_tickets: Optional[list[int]] = Field(..., description="The ticket IDs of the tickets that informed the suggested solution, in order of relevance. Return empty list if suggested_solution=None.")
                
            response = await self.llm_provider.get_response(
                prompt,
                config = {"temperature": 0.1, "model": SMART_MODEL},
                response_format = ItemEntry,
                observability_info = observability_info
            )
            max_relevant_ticket_ids = 5
            formatted_response = {
                "item": response.item,
                "suggested_solution": response.suggested_solution,
                "relevant_tickets_ids": response.relevant_tickets[:max_relevant_ticket_ids]
            }

            if response.item == "Unknown":
                response.item = None
            
            if response.relevant_tickets:
                ticket_ids_with_ref = [f"#{ticket_id}" for ticket_id in response.relevant_tickets]
                formatted_response["suggested_solution"] += f"\n\n(based on tickets: {', '.join(ticket_ids_with_ref)})"
                
            return formatted_response
            
        except Exception as e:
            # Handle any errors and return a fallback response
            logger.error(f"Error classifying item for issue: {str(e)}")
            logger.exception("Full traceback:")
            return {
                "item": "Unknown",
                "suggested_solution": None,
                "relevant_tickets": []
            }
        
    async def _llm_web_search_solution(self, issue_description: str, observability_info: Dict[str, Any], web_search_options: Dict = WEB_SEARCH_OPTIONS) -> str:
        """
        Use LLM to search the web for a solution to the issue.

        Args:
            issue_description (str): Description of the issue to search for a solution.
            observability_info (Dict[str, Any]): Observability information for logging.
            web_search_options (Dict): Options for web search (default: WEB_SEARCH_OPTIONS).

        Returns:
            str: Suggested solution from web search, or 'No solution found'.
        """
        prompt = f"""You are an IT support assistant who is proposing a potential solution to a user's issue that an IT tech will implement. 
Your task is to search the web for a solution to the user's issue. 

<issue>
{issue_description}
</issue>

If no solution is found, return 'No solution found'. 
Be concise (keep below 500 words).
Include markdown-formatted links to the web page used to find the solution in the bulleted list.
Use the following format:
<format>
A short assesment of what the situation is and what the root cause may be.

1. **Step 1 title**
    - bulleted list describing the step and substeps including links to the web pages if applicable [alt text](link)
2. **Step 2 title**
    - bulleted list describing the step and substeps including links to the web pages if applicable [alt text](link)
(etc.)
</format>
No addtitional text please
"""
        try:
            response = await self.llm_provider.get_response(
                prompt,
                config = {"model": WEB_SEARCH_MODEL},
                observability_info = observability_info,
                web_search_options = web_search_options
            )
            return response  
        except Exception as e:
            logger.error(f"Error searching the web for a solution: {str(e)}")
            logger.exception("Full traceback:")
            return "No web search solution found"
    

    def save_ticket(self, ticket_result: Dict[str, Any], folder: str = "app/data/tickets") -> str:
        """
        Save ticket results to a JSON file.
        
        Args:
            ticket_result: Dictionary with ticket processing results
            folder: Folder to save the file in
            
        Returns:
            str: Path to the saved file
        """
        try:
            # Ensure folder exists
            os.makedirs(folder, exist_ok=True)
            
            # Create filename with ticket ID
            ticket_id = ticket_result.get('ticket_id', 'unknown')
            filename = f"{ticket_id}.json"
            filepath = os.path.join(folder, filename)
            
            # Save to file as JSON
            with open(filepath, 'w') as f:
                json.dump(ticket_result, f, indent=4)
                
            logger.debug(f"Saved ticket {ticket_id} results to {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error saving ticket results to disk: {str(e)}")
            raise
```
## File: app/ticket_poller.py
```python
from datetime import datetime, timedelta, timezone
import asyncio
import logging
from typing import Optional, List, Dict, Any
import os
from app.api import ConnectWiseAPI
import json
from llm import get_llm_provider
from database.postgres_client import PostgresClient
from app.ticket_annotator import TicketAnnotator
from app.ticket_ingester import TicketIngester
from app.ticket_database import TicketDatabase
import traceback

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Authentication details for database access
USERNAME = "helpdesk_agent"
SMART_MODEL_NAME = "gpt-4.1-2025-04-14"
DUMB_MODEL_NAME = "gpt-4.1-mini-2025-04-14"
INGESTION_MODEL = "gpt-4.1-mini-2025-04-14"

AECHAI_FILTER_FROM = ["aechai", "agentaech"]

class TicketPoller:
    def __init__(
        self,
        company_identifiers: List[str],
        db_client: PostgresClient = None,
        username: str = USERNAME,
        polling_interval: int = 120,  # 2 minutes in seconds
        board_id: int = 17,  # Default board ID
        page_size: int = 50,
        max_tickets: int = 100,
        simultaneous_requests: int = 5,
        save_folder: str = None,
        n_user_history_tickets: int = 2,
        n_retrieved_tickets: int = 20
    ):
        """Initialize the TicketPoller.
        
        Args:
            company_identifiers (List[str]): List of company identifiers to poll tickets for
            db_client (PostgresClient): Database client instance
            polling_interval (int): How often to poll for new tickets in seconds
            board_id (int): The Scout board ID to poll tickets from
            page_size (int): Number of tickets to fetch per page
            max_tickets (int): Maximum number of tickets to process in one polling cycle
            simultaneous_requests (int): Number of simultaneous requests for getting ticket details
            save_folder (str): Folder to save ticket annotations to (for debugging) default is None
            n_user_history_tickets (int): Number of tickets to include in the user history
            n_retrieved_tickets (int): Number of similar tickets to retrieve from the database
        """
        self.company_identifiers = company_identifiers
        self.db_client = db_client or PostgresClient()
        self.username = username
        self.polling_interval = polling_interval
        self.board_id = board_id
        self.page_size = page_size
        self.max_tickets = max_tickets
        self.simultaneous_requests = simultaneous_requests
        self.semaphore = asyncio.Semaphore(simultaneous_requests)
        self.api = ConnectWiseAPI()
        self.is_running = False
        self.llm_provider = get_llm_provider(SMART_MODEL_NAME)
        self.tsi_dict = self._load_tsi_dict()
        self.last_ticket_id = None  # Will be initialized from database
        self.n_user_history_tickets = n_user_history_tickets
        self.n_retrieved_tickets = n_retrieved_tickets
        # New components (will be initialized in start method)
        self.annotator = None
        self.ingester = None
        self.ticket_db = None

        # for debugging
        self.save_folder = save_folder

    def _load_tsi_dict(self):
        """Load the TSI dictionary from the file."""
        with open(os.getenv("TSI_DICT_PATH"), "r") as f:
            self.tsi_dict = json.load(f)
        return self.tsi_dict
            
    async def start(self, add_note: bool = False, 
                    break_after_single_cycle: bool = False):
        """
        Start the continuous polling loop that checks for new tickets and newly closed tickets.
        Initializes required data, then runs poll_tickets() at regular intervals
        defined by polling_interval.
        """
        self.is_running = True
        # await self.db_client.initialize()  # Initialize the database connection
        self.tsi_dict = self._load_tsi_dict()
        
        # Get user_id from database client
        self.user_id = self.db_client.user_info.id
        
        # Initialize TicketDatabase and get last ticket ID
        self.ticket_db = await TicketDatabase.create(self.db_client, self.username)
        self.last_ticket_id = await self.ticket_db.get_last_ticket_id()
            
        # Initialize new components
        self.annotator = await TicketAnnotator.create(
            db_client=self.db_client,
            username=self.username,
            simultaneous_requests=self.simultaneous_requests
        )
        self.ingester = await TicketIngester.create(
            db_client=self.db_client,
            username=self.username
        )
        
        logger.info(f"Starting polling loop with interval {self.polling_interval} seconds")
        logger.info(f"Monitoring companies: {self.company_identifiers}")
        logger.info(f"Starting from ticket ID: {self.last_ticket_id}")
        logger.info(f"break_after_single_cycle: {break_after_single_cycle}")
        
        while self.is_running:
            try:
                start_time = datetime.now()
                logger.info(f"------------- Starting polling cycle at {start_time.strftime('%Y-%m-%d %H:%M:%S')} -------------")
                
                await self.poll_tickets(add_note)
                
                if break_after_single_cycle:
                    logger.info("Breaking after single cycle")
                    break
                
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                logger.debug(f"Completed polling cycle in {duration:.2f} seconds")
                
                # Calculate sleep time to maintain consistent polling interval
                sleep_time = max(0, self.polling_interval - duration)
                if sleep_time > 0:
                    logger.info(f"Sleeping for {sleep_time:.1f}s")
                    await asyncio.sleep(sleep_time)
                else:
                    logger.warning(f"Polling took longer than interval ({duration:.2f} > {self.polling_interval})")
                    # Sleep at least 1 second to avoid tight loop
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.error(f"Error in polling loop: {e}")
                logger.exception("Full traceback:")
                await asyncio.sleep(60)  # Wait a minute before retrying on error

    async def stop(self):
        """
        Stop the polling loop and clean up resources.
        Closes database connections and sets is_running to False.
        """
        self.is_running = False
        await self.db_client.close()  # Close database connection

    async def poll_tickets(self, add_note: bool = False):
        """
        Main polling method that orchestrates the entire ticket processing flow.
        First polls for new tickets, then checks if any previously open tickets
        are now closed.
        """
        try:
            # Make sure last_ticket_id is initialized
            if self.last_ticket_id is None:
                self.last_ticket_id = await self.ticket_db.get_last_ticket_id()
                logger.info(f"Initialized last_ticket_id to {self.last_ticket_id}")
            
            # Step 1: Poll for new tickets
            # for every new ticket, an note will be added to the ticket
            await self.poll_new_tickets(add_note)
            
            # Step 2: Check for newly closed tickets
            # for every newly closed ticket, the ticket will be fully ingested
            await self.poll_newly_closed_tickets(add_note)
                
        except Exception as e:
            logger.error(f"Error polling tickets: {e}")
            raise

##################################### NEW TICKETS #####################################

    async def poll_new_tickets(self, add_note: bool = False):
        """
        Find and process new tickets from the Scout API.
        
        For each new ticket:
        - If open: Classify it, suggest solutions, and create a skeleton database entry
        - If already closed: Fully ingest the ticket content immediately
        
        Updates last_ticket_id to the highest ID processed for future polling cycles.
        """
        try:
            # First get basic ticket info with minimal fields
            logger.info(f"Polling for new tickets since ticket id: {self.last_ticket_id}")
            tickets = await self.api.get_new_tickets(
                company_identifiers=self.company_identifiers,
                ticket_id=self.last_ticket_id,
                fields=[
                    "id", 
                    # "summary", "type", "subType", "item", "company", "_info", 
                    "dateResolved", "dateClosed"
                ],
                ascending=True,
                page_size=self.page_size,
                limit=self.max_tickets,
                board_id=self.board_id
            )

            if not tickets or len(tickets) == 0:
                logger.debug("No new tickets found")
                return
                
            # Separate tickets into closed and open
            closed_tickets = []
            open_tickets = []
            
            for ticket in tickets:
                # Check if the ticket is already closed
                if self._is_ticket_closed(ticket):
                    closed_tickets.append(ticket)
                else:
                    open_tickets.append(ticket)
            
            logger.info(f"Found {len(tickets)} new tickets ({len(closed_tickets)} closed, {len(open_tickets)} open)")
            

            # #########################################################
            # # Test limit - remove in production
            # num_tickets_to_process = 1
            # start_n = 0
            # end_n = start_n + num_tickets_to_process
            # closed_tickets = closed_tickets[start_n:end_n]
            # open_tickets = open_tickets[start_n:end_n]
            # #########################################################


            # Process open tickets concurrently
            if open_tickets:
                await self.annotate_open_tickets(
                    open_tickets, 
                    add_note=add_note
                )

            # Process already closed tickets concurrently using semaphore
            if closed_tickets:
                await self.ingest_closed_tickets(closed_tickets, add_note)
            
            # Update last_ticket_id to the most recent ticket's ID
            if tickets:
                latest_ticket = max(tickets, key=lambda x: x.get('id', 0))
                self.last_ticket_id = latest_ticket['id']
                logger.info(f"Updated last_ticket_id to: {self.last_ticket_id}")
                
        except Exception as e:
            logger.error(f"Error polling new tickets: {e}")
            raise

    async def annotate_open_tickets(self, 
                        open_tickets: List[Dict[str, Any]], 
                        add_note: bool = False) -> None:
        """
        Process a list of open tickets concurrently, with proper error handling.
        
        Args:
            open_tickets: List of open ticket dictionaries from the API
            add_note: Whether to add a note to the ticket in Scout
        """
        logger.info(f"--- Annotating {len(open_tickets)} open tickets ---")
        async def annotate_open_ticket_with_semaphore(ticket_id: int, idx: int) -> dict:
            async with self.semaphore:
                result = await self.annotate_open_ticket(
                    ticket_id, 
                    add_note, 
                    save_folder=self.save_folder
                )
                logger.info(f"Annotated open ticket {ticket_id} ({idx + 1}/{len(open_tickets)})")
                return result
                
        # Create tasks for each open ticket
        tasks = [
            annotate_open_ticket_with_semaphore(ticket['id'], idx) 
            for idx, ticket in enumerate(open_tickets)
        ]
        
        # Wait for all tasks to complete
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle any errors from the tasks
        for ticket, result in zip(open_tickets, results):
            if isinstance(result, Exception):
                logger.error(f"Error processing open ticket {ticket.get('id')}: {str(result)}")
                logger.exception(f"Full traceback: {traceback.format_exc()}")

        logger.info(f"Annotated {len(open_tickets)} new open tickets")
        
    async def ingest_closed_tickets(self, 
                    closed_tickets: List[Dict[str, Any]], 
                    add_note: bool = False) -> None:
        """
        Ingest a list of closed tickets concurrently, with proper error handling.
        
        Args:
            closed_tickets: List of closed ticket dictionaries from the API
            add_note: Whether to add a note to the ticket in Scout
        """
        logger.info(f"--- Ingesting {len(closed_tickets)} already closed tickets ---")
        async def ingest_closed_ticket_with_semaphore(ticket, index):
            async with self.semaphore:
                
                try:
                    full_ticket = await self.ingester.preprocess_ticket(ticket["id"],
                                                                        filter_aechai=True)
                    result = await self.ingester.ingest_ticket(full_ticket)
                    logger.info(f"Ingested closed ticket {ticket['id']} ({index + 1}/{len(closed_tickets)})")
                    return result
                except Exception as e:
                    logger.error(f"Error ingesting closed ticket {ticket['id']}: {str(e)}")
                    logger.exception(f"Full traceback: {traceback.format_exc()}")
                    return {"success": False, "ticket_id": ticket["id"], "error": str(e)}
        
        # Create tasks for each closed ticket
        tasks = [ingest_closed_ticket_with_semaphore(ticket, i) for i, ticket in enumerate(closed_tickets)]
        
        # Wait for all tasks to complete
        results = await asyncio.gather(*tasks)
        
        success_count = sum(1 for r in results if r.get("success", False))
        logger.info(f"Ingested {success_count}/{len(closed_tickets)} already closed tickets")

    def _is_ticket_closed(self, ticket: Dict) -> bool:
        """
        Check if a ticket is closed.
        
        Args:
            ticket (Dict): The ticket data from the Scout API
            
        Returns:
            bool: True if the ticket is closed, False otherwise
        """
        # Check all possible field variations that might indicate a closed ticket
        return (
            ticket.get('dateClosed') is not None or 
            ticket.get('dateResolved') is not None or
            ticket.get('closedDate') is not None or
            ticket.get('closed_date') is not None
        )

        

    async def annotate_open_ticket(self, 
                    ticket_id: int, 
                    add_note: bool = False,
                    save_folder: str = None) -> dict:
        """
        Core processing logic for a new, open ticket.
        Workflow:
        1. Format and clean ticket data
        2. Find similar tickets in the database
        3. Filter for the most relevant matches
        4. Classify the ticket (type/subtype/item)
        5. Generate a suggested solution
        6. Create a skeleton entry in the database
        7. Add the suggested solution as a note to the ticket in Scout (if no AechAI note exists)

        Args:
            ticket_id (int): The ID of the ticket to process
            
        Returns:
            dict: The processed ticket with classification and solution information
        """
        try:
            
            ticket = await self.ingester.preprocess_ticket(ticket_id,
                                                           filter_aechai=False)

            aech_note = self.has_aech_note(ticket)
            ticket = await self.annotator._convert_to_ticket(ticket, source="api")

            
            if aech_note:
                logger.info(f"Ticket {ticket_id} already has an AechAI note, skipping note addition")
                ticket_annotation = None
                metadata = None
            else:
                ticket_annotation = await self.annotator.annotate_ticket(
                    ticket, 
                    add_note=add_note,
                    save_folder=save_folder,
                    n_user_history_tickets=self.n_user_history_tickets,
                    n_matches=self.n_retrieved_tickets
                )
                metadata={"aech_classification": ticket_annotation.classification.model_dump()}
            
            # Create a skeleton entry for this open ticket
            await self._create_skeleton_entry(
                ticket_id=ticket.id, 
                group_id=ticket.group_id,
                metadata=metadata
            )

            return ticket_annotation
            
        except Exception as e:
            logger.error(f"Error in annotate_open_ticket for ticket {ticket_id}: {str(e)}")
            logger.exception(f"Full traceback: {traceback.format_exc()}")
            raise

    def has_aech_note(self, ticket: dict, filter_from: List[str] = AECHAI_FILTER_FROM) -> bool:
        """
        Check if the ticket has an AechAI note.
        AechAI notes are currently written by the agent, so we look for 'agentaech' in the message text.

        Args:
            ticket (dict): The preprocessed ticket with "messages" field
            
        Returns:
            bool: True if the ticket has an AgentAech note, False otherwise
        """
        for message in ticket.get('messages', []):
            if message.get('from', '').lower() in filter_from:
                return True
        return False
        

##################################### CLOSED TICKETS  #####################################
    async def poll_newly_closed_tickets(self, add_note: bool = False):
        """
        Poll for tickets that were previously open but are now closed.
        
        This method:
        1. Retrieves all skeleton ticket IDs from the database, sorted by creation date
        2. Checks if any of these tickets are now closed using the Scout API
        3. Fully ingests content for newly closed tickets using a semaphore for concurrency
        """
        logger.info("Checking for newly closed tickets")
        
        try:
            # Get all skeleton tickets, sorted by creation date
            skeleton_tickets = await self.get_skeleton_tickets()
            if not skeleton_tickets:
                logger.debug("No skeleton entries found")
                return
    
            # Check which tickets are now closed
            skeleton_ticket_ids = [t["id"] for t in skeleton_tickets]
            logger.debug(f"{len(skeleton_ticket_ids)} skeleton tickets found")
            closed_ticket_ids = await self.identify_newly_closed_tickets(skeleton_ticket_ids)
            
            if not closed_ticket_ids:
                logger.debug("No newly closed tickets found")
                return
                
            logger.info(f"Found {len(closed_ticket_ids)} newly closed out of {len(skeleton_ticket_ids)} skeleton tickets")
            
            # Process these closed tickets concurrently (full ingestion)
            async def ingest_closed_ticket_with_semaphore(ticket_id, idx):
                async with self.semaphore:
                    logger.info(f"Ingesting newly closed ticket {ticket_id} ({idx + 1}/{len(closed_ticket_ids)})")
                    try:
                        
                        result = await self.ingest_closed_ticket(ticket_id)
                        
                        if add_note:
                            
                            logger.debug(f"Adding post-closure note to ticket {ticket_id}")
                            initial_classification = [t.get("metadata", {}).get("aech_classification") for t in skeleton_tickets if t["id"] == ticket_id][0]
                            closure_note_response = await self.add_post_ticket_closure_note(
                                ticket_id, 
                                initial_classification, 
                            )
                        else:
                            closure_note_response = None
                        response = {
                            "success": result.get("success", False), 
                            "ticket_id": ticket_id,
                            "closure_note_response": closure_note_response
                        }
                        return response
                    except Exception as e:
                        logger.error(f"Error ingesting newly closed ticket {ticket_id}: {str(e)}")
                        logger.exception(f"Full traceback: {traceback.format_exc()}")
                        return {"success": False, "ticket_id": ticket_id, "error": str(e)}
            
            # Create tasks for each newly closed ticket
            logger.info(f"--- Ingesting {len(closed_ticket_ids)} newly closed tickets ---")
            tasks = [ingest_closed_ticket_with_semaphore(ticket_id, i) for i, ticket_id in enumerate(closed_ticket_ids)]
            
            # Wait for all tasks to complete
            results = await asyncio.gather(*tasks)
            
            success_count = sum(1 for r in results if r.get("success", False))
            logger.info(f"Successfully ingested {success_count}/{len(closed_ticket_ids)} newly closed tickets")
                
        except Exception as e:
            logger.error(f"Error checking closed tickets: {str(e)}")
            logger.exception("Full traceback:")

    async def ingest_closed_ticket(self, ticket_id: int) -> dict:
        """
        Ingest a closed ticket by creating full content in the database. 
        AgentAech notes are filtered out.
        
        This method:
        1. Uses TicketIngester to process and ingest the ticket
        2. Either creates a new entry or updates an existing skeleton entry
        
        Args:
            ticket (dict): The full ticket data including notes
            group_id (str): The group ID for the company
            
        Returns:
            dict: The result of the ingestion operation
        """
        try:
            logger.debug(f"Ingesting closed ticket {ticket_id}")
            
            # Use TicketIngester to ingest the ticket
            ticket = await self.ingester.preprocess_ticket(
                ticket_id,
                filter_aechai=True
            )

            ingestion_response = await self.ingester.ingest_ticket(ticket)
            
            logger.debug(f"Successfully ingested ticket {ticket['id']}")
            return ingestion_response
            
        except Exception as e:
            logger.error(f"Error ingesting closed ticket {ticket.get('id')}: {str(e)}")
            logger.exception("Full traceback:")
            return {"success": False, "error": str(e)}
    
    async def identify_newly_closed_tickets(self, ticket_ids: List[int]) -> List[Dict]:
        """
        Check which tickets from the list are now closed by querying the Scout API.
        
        Args:
            ticket_ids (List[int]): List of ticket IDs to check
            
        Returns:
            List[Dict]: List of fully closed ticket data
        """
        if not ticket_ids:
            return []
            
        logger.debug(f"Checking resolution status for {len(ticket_ids)} tickets")
        
        # Process tickets concurrently while respecting the semaphore limit
        async def fetch_ticket_with_semaphore(ticket_id, index):
            async with self.semaphore:
                try:
                    logger.debug(f"Fetching details for ticket {ticket_id} ({index + 1}/{len(ticket_ids)})")
                    
                    # Get the ticket from the API
                    ticket = await self.api.get_ticket(
                        ticket_id, 
                        fields=["id", "dateClosed", "dateResolved"]
                    )
                    
                    # Check if the ticket is closed
                    is_closed = self._is_ticket_closed(ticket)
                    if is_closed:
                        logger.debug(f"Ticket {ticket_id} is now closed")
                        return ticket_id
                    else:
                        logger.debug(f"Ticket {ticket_id} is still open")
                        return None
                except Exception as e:
                    logger.error(f"Error fetching ticket {ticket_id}: {str(e)}")
                    return None
        
        # Create tasks for all tickets, using the semaphore to limit concurrency
        tasks = [fetch_ticket_with_semaphore(ticket_id, i) for i, ticket_id in enumerate(ticket_ids)]
        results = await asyncio.gather(*tasks)
        
        # Filter out None results (tickets that are still open or had errors)
        newly_closed_ticket_ids = [ticket_id for ticket_id in results if ticket_id is not None]
            
        logger.debug(f"Found {len(newly_closed_ticket_ids)} newly closed tickets out of {len(ticket_ids)} checked")
        return newly_closed_ticket_ids
    
##################################### END CLOSED TICKETS #####################################
        

     
    
    async def _create_skeleton_entry(self, 
                ticket_id: int, 
                group_id: str, 
                metadata: dict|None = None) -> dict:
        """
        Create a minimal entry in the parent_documents table for an open ticket.
        
        Skeleton entries allow us to track tickets that we've seen but aren't yet
        fully ingested because they're still open. When these tickets become
        closed, we can fully ingest their content.
        
        Args:
            ticket_id (int): The ID of the ticket from Scout API
            group_id (str): The group ID for the company
            metadata (dict): The metadata for the ticket
        Returns:
            dict: The database result from creating the entry
        """
        try:
            logger.debug(f"Creating skeleton entry for open ticket {ticket_id}")
            
            # Use TicketDatabase to ensure the skeleton entry exists
            result = await self.ticket_db.ensure_ticket_skeleton(
                ticket_id, 
                group_id, 
                metadata
            )
            
            if result:
                return {"id": ticket_id, "group_id": group_id, "metadata": metadata}
            else:
                logger.error(f"Failed to create skeleton entry for ticket {ticket_id}")
                return None
            
        except Exception as e:
            logger.error(f"Error creating skeleton entry for ticket {ticket_id}: {str(e)}")
            logger.exception(f"Full traceback: {traceback.format_exc()}")
            raise
            
    async def get_skeleton_tickets(self) -> List[Dict[str, Any]]:
        """
        Retrieve skeleton tickets that have no summary.
        Searches across all companies, sorted by ticket id.
        
        These represent open tickets that we've processed but haven't fully
        ingested. Used to check which tickets might have become closed since
        last polling.
        
        Returns:
            List[Dict]: List of dicts containing ticket IDs and their group_ids, sorted by ticket id
        """
        try:
            skeleton_tickets = await self.ticket_db.get_skeleton_tickets()
            return skeleton_tickets
            
        except Exception as e:
            logger.error(f"Error getting open ticket IDs: {str(e)}")
            return []
        

    async def add_post_ticket_closure_note(self, 
                    ticket_id: int, 
                    initial_classification: dict) -> bool:
        """
        Add a note to the ticket after it has been closed.

        Args:
            ticket_id (int): The ID of the ticket to add the note to.
            initial_classification (dict): The initial classification data for the ticket.

        Returns:
            bool: True if the note was added successfully.
        """
        ingested_ticket = await self.ticket_db.get_ticket(ticket_id)
        metadata = ingested_ticket.get("metadata", {})
        final_classification = {
            "type": metadata.get("type", "Unknown"),
            "subtype": metadata.get("subtype", "Unknown"),
            "item": metadata.get("item", "Unknown"),
            "priority": metadata.get("priority", "Unknown")
        }
        note_text = self._compose_post_closure_note(initial_classification, final_classification)
        logger.info(f"Adding post-closure note to ticket {ticket_id}")


        ##### UNCOMMENT ME WHEN READY
        response = await self.api.add_note_to_ticket(ticket_id, note_text)
        if response.get("ticketId") == ticket_id:
            logger.info(f"Successfully added post-closure note to ticket {ticket_id}")
            return True
        else:
            logger.error(f"Error adding post-closure to ticket {ticket_id}: {response}")
            return False
    
    def _compose_post_closure_note(self, 
                    initial_classification: dict,
                    final_classification: dict) -> str:
        note_text = f"""Post-closure analysis:

AgentAech's initial classification:
- Service type: {initial_classification['service_type']}
- Subtype: {initial_classification['subtype']}
- Item: {initial_classification['item']}
- Priority: {initial_classification['priority']}

Actual classification:
- Service type: {final_classification['type']}
- Subtype: {final_classification['subtype']}
- Item: {final_classification['item']}
- Priority: {final_classification['priority']}
"""
        return note_text
```
## File: app/Dockerfile
```
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1
ENV PYTHONPATH=/app

# Install system dependencies and build tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    libreoffice \
    poppler-utils \
    libpango-1.0-0 \
    libharfbuzz0b \
    libpangoft2-1.0-0 \
    && ldconfig \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
# Copy the app directory to workdir
COPY . /app/

# Make sure the application has the necessary permissions
RUN chmod -R 755 /app

# Copy requirements and install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt
# RUN pip install -e .

EXPOSE 8000

# Run the ticket poller
CMD ["python3", "app/run_poller.py"] 
# CMD ["python3", "-m", "app.run_poller"]
```
## File: app/ticket_image_processor.py
```python
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import logging
import aiohttp
import base64
import re
from PIL import Image
from io import BytesIO
from pydantic import BaseModel, Field
from llm.provider import get_llm_provider
import asyncio
import json
from database import AuthenticatedPostgresClient
# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BATCH_SIZE = 10  # Maximum images per LLM call
# MODEL_NAME = "gpt-4o-2024-11-20"
MODEL_NAME = "gpt-4.1-2025-04-14"


class TicketImage(BaseModel):
    """Model for LLM image analysis results"""
    image_id: str = Field(description="The ID of the image")
    is_relevant: bool = Field(description="Whether the image is relevant to the ticket")   
    alt_text: Optional[str] = Field(description="The alt text of the image to be used for non-relevant images. Max 8 words. If image is relevant, return None.")
    transcription: Optional[str] = Field(description="A full transcription of all text in the image, preserving layout and formatting using markdown. If the image contains any visual elements that are key to understanding the content of the image, please describe them. If the image is not relevant to the ticket, return None.")
    error: Optional[str] = Field(description="If there is a problem transcribing the image, please write it here. If there is no problem, return None.")
    
class EmailPrivacyStatement(BaseModel):
    """Model for email privacy statement detection"""
    contains_privacy_statement: bool = Field(description="Whether the ticket contains any long email signoff messages such as privacy/security statement(s) that do not relate to the ticket.")
    privacy_regex: Optional[List[str]] = Field(description="A list of short regex patterns that can be used to extract the entire privacy messages/signoffs from the ticket that appear after an email signature. If possible use the first few words and last few words to keep regex short while ensuring the entire privacy statement is captured")  

class EmailSignatureURLs(BaseModel):
    """Model for email signature URLs detection"""
    contains_urls: bool = Field(description="Whether the ticket contains any urls in the email signature.")
    url_regex: Optional[List[str]] = Field(description="A list of short regex patterns that can be used to extract the entire urls from the ticket that appear after an email signature. If possible use the first few words and last few words to keep regex short while ensuring the entire url is captured")  

# class EmailSignatureData(BaseModel):
#     """Model for email signature URLs detection"""
#     contains_signature_data: bool = Field(description="Whether the ticket contains any contact data that appears in the email signatures (after the name and position) that do not relate to the ticket.")
#     signature_regex: Optional[List[str]] = Field(description="A list of short regex patterns that can be used to extract the entire email signatures from the ticket that appear after the name. Do not include the name or position in the regex.")  

class TicketCleanup(BaseModel):
    """Model for complete LLM analysis results"""
    images: List[TicketImage] = Field(description="A list of processed images that were found in the ticket. of there were no images return None")
    email_privacy_statement: EmailPrivacyStatement
    email_signature_urls: EmailSignatureURLs
    # email_signature_data: EmailSignatureData

@dataclass
class ExtractedImage:
    """Represents an extracted image and its metadata"""
    image_id: str
    original_location: Tuple[int, int]
    source_type: str  # 'base64' or 'url'
    pil_image: Optional[Image.Image] = None
    alt_text: Optional[str] = None
    transcription: Optional[str] = None

    @property
    def placeholder(self) -> str:
        """Generate placeholder text for this image"""
        return f"<img_place_holder_{self.image_id}>"

class TicketImageProcessor:
    """
    Processes ticket content to extract, analyze and replace images with text descriptions.
    
    This class provides functionality to handle images in support tickets by:
    1. Extracting both base64-encoded images and markdown-linked images from ticket text
    2. Using LLM to analyze images and determine their relevance to the ticket
    3. Generating transcriptions for relevant images and alt text for non-relevant ones
    4. Detecting and removing email privacy statements and signature URLs from tickets
    5. Replacing image placeholders with appropriate text descriptions
    
    Use this class during the initial processing of support tickets when you need to:
    - Make image content accessible to text-based search and analysis systems
    - Remove extraneous content like privacy statements and email signatures
    - Standardize tickets into a consistent text-only format
    - Preserve the informational content of images through detailed transcriptions
    - Clean and format ticket content for storage in databases
    
    The output of this processor can then be used by other components like the TicketAnnotator
    for classification, search, and solution generation.
    
    Attributes:
        image_counter (int): Counter to generate unique image IDs
        llm_provider: Provider for LLM services used for image analysis
    """
    
    def __init__(self, db_client: AuthenticatedPostgresClient|None = None):
        """
        Initialize the processor with counter and LLM provider
        
        Args:
            db_client: Optional database client for connection pooling
            username: Username for database operations (default: "helpdesk_agent")
        """
        self.image_counter = 0
        self.db_client = db_client
        self.llm_provider = get_llm_provider(MODEL_NAME, database_client=db_client)
        
    def _get_next_image_id(self) -> str:
        """Get the next sequential image ID"""
        self.image_counter += 1
        return str(self.image_counter)

    def _convert_bytes_to_pil_image(self, image_data: bytes) -> Optional[Image.Image]:
        """Create a PIL Image object from bytes data"""
        try:
            pil_image = Image.open(BytesIO(image_data))
            # Handle palette images with transparency properly
            if pil_image.mode in ('RGBA', 'LA') or (pil_image.mode == 'P' and 'transparency' in pil_image.info):
                background = Image.new('RGB', pil_image.size, (255, 255, 255))
                if pil_image.mode == 'P':
                    pil_image = pil_image.convert('RGBA')
                background.paste(pil_image, mask=pil_image.split()[-1])
                pil_image = background
            elif pil_image.mode not in ('RGB', 'RGBA'):
                pil_image = pil_image.convert('RGB')
            return pil_image
        except Exception as e:
            logger.error(f"Error creating PIL Image: {e}")
            return None

    def _decode_safelinks_url(self, url: str) -> str:
        """
        Decode a Microsoft SafeLinks URL to extract the original destination URL.
        
        Example:
        https://can01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fhidglobal.com%2Fdrivers&data=...
        becomes:
        http://hidglobal.com/drivers
        
        Args:
            url: A potentially SafeLinks-wrapped URL
            
        Returns:
            The decoded original URL if it's a SafeLinks URL, otherwise the original URL
        """
        try:
            # Check if this is a safelinks URL
            if 'safelinks.protection.outlook.com' in url:
                from urllib.parse import urlparse, parse_qs, unquote
                
                # Parse the URL
                parsed_url = urlparse(url)
                
                # Extract the 'url' query parameter
                query_params = parse_qs(parsed_url.query)
                
                # Get the original URL from the 'url' parameter
                if 'url' in query_params and query_params['url']:
                    original_url = query_params['url'][0]
                    
                    # URL-decode the original URL (converting %xx sequences)
                    decoded_url = unquote(original_url)
                    
                    # HTML decode entities like &amp; to &
                    decoded_url = decoded_url.replace('&amp;', '&')
                    
                    logger.debug(f"Decoded SafeLinks URL: {url} → {decoded_url}")
                    return decoded_url
            
            # If not a SafeLinks URL or couldn't decode, return the original
            return url
            
        except Exception as e:
            logger.warning(f"Error decoding SafeLinks URL {url}: {str(e)}")
            return url

    async def _download_image(self, session: aiohttp.ClientSession, url: str) -> Optional[Image.Image]:
        """Download image from URL and return PIL Image object"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': url
        }
        try:
            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    image_data = await response.read()
                    return self._convert_bytes_to_pil_image(image_data)
                else:
                    logger.debug(f"Failed to download image: HTTP {response.status}")
                    return None
        except Exception as e:
            logger.debug(f"Error downloading image: {str(e)}")
            return None

    async def _extract_base64_images(self, content: str) -> Tuple[str, List[ExtractedImage]]:
        """Extract base64-encoded images from content."""
        pattern = r'data:image/([a-zA-Z]+);base64,([^"\')\s]+)'
        images = []
        modified_content = content

        for match in re.finditer(pattern, content):
            try:
                image_type, base64_data = match.groups()
                # We don't need to store the mime type anymore
                
                try:
                    image_data = base64.b64decode(base64_data)
                except Exception as e:
                    logger.error(f"Failed to decode base64 data: {str(e)}")
                    continue
                    
                pil_image = self._convert_bytes_to_pil_image(image_data)

                if pil_image:
                    image = ExtractedImage(
                        image_id=self._get_next_image_id(),
                        original_location=match.span(),
                        source_type='base64',
                        pil_image=pil_image,
                        alt_text=None,
                        transcription=None
                    )
                    images.append(image)
                    modified_content = modified_content.replace(match.group(0), image.placeholder)
                else:
                    logger.warning(f"Could not create PIL image from base64 data")

            except Exception as e:
                logger.error(f"Error processing base64 image: {str(e)}")
                continue

        return modified_content, images

    async def _extract_markdown_images(self, content: str) -> Tuple[str, List[ExtractedImage]]:
        """Extract images from markdown image tags."""
        pattern = r'!\[(.*?)\]\((.*?)\)'
        matches = list(re.finditer(pattern, content))
        if not matches:
            # No images found
            return content, []
            
        # Prepare all image download tasks
        async with aiohttp.ClientSession() as session:
            # First gather all the image download tasks
            download_tasks = []
            for match in matches:
                alt_text, url = match.groups()
                url = url.strip()
                if not url:
                    logger.warning(f"Empty URL in markdown image tag: {match.group(0)}")
                    continue
                    
                logger.debug(f"Queueing download for image from URL: {url}")
                download_tasks.append({
                    'task': self._download_image(session, url),
                    'match': match,
                    'alt_text': alt_text,
                    'url': url
                })
            
            # No valid URLs to download
            if not download_tasks:
                return content, []
                
            # Execute all download tasks concurrently
            images = []
            modified_content = content
            
            # Create a list of tasks for asyncio.gather
            tasks = [task_info['task'] for task_info in download_tasks]
            # Wait for all downloads to complete
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            for i, pil_image in enumerate(results):
                task_info = download_tasks[i]
                match = task_info['match']
                alt_text = task_info['alt_text']
                url = task_info['url']
                
                # Handle errors or failed downloads
                if isinstance(pil_image, Exception):
                    logger.warning(f"Error downloading image from URL {url}: {str(pil_image)}")
                    continue
                    
                if not pil_image:
                    continue
                
                try:
                    # Create ExtractedImage object
                    image = ExtractedImage(
                        image_id=self._get_next_image_id(),
                        original_location=match.span(),
                        source_type='url',
                        pil_image=pil_image,
                        alt_text=alt_text if alt_text else None,
                        transcription=None
                    )
                    images.append(image)
                    modified_content = modified_content.replace(match.group(0), image.placeholder)
                    logger.debug(f"Successfully processed markdown image with ID: {image.image_id}")
                except Exception as e:
                    logger.error(f"Error processing markdown image: {str(e)}", exc_info=True)
            
            return modified_content, images

    async def _extract_images_and_insert_placeholders(self, content: str) -> Tuple[str, List[ExtractedImage]]:
        """
        Extract all images from content and replace them with unique placeholders.
        
        This method:
        1. Extracts base64-encoded images directly embedded in the content
        2. Extracts images referenced by markdown image tags (![alt](url))
        3. Replaces each image with a unique placeholder (<img_place_holder_X>)
        4. Returns the modified content and a list of extracted images
        
        Args:
            content: The message text that may contain images
            
        Returns:
            A tuple containing:
            - Modified content with image placeholders
            - List of ExtractedImage objects with metadata and PIL images
        """

        modified_content = content
        all_images = []

        # Extract base64 images
        modified_content, base64_images = await self._extract_base64_images(modified_content)
        all_images.extend(base64_images)

        # Extract markdown images
        modified_content, url_images = await self._extract_markdown_images(modified_content)
        all_images.extend(url_images)
            
        return modified_content, all_images

    async def _get_ticket_cleanup_from_llm(self, text: str, images: List[ExtractedImage], observability_info: Dict[str, Any] = None) -> TicketCleanup:
        """
        Send text and images to the LLM for analysis and return structured results.
        
        This method queries the LLM to:
        1. Determine which images are relevant to the ticket
        2. Generate transcriptions for relevant images
        3. Generate alt text for non-relevant images
        4. Identify privacy statements that should be removed
        5. Identify signature URLs that should be removed
        
        Args:
            text: The ticket text containing image placeholders
            images: List of ExtractedImage objects to be analyzed
            observability_info: Optional dictionary with observability info for logging
            
        Returns:
            TicketCleanup object with structured analysis results
            Raises exceptions for proper error handling by the caller
        """
        prompt = f"""You are a helpful assistant that helps converts IT tickets with images and extraneous information into a succinct text format with minimal noise. 
This will be used in an information-retrieval system so we want the text to be as concise as possible.
You will be given a ticket that contains image placeholder like <img_place_holder_1> and the actual images.

Your jobs are to:
1. analyze the tickets and determine which (if any) of the images are relevant to the ticket. If the image is relevant to the ticket provide a transcription/description of the image. The transcription should contain descriptions of any visual elements that are key to understanding the content of the image. The only images that should be considered relevant will contain information directly related to the IT issue. Ignore any company logos unless the ticket directly pertains to the logo.
2. Determine if the ticket contains any long email security statement(s) that do not relate to the ticket. If it does, provide the regex that can be used to extract the security statement(s).
3. Determine if the ticket contains email signature(s) that do not relate to the ticket. If it does, provide the regex that can be used to extract the signature(s).

Regex notes:
- should work directly in python re.sub() function
- prefer simple regex with the start of the string and the end of the string. (eg for the url: 'https://start_of_url_then_a_bunch_of_junk_and_then_end_of_url' the regex should be: r'https://start_of_url.*end_of_url')
- avoid using look-behind assertions (patterns that start with "(?<="). Instead, use capturing groups with standard patterns.

If there is any problem DO NOT make up information. If you cannot see the image, just say so.

Here is the text of the ticket:
{text}
"""
        # - avoid using lookbehind assertions (?<=...) with variable-width patterns like \s+, *, +, or {{m,n}}.
        
        messages = [prompt]
        for image in images:
            messages.append(f"Image {image.image_id}:")
            messages.append(image.pil_image)
        
        # Handle case with no images
        if len(images) == 0:
            messages.append("No images were found in the ticket")

        response = await self.llm_provider.get_response(
            messages,
            config={"model": MODEL_NAME, "temperature": 0.1},
            response_format=TicketCleanup,
            observability_info=observability_info
        )
        # for image in response.images:
        #     if image.transcription:
        #         print(f"Image Transcription: {image.transcription[0:250]}...")
        # for regex in response.email_signature_urls.url_regex or []:
        #     print(f"URL regex: {regex}")
        # for regex in response.email_privacy_statement.privacy_regex or []:
        #     print(f"PRIVACY regex  : {regex}")

        return response
        
    def _clean_and_replace_placeholders(self, content: str, llm_response: TicketCleanup) -> str:
        """
        Clean the ticket text and replace image placeholders with appropriate text.
        
        This method:
        1. Protects image placeholders during URL removal by temporarily replacing them
        2. Removes privacy statements identified by the LLM
        3. Cleans or removes URLs in email signatures
        4. Replaces image placeholders with:
           - Alt text for non-relevant images: "[alt_text]"
           - Transcriptions for relevant images: "<transcribed_image>transcription</transcribed_image>"
        5. Cleans up formatting issues and whitespace
        
        Args:
            content: Text with image placeholders and possibly privacy statements/URLs
            llm_response: LLM analysis results containing image data and cleaning instructions
            
        Returns:
            Cleaned text with image placeholders replaced by appropriate descriptions
        """
        try:
            # First replace image placeholders with temporary markers to protect them during URL removal
            placeholder_pattern = r'<img_place_holder_\d+>'
            placeholders = re.findall(placeholder_pattern, content)
            placeholder_map = {}
            
            # Create a temporary unique marker for each placeholder
            for i, placeholder in enumerate(placeholders):
                temp_marker = f"__TEMP_IMG_MARKER_{i}__"
                placeholder_map[temp_marker] = placeholder
                content = content.replace(placeholder, temp_marker)
            
            # Remove privacy statements
            if llm_response.email_privacy_statement.contains_privacy_statement:
                for regex in (llm_response.email_privacy_statement.privacy_regex or []):
                    if regex:
                        try:
                            content = re.sub(regex, "", content, flags=re.MULTILINE | re.DOTALL)
                        except re.error as e:
                            logger.error(f"Invalid privacy statement regex pattern: {regex}. Error: {str(e)}")
            
            # Remove signature URLs - handle both direct URLs and markdown links
            replacement_text = '(URL removed)'
            # if llm_response.email_signature_data.contains_signature_data:
            #     for regex in (llm_response.email_signature_data.signature_regex or []):
            if llm_response.email_signature_urls.contains_urls:
                for regex in (llm_response.email_signature_urls.url_regex or []):
                    if regex:
                        try:
                            sanitized_regex = regex
                            if ((sanitized_regex.startswith('r\'') and sanitized_regex.endswith('\'')) or sanitized_regex.startswith('r"') and sanitized_regex.endswith('"')):
                                sanitized_regex = sanitized_regex[2:-1]
                                logger.debug(f"Original regex : {regex}")
                                logger.debug(f"Sanitized regex: {sanitized_regex}")
                            
                            # Test if the regex is valid before using it
                            try:
                                re.compile(sanitized_regex)
                            except re.error as e:
                                logger.error(f"Invalid regex pattern: {sanitized_regex}. Error: {str(e)}")
                                continue 

                            content = re.sub(sanitized_regex, replacement_text, content)
                            
                            # Special handling for cases where there's a missing closing parenthesis
                            content = re.sub(r'\(URL removed\)', replacement_text, content)
                            # Fix cases where we have double closing parenthesis
                            content = re.sub(r'\(URL removed\)\)', replacement_text, content)
                            
                        except re.error as e:
                            logger.error(f"Error applying URL regex pattern: {regex}. Error: {str(e)}")
            
            # Restore image placeholders from temporary markers
            for temp_marker, placeholder in placeholder_map.items():
                content = content.replace(temp_marker, placeholder)
            
            # Process images and store transcriptions/alt text in the ExtractedImage objects
            for image in llm_response.images or []:
                # Extract image number from ID
                img_num = image.image_id.split("_")[-1] if "_" in image.image_id else image.image_id
                placeholder = f"<img_place_holder_{img_num}>"
                
                # Store the relevant data for later use
                if not image.is_relevant:
                    # Use alt text for non-relevant images
                    alt_text = image.alt_text if image.alt_text else 'Image'
                    content = content.replace(placeholder, f"[{alt_text}]")
                elif image.transcription:
                    # Use transcription for relevant images with new tag format
                    content = content.replace(placeholder, f"<transcribed_image>\n{image.transcription}\n</transcribed_image>")
                
            return content.strip()
        
        except Exception as e:
            logger.error(f"Unexpected error in _clean_and_replace_placeholders: {str(e)}")
            return content
            

    def _process_single_message_with_llm_results(self, message_text: str, message_images: List[ExtractedImage]) -> str:
        """
        Process a single message using stored LLM analysis results.
        
        This method:
        1. Retrieves the global LLM results stored during batch processing
        2. Filters these results to only include images from this specific message
        3. Updates the ExtractedImage objects with the transcriptions and alt text
        4. Applies text cleaning and placeholder replacement to just this message
        
        This approach ensures each message maintains its individual context while
        benefiting from the efficiency of batch processing with the LLM.
        
        Args:
            message_text: The message text containing image placeholders
            message_images: List of ExtractedImage objects for this message
            
        Returns:
            Processed message text with image transcriptions and cleaned content
        """
        # We need the overall LLM results that were stored during batch processing
        if not hasattr(self, '_last_llm_results'):
            logger.warning("LLM results not available. Message will not be properly processed.")
            return message_text
        
        # Clone the _last_llm_results object to avoid modifying the original
        import copy
        llm_response = copy.deepcopy(self._last_llm_results)
        
        # Get IDs of images in this message
        message_image_ids = [img.image_id for img in message_images]
        
        # Create a lookup for quick access to our ExtractedImage objects by ID
        image_lookup = {img.image_id: img for img in message_images}
        
        # Filter image results to only include those from this message
        # We need to handle both direct ID matches and formatted IDs (with prefix_)
        filtered_images = []
        for img in llm_response.images or []:
            image_id = img.image_id
            extracted_id = image_id.split("_")[-1] if "_" in image_id else image_id
            
            # If this image belongs to the current message
            if extracted_id in message_image_ids:
                filtered_images.append(img)
                
                # Store the alt_text and transcription in the ExtractedImage object
                if extracted_id in image_lookup:
                    extracted_img = image_lookup[extracted_id]
                    if not img.is_relevant:
                        extracted_img.alt_text = img.alt_text if img.alt_text else "Image"
                        extracted_img.transcription = None
                    else:
                        extracted_img.alt_text = None
                        extracted_img.transcription = img.transcription
        
        # Update the filtered images in the response
        llm_response.images = filtered_images
        
        # Apply text cleaning to just this message using the filtered LLM response
        cleaned_text = self._clean_and_replace_placeholders(message_text, llm_response)
        return cleaned_text
    
    async def _prepare_ticket_for_processing(self, ticket: Dict) -> Dict:
        """
        Prepare the ticket for processing by setting up necessary context.
        
        Args:
            ticket: Original ticket dictionary
            
        Returns:
            Dict with observability info and other context needed for processing
        """
        # Get ticket ID
        ticket_id = ticket.get('id')
        
        # Create simple observability info directly
        context = {
            "observability_info": {"ticket_id": ticket_id},
            "ticket_id": ticket_id
        }
        
        # Reset image counter at start of ticket
        self.image_counter = 0
        
        return context
        
    async def _extract_images_from_messages(self, messages: List[Dict]) -> List[Dict]:
        """
        Extract images from all messages and replace them with placeholders.
        
        Args:
            messages: List of message dictionaries from the ticket
            
        Returns:
            List of processed message data including original message, modified text, and extracted images
        """
        processed_messages = []
        
        for message in messages:
            message_text = message.get('text', '')
            
            try:
                # Decode any SafeLinks URLs in the message text
                message_text = self._decode_safelinks_in_text(message_text)
                
                # Extract images from this message
                modified_text, message_images = await self._extract_images_and_insert_placeholders(message_text)
                
                # Store the modified message with its images
                processed_messages.append({
                    'original': message,
                    'modified_text': modified_text,
                    'images': message_images
                })
                
            except Exception as e:
                logger.error(f"Error extracting images from message {message.get('id', 'unknown')}: {str(e)}")
                # Re-raise to be handled by caller
                raise
                
        return processed_messages
        
    def _decode_safelinks_in_text(self, text: str) -> str:
        """
        Replace SafeLinks URLs with their decoded versions in text.
        
        Args:
            text: Text that may contain SafeLinks URLs
            
        Returns:
            Text with SafeLinks URLs replaced with their decoded versions
        """
        if 'safelinks.protection.outlook.com' not in text:
            return text
            
        safelinks_pattern = r'https?://[^/]*safelinks\.protection\.outlook\.com/[^\s<>"\')]*'
        
        # Find and replace all SafeLinks URLs
        def replace_safelinks(match):
            safelinks_url = match.group(0)
            decoded_url = self._decode_safelinks_url(safelinks_url)
            if safelinks_url != decoded_url:
                logger.debug(f"Replaced SafeLinks URL in message text")
                return decoded_url
            return safelinks_url
        
        return re.sub(safelinks_pattern, replace_safelinks, text)
        
    def _create_processing_batches(self, processed_messages: List[Dict]) -> List[Dict]:
        """
        Organize messages into batches based on image count for efficient LLM processing.
        
        Args:
            processed_messages: List of processed message data with extracted images
            
        Returns:
            List of batches, each containing message text, images, and associated messages
        """
        batches = []
        current_batch = []
        current_batch_images = []
        
        for message_data in processed_messages:
            image_count = len(message_data['images'])
            
            # If this message alone has more images than batch_size, process it separately
            if image_count > BATCH_SIZE:
                batches.append({
                    'text': message_data['modified_text'],
                    'images': message_data['images'],
                    'messages': [message_data]
                })
                continue
            
            # If adding this message would exceed batch size, create a new batch
            if len(current_batch_images) + image_count > BATCH_SIZE and current_batch:
                # Finalize current batch
                batches.append({
                    'text': "\n\n".join(msg['modified_text'] for msg in current_batch),
                    'images': current_batch_images.copy(),
                    'messages': current_batch.copy()
                })
                current_batch = []
                current_batch_images = []
            
            # Add message to current batch
            current_batch.append(message_data)
            current_batch_images.extend(message_data['images'])
        
        # Add any remaining messages in the last batch
        if current_batch:
            batches.append({
                'text': "\n\n".join(msg['modified_text'] for msg in current_batch),
                'images': current_batch_images.copy(),
                'messages': current_batch.copy()
            })
            
        return batches
        
    async def _get_llm_analysis_for_batches(self, batches: List[Dict], observability_info: Dict) -> List[Dict]:
        """
        Process batches through the LLM to get analysis results.
        
        Args:
            batches: List of batches to be processed
            observability_info: Dictionary with observability info for logging
            
        Returns:
            List of batch results with LLM analysis
        """
        batch_results = []
        
        # Process batches one by one to properly capture and document errors
        for i, batch in enumerate(batches):
            try:
                logger.debug(f"Processing batch {i+1}/{len(batches)} with {len(batch['images'])} images")
                result = await self._get_ticket_cleanup_from_llm(batch['text'], batch['images'], observability_info)
                batch_results.append({
                    'result': result,
                    'messages': batch['messages']
                })
            except Exception as e:
                error_msg = f"Batch {i+1}/{len(batches)} failed: {str(e)}"
                logger.error(error_msg)
                # Re-raise with additional context
                raise Exception(error_msg) from e
                
        return batch_results
        
    def _clean_messages(self, batch_results: List[Dict]) -> List[Dict]:
        """
        Apply LLM analysis results to clean each message.
        
        Args:
            batch_results: List of batch results with LLM analysis
            
        Returns:
            List of cleaned messages
        """
        cleaned_messages = []
        
        # Process each batch
        for batch_result in batch_results:
            llm_result = batch_result['result']
            batch_messages = batch_result['messages']
            
            # Store the LLM results for later use in per-message processing
            self._last_llm_results = llm_result
            
            # Process each message in this batch
            for message_data in batch_messages:
                original_message = message_data['original']
                message_images = message_data['images']
                message_text = message_data['modified_text']
                
                # Clean the message using LLM results
                cleaned_text = self._process_single_message_with_llm_results(message_text, message_images)
                
                # Create a cleaned message object
                cleaned_message = {
                    'from': original_message.get('from', 'Unknown'),
                    'date': original_message.get('date', 'Unknown'),
                    'type': original_message.get('type', 'Unknown'),
                    'id': original_message.get('id', ''),
                    'text': cleaned_text
                }
                
                # Keep original_text with placeholders for PDF generation, only if there are actual images and text changed
                if message_images and message_text != cleaned_text:
                    cleaned_message['original_text'] = message_text
                
                cleaned_messages.append(cleaned_message)
                
        return cleaned_messages
        
    def _build_processed_ticket(self, ticket: Dict, cleaned_messages: List[Dict]) -> Dict:
        """
        Build a processed ticket using the cleaned messages.
        
        Args:
            ticket: Original ticket dictionary
            cleaned_messages: List of cleaned message dictionaries
            
        Returns:
            A processed ticket dictionary with cleaned messages
        """
        # Create the processed ticket with minimal fields
        processed_ticket = {
            'summary': ticket.get('summary', ''),
            'id': ticket.get('id'),
            'messages': cleaned_messages,
            'contact_id': ticket.get('contact', {}).get('id', ''),
            'contact_name': ticket.get('contact', {}).get('name', ''),
            'company': ticket.get('company', {}),
            'type': ticket.get('type', {}),
            'subtype': ticket.get('subType', {}),  # note we convert subType to subtype
            'item': ticket.get('item', {}),
            'closedDate': ticket.get('closedDate'),
            'dateResolved': ticket.get('dateResolved'),
        }
        
        return processed_ticket
    
    def _generate_ticket_pdfs(self, 
                          ticket: Dict, 
                          processed_messages: List[Dict], 
                          processed_ticket: Optional[Dict] = None, 
                          output_dir: str = "app/data") -> Dict:
        """
        Generate PDF files for tickets with images.
        
        This method:
        1. Extracts all images from processed messages
        2. Creates a modified ticket with image placeholders for the original PDF
        3. Generates an original PDF with placeholders
        4. Optionally generates a processed PDF with transcriptions if processed_ticket is provided
        
        Args:
            ticket: Original ticket dictionary
            processed_messages: List of processed message data with extracted images
            processed_ticket: Optional processed ticket with transcriptions (for processed PDF)
            output_dir: Directory where to save the PDF files
            
        Returns:
            Dictionary containing PDF paths and extracted images
        """
        pdf_info = {}
        
        try:
            from app.ticket_pdf_writer import write_pdf
            import os
            
            # Ensure output directory exists
            os.makedirs(output_dir, exist_ok=True)
            
            # Get ticket ID
            ticket_id = ticket.get('id', 'unknown')
            
            # Extract all images and create modified ticket with placeholders
            all_extracted_images = []
            modified_messages_for_pdf = []
            
            for message_data in processed_messages:
                original_message = message_data['original']
                message_images = message_data['images']
                modified_text = message_data['modified_text']
                
                all_extracted_images.extend(message_images)
                modified_messages_for_pdf.append({
                    **original_message,
                    'text': modified_text,
                    'images': message_images
                })
            
            # Create modified ticket with placeholders for PDF
            modified_ticket_for_pdf = {
                **ticket,
                'messages': modified_messages_for_pdf
            }
            
            # Write the original ticket with placeholders to PDF
            original_pdf_path = write_pdf(
                modified_ticket_for_pdf, 
                all_extracted_images,
                output_dir=output_dir,
                filename=f"ticket_{ticket_id}_original.pdf"
            )
            
            pdf_info['all_extracted_images'] = all_extracted_images
            pdf_info['original_pdf_path'] = original_pdf_path
            
            # Generate processed PDF if processed_ticket is provided
            if processed_ticket:
                # Write the processed ticket with transcriptions to PDF
                processed_pdf_path = write_pdf(
                    processed_ticket, 
                    all_extracted_images,
                    output_dir=output_dir,
                    filename=f"ticket_{ticket_id}_processed.pdf"
                )
                pdf_info['processed_pdf_path'] = processed_pdf_path
                
            logger.info(f"Generated PDF file(s) for ticket {ticket_id}")
            
        except Exception as e:
            logger.error(f"Error generating PDFs: {str(e)}")
            # Continue processing - PDF generation is optional
            
        return pdf_info
        
    async def transcribe_ticket(self, ticket: Dict, generate_pdf: bool = False, output_dir: str = "app/data") -> Dict:
        """
        Process a complete ticket by extracting images and generating transcriptions.
        
        This method orchestrates the entire ticket processing workflow:
        1. Prepares the ticket for processing (setting up context)
        2. Extracts images from each message and replaces them with placeholders
        3. Creates batches of messages for efficient LLM processing
        4. Gets LLM analysis for each batch
        5. Applies LLM results to clean messages
        6. Builds the final processed ticket
        7. Optionally generates PDF files with the processed ticket and images
        
        If processing fails, the original ticket is returned with an error field added
        so this can be documented in the results JSON file and retried later.
        
        Args:
            ticket: Original ticket dictionary with 'summary' and 'messages'
            generate_pdf: Whether to generate PDF files with the original and processed tickets
            output_dir: Directory where to save the PDF files (if generate_pdf is True)
            
        Returns:
            A processed ticket dictionary with cleaned messages and image descriptions,
            or the original ticket with an error field if processing failed.
            If generate_pdf=True, adds 'original_pdf_path' and 'processed_pdf_path' to the result.
        """
        try:
            # Step 1: Prepare ticket for processing
            observability_info = {"ticket_id": ticket.get('id')}

            
            # Step 2: Extract images from messages
            try:
                processed_messages = await self._extract_images_from_messages(ticket.get('messages', []))
            except Exception as e:
                error_msg = f"Error extracting images from messages: {str(e)}"
                logger.error(error_msg)
                ticket_copy = ticket.copy()
                ticket_copy['processing_error'] = error_msg
                ticket_copy['error_type'] = 'image_extraction_error'
                return ticket_copy
            
            # Step 2.5: Generate original PDF if enabled
            pdf_info = {}
            if generate_pdf:
                pdf_info = self._generate_ticket_pdfs(ticket, processed_messages, None, output_dir)
            
            # Step 3: Create processing batches
            batches = self._create_processing_batches(processed_messages)
            
            # Step 4: Get LLM analysis for batches
            if batches:
                try:
                    batch_results = await self._get_llm_analysis_for_batches(batches, observability_info)
                except Exception as e:
                    error_msg = f"Error during LLM analysis: {str(e)}"
                    logger.error(error_msg)
                    ticket_copy = ticket.copy()
                    ticket_copy['processing_error'] = error_msg
                    if 'LengthFinishReasonError' in str(e) or 'length limit was reached' in str(e):
                        ticket_copy['error_type'] = 'token_limit_exceeded'
                    else:
                        ticket_copy['error_type'] = 'llm_processing_error'
                    
                    # Add PDF info if we managed to create the original PDF
                    if 'original_pdf_path' in pdf_info:
                        ticket_copy['original_pdf_path'] = pdf_info['original_pdf_path']
                    
                    return ticket_copy
                
                # Step 5: Clean messages using LLM results
                cleaned_messages = self._clean_messages(batch_results)
                
                # Step 6: Build processed ticket with cleaned messages
                processed_ticket = self._build_processed_ticket(ticket, cleaned_messages)
                
                # Step 7: Generate processed PDF if enabled
                if generate_pdf and pdf_info and 'all_extracted_images' in pdf_info:
                    # Add the processed PDF to our existing PDF info
                    processed_pdf_info = self._generate_ticket_pdfs(
                        ticket, 
                        processed_messages, 
                        processed_ticket, 
                        output_dir
                    )
                    
                    # Merge the PDF info
                    if 'processed_pdf_path' in processed_pdf_info:
                        pdf_info['processed_pdf_path'] = processed_pdf_info['processed_pdf_path']
                
                # Add PDF paths to the processed ticket
                if 'original_pdf_path' in pdf_info:
                    processed_ticket['original_pdf_path'] = pdf_info['original_pdf_path']
                if 'processed_pdf_path' in pdf_info:
                    processed_ticket['processed_pdf_path'] = pdf_info['processed_pdf_path']
                
                return processed_ticket
            
            # If no images found, return the original ticket
            # Add PDF info if we managed to create the original PDF
            if 'original_pdf_path' in pdf_info:
                ticket_copy = ticket.copy()
                ticket_copy['original_pdf_path'] = pdf_info['original_pdf_path']
                return ticket_copy
                
            return ticket
            
        except Exception as e:
            error_msg = f"Critical error processing ticket {ticket.get('id', 'unknown')}: {str(e)}"
            logger.error(error_msg)
            
            # Add error information to the original ticket
            ticket_copy = ticket.copy()
            ticket_copy['processing_error'] = error_msg
            ticket_copy['error_type'] = 'general_processing_error'
            
            return ticket_copy
        
    async def transcribe_ticket_messages(self, ticket: Dict) -> Dict:
        """
        Transcribe the messages in a ticket and clean up the noisy text.

        Args:
            ticket (Dict): Original ticket dictionary with 'messages' field

        Returns:
            List[Dict]: List of cleaned message dictionaries with transcribed text,
            or the original ticket dict with error info if processing fails.
        """
        try:
            # Step 1: Prepare ticket for processing
            observability_info = {"ticket_id": ticket.get('id')}
            
            # Step 2: Extract images from messages
            try:
                processed_messages = await self._extract_images_from_messages(ticket.get('messages', []))
            except Exception as e:
                error_msg = f"Error extracting images from messages: {str(e)}"
                logger.error(error_msg)
                ticket_copy = ticket.copy()
                ticket_copy['processing_error'] = error_msg
                ticket_copy['error_type'] = 'image_extraction_error'
                return ticket_copy
            
            # Step 3: Create processing batches
            batches = self._create_processing_batches(processed_messages)
            
            # Step 4: Get LLM analysis for batches
            if batches:
                try:
                    batch_results = await self._get_llm_analysis_for_batches(batches, observability_info)
                except Exception as e:
                    error_msg = f"Error during LLM analysis: {str(e)}"
                    logger.error(error_msg)
                    ticket_copy = ticket.copy()
                    ticket_copy['processing_error'] = error_msg
                    if 'LengthFinishReasonError' in str(e) or 'length limit was reached' in str(e):
                        ticket_copy['error_type'] = 'token_limit_exceeded'
                    else:
                        ticket_copy['error_type'] = 'llm_processing_error'
                    
                    return ticket_copy
                
                # Step 5: Clean messages using LLM results
                cleaned_messages = self._clean_messages(batch_results)
                
                return cleaned_messages
            else:
                # No batches to process, return the original messages
                return ticket.get('messages', [])
            
        except Exception as e:
            # Catch any unhandled exceptions
            error_msg = f"Critical error processing ticket {ticket.get('id', 'unknown')}: {str(e)}"
            logger.error(error_msg)
            
            # Add error information to the original ticket
            ticket_copy = ticket.copy()
            ticket_copy['processing_error'] = error_msg
            ticket_copy['error_type'] = 'general_processing_error'
            
            return ticket_copy

    def _straighten_quotes(self, text: str) -> str:
        """
        Replace curly/smart quotes with straight quotes for improved compatibility.
        
        This method standardizes quotes in text by replacing:
        - Left/right single quotes ('' → ')
        - Left/right double quotes ("" → ")
        - Non-breaking spaces with regular spaces
        
        This ensures consistent formatting and prevents issues with systems that 
        don't handle Unicode quote characters properly.
        
        Args:
            text (str): Text that may contain curly quotes and special characters
            
        Returns:
            str: Text with standardized straight quotes and normalized spaces
        """
        replacements = {
            '\u2018': "'", 
            '\u2019': "'", 
            '\u201C': '"', 
            '\u201D': '"', 
            '\u00a0': ' ',
            '\u2013': '-'
        }
        for old, new in replacements.items():
            text = text.replace(old, new)
        return text
    
    def format_ticket_as_string(self, ticket: Dict) -> str:
        """
        Format all messages from a processed ticket into a single readable string.
        
        This method creates a human-readable representation of the entire ticket by:
        1. Starting with the ticket summary and ID as a header
        2. Adding each message with a clear header showing author, date, and type
        3. Standardizing quotes (replacing curly quotes with straight ones)
        4. Formatting everything with consistent spacing
        
        This is useful for creating a plain text version of the ticket that can be:
        - Displayed in a console or terminal
        - Saved to a text file
        - Used as input for other text-based systems
        
        Args:
            ticket (Dict): Processed ticket dictionary with 'summary' and 'messages' fields
            
        Returns:
            str: A formatted string containing the entire ticket conversation
        """
        if not ticket or 'messages' not in ticket:
            return ""
            
        summary = ticket.get('summary', '')
        
        # Start with the ticket summary if available
        ticket_string = f"# {summary}\n\n" if summary else ""
        
        # Process each message
        for message in ticket.get('messages', []):
            # Extract message metadata
            date = message.get('date', 'Unknown date')
            author = message.get('from', 'Unknown author')
            msg_type = message.get('type', 'Unknown type')
            msg_id = message.get('id', '')
            
            header = f"## On {date}, {author} wrote a {msg_type} ({msg_id}):\n"
            message_text = message.get('text', '')
            ticket_string += header + message_text + "\n\n"
        
        # Apply quote straightening to the entire result
        ticket_string = self._straighten_quotes(ticket_string)
        return ticket_string.strip()
```
## File: app/ticket_pdf_writer.py
```python
from typing import Dict, List
import os
from datetime import datetime
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as ReportLabImage
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import inch
from io import BytesIO
import re
from app.ticket_image_processor import ExtractedImage

def write_pdf(ticket: Dict, extracted_images: List[ExtractedImage] = None, output_dir: str = "app/data", filename: str = None) -> str:
    """
    Write ticket content and images to a PDF file in a simple sequential format.
    
    This function accepts a processed ticket dictionary and creates a PDF document that:
    1. Displays the ticket summary as a header
    2. Shows each message with author and date information
    3. Includes the processed text of each message
    4. Displays images below their corresponding messages
    
    Args:
        ticket: Dictionary containing ticket data with 'summary' and 'messages' fields
        extracted_images: List of ExtractedImage objects with the original images
        output_dir: Directory to save the PDF file
        filename: Optional custom filename (default: ticket_{id}.pdf)
        
    Returns:
        Path to the created PDF file
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate filename
    ticket_id = ticket.get('id', 'unknown')
    if filename is None:
        filename = f"ticket_{ticket_id}.pdf"
    filepath = os.path.join(output_dir, filename)
    
    # Create document
    doc = SimpleDocTemplate(filepath, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []
    
    # Add ticket summary
    summary = ticket.get('summary', '')
    if summary:
        p = Paragraph(f"<b>Ticket #{ticket_id}: {summary}</b>", styles['Heading2'])
        story.append(p)
        story.append(Spacer(1, 12))
    
    # Create image lookup dictionary from extracted_images
    image_lookup = {}
    if extracted_images:
        for img in extracted_images:
            image_lookup[img.placeholder] = img
    
    # Process each message
    for message in ticket.get('messages', []):
        # Minimal required fields
        author = message.get('from', 'Unknown')
        date = message.get('date', 'Unknown')
        msg_type = message.get('type', 'Unknown')
        message_text = message.get('text', '')
        
        # Add message header
        header = f"On {date}, {author} wrote a {msg_type}:"
        p = Paragraph(f"<b>{header}</b>", styles['Heading3'])
        story.append(p)
        story.append(Spacer(1, 6))
        
        # Original text may or may not be present
        original_text = message.get('original_text', '')
        
        # Add each line of processed text with minimal formatting
        for line in message_text.split('\n'):
            if line.strip():
                # Basic HTML escaping
                escaped_line = (line
                    .replace('&', '&amp;')
                    .replace('<', '&lt;')
                    .replace('>', '&gt;'))
                
                p = Paragraph(escaped_line, styles['Normal'])
                story.append(p)
        
        # Find image placeholders
        # First check original_text if available, otherwise check the message text
        # This allows flexibility in where the placeholders are stored
        text_to_check_for_placeholders = original_text if original_text else message_text
        
        # Find placeholders in the text for displaying images
        placeholder_pattern = r'<img_place_holder_\d+>'
        placeholders_in_message = re.findall(placeholder_pattern, text_to_check_for_placeholders)
        
        # Add images at the end of the message if we have placeholders
        if placeholders_in_message and image_lookup:
            story.append(Spacer(1, 12))
            
            # Add images header
            p = Paragraph("<b>Images:</b>", styles['Heading3'])
            story.append(p)
            story.append(Spacer(1, 6))
            
            # Add each image
            for placeholder in placeholders_in_message:
                img_obj = image_lookup.get(placeholder)
                
                if img_obj:
                    # Extract the image ID number from the placeholder
                    img_id_match = re.search(r'<img_place_holder_(\d+)>', placeholder)
                    img_id = img_id_match.group(1) if img_id_match else "?"
                    
                    # Create display text for this image
                    # Try to use transcription or alt_text if available
                    if hasattr(img_obj, 'transcription') and img_obj.transcription:
                        display_text = f"Image {img_id}: {img_obj.transcription}"
                    elif hasattr(img_obj, 'alt_text') and img_obj.alt_text:
                        display_text = f"Image {img_id}: {img_obj.alt_text}"
                    else:
                        display_text = f"Image {img_id}"
                    
                    p = Paragraph(f"<b>{display_text}</b>", styles['Normal'])
                    story.append(p)
                    story.append(Spacer(1, 6))
                    
                    # Add the image itself if available
                    if hasattr(img_obj, 'pil_image') and img_obj.pil_image:
                        try:
                            # Convert PIL Image to reportlab format
                            pil_image = img_obj.pil_image
                            img_buffer = BytesIO()
                            pil_image.save(img_buffer, format='PNG')
                            img_buffer.seek(0)
                            
                            # Calculate width to maintain aspect ratio
                            img_width, img_height = pil_image.size
                            max_width = 5 * inch
                            width = min(img_width, max_width)
                            height = (width / img_width) * img_height if img_width > 0 else 0
                            
                            # Add image to story
                            rl_img = ReportLabImage(img_buffer, width=width, height=height)
                            story.append(rl_img)
                            story.append(Spacer(1, 12))
                        except Exception as e:
                            p = Paragraph(f"Error displaying image: {str(e)}", styles['Normal'])
                            story.append(p)
                            story.append(Spacer(1, 6))
        
        # Add space between messages
        story.append(Spacer(1, 24))
    
    # Build the document
    doc.build(story)
    return filepath
```
## File: app/run_poller.py
```python
from datetime import datetime, timezone
import asyncio
import logging
import os
from dotenv import load_dotenv
from app.ticket_poller import TicketPoller
from database.authenticated_postgres_client import AuthenticatedPostgresClient
import json

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()
# os.environ["POSTGRES_HOST"] = "localhost"

SAVE_FOLDER = "app/data/annotated_tickets"



async def main():
    # Create database client
    username = "helpdesk_agent"
    
    db_client = AuthenticatedPostgresClient(username)
    await db_client.initialize()
    
    try:
        company_identifiers = os.getenv("COMPANY_IDENTIFIERS").split(",")
        
        # Get polling interval from environment or use default (60 seconds)
        polling_interval = int(os.getenv("POLLING_INTERVAL_SECONDS", "60"))
        
        # Initialize the poller
        poller = TicketPoller(
            company_identifiers=company_identifiers,
            db_client=db_client,
            polling_interval=polling_interval,
            page_size=int(os.getenv("PAGE_SIZE", "25")),
            max_tickets=int(os.getenv("MAX_TICKETS", "100")),
            simultaneous_requests=int(os.getenv("SIMULTANEOUS_REQUESTS", "5")),
            save_folder=SAVE_FOLDER
        )
        
        try:
            logger.info("Starting ticket poller...")
            logger.info(f"Companies being monitored: {company_identifiers}")
            logger.info(f"Polling interval: {polling_interval} seconds")
            
            ########## THIS STARTS THE WHOLE PROCESS ##########
            ADD_NOTE = True
            await poller.start(
                break_after_single_cycle=False,
                add_note=ADD_NOTE
            )
            #############################################################
            
        except KeyboardInterrupt:
            logger.info("Stopping ticket poller...")
            await poller.stop()
        except Exception as e:
            logger.error(f"Error running poller: {e}")
            raise
            
    finally:
        # Close the database client
        await db_client.close()

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/api.py
```python
import requests
import base64
import json
import os
from datetime import datetime
from dotenv import load_dotenv
import asyncio
import logging

load_dotenv()

logger = logging.getLogger(__name__)

class ConnectWiseAPI:
    def __init__(self):
        self.base_url = os.getenv("CONNECTWISE_API_BASE_URL")
        self.client_id = os.getenv("CONNECTWISE_CLIENT_ID")
        self.get_headers()
    
    def get_headers(self):
        public_key = os.getenv("CONNECTWISE_API_PUBLIC_KEY")
        private_key = os.getenv("CONNECTWISE_API_PRIVATE_KEY")
        company_id = os.getenv("CONNECTWISE_COMPANY_ID")
        auth_string = f"{company_id}+{public_key}:{private_key}"

        self.headers = {
            'Authorization': f"Basic {base64.b64encode(auth_string.encode()).decode()}",
            'clientId': self.client_id
        }

    async def get(self, url: str|None = None, route: str|None = None, params=None):
        """
        Get a resource from the API

        args:
            route (str): The route to the resource
            params (dict): The parameters to pass to the resource

        returns:
            dict: The resource data or bytes for binary content
        """
        
        if not url and not route:
            raise ValueError("Either url or route must be provided")
        url = url or f"{self.base_url}/{route}"
        
        # For document downloads, explicitly handle as binary
        is_document_download = '/download' in url or (route and '/download' in route)
        
        logger.debug(f"Making request to: {url}")
        response = requests.request("GET", url, headers=self.headers, params=params)
        
        if not response.ok:
            logger.error(f"API request failed: {response.status_code} - {response.text}")
            return {"error": f"Request failed with status code {response.status_code}", "details": response.text}
        
        # Check if response is a document download (binary data)
        content_type = response.headers.get('Content-Type', '')
        logger.debug(f"Response content type: {content_type}")
        
        if is_document_download or 'application/octet-stream' in content_type or 'image/' in content_type:
            logger.debug(f"Handling as binary data, size: {len(response.content)} bytes")
            return response.content
        elif 'application/json' in content_type:
            return response.json()
        else:
            try:
                return response.json()
            except requests.exceptions.JSONDecodeError:
                logger.debug("JSONDecodeError - returning raw content")
                return response.content
    
    async def post(self, url: str|None = None, route: str|None = None, data=None):
        """
        Post a resource to the API
        """
        url = url or f"{self.base_url}/{route}"
        headers = self.headers.copy()
        headers['Content-Type'] = 'application/json'
        response = requests.request("POST", url, headers=headers, json=data)
        return response.json()
    
    
    async def delete(self, url: str|None = None, route: str|None = None, data=None):
        """
        Delete a resource from the API
        """
        url = url or f"{self.base_url}/{route}"
        response = requests.request("DELETE", url, headers=self.headers, json=data)
        if response.status_code == 204:
            return {"status": "success", "status_code": 204}
        try:
            return response.json()
        except requests.exceptions.JSONDecodeError:
            logger.debug("JSONDecodeError - returning raw content")
            return response.content
        except:
            return {"status": "error", "status_code": response.status_code, "message": response.text}
    

    async def get_paginated(self, url: str|None = None, route: str|None = None, params=None, page_size=25):
        """
        Get resources from the API using navigable pagination.
        Returns an iterator that yields each page of results.
        
        args:
            route (str): The route to the resource
            params (dict): The parameters to pass to the resource (conditions, orderBy, etc.)
            page_size (int): Number of results per page (max 1000)
            
        yields:
            list: Each page of results as a list
        """
        if not url and not route:
            raise ValueError("Either url or route must be provided")
        url = url or f"{self.base_url}/{route}"
        if params is None:
            params = {}
        
        request_params = params.copy()
        request_params['pageSize'] = min(page_size, 1000)  # Ensure we don't exceed max
        current_page = 1
        
        while True:
            request_params['page'] = current_page
            response = requests.request("GET", url, headers=self.headers, params=request_params)
            
            if response.status_code != 200:
                raise Exception(f"API request failed with status code {response.status_code}: {response.text}")
            
            data = response.json()
            if data:
                yield data
            
            # If there are no more pages, break the loop
            if 'Link' not in response.headers or 'rel="next"' not in response.headers['Link']:
                break
            
            # Move to the next page
            current_page += 1
        return
    
    async def get_all(self, url: str|None = None, route: str|None = None, params=None, page_size=100):
         """
         Get all resources by automatically handling pagination.
         This method collects all pages into a single list.
         """

         if not url and not route:
            raise ValueError("Either url or route must be provided")
         url = url or f"{self.base_url}/{route}"
         all_data = []
         
         async for page_data in self.get_paginated(url = url, params = params, page_size = page_size):
             all_data.extend(page_data)
         
         return all_data
 

    def get_ticket_params(self, 
        company: str, 
        fields: list[str]|None = None, 
        after_date: str|datetime|None = None, 
        before_date: str|datetime|None = None, 
        ascending: bool = True, 
        page_size: int = 25, 
        board_id: int|None = None):

        conditions = []
        date_field = "dateResolved"
        if company:
            conditions.append(f'company/identifier = "{company}"')
        if after_date:
            after_date = after_date.strftime('%Y-%m-%dT%H:%M:%SZ') if isinstance(after_date, datetime) else after_date
            conditions.append(f'{date_field} > [{after_date}]')
        if before_date:
            before_date = before_date.strftime('%Y-%m-%dT%H:%M:%SZ') if isinstance(before_date, datetime) else before_date
            conditions.append(f'{date_field} < [{before_date}]')
        if board_id:
            conditions.append(f'board/id = {board_id}')
        
        fields = ['id', 'summary', 'recordType', 'board', 'company', 'workType', 'type', 'subType', 'item', 'closedDate', '_info', 'closedFlag', 'dateResolved', 'contact', 'priority', 'dateEntered'] if not fields else fields
                
        params = {
            'conditions': ' and '.join(conditions),
            'orderBy': f'dateResolved {"asc" if ascending else "desc"}',
            'fields': ','.join(fields),
            'pageSize': page_size
        }
        return params
    
    async def get_ticket(self, ticket_id: int, fields: list[str]|None = None):
        params = {'fields': ','.join(fields)} if fields else None
        return await self.get(route=f"service/tickets/{ticket_id}", params = params)

    
    async def get_tickets(
        self, 
        company: str, 
        fields: list[str]|None = None, 
        after_date: str|datetime|None = None, 
        before_date: str|datetime|None = None, 
        ascending: bool = True,
        page_size: int = 25,
        limit: int|None = None,
        board_id: int|None = 17
        ):
        """
        Get tickets from the API from a specific company and cutoff date

        args:
            company (str): The company to get tickets from
            fields (list[str]): The fields to get from the tickets
            before_date (str|datetime): The cutoff date to get tickets from
            after_date (str|datetime): The cutoff date to get tickets from
            ascending (bool): Whether to get the tickets in ascending order
            page_size (int): The number of tickets to get per page
            limit (int|None): The maximum number of tickets to get
            board_id (int|None): The ID of the board to filter tickets by
        """
        params = self.get_ticket_params(
            company, fields, after_date, before_date, ascending, page_size, board_id
        )
        logger.debug(f"API Query Parameters: {json.dumps(params, indent=2)}")

        all_tickets = []
        # print details as we paginate through the tickets (uses generator to save memory)
        page_number = 1
        async for page_data in self.get_paginated(
            route = "service/tickets", params = params, page_size = page_size
            ):
            logger.debug(f"Processing page {page_number} with {len(page_data)} records")
            all_tickets.extend(page_data)

            if limit and len(all_tickets) >= limit:
                logger.debug("stopping early!")
                all_tickets = all_tickets[:limit]
                break
            page_number += 1

        logger.debug(f"Retrieved {len(all_tickets)} tickets")

        return all_tickets
        

    async def get_tsi_data(self, board_id: int = 17, params: dict|None = None):
        url = f"https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/{board_id}/typeSubTypeItemAssociations"
        tsi_data = await self.get_all(url=url, params = params)
        tsi_data.sort(key=lambda x: x['type']['id'])
        return tsi_data


    def build_tsi_dict(self, tsi_data):
        """
        Build a nested dictionary from TSI (Type-SubType-Item) data.
        
        Args:
            tsi_data (list): List of TSI records from the API
            
        Returns:
            dict: A nested dictionary organized by type and subtype
            {
                "type_name": {
                    "subType_name": [],
                    "subType_name": [],
                }
            }
        """
        tsi_dict = {}
        
        for tsi_item in tsi_data:
            # Extract type and subtype information
            type_name = tsi_item.get('type', {}).get('name', 'Unknown Type')
            subtype_name = tsi_item.get('subType', {}).get('name', 'Unknown SubType')
            
            # Create type entry if it doesn't exist
            if type_name not in tsi_dict:
                tsi_dict[type_name] = {}
            
            # Create subtype entry if it doesn't exist
            if subtype_name not in tsi_dict[type_name]:
                tsi_dict[type_name][subtype_name] = []
            
            # Add item if it exists (in your example data there are no items)
            if 'item' in tsi_item and tsi_item['item']:
                item_name = tsi_item['item'].get('name', 'Unknown Item')
                if item_name not in tsi_dict[type_name][subtype_name]:
                    tsi_dict[type_name][subtype_name].append(item_name)
        
        return tsi_dict
    
    async def get_tsi_dict(self, board_id: int|None = 17, board_name: str|None = None):
        tsi_data = await self.get_tsi_data(board_id, board_name)
        return self.build_tsi_dict(tsi_data)
   

    async def get_new_tickets_params(
        self,
        company_identifiers: list[str],
        ticket_id: int,
        fields: list[str]|None = None,
        ascending: bool = True,
        page_size: int = 25,
        board_id: int|None = None
    ):
        """Helper method to build parameters for new tickets query"""
        conditions = []
        
        # Handle company identifiers
        if company_identifiers:
            company_conditions = [f"company/identifier = '{company}'" for company in company_identifiers]
            conditions.append(f"({' or '.join(company_conditions)})")
        
        # Handle ticket_id for filtering tickets with higher IDs
        if ticket_id:
            conditions.append(f'id>{ticket_id}')
        
        if board_id:
            conditions.append(f'board/id={board_id}')  # Removed space around = to match docs
        
        # Default fields if none specified
        fields = fields or ['id', 'type', 'subType', 'item', 'summary', 'recordType', 'board', 'company', '_info', 'status', 'dateResolved', 'priority']

        params = {
            'conditions': ' and '.join(conditions),
            'orderBy': f'id {"asc" if ascending else "desc"}',
            'fields': ','.join(fields),
            'pageSize': page_size
        }
        
        # Log the exact query parameters
        logger.debug(f"API Query Parameters: {json.dumps(params, indent=2)}")
        return params

    async def get_new_tickets(
        self,
        ticket_id: int,
        company_identifiers: list[str],
        fields: list[str]|None = None,
        ascending: bool = True,
        page_size: int = 25,
        limit: int|None = None,
        board_id: int|None = None
    ):
        """
        Get tickets with IDs greater than the specified ticket_id for specified companies.

        Args:
            ticket_id (int): Get tickets with IDs greater than this value
            company_identifiers (list[str]): List of company identifiers to filter by
            fields (list[str]|None): The fields to get from the tickets
            ascending (bool): Whether to get the tickets in ascending order by ID
            page_size (int): The number of tickets to get per page
            limit (int|None): The maximum number of tickets to get
            board_id (int|None): The ID of the board to filter tickets by

        Returns:
            list[dict]: List of tickets matching the criteria
        """
        params = await self.get_new_tickets_params(
            company_identifiers=company_identifiers,
            ticket_id=ticket_id,
            fields=fields,
            ascending=ascending,
            page_size=page_size,
            board_id=board_id
        )
        logger.debug(f"new ticket Query Parameters: {json.dumps(params, indent=2)}")
        
        logger.debug(f"Fetching tickets with ID greater than: {ticket_id}")
        
        all_tickets = []
        page_number = 1
        async for page_data in self.get_paginated(route="service/tickets", params=params, page_size=page_size):
            logger.debug(f"Processing page {page_number} with {len(page_data)} records")
            all_tickets.extend(page_data)

            if limit and len(all_tickets) >= limit:
                logger.debug(f"Reached limit of {limit} tickets")
                all_tickets = all_tickets[:limit]
                break
            page_number += 1

        logger.debug(f"Retrieved {len(all_tickets)} tickets")
        return all_tickets



    async def get_ticket_with_messages(self, ticket_id: int, omit_aech_notes: bool = False):
        """
        Get a ticket with both notes and time entries combined into a chronological message list
        and formatted as text
        
        Args:
            ticket_id (int): The ID of the ticket to retrieve
            omit_aech_notes (bool): Whether to filter out AechAI generated messages (default is False)
            
        Returns:
            dict: Ticket information with 'messages' field containing structured messages
                  and 'messages_text' field containing formatted text
        """
        fields = ['id', 'summary', 'company', 'contact', 'type', 'subType', 'item', 'closedDate', 'dateResolved', '_info', 'priority']
        params = {'fields': ','.join(fields)}
        
        # Create tasks for parallel execution of all needed API calls
        tasks = [
            # get base ticket info
            self.get(route=f"service/tickets/{ticket_id}", params=params),
            # get notes
            self.get(route=f"service/tickets/{ticket_id}/notes"),
            # get time entries
            self.get(route=f"time/entries?conditions=(chargeToType='ServiceTicket' OR chargeToType='ProjectTicket') AND chargeToId={ticket_id}")
        ]
        
        ticket, notes, time_entries = await asyncio.gather(*tasks)
        
        messages = self.sort_messages(notes, time_entries)

        if omit_aech_notes:
            messages = [message for message in messages if not "aechai" in message["text"].lower()]
        
        ticket['messages'] = messages
        
        return ticket
    
    def sort_messages(self, notes: list[dict], time_entries: list[dict]) -> list[dict]:
        """
        Sort notes and time entries into a merged messages list, sorted by date
        """
        # Create unified message list
        messages = []
        
        # Add notes to messages
        for note in notes:
            messages.append({
                "id": note.get('id'),
                "date": note.get('dateCreated'),
                "from": note.get('createdBy'),
                "type": "note",
                "text": note.get('text', '')
            })
            
        for entry in time_entries:
            messages.append({
                "id": entry.get('id'),
                "date": entry.get('timeStart'),
                "from": entry.get('member', {}).get('name'),
                "type": "time_entry",
                "text": entry.get('notes', '')
            })
        messages.sort(key=lambda x: x['date'])

        return messages



    async def add_note_to_ticket(self, ticket_id: int, note: str):
        """
        Add a note to a ticket
        
        Args:
            ticket_id (int): The ID of the ticket to add the note to
            note (str): The text content of the note
            
        Returns:
            dict: The created note object
        """
        data = {
            "ticketId": ticket_id,
            "text": note,
            "detailDescriptionFlag": False,
            "internalAnalysisFlag": True,
            "resolutionFlag": False
        }
        response = await self.post(route=f"service/tickets/{ticket_id}/notes", data=data)
        return response
```
## File: app/ticket_database.py
```python
import logging
import os
import asyncio
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime

from database.authenticated_postgres_client import AuthenticatedPostgresClient
from retrieval.hybrid_retriever import HybridRetriever
from app.models.ticket import Ticket

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TicketDatabase:
    """
    Handles all database operations related to tickets.
    
    This class provides a clean interface for ticket retrieval, 
    search, and management. It accepts a database client in the constructor
    to ensure efficient connection pool management.
    """
    
    def __init__(self, db_client: AuthenticatedPostgresClient, username: str = "helpdesk_agent"):
        """
        Initialize the TicketDatabase.
        
        Args:
            db_client: Database client for retrieving and storing ticket data
            username: Username to use for database operations (default: "helpdesk_agent")
        """
        self.db_client = db_client
        self.user_id = db_client.user_info.id
        
    @classmethod
    async def create(cls, db_client: AuthenticatedPostgresClient, username: str = "helpdesk_agent"):
        """
        Create and initialize a new TicketDatabase instance.
        
        Args:
            db_client: Database client for retrieving and storing ticket data
            username: Username to use for database operations (default: "helpdesk_agent")
            
        Returns:
            TicketDatabase: An initialized TicketDatabase instance
        """
        instance = cls(db_client, username)
        return instance
    
    
    async def get_last_ticket_id(self) -> int:
        """
        Retrieve the highest ticket ID currently in the database.
        Used to determine where to start polling for new tickets.
        
        Returns:
            int: The highest ticket ID in the database, or 0 if none found
        """
        try:
            # Use raw SQL query to get the maximum ticket ID
            query = "SELECT MAX(id) as max_id FROM parent_documents"
            result = await self.db_client.raw_query(query)
            
            if result and result[0] and result[0]['max_id'] is not None:
                return result[0]['max_id']
            else:
                logger.info("No tickets found in database, starting from ID 0")
                return 0
        except Exception as e:
            logger.error(f"Error getting last ticket ID: {e}")
            logger.info("Using default ticket ID 0 due to error")
            return 0
        
    async def get_ticket(self, ticket_id: int) -> Optional[Dict[str, Any]]:
        """
        Get a ticket by ID with basic metadata.
        
        Args:
            ticket_id (int): ID of the ticket to retrieve
            
        Returns:
            Optional[Dict[str, Any]]: Dictionary with ticket data if found, None otherwise
        """
        try:
            logger.debug(f"Retrieving ticket {ticket_id}")
            
            # Get basic ticket metadata
            query = """
            SELECT id, source, group_id, summary, metadata
            FROM parent_documents 
            WHERE id = $1
            """
            
            result = await self.db_client.raw_query(query, [ticket_id])
            
            if not result or len(result) == 0:
                logger.warning(f"Ticket {ticket_id} not found in database")
                return None
                
            return result[0]
            
        except Exception as e:
            logger.error(f"Error getting ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return None
    
    async def get_ticket_with_content(self, ticket_id: int) -> Optional[Dict[str, Any]]:
        """
        Get a ticket by ID with all child documents joined into a single content field.
        
        Args:
            ticket_id (int): ID of the ticket to retrieve
            
        Returns:
            Optional[Dict[str, Any]]: Dictionary with ticket data including content if found, None otherwise
        """
        try:
            # First get basic ticket data
            ticket_data = await self.get_ticket(ticket_id)
            if not ticket_data:
                return None
                
            # Create retriever to get the child documents
            async with await HybridRetriever.create(username=self.user_id, db_client=self.db_client) as retriever:
                # Get all child documents
                child_documents = await retriever.retrieve_child_documents(ticket_id)
                
                # Combine child documents into one content string
                content = "\n\n".join([doc.get('content', '') for doc in child_documents])
                ticket_data['content'] = content
                
            return ticket_data
            
        except Exception as e:
            logger.error(f"Error getting ticket with content {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return None
    
    async def get_ticket_as_model(self, ticket_id: int) -> Optional[Ticket]:
        """
        Get a ticket by ID and convert it to a Ticket model object.
        
        Args:
            ticket_id (int): ID of the ticket to retrieve
            
        Returns:
            Optional[Ticket]: Ticket object if found, None otherwise
        """
        ticket_data = await self.get_ticket_with_content(ticket_id)
        if not ticket_data:
            return None
            
        return Ticket.from_raw_data(ticket_data)
    
    async def ensure_ticket_skeleton(self, 
                                     ticket_id: int, 
                                     group_id: str,
                                     metadata: dict|None = None) -> bool:
        """
        Ensure a skeleton entry exists in the parent_documents table for the given ticket_id.
        This prevents foreign key constraint errors when adding LLM call records.
        
        Args:
            ticket_id: The ticket ID to check/create
            group_id: The group ID for the ticket
            
        Returns:
            bool: True if entry exists or was created, False on error
        """
        try:
            # Check if entry already exists
            existing = await self.db_client.table("parent_documents").select("id").eq("id", ticket_id).execute()
            
            # Handle different return formats from different database clients
            has_entry = False
            if hasattr(existing, 'data') and len(existing.data) > 0:
                has_entry = True
            elif isinstance(existing, list) and len(existing) > 0:
                has_entry = True
            elif isinstance(existing, dict) and existing.get('data') and len(existing['data']) > 0:
                has_entry = True
                
            if has_entry:
                logger.info(f"Skeleton entry for ticket {ticket_id} already exists")
                return True
            
            # Create the skeleton entry with minimal required fields
            result = await self.db_client.table("parent_documents").insert({
                "id": ticket_id,
                "group_id": group_id,
                "created_by": self.user_id,
                "metadata": metadata
            }).execute()

            if result and len(result) == 1:
                logger.debug(f"Created skeleton entry for ticket {ticket_id}")
                return True
            else:
                logger.error(f"Error creating skeleton entry for ticket {ticket_id}")
                return False
                
        except Exception as e:
            logger.error(f"Error ensuring skeleton entry exists for ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return False
        

    async def get_skeleton_tickets(self) -> List[Dict[str, Any]]:
        """
        Retrieve tickets that have skeleton entries, which means they have an entry in the parent_documents
        table, but no summary. Searches across all group_ids (companies), sorted by ticket id.
        
        These represent open tickets that we've processed but haven't fully
        ingested. Used to check which tickets might have become closed since
        last polling.
        
        Returns:
            List[Dict]: List of dicts containing ticket IDs and their group_ids, sorted by ticket id
        """
        try:
            logger.debug("Fetching all skeleton tickets")
            
            # Query for parent_documents with NULL content, including creation date and group_id
            query = """
            SELECT id, group_id, metadata
            FROM parent_documents 
            WHERE summary IS NULL
            ORDER BY id ASC
            """
            result = await self.db_client.raw_query(query)
            
            # Extract ticket information
            ticket_info = [
                {
                    "id": entry["id"],
                    "group_id": entry["group_id"],
                    "metadata": entry["metadata"]
                }
                for entry in result
            ] if result else []
            
            logger.debug(f"Found {len(ticket_info)} skeleton tickets")
            return ticket_info
            
        except Exception as e:
            logger.error(f"Error getting skeleton tickets: {str(e)}")
            return []
        
    
    async def get_user_tickets(self, 
                               contact_id: str, 
                               limit: int = None, 
                               max_ticket_id: int = None) -> List[Dict[str, Any]]:
        """
        Get previous tickets for a specific user in descending order of ticket ID.
        
        Args:
            contact_id (str): The user's contact_id, stored in the 'source' field of the parent_documents table
            limit (int): Maximum number of tickets to retrieve
            max_ticket_id (int, optional): Optional maximum ticket ID to consider
        
        Returns:
            List[Dict[str, Any]]: List of tickets associated with the contact
        """
        try:
            # Find tickets with this contact name
            query = """
            SELECT id, summary, metadata->>'type' as type,
                   metadata->>'subtype' as subtype, metadata->>'item' as item,
                   metadata->>'closed_date' as closed_date
            FROM parent_documents 
            WHERE source = $1""".replace("    ", "")
            if max_ticket_id:
                query += f"\nAND id < {max_ticket_id}"
            query += "\nORDER BY id DESC"
            if limit:
                query += f"\nLIMIT {limit}"

            result = await self.db_client.raw_query(query, [contact_id])
            
            if not result:
                return []
                
            # Format the results
            tickets = []
            for ticket in result:
                tickets.append({
                    "id": ticket["id"],
                    "summary": ticket.get("summary", ""),
                    "type": ticket.get("type", ""),
                    "subtype": ticket.get("subtype", ""),
                    "item": ticket.get("item", ""),
                    "closed_date": ticket.get("closed_date", "")
                })
            
            return tickets
            
        except Exception as e:
            logger.error(f"Error getting user tickets for {contact_id}: {str(e)}")
            logger.exception("Full traceback:")
            return []
    
    async def find_tickets_in_date_range(self, start_date: str, end_date: str) -> Tuple[int, int]:
        """
        Get the first and last ticket IDs within a date range based on closed_date.
        
        Args:
            start_date (str): Start date in ISO format (YYYY-MM-DD)
            end_date (str): End date in ISO format (YYYY-MM-DD)
            
        Returns:
            tuple[int, int]: Tuple containing (min_id, max_id) of tickets within the date range
        """
        try:
            logger.debug(f"Finding min/max ticket IDs between {start_date} and {end_date}")
            
            # Query for min and max ticket IDs within the date range
            query = """
            SELECT 
                MIN(id) as min_id, 
                MAX(id) as max_id 
            FROM parent_documents 
            WHERE metadata->>'closed_date' >= $1 
            AND metadata->>'closed_date' <= $2
            """
            
            result = await self.db_client.raw_query(query, [start_date, end_date])
            
            if not result or not result[0] or result[0]["min_id"] is None:
                logger.warning(f"No tickets found between {start_date} and {end_date}")
                return (0, 0)
                
            min_id, max_id = result[0]["min_id"], result[0]["max_id"]
            logger.debug(f"Found ticket ID range: {min_id} to {max_id}")
            return (min_id, max_id)
            
        except Exception as e:
            logger.error(f"Error finding tickets in date range: {str(e)}")
            logger.exception("Full traceback:")
            return (0, 0)
    
    async def get_ticket_ids_in_range(self, start_id: int, end_id: int) -> List[int]:
        """
        Get a list of ticket IDs between start_id and end_id (inclusive).
        
        Args:
            start_id (int): Starting ticket ID
            end_id (int): Ending ticket ID
            
        Returns:
            List[int]: List of ticket IDs within the specified range
        """
        try:
            if start_id <= 0 or end_id <= 0 or start_id > end_id:
                logger.warning(f"Invalid ID range: {start_id} to {end_id}")
                return []
                
            logger.debug(f"Getting ticket IDs from {start_id} to {end_id}")
            
            query = """
            SELECT id FROM parent_documents 
            WHERE id >= $1 AND id <= $2
            ORDER BY id ASC
            """
            
            result = await self.db_client.raw_query(query, [start_id, end_id])
            
            ticket_ids = [entry["id"] for entry in result] if result else []
            
            logger.debug(f"Retrieved {len(ticket_ids)} ticket IDs between {start_id} to {end_id}")
            return ticket_ids
            
        except Exception as e:
            logger.error(f"Error getting ticket IDs in range: {str(e)}")
            logger.exception("Full traceback:")
            return []
    
    async def get_user_id_from_username(self, username: str) -> Optional[str]:
        """
        Get a user ID from a username.
        
        Args:
            username (str): Username to look up
            
        Returns:
            Optional[str]: User ID if found, None otherwise
        """
        try:
            result = await self.db_client.table("users").select("id").eq("username", username).execute()
            
            if not result or len(result) == 0:
                logger.warning(f"User {username} not found")
                return None
                
            return result[0]["id"]
            
        except Exception as e:
            logger.error(f"Error getting user ID for {username}: {str(e)}")
            logger.exception("Full traceback:")
            return None
    
    async def get_group_id_from_company(self, company_identifier: str) -> Optional[str]:
        """
        Get a group ID from a company identifier.
        
        Args:
            company_identifier (str): Company identifier to look up
            
        Returns:
            Optional[str]: Group ID if found, None otherwise
        """
        try:
            group_id = await self.db_client.rpc("get_group_id", {"p_group_name": company_identifier}).execute()
            
            if not group_id:
                logger.warning(f"Group ID not found for company {company_identifier}")
                return None
                
            return group_id
            
        except Exception as e:
            logger.error(f"Error getting group ID for {company_identifier}: {str(e)}")
            logger.exception("Full traceback:")
            return None
            
    async def search_similar_tickets(self, 
                                     ticket: Union[Ticket, Dict[str, Any]], 
                                     match_count: int = 10,
                                     lookback_only: bool = True) -> List[Dict[str, Any]]:
        """
        Search for tickets similar to the provided ticket.
        
        Args:
            ticket (Ticket or Dict[str, Any]): Ticket object or dictionary with ticket data
            match_count (int): Maximum number of matches to return
            lookback_only (bool): If True, only return tickets with IDs less than the current ticket ID
        
        Returns:
            List[Dict[str, Any]]: List of similar tickets
        """
        try:
            # Format the query depending on the type of ticket
            if isinstance(ticket, Ticket):
                ticket_id = ticket.id
                query_text = ticket.user_query
                group_id = ticket.group_id
            else:
                ticket_id = ticket.get('id')
                query_text = ticket.get('user_query') or ticket.get('query')
                group_id = ticket.get('group_id')
            
            if not query_text:
                logger.warning("No query text available for similarity search")
                return []
                
            # Use the HybridRetriever to search for similar tickets
            search_filters = {
                "required_parent_metadata_keys": ["type", "subtype"],
                "group_ids": [group_id]
            }
            if lookback_only and ticket_id is not None:
                search_filters["max_parent_id"] = ticket_id-1
                
            async with await HybridRetriever.create(username=self.user_id, db_client=self.db_client) as retriever:
                results = await retriever.retrieve_documents(
                    query=query_text,
                    match_count=match_count,
                    search_type="hybrid",
                    search_filters=search_filters
                )
                
                # Fetch full text from all retrieved chunks asynchronously
                full_text_tasks = [
                    retriever.retrieve_full_child_document(result['parent_document_id'])
                    for result in results
                ]
                full_texts = await asyncio.gather(*full_text_tasks)
                
                # Create reference tickets dictionary
                retrieved_tickets = [
                    {
                        "ticket_id": result.get('parent_document_id'),
                        "type": result.get('parent_metadata', {}).get('type'),
                        "subtype": result.get('parent_metadata', {}).get('subtype'),
                        "item": result.get('parent_metadata', {}).get('item'),
                        "priority": result.get('parent_metadata', {}).get('priority'),
                        "messages": full_text
                    }
                    for (result, full_text) in zip(results, full_texts)
                ]
                
                return retrieved_tickets
                
        except Exception as e:
            logger.error(f"Error searching similar tickets: {str(e)}")
            logger.exception("Full traceback:")
            return []
```
## File: app/test_ticket_ingester.py
```python
import os
import sys
import json
import asyncio
import logging
from datetime import datetime, timedelta
from dotenv import load_dotenv
from app.ticket_ingester import TicketIngester
from app.models.ticket import Ticket
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from dotenv import load_dotenv  

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"
# username = "helpdesk_agent"

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)




FOLDER_PATH = "ticket_data"
os.makedirs(FOLDER_PATH, exist_ok=True)

async def test_preprocess_single_ticket(ticket_id: int, 
                                        db_client: AuthenticatedPostgresClient):
    """
    Test preprocessing a single ticket.
    
    Args:
        ticket_id: ID of the ticket to process
        db_client: Database client
    """
    logger.info(f"Testing preprocessing of ticket {ticket_id}")
    
    # Create the ingester
    ingester = await TicketIngester.create(db_client)
    
    # Process the ticket
    ticket_data = await ingester.preprocess_ticket(ticket_id)
   
    return ticket_data


async def test_ingest_single_ticket(ticket: dict, 
                                    db_client: AuthenticatedPostgresClient):
    """
    Test ingesting a single ticket.
    """
    ingester = await TicketIngester.create(db_client)
    response = await ingester.ingest_ticket(ticket)
    return response



async def test_batch_preprocessing(ticket_ids: list, 
                                   db_client: AuthenticatedPostgresClient,
                                   max_concurrent: int = 3):
    """
    Test batch preprocessing of tickets with concurrent processing
    using the TicketIngester.preprocess_batch method.
    
    Args:
        ticket_ids: List of ticket IDs to process
        db_client: Database client
        max_concurrent: Maximum number of concurrent ticket processing tasks
        
    Returns:
        List of processed ticket data
    """
    logger.info(f"Testing batch preprocessing of {len(ticket_ids)} tickets with max {max_concurrent} concurrent tasks")
    
    ingester = await TicketIngester.create(db_client)

    processed_tickets = await ingester.preprocess_batch(
        ticket_ids=ticket_ids,
        max_concurrent=max_concurrent
    )
    logger.info(f"Batch processing complete. Successfully processed {len(processed_tickets)}/{len(ticket_ids)} tickets")
    
    return processed_tickets


async def test_batch_ingestion(processed_tickets: list, 
                               db_client: AuthenticatedPostgresClient, 
                               max_concurrent: int = 3):
    """
    Test batch ingestion of tickets with concurrent processing
    using the TicketIngester.ingest_ticket_batch method.
    """
    ingester = await TicketIngester.create(db_client)
    ingested_tickets = await ingester.ingest_ticket_batch(
        tickets=processed_tickets,
        max_concurrent=max_concurrent
    )
    return ingested_tickets

async def load_processed_tickets(folder: str, n_tickets: int):
    files = [f for f in os.listdir(folder) if f.endswith(".json")]
    ticket_ids = [int(file.split(".")[0]) for file in files]
    ticket_ids.sort()
    ticket_ids = ticket_ids[:n_tickets]
    print(f"ticket_ids: {ticket_ids}")
    ticket_files = [f"{folder}/{ticket_id}.json" for ticket_id in ticket_ids]
    print(f"ticket_files: {ticket_files}")
    processed_tickets = []
    for ticket_file in ticket_files:
        with open(ticket_file, "r") as f:
            processed_tickets.append(json.load(f))
    return processed_tickets

async def main():
    """Main test function."""
    logger.info("Starting TicketIngester tests")
    
    load_dotenv()

    os.environ["POSTGRES_HOST"] = "localhost"
    username = "helpdesk_agent"

    async with AuthenticatedPostgresClient(username=username) as db_client:
        logger.info("Connected to database")      
        


        # Test single ticket preprocessing
        ticket_id = 276501
        logger.info(f"Testing single ticket preprocessing for ticket {ticket_id}")
        preprocessed_ticket = await test_preprocess_single_ticket(ticket_id, db_client)
        # print(f"preprocessed_ticket:\n{json.dumps(preprocessed_ticket, indent=4)}")

        # Test single ticket ingestion
        ingested_ticket = await test_ingest_single_ticket(preprocessed_ticket, db_client)
        print(f"ingested_ticket:\n{json.dumps(ingested_ticket, indent=4)}")
        


        # # Test batch preprocessing with the updated test_batch_preprocessing function
        # max_concurrent = 3
        # folder = "ticket_data"
        # ticket_ids = [1032750, 1031801, 1031781, 1031778, 1031741]  # Replace with valid ticket IDs
        # logger.info(f"Testing batch processing with {len(ticket_ids)} tickets")

        # processed_tickets = await test_batch_preprocessing(ticket_ids, db_client, folder=folder,max_concurrent=max_concurrent)
        # logger.info(f"Preprocessed {len(processed_tickets)}/{len(ticket_ids)} tickets in total")


        # # Test batch ingestion
        # # load the processed tickets from the file
        # max_concurrent = 3
        # n_tickets = 5
        # folder = "ticket_data/raw"
        # processed_tickets = await load_processed_tickets(folder, n_tickets)
        # print(json.dumps(processed_tickets, indent=4))
        # response = await test_batch_ingestion(processed_tickets, db_client, max_concurrent=max_concurrent)
        # print(f"ingestion response:\n{json.dumps(response, indent=4)}")

       
if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/test_ticket_image_processor.py
```python
import asyncio
import logging
from app.ticket_image_processor import TicketImageProcessor, ExtractedImage
from app.ticket_pdf_writer import write_pdf
from app.api import ConnectWiseAPI
import json
import os
import re
from database import AuthenticatedPostgresClient

from dotenv import load_dotenv

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"
USERNAME = "trevor@aech.ai"

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_process_ticket():
    """Test the ticket image processing functionality"""
    connectwise_api = ConnectWiseAPI()
    
    # Test tickets with different characteristics
    test_tickets = [
        "628412",  # ticket with multiple images
        # "620941",  # ticket with base64 images
        # "826326",   # ticket with markdown images
        # "1009423",
        # "1031431", # potential spam
        # "1030432",
        # "1030209"
    ]
    generate_pdf=True
    async with AuthenticatedPostgresClient(USERNAME) as db_client:
        print(f"db_client.user_info:\n{db_client.user_info}")
        processor = TicketImageProcessor(
            db_client=db_client
        )
    
        for ticket_id in test_tickets:
            logger.info(f"\nProcessing ticket: {ticket_id}")
            try:
                # Get ticket data
                ticket = await connectwise_api.get_ticket_with_messages(ticket_id)
                # print(f"original messages:\n{json.dumps(ticket.get('messages', []), indent=4)}")

                # # Process the ticket with LLM and generate PDFs all in one call
                # logger.info(f"Processing ticket with LLM to get image transcriptions (pdf={generate_pdf})")
                # transcribed_messages = await processor.transcribe_ticket_messages(ticket)
                # print(f"transcribed_messages:\n{json.dumps(transcribed_messages, indent=4)}")


                transcribed_ticket = await processor.transcribe_ticket(
                    ticket, 
                    generate_pdf=generate_pdf,
                    output_dir="app/data"
                )
                
                logger.info(f"LLM processing complete. Generated {len(transcribed_ticket.get('messages', []))} processed messages")
                
                # Check if PDFs were generated
                if 'original_pdf_path' in transcribed_ticket:
                    logger.info(f"Original ticket PDF written to: {transcribed_ticket['original_pdf_path']}")
                if 'processed_pdf_path' in transcribed_ticket:
                    logger.info(f"Processed ticket PDF written to: {transcribed_ticket['processed_pdf_path']}")
                
                # # Convert the processed ticket to a single string for simple text output
                # formatted_text = processor.format_ticket_as_string(transcribed_ticket)
                # print(f"********formatted_text:\n{formatted_text}")

            except Exception as e:
                logger.error(f"Error processing ticket {ticket_id}: {str(e)}")
                logger.error(f"Stack trace:", exc_info=True)


if __name__ == "__main__":
    asyncio.run(test_process_ticket())
```
## File: app/test_ticket_annotator.py
```python
from ticket_annotator import TicketAnnotator
import asyncio
import os
import json
from datetime import datetime, timezone
import logging
from dotenv import load_dotenv
from database import AuthenticatedPostgresClient
from typing import List
from models.ticket import Ticket

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


USERNAME = "helpdesk_agent"
SAVE_FOLDER = "app/data/test"

def save_note(note: str, ticket_id: int):
    with open(f"{SAVE_FOLDER}/{ticket_id}.md", "w") as f:
        f.write(note)

async def process_single_ticket(
        ticket_id: int, 
        save_folder: str = SAVE_FOLDER, 
        initial_messages_only: bool = True,
        lookback_only: bool = True,
        source: str = "database"
    ):
    """
    Process a single ticket from the database.
    """
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        # Create and initialize the annotator using the factory method
        annotator = await TicketAnnotator.create(db_client=db_client)
        response = await annotator.annotate_ticket(
            ticket_id, 
            add_note=False,
            save_folder=save_folder,
            n_matches=20,
            initial_messages_only=initial_messages_only,
            lookback_only=lookback_only,
            source=source, 
            n_user_history_tickets=2
        )
        # Convert TicketAnnotation to dict for JSON serialization
        response_dict = response.to_dict()
        print(f"Response: {json.dumps(response_dict, indent=2)}")
        
        # print(f"***** Annotation: ******\n{response.note_content}")
        save_note(response.note_content, ticket_id)
        print(f"\nSaved note to {save_folder}/{ticket_id}.md")


async def process_ticket_batch(
        ticket_ids: List[int], 
        add_note: bool = False, 
        batch_size: int = 50,
        simultaneous_requests: int = 15,
        save_folder: str = SAVE_FOLDER):
    """
    Process tickets closed between start_date and end_date.
    
    Args:
        ticket_ids (List[int]): List of ticket IDs to process
        add_note (bool): Whether to add notes to tickets in Scout
        batch_size (int): Size of batches for processing tickets
    """
    
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        # Create and initialize the annotator using the factory method
        annotator = await TicketAnnotator.create(db_client=db_client)
        
        # Process tickets in the date range, saving each result immediately
        results = await annotator.annotate_tickets(
            ticket_ids, 
            save_folder = save_folder,
            simultaneous_requests=simultaneous_requests,
            batch_size=batch_size
        )
        
        # Convert list of TicketAnnotation objects to dictionaries
        results_dicts = [result.to_dict() if hasattr(result, 'to_dict') else result for result in results]
        
        # Save the full results for reference
        full_results_path = os.path.join(save_folder, "all_results.json")
        with open(full_results_path, "w") as f:
            json.dump(results_dicts, f, indent=2)
        logger.info(f"Saved combined results to {full_results_path}")

async def test_lookback_only(ticket_id: int):
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        annotator = await TicketAnnotator.create(db_client=db_client)
        
        ticket = await annotator._get_ticket(ticket_id)
        user_query = annotator._extract_user_query(ticket)
        ticket["user_query"] = user_query
        print(f"Ticket: {json.dumps(ticket, indent=4)}")
        print(f"Testing lookback_only for ticket_id: {ticket['id']}")

        # First get tickets with lookback_only=True
        lookback_only = True
        similar_tickets = await annotator._retrieve_similar_tickets(
            ticket,
            lookback_only=lookback_only
        )
        similar_ticket_ids = [t['ticket_id'] for t in similar_tickets]
        similar_ticket_ids.sort()
        lookback_check = all(tid < ticket_id for tid in similar_ticket_ids)
        print(f"\nlookback_only=True results:")
        print(f"Similar ticket IDs: {similar_ticket_ids}")
        print(f"All IDs less than current ticket: {lookback_check}")

        # Then get tickets without lookback restriction
        lookback_only = False
        similar_tickets = await annotator._retrieve_similar_tickets(
            ticket, 
            lookback_only=lookback_only
        )
        similar_ticket_ids = [t['ticket_id'] for t in similar_tickets]
        similar_ticket_ids.sort()
        lookback_check = all(tid < ticket_id for tid in similar_ticket_ids)
        print(f"\nlookback_only=False results:")
        print(f"Similar ticket IDs: {similar_ticket_ids}")
        print(f"All IDs less than current ticket: {lookback_check}")

async def test_get_ticket(ticket_id: int):
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        annotator = await TicketAnnotator.create(db_client=db_client)

        source = "database"
        print(f"******* SOURCE = {source} *******")
        ticket = await annotator._get_ticket(ticket_id, source=source)
        # print(f"\nticket dict: {json.dumps(ticket, indent=4)}")
        ticket_model_db = Ticket.from_database_format(ticket)
        print(f"\n--DATABASE model_dump: --\n{ticket_model_db.model_dump_json(indent=4)}")

        source = "api"
        print(f"******* SOURCE = {source} *******")
        ticket = await annotator._get_ticket(ticket_id, source=source)
        print(f"\nAPI ticket dict: {json.dumps(ticket, indent=4)}")
        ticket_model_api = Ticket.from_api_format(ticket)
        print(f"\n--API model_dump: --\n{ticket_model_api.model_dump_json(indent=4)}")

        api_dict = ticket_model_api.model_dump()
        db_dict = ticket_model_db.model_dump()
        #comapre attributes of the two models
        for api_attr, db_attr in zip(api_dict.keys(), db_dict.keys()):
            if api_dict[api_attr] != db_dict[db_attr]:
                print(f"\nAttribute mismatch: {api_attr}")
                print(f"api value: {api_dict[api_attr]}")
                print(f"db value:  {db_dict[db_attr]}")

# If running this script directly, execute the example
if __name__ == "__main__":

    # test get ticket:
    # ticket_id = 381487
    # asyncio.run(test_get_ticket(ticket_id))


    # process single ticket:
    # ticket_id = 978474
    # ticket_id = 1033009 # Aech test ticket
    # ticket_id = 1020325
    # ticket_id = 1034603
    ticket_id = 1036301
    # source = "database"
    source = "api"
    asyncio.run(process_single_ticket(ticket_id, SAVE_FOLDER, source=source))

    # # Default test values - convert to UTC datetime strings
    # ticket_ids = [
    #     1034603, 
    #     449775
    # ]
    # add_note = False
    # batch_size = 50
    # simultaneous_requests = 15
    # asyncio.run(process_ticket_batch(ticket_ids, add_note, simultaneous_requests, save_folder))

    # ticket_id = 1024068
    # asyncio.run(test_lookback_only(ticket_id))
```
## File: app/test_connectwise_api.py
```python
import asyncio
from datetime import datetime, timezone
from app.api import ConnectWiseAPI
from dotenv import load_dotenv
import json
import logging
import os
import pathlib

# Set up logging
logging.basicConfig(level=logging.INFO)

load_dotenv()


api = ConnectWiseAPI()

def load_json_file(file_path: str):
    with open(file_path, "r") as f:
        return json.load(f)

def save_json_file(data: dict, file_path: str):
    with open(file_path, "w") as f:
        json.dump(data, f, indent=4)

tsi_dict_path = "app/data/tsi_dict.json"
tsi_dict = load_json_file(tsi_dict_path)
# print(f"tsi_dict:\n{json.dumps(tsi_dict, indent=4)}")

def count_dict_items(d: dict):
    n_types = len(d)
    n_subtypes = 0
    n_items = 0
    for type in d:
        n_subtypes += len(d[type])
        for subtype in d[type]:
            n_items += len(d[type][subtype])
    return n_types, n_subtypes, n_items

async def main():

    

    
    # TEST GETTING TICKET WITH MESSAGES
    ticket_id = 1036306 
    # fields = [
    #         "id",
    #         # "company",
    #         # "type",
    #         # "subtype",
    #         # "item",
    #         "_info"
    #     ]

    # ticket = await api.get(
    #     route = f"service/tickets/{ticket_id}",
    #     params = {"fields": ",".join(fields)}
    # )
    # try:
    #     print(f"ticket: {json.dumps(ticket, indent=4)}")
    # except Exception as e:
    #     print(f"Error: {e}")
    #     print(f"ticket: {ticket}")


    ticket_with_messages = await api.get_ticket_with_messages(ticket_id)
    print(f"\n\nticket_with_messages: {json.dumps(ticket_with_messages, indent=4)}")

    

if __name__ == "__main__":
    asyncio.run(main())
```
## File: retrieval/ingestion.py
```python
import os
import logging
import json
import asyncio
import base64
from typing import List, Dict, Any, Optional, Tuple, Union
from uuid import uuid4
from datetime import datetime

from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from retrieval.hybrid_retriever import HybridRetriever
from llm import get_llm_provider
from retrieval.transcription import Transcription

load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logging.getLogger("azure.core.pipeline").setLevel(logging.WARNING)

INGESTION_MODEL = "gpt-4o-2024-11-20"

DEFAULT_CHUNK_SIZE = 1500

class Ingestion:
    """
    A class that handles the complete document ingestion pipeline:
    1. Converting documents to images
    2. Transcribing images to markdown
    3. Ingesting markdown into Postgres
    """

    TEXT_EXTENSIONS = ["txt", "md", "json"]
    
    TEMPERATURE = 0.1
    MAX_TOKENS = 10000

    TRANSCRIPTION_PROMPT = """
    Transcribe this image of a document in markdown format with markdown headings, tables and text formatting. 
    - Ensure that all text is transcribed faithfully including all words on the page.
    - Follow correct markdown formatting, including blank lines around headings, subheadings, captions, tables, etc.
    - Insert a detailed text description of what is portrayed in any image in square brackets (eg "[Image description: <description>]) AT THE SAME POSITION that the image appears on the page.
      - Image descriptions should not include any placeholder urls or base64 strings.
      - If the image contains a chart, explain what is plotted and give basic quantitative information about the chart, including units and any other relevant information.
    - Insert handwritten annotations in square brackets like this: "[Annotation: <transcription of annotation>]"
    - Tables should be transcribed as markdown rather than described as images whenever possible.

    It is crucial that the transcription is faithful to the image. 
    Leave nothing out and do not add any words that are not in the image.
    Return only the markdown and nothing else."""

    HEADINGS_PROMPT = """
    The image is part of a multi-page document. Here are the headings from previous pages in order:
    {previous_headings}

    Ensure that:
    - New headings maintain a logical hierarchy with the previous headings
    - Do not repeat any headings that have already appeared
    - If this page continues a section from the previous page, use the same heading level
    - If the page begins mid-sentence, simply transcribe the partial sentence without adding headings
    """

    def __init__(
            self, 
            username: str,
            db_client=None,
            observability_info: dict = None,
            model_name: str = INGESTION_MODEL
        ):
        """Initialize the Ingestion class.

        Args:
            username (str): Email of the authenticated user.
            db_client: Optional database client. If provided, this will be used instead of creating a new one.
            observability_info (dict, optional): Information for observability. Defaults to None.
            model_name (str, optional): The model to use for summarization. Defaults to INGESTION_MODEL.
        """
        self.username = username
        self._db_client = db_client
        self._db_client_provided = db_client is not None
        self.observability_info = observability_info
        self.model_name = model_name
        self.transcription = Transcription()
        logger.debug(f"Ingestion class initialized for user: {username}")

    @classmethod
    async def create(cls, username: str, db_client=None, observability_info: dict = None, model_name: str = INGESTION_MODEL):
        """Create a new instance with a configured database client.
        
        Args:
            username (str): Email of the authenticated user.
            db_client: Optional database client. If provided, this will be used instead of creating a new one.
            observability_info (dict, optional): Information for observability. Defaults to None.
            model_name (str, optional): The model to use for summarization. Defaults to INGESTION_MODEL.
        
        Returns:
            Ingestion: A new instance with an initialized database client.
        """
        self = cls(username, db_client, observability_info, model_name)
        
        # Only create a new client if one wasn't provided
        if not self._db_client_provided:
            self._db_client = await AuthenticatedPostgresClient.create(username=username)
            if not self._db_client:
                raise Exception(f"Failed to create database client for user: {username}")
        return self

    async def close(self):
        """Close the database connection if we created it."""
        if self._db_client and not self._db_client_provided:
            await self._db_client.close()
            self._db_client = None

    async def __aenter__(self):
        if not self._db_client and not self._db_client_provided:
            self._db_client = await AuthenticatedPostgresClient.create(username=self.username)
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()

    @property
    def database_client(self):
        """
        Get the database client, raising an exception if it's not initialized.
        """
        if not self._db_client:
            raise Exception("Database client not initialized. Use 'async with' or 'create()'.")
        return self._db_client

    def _split_text(
        self,
        text: str,
        chunk_size: int = DEFAULT_CHUNK_SIZE,
        separators: List[str] = [
            "\n# ", "\n## ", "\n### ", "\n#### ", "\n##### ", "\n###### ",
            "\n\n\n", "\n\n", "\n", ".", "!", "?", ","
        ],
    ) -> List[str]:
        """Split text into chunks using recursive character splitting.

        Args:
            text (str): The text to split into chunks.
            chunk_size (int, optional): Maximum size of each chunk. Default is 1500.
            separators (List[str], optional): List of separators to use for splitting. Default includes common markdown and punctuation.

        Returns:
            List[str]: A list of text chunks.
        """
        splitter = RecursiveCharacterTextSplitter(
            separators=separators,
            chunk_size=chunk_size,
            chunk_overlap=0
        )
        return splitter.split_text(text)

    async def _get_data_from_text(self, text: str, summary_instructions: str = None) -> str:
        """Process markdown text to extract summary.

        Args:
            text (str): The markdown text to process.
            summary_instructions (str, optional): Special instructions for the summary.
        Returns:
            str: The summary of the text.
        """
        logger.debug("Extracting info from text")
        tasks = [
            self._summarize_text(text, special_instructions=summary_instructions),
            # TODO: extract other info from text like dates and entities
        ]
        
        [summary] = await asyncio.gather(*tasks)
        
        return summary

    async def _summarize_text(self, text: str, n_words: int = 250, special_instructions: str = None) -> str:
        """Generate a summary of the text.

        Args:
            text (str): The text to summarize.
            n_words (int, optional): Maximum number of words in the summary. Default is 500.
            special_instructions (str, optional): Special instructions for the summary.
        Returns:
            str: The generated summary of the text.
        """
        # Build the prompt using proper string formatting
        special_instructions_text = f"special_instructions:\n{special_instructions}\n" if special_instructions else ""
        prompt = f"""please summarize this text in no more than {n_words} words.
{special_instructions_text}
Text: {text}"""
        
        json_output_format = {"summary": "<summary>"}
        
        provider = get_llm_provider(self.model_name)
        response = await provider.get_response(
            prompt,
            config={
                'temperature': 0.10,
                'max_tokens': int(n_words * 1.4),
            },
            response_format=json_output_format,
            observability_info=self.observability_info
        )
        return self._straighten_quotes(response["summary"])

    def _straighten_quotes(self, text: str) -> str:
        """Replace curved quotation marks with straight ones.

        Args:
            text (str): The text to process.

        Returns:
            str: The processed text with straight quotation marks.
        """
        replacements = {
            '\u2018': "'", 
            '\u2019': "'", 
            '\u201C': '"', 
            '\u201D': '"', 
            '\u00a0': ' ',
            '\u2013': '-'
        }
        for curved, straight in replacements.items():
            text = text.replace(curved, straight)
        return text

    async def ingest_markdown(
        self,
        text: str,
        group_id: str,
        id: str|int|None = None,
        source: str = None,
        user_id: str = None,
        chunk_size: int = DEFAULT_CHUNK_SIZE,
        metadata: dict = None,
        summary_instructions: str = None
    ) -> dict:
        """
        Ingest markdown or raw text content into the database.
        
        Args:
            text (str): The markdown or raw text content to ingest
            group_id (str): Group ID for the document
            id (str|int|None, optional): ID of the parent document
            source (str, optional): Source identifier for the document
            user_id (str, optional): User ID of the person ingesting the document
            chunk_size (int, optional): Size of chunks for text ingestion
            metadata (dict, optional): Metadata to add to the document
            summary_instructions (str, optional): Special instructions for summary generation
        
        Returns:
            dict: A dictionary containing the ingestion success status
        """
        success = False
        
        try:
            if not text:
                logger.error("No text provided for ingestion")
                return {"success": False, "error": "No text provided"}

            if not group_id:
                logger.error("No group_id provided for ingestion")
                return {"success": False, "error": "No group ID provided"}
            
            # Apply quote straightening
            cleaned_text = self._straighten_quotes(text)

            # Extract document-level data
            summary = await self._get_data_from_text(cleaned_text, summary_instructions=summary_instructions) 

            # Create and use the retriever with async context manager, passing our database client
            async with await HybridRetriever.create(self.username, db_client=self.database_client) as retriever:
                logger.debug(f"Adding parent document, source: {source}")
                
                result = await retriever.add_parent_document(
                    id=id,
                    summary=summary,
                    group_id=group_id,
                    created_by=user_id,
                    source=source,
                    metadata=metadata
                )
                parent_document_id = result[0]["id"]

                # Add child documents
                documents = self._split_text(cleaned_text, chunk_size=chunk_size)
                result = await retriever.add_documents(
                    documents=documents,
                    parent_document_id=parent_document_id,
                    group_id=group_id,
                )
                success = bool(result[0])
        
        except Exception as e:
            logger.error(f"Error during text ingestion: {str(e)}")
            logger.exception("Full traceback:")
            success = False
        
        return {"success": success}

    # async def ingest_document(self, 
    #         filename: str|None, 
    #         file_content: bytes | str, 
    #         group_id: str, 
    #         user_id: str = None, 
    #         chunk_size: int = DEFAULT_CHUNK_SIZE, 
    #         cloud_storage_client: Any = None,
    #         metadata: dict = None,
    #         summary_instructions: str = None
    #     ) -> dict:
    #     """
    #     Process a document through the complete ingestion pipeline.

    #     Args:
    #         filename (str|None): Name of the file.
    #         file_content (bytes | str): Content of the file (bytes or base64 string).
    #         group_id (str): Group ID for the document.
    #         user_id (str, optional): User ID of the person ingesting the document.
    #         chunk_size (int, optional): Size of chunks for markdown ingestion.
    #         cloud_storage_client (Any, optional): Cloud storage client instance.
    #         metadata (dict, optional): Metadata to be added to the document.
    #         summary_instructions (str, optional): Special instructions for the summary.
    #     Returns:
    #         dict: A dictionary containing the ingestion success status and file paths.
    #             - "success" (bool): True if ingestion and saving were successful, False otherwise.
    #             - "ingestion" (bool): True if ingestion was successful, False otherwise.
    #             - "save" (bool): True if saving was successful, False otherwise.
    #             - "file_path" (str | None): Path to the saved original file in cloud storage.
    #             - "markdown_path" (str | None): Path to the saved markdown file in cloud storage.
    #     """
    #     file_path = await self.get_file_path(filename, group_id)
    #     markdown_path = await self.get_markdown_path(filename, group_id)
    #     ingestion_success = False
    #     save_success = False

    #     try:
    #         # Convert file content to bytes if it's a base64 string
    #         if isinstance(file_content, str):
    #             file_content = base64.b64decode(file_content)

    #         if filename.split(".")[-1] in self.TEXT_EXTENSIONS:
    #             # For text files, decode the content and use it directly
    #             markdown_content = file_content.decode('utf-8')
    #         else:
    #             # For non-text files, convert to images and transcribe
    #             images = await self.transcription.doc_to_images(filename, file_content)
    #             markdown_content = await self.transcription.images_to_markdown(
    #                 images=images,
    #                 batch_size=5,
    #                 model_name=self.model_name,
    #                 max_tokens=self.MAX_TOKENS,
    #                 temperature=self.TEMPERATURE,
    #                 observability_info=self.observability_info
    #             )
            
    #         # Ingest markdown into database
    #         ingestion_success = await self.ingest_markdown(
    #             filename=filename,
    #             group_id=group_id,
    #             markdown_text=markdown_content,
    #             chunk_size=chunk_size,  
    #             user_id=user_id,
    #             metadata=metadata,
    #             summary_instructions=summary_instructions
    #         )

    #         # Save to cloud
    #         if cloud_storage_client:
    #             save_success = await self.save_to_cloud(
    #                 file_content, 
    #                 markdown_content, 
    #                 filename, 
    #                 group_id, 
    #                 cloud_storage_client
    #             )

    #     except Exception as e:
    #         logger.error(f"Error during document ingestion: {str(e)}")
    #         logger.error(f"ingested={ingestion_success}, saved={save_success}")
    #         import traceback
    #         logger.error(f"Traceback: {traceback.format_exc()}")

    #     finally:
    #         response = {
    #             "success": ingestion_success and save_success,
    #             "ingestion": ingestion_success,
    #             "save": save_success,
    #             "file_path": file_path if save_success else None,
    #             "markdown_path": markdown_path if save_success else None,
    #         }
    #         return response

    # async def save_to_cloud(self, file_content: bytes, markdown_text: str, 
    #                         filename: str, group_id: str, cloud_storage_client: Any) -> bool:
    #     """Save the original file and its markdown version to cloud storage.

    #     Args:
    #         file_content (bytes): The original file content to save.
    #         markdown_text (str): The markdown content to save.
    #         filename (str): The name of the original file.
    #         group_id (str): Group ID associated with the document.
    #         cloud_storage_client (Any): Cloud storage client instance.

    #     Returns:
    #         bool: True if saving was successful, False otherwise.

    #     Raises:
    #         ValueError: If content is not in bytes format
    #     """
    #     if not isinstance(file_content, bytes):
    #         raise ValueError(f"content to be saved must be in bytes, not {type(file_content)}")
        
    #     if not filename:
    #         logger.warning("No filename provided for saving to cloud")
    #         return False
        
    #     # Save the original file to the cloud
    #     file_path = await self.get_file_path(filename, group_id)
    #     logger.info(f"Saving original file: {file_path}")
    #     try:
    #         file_success = await cloud_storage_client.upload_file(file_path, file_content)
    #     except Exception as e:
    #         logger.error(f"Error saving original file: {e}")
    #         file_path = None
            
    #     # Save the markdown version to the cloud
    #     markdown_path = await self.get_markdown_path(filename, group_id)
    #     markdown_bytes = markdown_text.encode('utf-8') if isinstance(markdown_text, str) else markdown_text
    #     logger.info(f"Saving markdown file: {markdown_path}")
    #     try:
    #         success = await cloud_storage_client.upload_file(markdown_path, markdown_bytes)
    #     except Exception as e:
    #         logger.error(f"Error saving markdown file: {e}")
    #         success = False

    #     return success
    
    # async def get_markdown_path(self, orig_filename: str, group_id: str) -> str:
    #     """Get the path to where the markdown version of the file is stored.

    #     Args:
    #         orig_filename (str): The name of the original file.
    #         group_id (str): The group ID associated with the file.

    #     Returns:
    #         str: The path to the markdown file.
    #     """
    #     if not orig_filename:
    #         logger.warning("No filename provided for markdown path")
    #         return None
    #     markdown_filename = f"{orig_filename.split('.')[0]}.md"
    #     return f"{self.ROOT_PATH}/{group_id}/markdown/{markdown_filename}"
    

    
    # async def get_file_path(self, filename: str|None, group_id: str) -> str | None:
    #     """Get the path to where the file is stored.

    #     Args:
    #         filename (str): The name of the file.
    #         group_id (str): The group ID associated with the file.

    #     Returns:
    #         str | None: The path to the original file, or None if filename is None.
    #     """
    #     if not filename:
    #         return None
    #     return f"{self.ROOT_PATH}/{group_id}/{filename}"
```
## File: retrieval/transcription.py
```python
import os
import logging
import tempfile
import subprocess
from typing import List, Dict, Any
from PIL import Image
from pdf2image import convert_from_path
import mimetypes
from llm import get_llm_provider, LLMProvider
from io import BytesIO
from dotenv import load_dotenv
import asyncio
from datetime import datetime
load_dotenv()

logger = logging.getLogger(__name__)

class Transcription:
    """
    A class that handles document transcription:
    1. Converting documents to images
    2. Transcribing images to markdown
    """

    DOCUMENT_MIMETYPES = [
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document',   # docx
        'application/vnd.openxmlformats-officedocument.presentationml.presentation', # pptx
        'application/vnd.oasis.opendocument.text',  # odt
        'application/vnd.oasis.opendocument.presentation',  # odp
        'application/pdf',  # pdf
        'application/msword',  # doc
        'application/vnd.ms-powerpoint',  # ppt
        
    ]

    IMAGE_MIMETYPES = [
        'image/png',  # png
        'image/jpeg', # jpg, jpeg
    ]

    TEXT_MIMETYPES = [
        'text/plain',       # txt
        'text/markdown',    # md
        'application/json', # json
    ]

    AUDIO_MIMETYPES = [
        'audio/flac', # flac
        'audio/mp4',  # mp4, m4a
        'audio/mpeg', # mpeg
        'audio/mpga', # mpga
        'audio/oga',  # oga
        'audio/ogg',  # ogg
        'audio/wav',  # wav
        'audio/webm', # webm
    ]
    ALLOWED_MIMETYPES = DOCUMENT_MIMETYPES + TEXT_MIMETYPES + IMAGE_MIMETYPES + AUDIO_MIMETYPES
    

    TRANSCRIPTION_PROMPT = """Transcribe These images of a document into markdown format with markdown headings, tables and text formatting. 

Markdown formatting:
- Ensure that all text is transcribed faithfully including all words on the page (including captions and footnotes).
- Follow correct markdown formatting, including blank lines around headings, subheadings, captions, tables ,etc.
- Use markdown checkboxes where appropriate.
- Footnotes should be indicated with carets in the text where they appear (eg "[^1]") and their content (eg "[^1]: <content of footnote>") should be included in the same position relative to the text as it appears in the original document.

Visual elements:
- Insert a detailed text description of what is portrayed in any image in square brackets (eg "[Image: <description of image>]") AT THE SAME POSITION that the image appears on the page.
    - Image descriptions should not include any placeholder urls or base64 strings.
    - If the image contains a chart, explain what is plotted and give basic quantitative information about the chart, including units and any other relevant information.
    - The image description should contain enough information to understand the document using the description instead of the image.
    - If the image is a graph or a table with a heading, include the heading in the image description but do not include it as a markdown heading.
- If there are handwritten annotations, place them in square brackets like this: "[Annotation: <transcription of annotation>]"
- Tables should be transcribed as markdown rather than described as images whenever possible.
- The captions for figures and tables should always be included verbatim, italicized, and in the same position relative to the figure or table as they appear on the page. If the caption is below the figure, then it should be below the the text description of the figure.

General notes:
- Pay particular attention not to miss any of the main body text when inserting tables and figures.
- This document could be the continuation of a larger document (especially if it starts at page greater than 1), so be to include any partial sentences or paragraphs on the first page you are given. Also create headings by default for the first page unless it is clear it is really a heading.
- Return only the markdown and nothing else.
- It is crucial that the transcription is faithful to the image in terms of layout and content. 
- Leave nothing out and do not add any words that are not in the image.
"""


    def __init__(self):
        logger.debug("Initializing Transcription")

    async def transcribe_document(
            self, 
            filename: str, 
            file_content: bytes,
            model_name: str = "gpt-4o-2024-11-20",
            max_tokens: int = 8000,
            temperature: float = 0.05,
            batch_size: int = 5,
            observability_info: dict = None
            ) -> str:
        """
        Transcribe a document file to markdown.

        Args:
            filename (str): Name of the file.
            file_content (bytes): Content of the file.
            model_name (str, optional): Name of the LLM model to use. Default is "gpt-4o-2024-11-20".
            max_tokens (int, optional): Maximum number of tokens to generate. Default is 8000.
            temperature (float, optional): Temperature for the LLM. Default is 0.05.
            batch_size (int, optional): Number of images to transcribe at a time. Default is 5.
            observability_info (dict, optional): Observability info for logging. Default is None.

        Returns:
            str: Transcribed markdown content from the document.

        Raises:
            ValueError: If the file type is not supported.
        """
        if isinstance(file_content, str):
            raise ValueError("file_content is a string, not bytes")
        
        # Check file type
        content_type, _ = mimetypes.guess_type(filename)
        if content_type not in self.ALLOWED_MIMETYPES:
            logger.error(f"File '{filename}' is not a valid file type for transcription: {content_type}")
            raise ValueError(f"Unsupported file type for transcription: {filename}")

        # For text files, simply return the decoded content
        if content_type in self.TEXT_MIMETYPES:
            logger.debug(f"File is plain text: {filename}")
            if type(file_content) == bytes:
                return file_content.decode('utf-8')
            else:
                logger.info(f"file content is already a string: {filename}")
                return file_content
        
        elif content_type in self.AUDIO_MIMETYPES:
            logger.debug(f"File is audio: {filename}")
            transcription = await self.transcribe_audio(filename, file_content)
            return transcription
            
        elif content_type in self.IMAGE_MIMETYPES:
            logger.debug(f"File is already an image: {filename}")
            images = [Image.open(BytesIO(file_content))]
            
        elif content_type in self.DOCUMENT_MIMETYPES:
            images = await self.doc_to_images(filename, file_content)

        else:
            raise ValueError(f"Unsupported file type for transcription: {filename}")
        

        markdown = await self.images_to_markdown(
            images, 
            batch_size = batch_size,
            model_name = model_name,
            max_tokens = max_tokens,
            temperature = temperature,
            max_concurrent_requests=3,
            observability_info=observability_info
        )
        return markdown
        
    

    async def doc_to_images(self, filename: str, file_content: bytes) -> List[Image.Image]:
        """
        Convert a document file to a list of images. Document can be a pdf, MS Office doc, or image.

        Args:
            filename (str): Name of the file.
            file_content (bytes): Content of the file.

        Returns:
            List[Image.Image]: List of PIL Image objects.
        """
        # Check file type
        content_type, _ = mimetypes.guess_type(filename)
        
        
        if content_type in self.IMAGE_MIMETYPES:
            logger.debug(f"'{filename}' is already an image so no conversion needed")
            return [Image.open(BytesIO(file_content))]
        
        if content_type not in self.DOCUMENT_MIMETYPES + self.TEXT_MIMETYPES:
            raise ValueError(f"Unsupported file type for image conversion: {filename}")
        
        logger.info(f"Converting file: '{filename}' to images")

        # Create temporary directory for conversion
        conversion_dir = tempfile.mkdtemp()
        logger.debug(f"Created temporary directory for conversion: {conversion_dir}")

        try:
            # Save file content
            temp_file_path = os.path.join(conversion_dir, filename)
            with open(temp_file_path, "wb") as f:
                f.write(file_content)

            # Convert to PDF if needed
            if content_type != 'application/pdf':
                pdf_path = os.path.join(conversion_dir, f"{os.path.splitext(filename)[0]}.pdf")
                self._office_file_to_pdf(temp_file_path, conversion_dir)
            else:
                pdf_path = temp_file_path

            # Convert PDF to images
            images = self._pdf_to_images(pdf_path)
            return images

        finally:
            if os.path.exists(conversion_dir):
                self._cleanup_temp_dir(conversion_dir)
                logger.debug(f"Cleaned up temporary directory: {conversion_dir}")


    def _office_file_to_pdf(self, input_file_path: str, output_dir: str):
        """Convert Office document to PDF using LibreOffice.

        Args:
            input_file_path (str): Path to the input Office document.
            output_dir (str): Directory where the output PDF will be saved.
        """
        subprocess.run(
            [
                'libreoffice',
                '--headless',
                '--convert-to', 'pdf',
                '--outdir', output_dir,
                input_file_path
            ], 
            check=True, # raise an exception if the command fails
            stderr=subprocess.DEVNULL # suppress error messages
        )

    def _pdf_to_images(self, pdf_path: str, dpi: int = 300) -> List[Image.Image]:
        """Convert PDF to list of PIL Image objects.

        Args:
            pdf_path (str): Path to the PDF file.
            dpi (int, optional): Dots per inch for image conversion. Default is 300.

        Returns:
            List[Image.Image]: List of PIL Image objects converted from the PDF.
        """
        return convert_from_path(pdf_path, dpi=dpi)

    def _cleanup_temp_dir(self, directory: str):
        """Clean up temporary directory.

        Args:
            directory (str): Path to the temporary directory to be cleaned up.
        """
        if os.path.exists(directory):
            import shutil
            shutil.rmtree(directory, ignore_errors=True)

    async def images_to_markdown(
            self, 
            images: List[Image.Image], 
            batch_size: int = 5,
            model_name: str = "gpt-4o-2024-11-20",
            max_tokens: int = 8000,
            temperature: float = 0.05,
            max_concurrent_requests: int = 3,
            observability_info: dict = None
        ) -> str:
        """Convert a list of images to markdown using AI transcription.

        Args:
            images (List[Image.Image]): List of PIL Image objects to be transcribed.
            batch_size (int, optional): Number of images to transcribe at a time. Default is 5.
            model_name (str, optional): Name of the LLM model to use. Default is "gpt-4o-2024-11-20".
            max_tokens (int, optional): Maximum number of tokens to generate. Default is 8000.
            temperature (float, optional): Temperature for the LLM. Default is 0.05.
            max_concurrent_requests (int, optional): Maximum number of concurrent requests. Default is 3.
            observability_info (dict, optional): Observability info for logging. Default is None.

        Returns:
            str: Transcribed markdown content from the images.
        """
        if len(images) == 0:
            logger.warning("No images to transcribe")
            return ""
        
        if batch_size > 5:
            logger.warning(f"Batch size {batch_size} is greater than 5, possibly resulting in lower quality transcription")
        
        config = {
            "max_tokens": max_tokens, 
            "temperature": temperature
        }
        provider = get_llm_provider(model_name)
        
        total_images = len(images)
        if total_images <= batch_size:
            logger.info(f"Transcribing {total_images} images using {model_name}")
        else:
            logger.info(f"Transcribing {total_images} images in batches of {batch_size} (max {max_concurrent_requests} concurrent batches) using {model_name}")

        # Create semaphore to limit concurrent requests
        semaphore = asyncio.Semaphore(max_concurrent_requests)

        async def _process_batch_with_rate_limit(batch_idx, images_batch):
            async with semaphore:  # This ensures only max_concurrent_requests are running at once
                start_time = datetime.now()
                result = await self._images_to_markdown_batch(
                    provider=provider,
                    images=images_batch,
                    config=config,
                    observability_info=observability_info
                )
                end_time = datetime.now()
                time_elapsed = (end_time - start_time).total_seconds()
                logger.info(f"Completed batch {batch_idx + 1} of {(total_images + batch_size - 1) // batch_size} in {time_elapsed:.1f}s")
                return result

        # Create tasks for all batches
        tasks = [
            _process_batch_with_rate_limit(
                i // batch_size,
                images[i:i + batch_size]
            )
            for i in range(0, len(images), batch_size)
        ]
        
        markdown_parts = await asyncio.gather(*tasks)

        # Combine all markdown parts with newlines between them
        return "\n".join(markdown_parts)

    async def _images_to_markdown_batch(
            self, 
            provider: LLMProvider,
            images: List[Image.Image], 
            config: Dict[str, Any], 
            observability_info: dict = None
        ) -> str:
        """Convert a batch of images to markdown using AI transcription.

        Args:
            images (List[Image.Image]): List of PIL Image objects to be transcribed.
            batch_size (int): Maximum number of images allowed in the batch.

        Returns:
            str: Transcribed markdown content from the images.

        Raises:
            ValueError: If the number of images exceeds the batch_size.
        """
        logger.debug(f"Transcribing batch of {len(images)} images to markdown")

        response = await provider.get_response(
            [self.TRANSCRIPTION_PROMPT] + images, 
            config = config,
            observability_info=observability_info
        )
        # tidy up the response
        response = response.replace("```markdown", "").replace("```", "")
        response = self._straighten_quotes(response)
        response = self._clean_text(response)

        return response



    def _limit_char_occurrences(
        self, 
        input_string: str, 
        chars: List[str] = [" ", ".", "-", "_", "/n"], 
        max_occurrences: int = 3
    ) -> str:
        """Limit repeated instances of common formatting characters.

        Args:
            input_string (str): The input string to process.
            chars (List[str], optional): List of characters to limit. Default is [" ", ".", "-", "_", "/n"].
            max_occurrences (int, optional): Maximum allowed occurrences of each character. Default is 3.

        Returns:
            str: The processed string with limited character occurrences.
        """
        result = input_string
        for char in chars:
            pattern = char * (max_occurrences + 1)
            replacement = char * max_occurrences
            while pattern in result:
                result = result.replace(pattern, replacement)
        return result

    

    def _straighten_quotes(self, text: str) -> str:
        """Replace curved quotation marks with straight ones.

        Args:
            text (str): The text to process.

        Returns:
            str: The processed text with straight quotation marks.
        """
        replacements = {
            '\u2018': "'", '\u2019': "'",
            '\u201C': '"', '\u201D': '"',
            '\u00a0': ' ',
            '\u2013': '-'
        }
        for curved, straight in replacements.items():
            text = text.replace(curved, straight)
        return text
    
    def _clean_text(self, text: str) -> str:
        """Clean text by removing non-ASCII characters.
        
        Args:
            text (str): The text to clean.

        Returns:
            str: The cleaned text containing only ASCII characters.
        """
        return text.encode('ascii', 'ignore').decode('ascii')
    

    async def transcribe_audio(self,filename: str, 
                               audio_bytes: bytes, 
                           transcription_model: str = "whisper-1", 
                           response_format: str = "text") -> str:
        """
        Transcribe an audio file from a base64 encoded string using OpenAI.
        
        Args:
            filename (str): Original filename of the audio (used for extension checking).
            audio_bytes (bytes): Base64 encoded audio string.
            transcription_model (str, optional): The model to use for transcription. Defaults to "whisper-1".
            response_format (str, optional): The format of the response. Defaults to "text".

        Returns:
            str: Transcribed text from the audio file.

        Raises:
            ValueError: If the file type is not in ALLOWED_AUDIO_EXTENSIONS.
        """
        from openai import AsyncOpenAI
        import base64

        client = AsyncOpenAI()

        transcription = await client.audio.transcriptions.create(
            model=transcription_model,
            file=(filename, audio_bytes),
            response_format=response_format
        )
        return transcription
```
## File: retrieval/test_transcription.py
```python
from tools import Transcription
import asyncio
from datetime import datetime
import os
from PIL import Image

transcription = Transcription()

async def save_images(images, output_dir, file_base_name):
    for i, image in enumerate(images, start=1):
        image_path = f"{output_dir}/{file_base_name}_page_{i}.png"
        image.save(image_path)

async def main():

    # path = "tests/data/transcribe/gpt-4-technical-report_1-10.pdf"
    # path = "tests/data/transcribe/Apple-Developer-Program-License-Agreement.pdf"
    path = "tests/data/transcribe/Sample-Powerpoint-Document.pptx"
    output_dir = "_local_files/transcribe"
    

    file_name = path.split("/")[-1]
    file_base_name = file_name.split(".")[0]
    image_folder = f"{output_dir}/images/{file_base_name}"

    print(f"images_folder: {image_folder}, exists = {os.path.exists(image_folder)}")

    if not os.path.exists(image_folder):
        print(f"\n--------Generating screenshots from {file_name}--------\n")
        os.makedirs(image_folder, exist_ok=True)
        with open(path, "rb") as file:
            file_content = file.read()
        images = await transcription.doc_to_images(path.split("/")[-1], file_content)
        await save_images(images, image_folder, file_base_name)
    else:
        print(f"\n--------loading saved screenshots for {file_name}--------\n")
        image_files = os.listdir(image_folder)
        image_files.sort(key=lambda x: int(x.split("_")[-1].split(".")[0]))
        images = [Image.open(f"{image_folder}/{image_file}") for image_file in image_files]
    
    
    # images = images[:15]

    print(f"\n--------Transcribing {file_name}--------\n")

    for batch_size in [5]:

        start_time = datetime.now()
        markdown = await transcription.images_to_markdown(
            images,
            batch_size=batch_size,
            model_name="gpt-4o-2024-11-20",
            max_tokens=batch_size * 1000,
            temperature=0.05,
            max_concurrent_requests=5,
        )
        end_time = datetime.now()
        time_elapsed = (end_time - start_time).total_seconds()
        print(f"\n{'*' * 50}")
        print(f"Batch size: {batch_size}\ntotal time: {time_elapsed:.1f}s\ntime per image: {time_elapsed / len(images):.1f}s")

        output_path = f"{output_dir}/{file_base_name}_batch_{batch_size}.md"
        with open(output_path, "w") as file:
            file.write(markdown)
        
        print(f"Transcription saved to {output_path}")
        print(f"{'*' * 50}\n")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: retrieval/__init__.py
```python
from retrieval.hybrid_retriever import HybridRetriever
from retrieval.ingestion import Ingestion

__all__ = [
    HybridRetriever,
    Ingestion
]
```
## File: retrieval/test_hybrid_retriever.py
```python
import asyncio
import logging
from retrieval.hybrid_retriever import HybridRetriever
from dotenv import load_dotenv
import os
import certifi
from database.authenticated_postgres_client import AuthenticatedPostgresClient

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

os.environ["SSL_CERT_FILE"] = certifi.where()
logger.info(f"SSL certificate file set to: {os.environ['SSL_CERT_FILE']}")


load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"
os.environ["POSTGRES_PORT"] = "5432"

user_email = "helpdesk_agent"
user_id = "88a28dd0-3294-4780-b9c7-874cd4e4654d"
user_group_id = "84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b"

async def add_single_group(retriever, index: int, semaphore: asyncio.Semaphore):
    """Add a document group using atomic operation"""
    async with semaphore:
        try:
            logger.info(f"Starting document group #{index}")
            
            dummy_text = f"""
            This is test document #{index}.
            It contains some sample text to test concurrent document addition.
            We'll see how the system handles multiple simultaneous requests.
            Each document is numbered to track which one is being processed.
            """
            
            result = await retriever.add_parent_document(
                summary=f"Test document group #{index}",
                group_id=user_group_id,
                created_by=user_id,
                source=None,
                metadata={"type": "test", "document_number": index}
            )

            result = await retriever.add_documents(
                documents=[dummy_text], 
                parent_document_id=result[0]["id"], 
                group_id=user_group_id, 
                metadata=None
            )
            logger.info(f"Successfully added document group #{index}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to add document group #{index}: {e}")
            return False

async def test_concurrent_document_ingestion(n_docs=25, max_concurrent=5):
    """Test ingesting multiple document groups concurrently"""
    
    # Create retriever with configured pool using only the user email
    async with await HybridRetriever.create(user_email) as retriever:
        try:
            # Create a semaphore to limit concurrency
            semaphore = asyncio.Semaphore(max_concurrent)
            
            # Create all tasks at once
            tasks = [add_single_group(retriever, i+1, semaphore)for i in range(n_docs)]
            
            # Execute all tasks concurrently with the semaphore controlling concurrency
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Log final results
            successes = sum(1 for r in results if r is True)
            failures = sum(1 for r in results if isinstance(r, Exception))
            logger.info(f"Final Results: Successful: {successes}/{n_docs}, Failed: {failures}/{n_docs}")
            
        except Exception as e:
            logger.error(f"Error during test: {e}")
            raise

async def test_retrieval():
    username = "helpdesk_agent"
    async with await HybridRetriever.create(username) as retriever:
        query = "Remove from Slack Channel?"
        print(f"query: {query}")
        results = await retriever.retrieve_documents(query=query, match_count=10, search_type="hybrid")
        print("\n\t"+"\n\t".join([f'{r["parent_document_id"]}: {r["id"]}' for r in results]))

        
        parent_document_id = results[0]["parent_document_id"]
        combined_document = await retriever.retrieve_full_child_document(parent_document_id)
        print(f"\nfirst full document:\n{combined_document}")

async def test_db_client_passing():
    """Test that a database client can be passed to the HybridRetriever"""
    
    # First create a database client
    username = "helpdesk_agent"
    db_client = await AuthenticatedPostgresClient.create(username=username)
    logger.info("Created database client")
    
    try:
        # Create retriever with the database client
        async with await HybridRetriever.create(username, db_client=db_client) as retriever:
            logger.info("Created retriever with provided database client")
            
            # Run a simple query to verify it works
            query = "can't login"
            results = await retriever.retrieve_documents(query=query, match_count=2, search_type="hybrid")
            logger.info(f"Retrieved {len(results)} results using provided database client")
            
            # Check that the retriever is using our database client
            assert retriever._db_client is db_client, "Retriever is not using the provided database client"
            logger.info("Retriever is correctly using the provided database client")
            
            # # Make a small addition to verify writing works too
            # dummy_text = "This is a test document for database client passing."
            # parent_result = await retriever.add_parent_document(
            #     id=12345
            #     summary="Test database client passing",
            #     group_id=user_group_id,
            #     created_by=user_id,
            #     source=None,
            #     metadata={"type": "test_db_client"}
            # )
            # parent_id = parent_result[0]["id"]
            # logger.info(f"Successfully added parent document with ID: {parent_id}")
            
            # document_result = await retriever.add_documents(
            #     documents=[dummy_text], 
            #     parent_document_id=parent_id, 
            #     group_id=user_group_id
            # )
            # logger.info(f"Successfully added child document")
            
            return True
    except Exception as e:
        logger.error(f"Error testing database client passing: {e}")
        logger.exception("Full traceback:")
        return False
    finally:
        # We need to close the client manually since we created it
        await db_client.close()
        logger.info("Closed database client")

async def main():
    logger.info("Starting tests")
    
    # Test database client passing
    db_client_result = await test_db_client_passing()
    logger.info(f"Database client passing test {'succeeded' if db_client_result else 'failed'}")
    
    # # Test concurrent document ingestion with a smaller number for quick testing
    # n_docs = 3  
    # max_concurrent = 2
    # logger.info(f"Testing concurrent document ingestion with {n_docs} documents and {max_concurrent} concurrent tasks")
    # await test_concurrent_document_ingestion(n_docs=n_docs, max_concurrent=max_concurrent)
    
    # # Test retrieval
    # logger.info("Testing retrieval")
    # await test_retrieval()
    
    logger.info("All tests completed")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: retrieval/test_ingestion.py
```python
import asyncio
import logging
from retrieval.ingestion import Ingestion
from dotenv import load_dotenv
import os
from database.authenticated_postgres_client import AuthenticatedPostgresClient

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"
os.environ["POSTGRES_PORT"] = "5432"

# Test data
text = "This little piggy went to the market, this little piggy stayed home, this little piggy had roast beef, this little piggy had none, and this little piggy cried, wee wee wee, all the way home."
group_id = "84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b"  # users group
user_id = "88a28dd0-3294-4780-b9c7-874cd4e4654d"
username = "helpdesk_agent"

async def test_shared_db_client():
    """Test ingestion with a shared database client"""
    logger.info("Testing ingestion with shared database client")
    
    # First create a database client
    db_client = await AuthenticatedPostgresClient.create(username=username)
    logger.info("Created shared database client")
    
    try:
        # Pass the client to the ingestion class
        async with await Ingestion.create(username=username, db_client=db_client) as ingestion:
            logger.info("Created ingestion with provided database client")
            
            # Check that the ingestion is using our database client
            assert ingestion._db_client is db_client, "Ingestion is not using the provided database client"
            logger.info("Ingestion is correctly using the provided database client")
            
            # Perform a test ingestion
            result = await ingestion.ingest_markdown(
                text="This is a test for shared database client in ingestion.",
                id = 12345,
                group_id=group_id,
                user_id=user_id,
                chunk_size=1500,
                metadata={"test": True, "method": "shared_db_client"}
            )
            logger.info(f"Ingestion with shared client result: {result}")
            
            return result.get("success", False)
    except Exception as e:
        logger.error(f"Error testing shared database client: {e}")
        logger.exception("Full traceback:")
        return False
    finally:
        # We need to close the client manually since we created it
        await db_client.close()
        logger.info("Closed shared database client")


# Example usage
async def main():
    logger.info("Starting ingestion tests")
    
    # # Test with shared database client
    # shared_db_result = await test_shared_db_client()
    # logger.info(f"Shared database client test {'succeeded' if shared_db_result else 'failed'}")
    
    # Regular usage with context manager (creates its own client)
    logger.info("Testing ingestion with context manager")
    async with await Ingestion.create(username=username) as ingestion:
        result = await ingestion.ingest_markdown(
            text=text,
            id=12345,
            group_id=group_id,
            user_id=user_id,
            chunk_size=2000,
            metadata={"test": True, "method": "context_manager"}
        )
        logger.info(f"Ingestion with context manager result: {result}")

    # Alternative approach using create() and close() explicitly
    logger.info("Testing ingestion with explicit create/close")
    ingestion = await Ingestion.create(username=username)
    try:
        result = await ingestion.ingest_markdown(
            text="The quick brown fox jumps over the lazy dog.",
            group_id=group_id,
            id=12346,
            user_id=user_id,
            chunk_size=1500,
            metadata={"test": True, "method": "explicit_create"}
        )
        logger.info(f"Ingestion with explicit create result: {result}")
    finally:
        await ingestion.close()
        
    logger.info("All ingestion tests completed")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: retrieval/hybrid_retriever.py
```python
"""
Asynchronous hybrid retrieval module that combines full-text and semantic search capabilities.
Provides functionality for document retrieval, embedding generation, and context expansion
using both PostgreSQL and Azure OpenAI services.
"""

import os
import logging
import json
from dotenv import load_dotenv
from datetime import datetime
from uuid import uuid4
from openai import AsyncOpenAI
from typing import List, Dict, Any, Optional, Tuple, Union
from database import AuthenticatedPostgresClient
import asyncio

load_dotenv()

EMBEDDING_MODEL = "text-embedding-3-small"

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logging.getLogger("httpx").setLevel(logging.WARNING)

class HybridRetriever:
    """
    An asynchronous class that combines full-text and semantic search for document retrieval.
    It can either use a provided database client or instantiate its own authenticated database client,
    managing its lifecycle using an asynchronous context manager.
    
    Attributes:
        username (str): Email of the authenticated user.
        _db_client: Authenticated PostgreSQL client.
        _db_client_provided (bool): Whether the database client was provided externally.
        table_name (str): Name of the documents table.
        parent_documents_table_name (str): Name of the parent documents table.
        openai_client (AsyncOpenAI): Client for OpenAI operations.
    """

    def __init__(self, username: str, db_client=None):
        """
        Initialize the HybridRetriever.
        
        Args:
            username (str): Email of the authenticated user.
            db_client: Optional database client. If provided, this will be used instead of creating a new one.
        """
        self.username = username
        self._db_client = db_client
        self._db_client_provided = db_client is not None
        self.table_name = "documents"
        self.parent_documents_table_name = "parent_documents"
        self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY")) 
        
    @classmethod
    async def create(cls, username: str, db_client=None):
        """
        Create a new instance with a configured database client.
        
        Args:
            username (str): Email of the authenticated user.
            db_client: Optional database client. If provided, this will be used instead of creating a new one.
        
        Returns:
            HybridRetriever: A new instance with an initialized database client.
        """
        self = cls(username, db_client)
        
        # Only create a new client if one wasn't provided
        if not self._db_client_provided:
            self._db_client = await AuthenticatedPostgresClient.create(username=username)
            if not self._db_client:
                raise Exception(f"Failed to create database client for user: {username}")
        return self

    async def close(self):
        """Close the database connection if we created it."""
        if self._db_client and not self._db_client_provided:
            await self._db_client.close()
            self._db_client = None

    async def __aenter__(self):
        if not self._db_client and not self._db_client_provided:
            self._db_client = await AuthenticatedPostgresClient.create(username=self.username)
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()

    @property
    def database_client(self):
        """
        Get the database client, raising an exception if it's not initialized.
        """
        if not self._db_client:
            raise Exception("Database client not initialized. Use 'async with' or 'create()'.")
        return self._db_client

    async def retrieve_documents(
        self, 
        query: str, 
        match_count: int = 10,
        full_text_weight: float = 1.0,
        semantic_weight: float = 1.0,
        rrf_k: int = 50,
        search_type: str = "hybrid",
        search_filters: dict = None,
        max_terms: int = 50,
        expand_context: bool = False
    ):
        """
        Retrieve documents using the specified search method.
        
        Args:
            query (str): Search query text.
            match_count (int): Number of documents to retrieve. Defaults to 10.
            full_text_weight (float): Weight for full-text search component (only used for hybrid search). Defaults to 1.0.
            semantic_weight (float): Weight for semantic search component (only used for hybrid search). Defaults to 1.0.
            rrf_k (int): Constant for Reciprocal Rank Fusion (only used for hybrid search). Defaults to 50.
            search_type (str): Which search method to use: "hybrid", "semantic", or "fts". Defaults to "hybrid".
            search_filters (dict): Filters to apply to search results. Defaults to None.
            max_terms (int): Maximum number of terms for full-text search. Defaults to 50.
            expand_context (bool): Whether to expand document context. Defaults to False.
            
        Returns:
            list: Retrieved documents matching the query criteria.
        """
        logger.debug(f"Retrieving {match_count} documents for query: {query[:100]}")

        try:
            if search_type == "hybrid":
                return await self.retrieve_documents_hybrid(
                    query=query,
                    match_count=match_count,
                    full_text_weight=full_text_weight,
                    semantic_weight=semantic_weight,
                    rrf_k=rrf_k,
                    search_filters=search_filters,
                    max_terms=max_terms,
                    expand_context=expand_context
                )
            elif search_type == "semantic":
                return await self.retrieve_documents_semantic(
                    query=query,
                    match_count=match_count,
                    search_filters=search_filters,
                    expand_context=expand_context
                )
            elif search_type == "fts":
                return await self.retrieve_documents_fts(
                    query=query,
                    match_count=match_count,
                    search_filters=search_filters,
                    max_terms=max_terms,
                    expand_context=expand_context
                )
            else:
                raise ValueError(f"Unknown search type: {search_type}")
        except Exception as e:
            logger.error(f"Error retrieving documents for query '{query[:50]}...': {str(e)}")
            logger.error("Full traceback:", exc_info=True)
            # Return empty results on error to avoid breaking application flow
            return []

    async def retrieve_documents_semantic(
        self, 
        query: str, 
        match_count: int = 10,
        similarity_threshold: float = 0.0,
        search_filters: dict = None,
        expand_context: bool = False
    ):
        """
        Retrieve documents using semantic search only.
        
        Args:
            query (str): Search query text.
            match_count (int): Number of documents to retrieve.
            similarity_threshold (float): Minimum similarity threshold.
            search_filters (dict): Filters to apply to search results.
            expand_context (bool): Whether to expand document context.
            
        Returns:
            list: Retrieved documents matching the query criteria.
        """
        logger.debug(f"Retrieving {match_count} documents using semantic search for query: {query[:300]}...")
        
        query_embedding = await self.create_embeddings([query])
        
        # Format base RPC parameters
        rpc_params = {
            "p_query_embedding": query_embedding[0],
            "p_match_count": int(match_count),
            "p_similarity_threshold": float(similarity_threshold)
        }
        
        # Merge with formatted search filters
        rpc_params.update(self._format_search_filters(search_filters))

        # Use the async RPC interface
        response = await self.database_client.rpc("document_semantic_search", params=rpc_params).execute()
        
        if response is None:
            logger.error(f"Error in semantic search: {response}")
            raise Exception(f"Error in semantic search: {response}")
        
        logger.debug(f"Retrieved {len(response)} documents via semantic search")
        if expand_context:
            response = await self.get_expanded_context(response)
        return response

    def _format_search_filters(self, search_filters: dict):
        """Format search filters for the semantic search RPC."""
        rpc_params = {}
        search_filters = search_filters or {}
        if "created_before" in search_filters:
            search_filters["created_before"] = datetime.fromisoformat(search_filters["created_before"].replace('Z', '+00:00'))
        if "created_after" in search_filters:
            search_filters["created_after"] = datetime.fromisoformat(search_filters["created_after"].replace('Z', '+00:00'))
        
        if search_filters.get("group_ids") is not None:
            rpc_params["p_group_ids"] = search_filters.get("group_ids")
        if search_filters.get("created_before") is not None:
            rpc_params["p_created_before"] = search_filters.get("created_before")
        if search_filters.get("created_after") is not None:
            rpc_params["p_created_after"] = search_filters.get("created_after")
        if search_filters.get("parent_metadata") is not None:
            rpc_params["p_parent_metadata"] = search_filters.get("parent_metadata")
        if search_filters.get("required_parent_metadata_keys") is not None:
            rpc_params["p_non_null_parent_metadata_keys"] = search_filters.get("required_parent_metadata_keys")
        if search_filters.get("min_parent_id") is not None:
            rpc_params["p_min_parent_id"] = search_filters.get("min_parent_id")
        if search_filters.get("max_parent_id") is not None:
            rpc_params["p_max_parent_id"] = search_filters.get("max_parent_id")
 
        return rpc_params

    def _sanitize_fts_query(self, query: str) -> str:
        """
        Sanitize a query string for PostgreSQL full-text search.
        
        Args:
            query (str): The raw search query
            
        Returns:
            str: A sanitized query suitable for PostgreSQL's tsquery
        """
        if not query:
            return ""
            
        try:
            # Replace special characters that cause syntax errors
            sanitized = query
            
            # Replace characters that have special meaning in tsquery
            special_chars = [':', '&', '|', '!', '(', ')', '*', '<', '>', '-', '@', '"', '~', '\'']
            for char in special_chars:
                sanitized = sanitized.replace(char, ' ')
                
            # Replace multiple spaces with a single space
            sanitized = ' '.join(sanitized.split())
            
            # Convert to a simple phrase search by joining with &
            if sanitized:
                words = sanitized.split()
                # Only use words that are at least 2 characters long
                words = [word for word in words if len(word) >= 2]
                if not words:
                    return ""
                    
                # Join words with the & operator
                sanitized = ' & '.join(words)
                
            logger.debug(f"Sanitized FTS query from '{query}' to '{sanitized}'")
            return sanitized
            
        except Exception as e:
            logger.warning(f"Error sanitizing FTS query '{query}': {str(e)}")
            # Return a safe fallback if sanitization fails
            return ""

    async def retrieve_documents_fts(
        self,
        query: str,
        match_count: int = 20,
        similarity_threshold: float = 0.0,
        search_filters: dict = None,
        max_terms: int = 50,
        expand_context: bool = False
    ):
        """
        Retrieve documents using full-text search.
        
        Args:
            query (str): Search query text.
            match_count (int): Number of documents to retrieve.
            similarity_threshold (float): Minimum similarity threshold.
            search_filters (dict): Filters to apply to search results.
            max_terms (int): Maximum number of terms for full-text search.
            expand_context (bool): Whether to expand document context.
            
        Returns:
            list: Retrieved documents matching the query criteria.
        """
        original_query = query
        try:
            logger.debug(f"Performing FTS on query: {query[:300]}...")
            
            # Sanitize the query to prevent PostgreSQL syntax errors
            query = self._sanitize_fts_query(query)
            
            # Log both original and sanitized queries for debugging
            logger.debug(f"FTS query transformation: '{original_query[:100]}' -> '{query[:100]}'")
            
            if not query:
                logger.warning("FTS query was empty after sanitization, returning empty results")
                return []
            
            # Format base RPC parameters - passing max_terms to the SQL function
            rpc_params = {
                "p_query_text": query,
                "p_match_count": int(match_count),
                "p_max_terms": int(max_terms),  # SQL function will handle term limiting
                "p_similarity_threshold": float(similarity_threshold),
            }
            
            # Merge with formatted search filters
            rpc_params.update(self._format_search_filters(search_filters))
            
            # Use the async RPC interface
            response = await self.database_client.rpc("document_fts_search", params=rpc_params).execute()
            
            if response is None:
                logger.error(f"Error in FTS search: response was None")
                raise Exception(f"Error in FTS search: response was None")
            
            logger.debug(f"Retrieved {len(response)} documents via FTS")
            if expand_context:
                response = await self.get_expanded_context(response)
            return response
            
        except Exception as e:
            logger.error(f"Error in FTS search for query '{query}': {str(e)}")
            # Return empty list instead of raising exception to make the search more robust
            return []

    async def retrieve_documents_hybrid(
        self,
        query: str,
        match_count: int = 10,
        full_text_weight: float = 1.0,
        semantic_weight: float = 1.0,
        rrf_k: int = 50,
        search_filters: dict = None,
        max_terms: int = 50,
        expand_context: bool = False,
        debug: bool = False
    ):
        """
        Retrieve documents using both semantic and full-text search with client-side RRF.
        
        Args:
            query (str): Search query text.
            match_count (int): Number of documents to retrieve.
            full_text_weight (float): Weight for full-text search component.
            semantic_weight (float): Weight for semantic search component.
            rrf_k (int): Constant for Reciprocal Rank Fusion.
            search_filters (dict): Filters to apply to search results.
            max_terms (int): Maximum number of terms for full-text search.
            expand_context (bool): Whether to expand document context.
            debug (bool): Whether to print debug data.
            
        Returns:
            list: Retrieved documents matching the query criteria.
        """
        logger.debug(f"Retrieving {match_count} documents using hybrid search for query: {query[:300]}...")
        
        # Run both searches in parallel
        fts_results, semantic_results = await asyncio.gather(
            self.retrieve_documents_fts(
                query=query,
                match_count=match_count * 2,
                search_filters=search_filters,
                max_terms=max_terms,
                expand_context=False
            ),
            self.retrieve_documents_semantic(
                query=query,
                match_count=match_count * 2,
                search_filters=search_filters,
                expand_context=False
            )
        )

        try:
            # Handle potential exceptions in either search result
            if isinstance(fts_results, Exception):
                logger.error(f"FTS search failed: {str(fts_results)}")
                fts_results = []
                
            if isinstance(semantic_results, Exception):
                logger.error(f"Semantic search failed: {str(semantic_results)}")
                semantic_results = []
                
            # If both searches failed, return empty list
            if not fts_results and not semantic_results:
                logger.error("Both FTS and semantic search failed, returning empty results")
                return []
        
            if debug:
                self._debug_print_results("fts", fts_results, n=match_count)
                self._debug_print_results("semantic", semantic_results, n=match_count)

            # Determine which result sets to use for RRF
            result_sets = []
            if fts_results:
                result_sets.append((fts_results, full_text_weight))
            if semantic_results:
                result_sets.append((semantic_results, semantic_weight))
                
            # If we only have one type of results, just return those (up to match_count)
            if len(result_sets) == 1:
                results = result_sets[0][0][:match_count]
            else:
                # Apply RRF to combine results
                results = self.apply_reciprocal_rank_fusion(
                    result_sets=result_sets,
                    rrf_k=rrf_k,
                    max_results=match_count
                )
                
            logger.debug(f"Retrieved {len(results)} documents via hybrid search")
            
            if expand_context:
                results = await self.get_expanded_context(results)
            return results
            
        except Exception as e:
            logger.error(f"Error in hybrid search: {str(e)}")
            logger.exception("Full traceback:")
            return []

    def _debug_print_results(self, search_type: str, results: List[Dict], n: int = 10):
        debug_data = []
        for idx, doc in enumerate(results):
            debug_doc = {
                "rank": idx + 1,
                "id": doc["id"],
                "content": doc["content"][:100].replace("\n", " ")
            }
            if "similarity" in debug_doc:
                del debug_doc["similarity"]
            debug_data.append(debug_doc)

        print(f"\n{search_type.upper()} search results:")
        print(f"{'rank':<4} | {'id':<8} | {'content':<60} ")
        print("-" * 80)
        for doc in debug_data[:n]:
            print(f"{doc['rank']:<4} | {doc['id'][:8]:<8} | {doc['content']:<60}")

    def apply_reciprocal_rank_fusion(
        self,
        result_sets: List[Tuple[List, float]],
        rrf_k: int = 50,
        max_results: int = 10
    ):
        """
        Apply Reciprocal Rank Fusion to combine multiple result sets.
        
        Args:
            result_sets (list of tuple): Each tuple contains (results, weight), where results is a list of documents.
            rrf_k (int): Constant for RRF calculation.
            max_results (int): Maximum number of results to return.
            
        Returns:
            list: Combined and re-ranked results.
        """
        logger.debug(f"Applying RRF to {len(result_sets)} result sets")
        
        # Create a dictionary to store all unique documents
        all_docs = {}
        
        # Create dictionaries to store rankings for each result set
        rankings = []
        for results, weight in result_sets:
            rank_dict = {doc['id']: idx + 1 for idx, doc in enumerate(results)}
            rankings.append((rank_dict, weight, len(results)))
            
            # Add documents to all_docs dictionary
            for doc in results:
                if doc['id'] not in all_docs:
                    all_docs[doc['id']] = doc
        
        # Calculate RRF scores for each document
        doc_scores = []
        for doc_id, doc in all_docs.items():
            rrf_score = 0
            
            # Calculate contribution from each result set
            for rank_dict, weight, result_count in rankings:
                # Get rank, default to worst rank + 1 if not in this result set
                rank = rank_dict.get(doc_id, result_count + 1)
                # Apply RRF formula with weight
                rrf_score += weight * (1.0 / (rrf_k + rank))
            doc_scores.append((doc, rrf_score))
        
        # Sort by RRF score (descending) and take top results
        doc_scores.sort(key=lambda x: x[1], reverse=True)
        results = [doc for doc, _ in doc_scores[:max_results]]
        logger.debug(f"RRF returned {len(results)} results")
        return results

    async def retrieve_parent_documents(self, documents: List[Dict], columns: Union[List[str], str] = "*"):
        """
        Retrieve parent documents for a list of child documents.
        
        Args:
            documents (list): List of child documents containing parent_document_id.
            columns (list or str): Columns to retrieve from parent documents.
            
        Returns:
            list: Retrieved parent documents.
        """
        parent_document_ids = list(set(item['parent_document_id'] for item in documents if item.get('parent_document_id')))
        logger.info(f"Retrieving {len(parent_document_ids)} parent documents")
        if not parent_document_ids:
            logger.info("No parent document IDs found. Skipping retrieve_parent_documents.")
            return []
        if columns != "*":
            if "id" not in columns:
                columns.append("id")
            columns = ", ".join(columns)
        logger.debug(f"Retrieving columns = {columns}")
        response = await self.database_client.table(self.parent_documents_table_name) \
            .select(columns) \
            .in_("id", parent_document_ids) \
            .execute()
        if response is None:
            logger.error(f"Error in retrieving parent documents: {response}")
            raise Exception("Error retrieving parent documents")
        logger.debug(f"Retrieved {len(response)} parent documents")
        return response

    def merge_parent_documents(self, documents: List[Dict], parent_documents: List[Dict]) -> List[Dict]:
        """
        Merge child documents with their corresponding parent documents.
        
        Args:
            documents (list): List of child documents.
            parent_documents (list): List of parent documents.
            
        Returns:
            list: Merged documents containing both child and parent information.
        """
        logger.info(f"Merging {len(documents)} documents with {len(parent_documents)} parent documents")
        parent_doc_map = {pd['id']: pd for pd in parent_documents}
        grouped_docs = {}
        for doc in documents:
            parent_id = doc['parent_document_id']
            grouped_docs.setdefault(parent_id, []).append(doc['content'])
        merged_docs = []
        for parent_id, contents in grouped_docs.items():
            parent = parent_doc_map.get(parent_id)
            if parent:
                merged_doc = {
                    "parent_document_id": parent_id,
                    "source": parent.get('source'),
                    "summary": parent.get('summary'),
                    "content": contents
                }
                merged_docs.append(merged_doc)
        logger.debug(f"Merged {len(documents)} docs with {len(merged_docs)} parent docs")
        return merged_docs

    async def create_embeddings(self, texts: List[str]) -> List[float]:
        """
        Generate embeddings for a list of texts using OpenAI.
        
        Args:
            texts (list): List of texts to generate embeddings for.
            
        Returns:
            list: List of embedding vectors.
        """
        logger.debug(f"Creating embeddings for {len(texts)} texts")
        try:
            response = await self.openai_client.embeddings.create(
                input=texts,
                model=EMBEDDING_MODEL
            )

            logger.debug(f"Created {len(response.data)} embeddings")
            return [embedding.embedding for embedding in response.data]
        except Exception as e:
            logger.error(f"Error creating embeddings: {e}")
            return None

    async def get_expanded_context(self, documents: List[Dict]) -> List[Dict]:
        """
        Expand each document's context by retrieving and attaching parent document info.
        
        Args:
            documents (list): List of child documents containing parent_document_id.
            
        Returns:
            list: Same documents with added parent document information.
        """
        if not documents:
            return documents
            
        try:
            # Extract unique parent_document_ids
            parent_document_ids = list(set(item['parent_document_id'] for item in documents if item.get('parent_document_id')))
            logger.info(f"Retrieving {len(parent_document_ids)} parent documents")
            if not parent_document_ids:
                return documents
                
            # Convert all parent_document_ids to strings for consistent handling
            parent_document_ids = [str(pid) for pid in parent_document_ids]
                
            # Fetch all parent documents in one query
            # We're using raw query here because the query builder's `in_()` might have issues with mixed types
            parent_docs_query = f"""
            SELECT * FROM parent_documents 
            WHERE id IN ({','.join([f"'{pid}'" for pid in parent_document_ids])})
            """
            
            parent_docs = await self.database_client.raw_query(parent_docs_query)
            if not parent_docs:
                logger.warning(f"No parent documents found for ids: {parent_document_ids}")
                return documents
                
            # Create a lookup dict for fast access
            parent_docs_dict = {str(doc['id']): doc for doc in parent_docs}
            
            # Add parent document info to each document
            for doc in documents:
                if 'parent_document_id' in doc:
                    parent_id = str(doc['parent_document_id'])
                    if parent_id in parent_docs_dict:
                        parent_doc = parent_docs_dict[parent_id]
                        doc['parent_title'] = parent_doc.get('title', 'Untitled')
                        doc['parent_document_id'] = parent_id
                        doc['parent_metadata'] = parent_doc.get('metadata', {})
                    else:
                        logger.warning(f"Parent document {parent_id} not found")
                        
            return documents
        except Exception as e:
            logger.error(f"Error expanding context: {str(e)}")
            logger.exception("Full traceback:")
            # Return original documents on error
            return documents

    def link_documents(self, documents: List[Dict]) -> List[List[str]]:
        """
        Create chains of linked documents based on prev_id and next_id relationships.
        
        Args:
            documents (list): List of documents containing prev_id and next_id fields.
            
        Returns:
            list: List of document chains (each chain is a list of linked document IDs).
        """
        logger.debug(f"Linking {len(documents)} documents")
        prev_ids = [d["prev_id"] for d in documents]
        ids = [d["id"] for d in documents]
        next_ids = [d["next_id"] for d in documents]
        links = {}
        for prev, current, nxt in zip(prev_ids, ids, next_ids):
            links[current] = {"prev": prev, "next": nxt}
        def build_chain(start_id):
            chain = [start_id]
            current = start_id
            while True:
                if current not in links or links[current]["next"] is None:
                    break
                next_id = links[current]["next"]
                if next_id in chain:
                    break
                if next_id not in links:
                    chain.append(next_id)
                    break
                current = next_id
                chain.append(current)
            current = start_id
            while True:
                if current not in links or links[current]["prev"] is None:
                    break
                prev_id = links[current]["prev"]
                if prev_id in chain:
                    break
                if prev_id not in links:
                    chain.insert(0, prev_id)
                    break
                current = prev_id
                chain.insert(0, current)
            return chain
        linked_ids = []
        processed = set()
        for id in ids:
            if id not in processed:
                chain = build_chain(id)
                linked_ids.append(chain)
                processed.update(chain)
        return linked_ids

    async def check_parent_document_exists(self, id: str|int = None) -> bool:
        """
        Check if a parent document with the given id exists.
        
        Args:
            
            id (str|int, optional): ID of the document
            
        Returns:
            bool: True if a document with the ID exists, False otherwise
            
        
        """
        response = await self.database_client.table(self.parent_documents_table_name).select("id").eq("id", id).execute()
        if len(response) > 0:
            return True
        return False

    async def add_parent_document(self, 
        summary: str, 
        group_id: str, 
        created_by: str,
        id: str|int|None = None,
        source: str = None,
        metadata: dict = None
    ) -> dict:
        """
        Add a new parent document to the database or update an existing one.

        Args:
            summary (str): Document summary
            group_id (str): Group identifier for the document
            created_by (str): User identifier who created the document
            id (str|int|None, optional): Specific ID for the document. If provided and exists, update that entry.
            source (str, optional): Document source identifier. Defaults to None.
                If None, no source-based deduplication will be performed.
            metadata (dict, optional): Metadata to be added to the document.
        Returns:
            dict: Database response after inserting or updating the document

        Note:
            - If source is provided, replaces existing documents from the same source and group
            - If id is provided, updates existing entry with that ID or creates new if none exists
        """
        logger.debug(f"Adding/updating parent_document with source: {source or 'None (API-derived)'}, id: {id or 'auto-generated'}")
        
        # Check if a document with this ID exists and update it if it does
        exists = id is not None and await self.check_parent_document_exists(id=id)
        if exists:
            logger.info(f"Deleting existing parent_document with ID: {id}")
            # delete existing child documents
            response = await self.database_client.table(self.parent_documents_table_name).delete().eq("id", id).execute()
        
        # Create new parent document
        item = {
            "summary": summary, 
            "group_id": group_id,
            "created_by": created_by
        }

        # Add optional fields if provided
        if id is not None:
            item["id"] = id
        if source:
            item["source"] = source
        if metadata:
            item["metadata"] = metadata
        
        response = await self.database_client.table(self.parent_documents_table_name).insert(item).execute()

        logger.debug(f"{len(response)} documents added {f'from {source}' if source else 'without source'}")
        return response
    
    async def update_parent_document(self, id: str|int, summary: str = None, source: str = None, metadata: dict = None):
        """
        Update an existing parent document.

        Args:
            id (str|int): ID of the document to update
            summary (str, optional): New summary for the document
            source (str, optional): New source for the document
            metadata (dict, optional): New metadata for the document

        Returns:
            dict: Database response after updating the document

        Note:
            If summary is provided, updates the summary of the document
            If source is provided, updates the source of the document
            If metadata is provided, updates the metadata of the document
        """
        if not summary and not metadata and not source:
            raise ValueError("At least one of summary, metadata, or source must be provided")
        
        update_data = {}
        if summary:
            update_data["summary"] = summary
        if source:
            update_data["source"] = source
        if metadata:
            update_data["metadata"] = metadata
                
        response = await self.database_client.table(self.parent_documents_table_name).update(update_data).eq("id", id).execute()
        logger.debug(f"Updated parent_document with ID: {id}")
        return response
    
    async def delete_parent_document(self, source: str):
        """
        Delete a parent document and its associated child documents.

        Args:
            source (str): Source identifier of the document

        Returns:
            Response: Database response after deletion

        Note:
            Deletion cascades to child documents
            Does nothing if source is None
        """
        if not source:
            logger.warning("Cannot delete parent document: no source provided")
            return None

        logger.debug(f"Deleting previous parent_document with source: {source} and its associated documents")
        
        try:
            response = await (
                self.database_client.table(self.parent_documents_table_name)
                .delete()
                .match({"source": source})
                .execute()
            )
            if len(response) > 0:
                logger.debug(f"Deleted {len(response)} parent_document with cascade to documents")
            return response
        
        except Exception as e:
            logger.error(f"Error deleting parent_document: {e}")
            return None

    async def add_documents(self, 
        documents: list[str], 
        parent_document_id: str, 
        group_id: str, 
        metadata: dict|None = None
    ):
        """
        Add new child documents linked to a parent document.

        Args:
            documents (list[str]): List of document texts (chunks)
            parent_document_id (str): ID of the parent document
            group_id (str): Group identifier for the documents
            metadata (dict, optional): Additional metadata for the documents

        Returns:
            Response: Database response after insertion

        Note:
            Automatically generates embeddings for semantic search
        """
        logger.debug(f"Adding {len(documents)} documents from parent_document_id: {parent_document_id}")

        # insert new documents
        embeddings = await self.create_embeddings(documents)
        uuids = [str(uuid4()) for _ in documents]
        data = []
        for i, (document, uuid, embedding) in enumerate(
            zip(documents, uuids, embeddings)
        ):
            item = {
                "id": uuid,
                "prev_id": uuids[i - 1] if i > 0 else None,
                "next_id": uuids[i + 1] if i < len(uuids) - 1 else None,
                "parent_document_id": parent_document_id, 
                "content": document,
                "group_id": group_id,
                "embedding": embedding,
            }
            if metadata:
                item["metadata"] = metadata
            data.append(item)
        try:
            response = await self.database_client.table(self.table_name).insert(data).execute()
        except Exception as e:
            logger.error(f"Error adding documents: {e}")
            raise

        logger.debug(f"Added {len(documents)} documents from parent_document_id: {parent_document_id}")
        return response

    async def retrieve_child_documents(self, parent_document_id: str) -> List[Dict]:
        """
        Retrieve all documents with the given parent_document_id and link them in order.
        
        Args:
            parent_document_id (str): ID of the parent document
            
        Returns:
            List[Dict]: List of documents in order based on prev_id/next_id links
            
        Note:
            Documents are returned in order starting from the first document 
            (the one with prev_id=NULL) and following next_id links
        """
        logger.debug(f"Retrieving all documents for parent_document_id: {parent_document_id}")
        
        try:
            # First get all documents with this parent_document_id
            response = await self.database_client.table(self.table_name) \
                .select("*") \
                .eq("parent_document_id", parent_document_id) \
                .execute()
                
            if not response:
                logger.info(f"No documents found for parent_document_id: {parent_document_id}")
                return []
                
            # Create a map of documents by ID for easy lookup
            doc_map = {doc["id"]: doc for doc in response}
            
            # Find the first document (prev_id is NULL)
            first_doc = next((doc for doc in response if doc["prev_id"] is None), None)
            if not first_doc:
                logger.warning(f"No first document found for parent_document_id: {parent_document_id}")
                return response  # Return unordered if we can't find start
                
            # Build ordered list by following next_id links
            ordered_docs = []
            current_doc = first_doc
            seen_ids = set()  # Protect against circular references
            
            while current_doc is not None:
                ordered_docs.append(current_doc)
                current_id = current_doc["id"]
                seen_ids.add(current_id)
                
                # Get next document
                next_id = current_doc["next_id"]
                if next_id is None or next_id in seen_ids:
                    break
                current_doc = doc_map.get(next_id)
                
            logger.debug(f"Retrieved {len(ordered_docs)} document(s) from parent_document_id: {parent_document_id}")
            return ordered_docs
            
        except Exception as e:
            logger.error(f"Error retrieving documents: {e}")
            raise

    async def retrieve_full_child_document(self, parent_document_id):
        """
        Convert parent_document_id to string to handle both UUID and integer types.
        
        Args:
            parent_document_id: The ID of the parent document (could be UUID or integer)
            
        Returns:
            str: The full text of all child documents concatenated
        """
        # Convert to string to handle both UUID and integer types
        parent_id_str = str(parent_document_id)
        
        try:
            # Use str(parent_document_id) to handle both UUID and integer types
            query = f"""
            SELECT 
                string_agg(content, ' ' ORDER BY array_position(path, id)) as full_text
            FROM (
                WITH RECURSIVE doc_tree AS (
                    SELECT id, content, parent_document_id, prev_id, next_id, ARRAY[id] as path
                    FROM documents
                    WHERE parent_document_id = '{parent_id_str}'
                    AND prev_id IS NULL
                    
                    UNION ALL
                    
                    SELECT d.id, d.content, d.parent_document_id, d.prev_id, d.next_id, doc_tree.path || d.id
                    FROM documents d
                    JOIN doc_tree ON d.prev_id = doc_tree.id
                )
                SELECT * FROM doc_tree
            ) as tree;
            """
            result = await self.database_client.raw_query(query)
            if result and result[0] and result[0].get('full_text'):
                return result[0]['full_text']
            else:
                logger.warning(f"No child documents found for parent ID {parent_id_str}")
                return ""
        except Exception as e:
            logger.error(f"Error retrieving full child document for parent {parent_id_str}: {str(e)}")
            return ""
```
## File: experiment/analysis_updated.ipynb
```markdown
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "import os\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275 ticket files loaded\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"ticket_data/experiment\"\n",
    "files = os.listdir(data_folder)\n",
    "\n",
    "print(f\"{len(files)} ticket files loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ticket_id': 1007702,\n",
       " 'user_query': \"# Create A Holiday Autoreply For ortho@protecdental.com\\n\\n## On 2024-12-24T20:05:07Z, Daniel Gu wrote a note (2324692):\\nHi Scout,\\n\\nAre we able to create a holiday autoreply for ortho@protecdental.com with the text Nicole sent me below?\\n\\nThank you!\\n\\n**Best Regards,**\\n\\n**DANIEL GU**\\n*IT Support*\\n****PROTEC DENTAL LABORATORIES**\\n1880 Ontario Street\\nVancouver, BC\\nV5T 2W6\\nEmail:  <url>\\nPhone: 604.500.5489\\nFax: 604.873.8527\\n\\n**From:** Nicole Laffin <nlaffin@protecdental.com>\\n**Sent:** Tuesday, December 24, 2024 9:43 AM\\n**To:** Daniel Gu <dgu@protecdental.com>\\n**Subject:** auto reply for ortho email \\n\\nThank you for contacting Protec Orthodontics Lab. Please note Protec will be closed until January 2, 2025\\nWe will respond to emails upon return Thursday Jan 2nd, 2025.\\n\\nHappy Holidays! & Happy New Year !\\n\\nOrthodontics Department\\n**PROTEC DENTAL LABORATORIES**\\nTel:  604.873.8000 \\nToll-Free: 800-663-5488\\n\\nWeb: <url>\\n\\n<image>\\n\\n## On 2024-12-24T20:55:00Z, Brian Garcia wrote a time_entry (1015839):\\n* Reviewed ticket\\n* Tried creating autoreply\\n* Noticed its a distribution list\\n* Tried searching for option for autoreply\\n* Unable to find option\\n* Escalating for review\\n\\n## On 2024-12-24T21:16:02Z, FCojSulugui wrote a note (2324720):\\nAssigned / AAlderson /\\n\\n## On 2024-12-24T21:17:00Z, Alder Alderson wrote a time_entry (1015845):\\nHi Daniel,\\n\\nThe ortho@protecdental.com email address is a Distribution List and therefore can't have an auto-reply/Out of Office setup on it.\\n\\nWe can look at creating a new mailbox with that email address, removing the old Distribution List, then creating a new Distribution List to forward emails from the new mailbox to the users that were on the old Distribution List. \\n\\nBasically what we'd do is create a middleman for the mail coming in, but this would allow us to setup an auto-reply for emails sent to it.\\n\\nMy only hesitation is setting this up right before a holiday as it may cause an interruption to this particular mail-flow and emails may be missed.\\n\\nLet me know if you'd like us to look at this option or if you'd like us to just leave it.\\n\\nRegards,\\n\\n**ALDER ALDERSON**\\nHelpdesk Technician\\n604\\\\.259\\\\.3287 - Direct\\n========================\\n\\n## On 2024-12-26T17:08:29Z, Alder Alderson wrote a time_entry (1016435):\\nHi Daniel,\\n\\nJust following up on this ticket.\\n\\nThe <url> email address is a Distribution List and therefore can't have an auto-reply/Out of Office setup on it.\\n\\nWe can look at creating a new mailbox with that email address, removing the old Distribution List, then creating a new Distribution List to forward emails from the new mailbox to the users that were on the old Distribution List.\\n\\nBasically what we'd do is create a middleman for the mail coming in, but this would allow us to setup an auto-reply for emails sent to it.\\n\\nMy only hesitation is setting this up right before a holiday as it may cause an interruption to this particular mail-flow and emails may be missed.\\n\\nLet me know if you'd like us to look at this option or if you'd like us to just leave it.\\n\\nRegards,\\n\\n**ALDER ALDERSON**\\nHelpdesk Technician\\n604.259.3287 - Direct\\n========================\\n\\n## On 2024-12-27T17:13:00Z, Florinda Coj Sulugui wrote a time_entry (1017140):\\nGood morning Daniel, \\n\\nI hope you are doing well, we just want to follow up with you behalf of Alder on this email.\\n\\nThe <url> email address is a Distribution List and therefore can't have an auto-reply/Out of Office setup on it.\\n\\nWe can look at creating a new mailbox with that email address, removing the old Distribution List, then creating a new Distribution List to forward emails from the new mailbox to the users that were on the old Distribution List.\\n\\nBasically what we'd do is create a middleman for the mail coming in, but this would allow us to setup an auto-reply for emails sent to it.\\n\\nThe only hesitation is setting this up right before a holiday as it may cause an interruption to this particular mail-flow and emails may be missed.\\n\\nLet us know if you'd like us to look at this option or if you'd like us to just leave it. Please let us know\\n\\nThank you,\\n\\n**FLORINDA COJ SULUGUI**\\nSupport Coordinator\\n236\\\\.200\\\\.5765 - Direct\\n========================\\n\\n## On 2024-12-30T17:25:00Z, Brian Garcia wrote a time_entry (1017488):\\n* Reviewed ticket\\n* Reviewed response\\n* Called Daniel\\n* No response\\n* Left voicemail with information\\n\\n## On 2025-01-02T14:48:44Z, Daniel Gu dgu@protecdental.com wrote a note (2328900):\\nSorry, we were in holidays for the last 8 days. It is too late to do this right now. But, give me a call and let's discuss what would be the best setup for the same requirements in the feature.\\n\\n**Best Regards,**\\n\\n**DANIEL GU**\\n*IT Support*\\n****PROTEC DENTAL LABORATORIES**\\n1880 Ontario Street\\nVancouver, BC\\nV5T 2W6\\nEmail:  <url>\\nPhone: 604.500.5489\\nFax: 604.873.8527\\n\\n## On 2025-01-02T16:00:19Z, FCojSulugui wrote a note (2328978):\\nUpdated / AAlderson /\\n\\n## On 2025-01-02T19:39:12Z, Alder Alderson wrote a time_entry (1018142):\\n* Reviewed\\n* Called Daniel\\n* Discussed\\n* Daniel said he'd like to get the shared mailbox setup so that in the future they can setup auto-replies\\n* Daniel verified they were good to move the current DL's address to the Shared Mailbox and create a new email for the DL\\n* Daniel asked for this to be done later today or early in the morning to avoid active hours and potential missed emails\\n* Told Daniel I'd do it around 4:30 either today or tomorrow\\n* Daniel verified this was good\\n\\n## On 2025-01-04T00:26:58Z, Alder Alderson wrote a time_entry (1018556):\\nHi Daniel,\\n\\nI have renamed the Ortho@ DL to orthodl@ and created a new Shared Mailbox with the email ortho@ and set it to forward emails to orthodl@.\\n\\nThis should keep the same mailflow while allowing the possibility for an auto-reply to be setup in the future.\\n\\nLet me know if there are any issues.\\n\\nRegards,\\n\\n**ALDER ALDERSON**\\nHelpdesk Technician\\n604\\\\.259\\\\.3287 - Direct\\n========================\",\n",
       " 'contact_name': 'Daniel Gu',\n",
       " 'user_history': {'overview': 'Daniel Gu frequently encounters issues related to email configurations, server management, and software licensing. The user has 10 previous tickets.',\n",
       "  'similar_tickets': [1030900, 1030901, 1030420],\n",
       "  'recurring_issue': True,\n",
       "  'recurring_issue_cause': 'The user often requests assistance with email configurations and related setups, indicating a recurring need for support in this area.'},\n",
       " 'suggested': {'classification': {'type': 'User',\n",
       "   'subtype': 'Discussion',\n",
       "   'item': 'Unknown',\n",
       "   'priority': 'P3'},\n",
       "  'solution': {'solution': 'Suggested steps: Create a shared mailbox for the email address ortho@protecdental.com, replacing the current distribution list, and configure it to forward emails to a new distribution list. This setup will enable the possibility of setting up an auto-reply for the email address. (based on tickets: #1007702)',\n",
       "   'helpfulness_score': 80,\n",
       "   'analysis': \"The suggested solution proposed creating a shared mailbox for the email address ortho@protecdental.com, replacing the current distribution list, and configuring it to forward emails to a new distribution list. This approach aligns closely with the actual solution, which involved renaming the existing distribution list and creating a new shared mailbox to facilitate auto-replies. \\n\\n1. **Helpfulness of the Suggested Solution**: The suggested solution would have been quite helpful in resolving the user's issue. It correctly identified the need to transition from a distribution list to a shared mailbox to enable auto-replies, which is the core requirement of the user's request. \\n\\n2. **Resolution of the Same Issue**: The suggested solution would likely have resolved the same issue, as it proposed a similar methodology to the actual solution. Both solutions aimed to create a setup that allows for auto-replies, addressing the limitation of the distribution list. \\n\\n3. **Key Differences in Methodology or Effectiveness**: The main difference lies in the specifics of the implementation. The actual solution included the step of renaming the existing distribution list to maintain continuity in email flow, which was not explicitly mentioned in the suggested solution. This additional step is crucial as it ensures that no emails are lost during the transition. \\n\\nOverall, the suggested solution is highly effective but lacks the detail of maintaining the existing distribution list's functionality during the transition. Therefore, it receives a score of 80, indicating it is a helpful solution with minor limitations.\"},\n",
       "  'web_search_solution': {'solution': \"To set up an automatic holiday reply for the shared mailbox ortho@protecdental.com, follow these steps:\\n\\n### Steps to try:\\n\\n1. **Assign Full Access Permissions to a User:**\\n   - In the Exchange Admin Center, navigate to **Recipients** > **Mailboxes**.\\n   - Select the shared mailbox **ortho@protecdental.com**.\\n   - Click on **Delegation** and under **Read and manage (Full Access)**, add a user who will configure the auto-reply.\\n   - Save the changes.\\n   - For detailed instructions, refer to [How to set automatic replies on a user's mailbox in Microsoft 365](https://learn.microsoft.com/en-us/exchange/troubleshoot/user-and-shared-mailboxes/set-automatic-replies).\\n\\n2. **Configure Automatic Replies via Outlook on the Web (OWA):**\\n   - The assigned user should sign in to [Outlook on the web](https://outlook.office.com/).\\n   - Click on their profile picture in the top-right corner and select **Open another mailbox**.\\n   - Enter **ortho@protecdental.com** and click **Open**.\\n   - In the new window, go to **Settings** (gear icon) > **View all Outlook settings** > **Mail** > **Automatic replies**.\\n   - Enable **Automatic replies on** and enter the desired message for both internal and external senders.\\n   - Save the changes.\\n   - For more details, see [How to set up autoreply for a shared mailbox in Office 365](https://answers.microsoft.com/en-us/outlook_com/forum/all/how-to-set-up-autoreply-for-a-shared-mailbox-in/fcdf0520-ffab-4eec-9f56-4a325b5b21b2).\\n\\n3. **Verify the Auto-Reply Configuration:**\\n   - Send a test email to **ortho@protecdental.com** from an internal and an external account to ensure the auto-reply functions correctly.\\n   - Confirm that the auto-reply message is received as expected.\\n\\nBy following these steps, you can effectively set up an automatic holiday reply for the shared mailbox. \",\n",
       "   'helpfulness_score': 41,\n",
       "   'analysis': \"The web search solution provides a detailed step-by-step guide for setting up an automatic holiday reply for a shared mailbox, which is a common method for handling auto-replies in Microsoft 365 environments. However, it fails to address the core issue that the email address ortho@protecdental.com was a Distribution List, which inherently does not support auto-replies. Therefore, the web search solution would not have resolved the user's issue as it assumes the email address is a shared mailbox, which is not the case here.\\n\\nThe actual solution correctly identifies the limitation of the Distribution List and proposes a workaround by creating a new Shared Mailbox and renaming the Distribution List. This approach effectively maintains email flow while allowing for future auto-replies, which is a more practical and effective solution given the circumstances.\\n\\nWhile the web search solution does provide useful information on setting up auto-replies for shared mailboxes, it does not offer any insights or alternative methods for dealing with Distribution Lists, which is a significant limitation. Thus, while the web search solution is moderately helpful in terms of general knowledge about auto-replies, it does not directly address the specific issue at hand, leading to a lower helpfulness score.\"}},\n",
       " 'actual': {'classification': {'type': 'User',\n",
       "   'subtype': 'Signature',\n",
       "   'item': None,\n",
       "   'priority': 'P3',\n",
       "   'solution': 'The issue was that the email address ortho@protecdental.com was a Distribution List, which does not support auto-replies. To resolve this, the Distribution List was renamed to orthodl@, and a new Shared Mailbox was created with the email address ortho@. This new Shared Mailbox was configured to forward emails to the renamed Distribution List (orthodl@), thereby maintaining the existing mail flow while allowing for the possibility of setting up an auto-reply in the future.'}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_file(file_name, folder = data_folder):\n",
    "    with open(os.path.join(folder, file_name), 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "data = load_file(files[1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>contact_name</th>\n",
       "      <th>user_query</th>\n",
       "      <th>user_history_overview</th>\n",
       "      <th>user_similar_tickets</th>\n",
       "      <th>recurring_issue</th>\n",
       "      <th>recurring_issue_cause</th>\n",
       "      <th>suggested_type</th>\n",
       "      <th>suggested_subtype</th>\n",
       "      <th>suggested_item</th>\n",
       "      <th>...</th>\n",
       "      <th>suggested_helpfulness</th>\n",
       "      <th>suggested_analysis</th>\n",
       "      <th>web_search_solution</th>\n",
       "      <th>web_search_helpfulness</th>\n",
       "      <th>web_search_analysis</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>actual_subtype</th>\n",
       "      <th>actual_item</th>\n",
       "      <th>actual_priority</th>\n",
       "      <th>actual_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>986176</td>\n",
       "      <td>Charlie Steele</td>\n",
       "      <td># New Voicemail from 16472896599 - Charlie Ste...</td>\n",
       "      <td>Charlie Steele frequently encounters issues re...</td>\n",
       "      <td>[986176, 986155, 963300, 957187, 957188]</td>\n",
       "      <td>True</td>\n",
       "      <td>Challenges with setting up and configuring new...</td>\n",
       "      <td>User</td>\n",
       "      <td>User</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Charlie Steele from Excel Battery Company has ...</td>\n",
       "      <td>61</td>\n",
       "      <td>The web search solution provides a structured ...</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>P1</td>\n",
       "      <td>The issue reported was related to a setup prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007702</td>\n",
       "      <td>Daniel Gu</td>\n",
       "      <td># Create A Holiday Autoreply For ortho@protecd...</td>\n",
       "      <td>Daniel Gu frequently encounters issues related...</td>\n",
       "      <td>[1030900, 1030901, 1030420]</td>\n",
       "      <td>True</td>\n",
       "      <td>The user often requests assistance with email ...</td>\n",
       "      <td>User</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>The suggested solution proposed creating a sha...</td>\n",
       "      <td>To set up an automatic holiday reply for the s...</td>\n",
       "      <td>41</td>\n",
       "      <td>The web search solution provides a detailed st...</td>\n",
       "      <td>User</td>\n",
       "      <td>Signature</td>\n",
       "      <td>None</td>\n",
       "      <td>P3</td>\n",
       "      <td>The issue was that the email address ortho@pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007217</td>\n",
       "      <td>Ronald Fabre</td>\n",
       "      <td># Cannot Select as Printer When Printing a Che...</td>\n",
       "      <td>Ronald Fabre frequently encounters issues rela...</td>\n",
       "      <td>[1007217, 941987, 926836]</td>\n",
       "      <td>True</td>\n",
       "      <td>The recurring issue is related to the configur...</td>\n",
       "      <td>Print/Scan/eFax</td>\n",
       "      <td>Printing</td>\n",
       "      <td>Problem</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>The suggested solution provided a reasonable a...</td>\n",
       "      <td>The user, Ronald Fabre, experienced an issue w...</td>\n",
       "      <td>80</td>\n",
       "      <td>The web search solution provided a structured ...</td>\n",
       "      <td>Print/Scan/eFax</td>\n",
       "      <td>Printing</td>\n",
       "      <td>None</td>\n",
       "      <td>P3</td>\n",
       "      <td>The actual problem was that the user was unabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000881</td>\n",
       "      <td>Matthew Johnston</td>\n",
       "      <td># Unable to Access Email on Phone\\n\\n## On 202...</td>\n",
       "      <td>Matthew Johnston frequently encounters issues ...</td>\n",
       "      <td>[1000881, 1001261, 1000680, 1000489, 1000339]</td>\n",
       "      <td>True</td>\n",
       "      <td>Matthew often faces challenges with accessing ...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Phone</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>The suggested solution provided a reasonable a...</td>\n",
       "      <td>The user is unable to access a shared mailbox ...</td>\n",
       "      <td>80</td>\n",
       "      <td>The web search solution provides a structured ...</td>\n",
       "      <td>Application</td>\n",
       "      <td>MS - Outlook</td>\n",
       "      <td>None</td>\n",
       "      <td>P2</td>\n",
       "      <td>The issue was that the user was unable to acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003604</td>\n",
       "      <td>Sachin Chaudhari</td>\n",
       "      <td># Authenticator on New Phone\\n\\n## On 2024-12-...</td>\n",
       "      <td>Sachin Chaudhari frequently encounters issues ...</td>\n",
       "      <td>[1003604]</td>\n",
       "      <td>True</td>\n",
       "      <td>The user often requires assistance with settin...</td>\n",
       "      <td>User</td>\n",
       "      <td>Multi Factor Authentication</td>\n",
       "      <td>New Phone</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>The suggested solution provides a clear outlin...</td>\n",
       "      <td>When a user acquires a new phone, transferring...</td>\n",
       "      <td>61</td>\n",
       "      <td>The web search solution provides a comprehensi...</td>\n",
       "      <td>User</td>\n",
       "      <td>Multi Factor Authentication</td>\n",
       "      <td>None</td>\n",
       "      <td>P2</td>\n",
       "      <td>The issue was that the user needed assistance ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id      contact_name  \\\n",
       "0     986176    Charlie Steele   \n",
       "1    1007702         Daniel Gu   \n",
       "2    1007217      Ronald Fabre   \n",
       "3    1000881  Matthew Johnston   \n",
       "4    1003604  Sachin Chaudhari   \n",
       "\n",
       "                                          user_query  \\\n",
       "0  # New Voicemail from 16472896599 - Charlie Ste...   \n",
       "1  # Create A Holiday Autoreply For ortho@protecd...   \n",
       "2  # Cannot Select as Printer When Printing a Che...   \n",
       "3  # Unable to Access Email on Phone\\n\\n## On 202...   \n",
       "4  # Authenticator on New Phone\\n\\n## On 2024-12-...   \n",
       "\n",
       "                               user_history_overview  \\\n",
       "0  Charlie Steele frequently encounters issues re...   \n",
       "1  Daniel Gu frequently encounters issues related...   \n",
       "2  Ronald Fabre frequently encounters issues rela...   \n",
       "3  Matthew Johnston frequently encounters issues ...   \n",
       "4  Sachin Chaudhari frequently encounters issues ...   \n",
       "\n",
       "                            user_similar_tickets  recurring_issue  \\\n",
       "0       [986176, 986155, 963300, 957187, 957188]             True   \n",
       "1                    [1030900, 1030901, 1030420]             True   \n",
       "2                      [1007217, 941987, 926836]             True   \n",
       "3  [1000881, 1001261, 1000680, 1000489, 1000339]             True   \n",
       "4                                      [1003604]             True   \n",
       "\n",
       "                               recurring_issue_cause   suggested_type  \\\n",
       "0  Challenges with setting up and configuring new...             User   \n",
       "1  The user often requests assistance with email ...             User   \n",
       "2  The recurring issue is related to the configur...  Print/Scan/eFax   \n",
       "3  Matthew often faces challenges with accessing ...           Mobile   \n",
       "4  The user often requires assistance with settin...             User   \n",
       "\n",
       "             suggested_subtype suggested_item  ... suggested_helpfulness  \\\n",
       "0                         User           None  ...                   NaN   \n",
       "1                   Discussion           None  ...                  80.0   \n",
       "2                     Printing        Problem  ...                  61.0   \n",
       "3                        Phone           None  ...                  61.0   \n",
       "4  Multi Factor Authentication      New Phone  ...                  75.0   \n",
       "\n",
       "                                  suggested_analysis  \\\n",
       "0                                               None   \n",
       "1  The suggested solution proposed creating a sha...   \n",
       "2  The suggested solution provided a reasonable a...   \n",
       "3  The suggested solution provided a reasonable a...   \n",
       "4  The suggested solution provides a clear outlin...   \n",
       "\n",
       "                                 web_search_solution web_search_helpfulness  \\\n",
       "0  Charlie Steele from Excel Battery Company has ...                     61   \n",
       "1  To set up an automatic holiday reply for the s...                     41   \n",
       "2  The user, Ronald Fabre, experienced an issue w...                     80   \n",
       "3  The user is unable to access a shared mailbox ...                     80   \n",
       "4  When a user acquires a new phone, transferring...                     61   \n",
       "\n",
       "                                 web_search_analysis      actual_type  \\\n",
       "0  The web search solution provides a structured ...      Workstation   \n",
       "1  The web search solution provides a detailed st...             User   \n",
       "2  The web search solution provided a structured ...  Print/Scan/eFax   \n",
       "3  The web search solution provides a structured ...      Application   \n",
       "4  The web search solution provides a comprehensi...             User   \n",
       "\n",
       "                actual_subtype actual_item actual_priority  \\\n",
       "0                         None        None              P1   \n",
       "1                    Signature        None              P3   \n",
       "2                     Printing        None              P3   \n",
       "3                 MS - Outlook        None              P2   \n",
       "4  Multi Factor Authentication        None              P2   \n",
       "\n",
       "                                     actual_solution  \n",
       "0  The issue reported was related to a setup prob...  \n",
       "1  The issue was that the email address ortho@pro...  \n",
       "2  The actual problem was that the user was unabl...  \n",
       "3  The issue was that the user was unable to acce...  \n",
       "4  The issue was that the user needed assistance ...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_flatten_json_files(folder=data_folder):\n",
    "    \"\"\"\n",
    "    Load all JSON files in the specified folder and flatten them into a DataFrame\n",
    "    with no nested columns by prepending parent keys to child keys.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): Path to the folder containing JSON files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Flattened DataFrame with all data\n",
    "    \"\"\"\n",
    "    # Get all JSON files in the folder\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.json')]\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for file in files:\n",
    "        with open(os.path.join(folder, file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        keys = list(data.keys())\n",
    "        for key in keys:\n",
    "            if data[key] is None:\n",
    "                del data[key]\n",
    "        flattened_data = {\n",
    "            \"ticket_id\": data[\"ticket_id\"],\n",
    "            \"contact_name\": data.get(\"contact_name\"),\n",
    "            \"user_query\": data.get(\"user_query\"),\n",
    "            \"user_history_overview\": data.get(\"user_history\", {}).get(\"overview\"),\n",
    "            \"user_similar_tickets\": data.get(\"user_history\", {}).get(\"similar_tickets\"),\n",
    "            \"recurring_issue\": data.get(\"user_history\", {}).get(\"recurring_issue\"),\n",
    "            \"recurring_issue_cause\": data.get(\"user_history\", {}).get(\"recurring_issue_cause\"),\n",
    "            \n",
    "            # Suggested classification\n",
    "            \"suggested_type\": data.get(\"suggested\", {}).get(\"classification\", {}).get(\"type\"),\n",
    "            \"suggested_subtype\": data.get(\"suggested\", {}).get(\"classification\", {}).get(\"subtype\"),\n",
    "            \"suggested_item\": data.get(\"suggested\", {}).get(\"classification\", {}).get(\"item\"),\n",
    "            \"suggested_priority\": data.get(\"suggested\", {}).get(\"classification\", {}).get(\"priority\"),\n",
    "            \n",
    "            # Suggested solution\n",
    "            \"suggested_solution\": data.get(\"suggested\", {}).get(\"solution\", {}).get(\"solution\"),\n",
    "            \"suggested_helpfulness\": data.get(\"suggested\", {}).get(\"solution\", {}).get(\"helpfulness_score\"),\n",
    "            \"suggested_analysis\": data.get(\"suggested\", {}).get(\"solution\", {}).get(\"analysis\"),\n",
    "            \n",
    "            # Web search solution\n",
    "            \"web_search_solution\": data.get(\"suggested\", {}).get(\"web_search_solution\", {}).get(\"solution\"),\n",
    "            \"web_search_helpfulness\": data.get(\"suggested\", {}).get(\"web_search_solution\", {}).get(\"helpfulness_score\"),\n",
    "            \"web_search_analysis\": data.get(\"suggested\", {}).get(\"web_search_solution\", {}).get(\"analysis\"),\n",
    "            \n",
    "            # Actual classification\n",
    "            \"actual_type\": data.get(\"actual\", {}).get(\"classification\", {}).get(\"type\"),\n",
    "            \"actual_subtype\": data.get(\"actual\", {}).get(\"classification\", {}).get(\"subtype\"),\n",
    "            \"actual_item\": data.get(\"actual\", {}).get(\"classification\", {}).get(\"item\"),\n",
    "            \"actual_priority\": data.get(\"actual\", {}).get(\"classification\", {}).get(\"priority\"),\n",
    "            \"actual_solution\": data.get(\"actual\", {}).get(\"classification\", {}).get(\"solution\"),\n",
    "        }\n",
    "        \n",
    "        all_data.append(flattened_data)\n",
    "    \n",
    "    # Convert the list of flattened dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    for column in [\"suggested_type\", \"suggested_subtype\", \"suggested_item\"]:\n",
    "        df[column] = df[column].replace(\"Unknown\", None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_and_flatten_json_files()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ticket_data/experiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = pio.templates[\"seaborn\"].layout.colorway\n",
    "PLOT_WIDTH=700\n",
    "PLOT_HEIGHT=500\n",
    "TEMPLATE=\"seaborn\"\n",
    "\n",
    "style_settings = {\n",
    "    \"width\": PLOT_HEIGHT, \n",
    "    \"height\": PLOT_HEIGHT, \n",
    "    \"template\": TEMPLATE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSI prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Actual Null Count</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Suggested Null Count</th>\n",
       "      <th>Suggested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtype</td>\n",
       "      <td>253</td>\n",
       "      <td>19.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item</td>\n",
       "      <td>1033</td>\n",
       "      <td>81.0</td>\n",
       "      <td>166</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Field  Actual Null Count  Actual  Suggested Null Count  Suggested\n",
       "0     type                  0     0.0                     0        0.0\n",
       "1  subtype                253    19.8                     7        0.5\n",
       "2     item               1033    81.0                   166       13.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame showing null counts and fractions for type, subtype, and item\n",
    "comparison_data = []\n",
    "total_rows = len(df)\n",
    "\n",
    "for field in ['type', 'subtype', 'item']:\n",
    "    suggested_field = f'suggested_{field}'\n",
    "    actual_field = f'actual_{field}'\n",
    "    \n",
    "    suggested_null_count = df[suggested_field].isna().sum()\n",
    "    actual_null_count = df[actual_field].isna().sum()\n",
    "    \n",
    "    suggested_null_fraction = suggested_null_count / total_rows *100\n",
    "    actual_null_fraction = actual_null_count / total_rows*100\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Field': field,\n",
    "        'Actual Null Count': actual_null_count,\n",
    "        'Actual': actual_null_fraction,\n",
    "        'Suggested Null Count': suggested_null_count,\n",
    "        'Suggested': suggested_null_fraction,\n",
    "        \n",
    "    })\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data).round(1)\n",
    "comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Category=Suggested<br>Classification=%{x}<br>Null Percentage (%)=%{y}<extra></extra>",
         "legendgroup": "Suggested",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Suggested",
         "offsetgroup": "Suggested",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "type",
          "subtype",
          "item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAADgPwAAAAAAACpA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Category=Actual<br>Classification=%{x}<br>Null Percentage (%)=%{y}<extra></extra>",
         "legendgroup": "Actual",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual",
         "offsetgroup": "Actual",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.0f}",
         "type": "bar",
         "x": [
          "type",
          "subtype",
          "item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAAADNzMzMzMwzQAAAAAAAQFRA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 500,
        "legend": {
         "title": {
          "text": ""
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Null TSI Classifications"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Classification"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          89.10000000000001
         ],
         "title": {
          "text": "Null Percentage (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the data for plotting\n",
    "plot_data = pd.melt(\n",
    "    comparison_df, \n",
    "    id_vars=['Field'],\n",
    "    value_vars=['Suggested', 'Actual'],\n",
    "    var_name='Category',\n",
    "    value_name='Null Percentage'\n",
    ")\n",
    "\n",
    "# Create the bar chart with the correct data structure\n",
    "fig = px.bar(\n",
    "    plot_data,\n",
    "    x='Field',\n",
    "    y='Null Percentage',\n",
    "    color='Category',\n",
    "    barmode='group',\n",
    "    title='Null TSI Classifications',\n",
    "    labels={'Field': 'Classification', 'Null Percentage': 'Null Percentage (%)'},\n",
    "    color_discrete_map={\n",
    "        'Suggested': COLORS[1],  # orange\n",
    "        'Actual': COLORS[0]      # blue\n",
    "    },\n",
    "    text_auto='.0f',\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text='',\n",
    "    yaxis_range=[0, max(plot_data['Null Percentage'])*1.1]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "=%{x}<br>Count=%{y}<extra></extra>",
         "legendgroup": "Actual valid type",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid type",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid type"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "+wQ=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "=%{x}<br>Count=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "wQM=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Type suggestion accuracy: 75%",
          "x": 0.5,
          "y": 1338.75
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": ""
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Type Suggestions"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid type",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual valid type</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matching suggestions</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value\n",
       "0     Actual valid type   1275\n",
       "1  Matching suggestions    961"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the match data for types\n",
    "valid_actual_type = df[df['actual_type'].notna()]\n",
    "matches = (valid_actual_type['suggested_type'] == valid_actual_type['actual_type']).sum()\n",
    "total_valid = len(valid_actual_type)\n",
    "match_percentage = (matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results - keep all values as their original types\n",
    "type_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid type', 'Matching suggestions'],\n",
    "    'Value': [total_valid, matches]\n",
    "})\n",
    "\n",
    "\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    type_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Type Suggestions',\n",
    "    labels={'Metric': '', 'Value': 'Count'},\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid type': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Type suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(type_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtype Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Actual valid subtype",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid subtype",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid subtype"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "bgM=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "xAI=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Subtype suggestion accuracy: 81%",
          "x": 0.5,
          "y": 921.9000000000001
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Subtype Suggestions (matching <b><i>type</i></b>)"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid subtype",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'].notna())]\n",
    "\n",
    "# Count subtype matches\n",
    "subtype_matches = (valid_rows['suggested_subtype'] == valid_rows['actual_subtype']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (subtype_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "subtype_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid subtype', 'Matching suggestions'],\n",
    "    'Value': [total_valid, subtype_matches]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "subtype_df.round()\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    subtype_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Subtype Suggestions (matching <b><i>type</i></b>)',\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid subtype': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Subtype suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(subtype_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a promising, but limited result since so many tickets do not have subtypes defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valid rows (types match &amp; actual_item not null)</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item matches (suggested = actual)</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item match percentage (%)</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Metric  Value\n",
       "0  Valid rows (types match & actual_item not null)  205.0\n",
       "1                Item matches (suggested = actual)  195.0\n",
       "2                        Item match percentage (%)   95.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to rows where:\n",
    "# 1. actual_type is not null\n",
    "# 2. suggested_type matches actual_type\n",
    "# 3. actual_item is not null\n",
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'] == df['suggested_subtype']) &\n",
    "                (df['actual_item'].notna())]\n",
    "\n",
    "# Count item matches\n",
    "item_matches = (valid_rows['suggested_item'] == valid_rows['actual_item']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (item_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "item_match_df = pd.DataFrame({\n",
    "    'Metric': ['Valid rows (types match & actual_item not null)', \n",
    "               'Item matches (suggested = actual)', \n",
    "               'Item match percentage (%)'],\n",
    "    'Value': [total_valid, item_matches, match_percentage]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "item_match_df.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Actual valid item",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Actual valid item",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Actual valid item"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "zQA=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Metric=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Matching suggestions",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Matching suggestions",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Matching suggestions"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "wwA=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Item suggestion accuracy: 95%",
          "x": 0.5,
          "y": 215.25
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Item Suggestions (matching <b><i>type/subtype</i></b>)"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Actual valid item",
          "Matching suggestions"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual valid item</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matching suggestions</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric  Value\n",
       "0     Actual valid item    205\n",
       "1  Matching suggestions    195"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rows = df[(df['actual_type'].notna()) & \n",
    "                (df['suggested_type'] == df['actual_type']) & \n",
    "                (df['actual_subtype'] == df['suggested_subtype']) &\n",
    "                (df['actual_item'].notna())]\n",
    "\n",
    "# Count subtype matches\n",
    "item_matches = (valid_rows['suggested_item'] == valid_rows['actual_item']).sum()\n",
    "\n",
    "# Calculate total valid rows and match percentage\n",
    "total_valid = len(valid_rows)\n",
    "match_percentage = (item_matches / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "subtype_df = pd.DataFrame({\n",
    "    'Metric': ['Actual valid item', 'Matching suggestions'],\n",
    "    'Value': [total_valid, item_matches]\n",
    "})\n",
    "\n",
    "# Create the bar chart with custom color mapping\n",
    "fig = px.bar(\n",
    "    subtype_df,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    title='Item Suggestions (matching <b><i>type/subtype</i></b>)',\n",
    "    color='Metric',\n",
    "    color_discrete_map={\n",
    "        'Actual valid item': COLORS[0],\n",
    "        'Matching suggestions': COLORS[1]\n",
    "    },\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "# Add annotation for match percentage\n",
    "fig.add_annotation(\n",
    "    text=f\"Item suggestion accuracy: {match_percentage:.0f}%\",\n",
    "    x=0.5,\n",
    "    y=max(subtype_df['Value'])*1.05,\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "subtype_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Solutions\n",
    "\n",
    "These were rated by an LLM, comparing the suggested solution with the one that was implemented.\n",
    "\n",
    "Note that often the suggested solution is based on minimal information, and that the actual solution involves interactions with the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>contact_name</th>\n",
       "      <th>user_query</th>\n",
       "      <th>user_history_overview</th>\n",
       "      <th>user_similar_tickets</th>\n",
       "      <th>recurring_issue</th>\n",
       "      <th>recurring_issue_cause</th>\n",
       "      <th>suggested_type</th>\n",
       "      <th>suggested_subtype</th>\n",
       "      <th>suggested_item</th>\n",
       "      <th>...</th>\n",
       "      <th>suggested_helpfulness</th>\n",
       "      <th>suggested_analysis</th>\n",
       "      <th>web_search_solution</th>\n",
       "      <th>web_search_helpfulness</th>\n",
       "      <th>web_search_analysis</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>actual_subtype</th>\n",
       "      <th>actual_item</th>\n",
       "      <th>actual_priority</th>\n",
       "      <th>actual_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>986176</td>\n",
       "      <td>Charlie Steele</td>\n",
       "      <td># New Voicemail from 16472896599 - Charlie Ste...</td>\n",
       "      <td>Charlie Steele frequently encounters issues re...</td>\n",
       "      <td>[986176, 986155, 963300, 957187, 957188]</td>\n",
       "      <td>True</td>\n",
       "      <td>Challenges with setting up and configuring new...</td>\n",
       "      <td>User</td>\n",
       "      <td>User</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Charlie Steele from Excel Battery Company has ...</td>\n",
       "      <td>61</td>\n",
       "      <td>The web search solution provides a structured ...</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>P1</td>\n",
       "      <td>The issue reported was related to a setup prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007702</td>\n",
       "      <td>Daniel Gu</td>\n",
       "      <td># Create A Holiday Autoreply For ortho@protecd...</td>\n",
       "      <td>Daniel Gu frequently encounters issues related...</td>\n",
       "      <td>[1030900, 1030901, 1030420]</td>\n",
       "      <td>True</td>\n",
       "      <td>The user often requests assistance with email ...</td>\n",
       "      <td>User</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>The suggested solution proposed creating a sha...</td>\n",
       "      <td>To set up an automatic holiday reply for the s...</td>\n",
       "      <td>41</td>\n",
       "      <td>The web search solution provides a detailed st...</td>\n",
       "      <td>User</td>\n",
       "      <td>Signature</td>\n",
       "      <td>None</td>\n",
       "      <td>P3</td>\n",
       "      <td>The issue was that the email address ortho@pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id    contact_name  \\\n",
       "0     986176  Charlie Steele   \n",
       "1    1007702       Daniel Gu   \n",
       "\n",
       "                                          user_query  \\\n",
       "0  # New Voicemail from 16472896599 - Charlie Ste...   \n",
       "1  # Create A Holiday Autoreply For ortho@protecd...   \n",
       "\n",
       "                               user_history_overview  \\\n",
       "0  Charlie Steele frequently encounters issues re...   \n",
       "1  Daniel Gu frequently encounters issues related...   \n",
       "\n",
       "                       user_similar_tickets  recurring_issue  \\\n",
       "0  [986176, 986155, 963300, 957187, 957188]             True   \n",
       "1               [1030900, 1030901, 1030420]             True   \n",
       "\n",
       "                               recurring_issue_cause suggested_type  \\\n",
       "0  Challenges with setting up and configuring new...           User   \n",
       "1  The user often requests assistance with email ...           User   \n",
       "\n",
       "  suggested_subtype suggested_item  ... suggested_helpfulness  \\\n",
       "0              User           None  ...                   NaN   \n",
       "1        Discussion           None  ...                  80.0   \n",
       "\n",
       "                                  suggested_analysis  \\\n",
       "0                                               None   \n",
       "1  The suggested solution proposed creating a sha...   \n",
       "\n",
       "                                 web_search_solution web_search_helpfulness  \\\n",
       "0  Charlie Steele from Excel Battery Company has ...                     61   \n",
       "1  To set up an automatic holiday reply for the s...                     41   \n",
       "\n",
       "                                 web_search_analysis  actual_type  \\\n",
       "0  The web search solution provides a structured ...  Workstation   \n",
       "1  The web search solution provides a detailed st...         User   \n",
       "\n",
       "  actual_subtype actual_item actual_priority  \\\n",
       "0           None        None              P1   \n",
       "1      Signature        None              P3   \n",
       "\n",
       "                                     actual_solution  \n",
       "0  The issue reported was related to a setup prob...  \n",
       "1  The issue was that the email address ortho@pro...  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticket_id', 'contact_name', 'user_query', 'user_history_overview',\n",
       "       'user_similar_tickets', 'recurring_issue', 'recurring_issue_cause',\n",
       "       'suggested_type', 'suggested_subtype', 'suggested_item',\n",
       "       'suggested_priority', 'suggested_solution', 'suggested_helpfulness',\n",
       "       'suggested_analysis', 'web_search_solution', 'web_search_helpfulness',\n",
       "       'web_search_analysis', 'actual_type', 'actual_subtype', 'actual_item',\n",
       "       'actual_priority', 'actual_solution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_suggested_solutions:       1229\n",
      "n_tickets:                   1275\n",
      "percent_suggested_solutions: 96%\n",
      "\n",
      "Mean solution score:   66\n",
      "Median solution score: 61\n",
      "\n",
      "n_suggested_solutions:       1275\n",
      "n_tickets:                   1275\n",
      "percent_suggested_solutions: 100%\n",
      "\n",
      "Mean solution score:   63\n",
      "Median solution score: 61\n"
     ]
    }
   ],
   "source": [
    "score_cols = [\"suggested_helpfulness\", \"web_search_helpfulness\"]\n",
    "\n",
    "for score_col in score_cols:\n",
    "    n_suggested_solutions = df[score_col].notnull().sum()\n",
    "    n_tickets = df.shape[0]\n",
    "    percent_suggested_solutions = n_suggested_solutions/n_tickets * 100\n",
    "    percent_suggested_solutions\n",
    "    print(f\"\\nn_suggested_solutions:       {n_suggested_solutions}\")\n",
    "    print(f\"n_tickets:                   {n_tickets}\")\n",
    "    print(f\"percent_suggested_solutions: {percent_suggested_solutions:.0f}%\")\n",
    "\n",
    "    mean_solution_score =  df[score_col].mean()\n",
    "    median_solution_score =  df[score_col].median()\n",
    "    print(f\"\\nMean solution score:   {mean_solution_score:.0f}\")\n",
    "    print(f\"Median solution score: {median_solution_score:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solutions_count</th>\n",
       "      <th>tickets_count</th>\n",
       "      <th>coverage_percent</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>median_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suggested_helpfulness</th>\n",
       "      <td>1229</td>\n",
       "      <td>1275</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web_search_helpfulness</th>\n",
       "      <td>1275</td>\n",
       "      <td>1275</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        solutions_count  tickets_count  coverage_percent  \\\n",
       "score_type                                                                 \n",
       "suggested_helpfulness              1229           1275                96   \n",
       "web_search_helpfulness             1275           1275               100   \n",
       "\n",
       "                        mean_score  median_score  \n",
       "score_type                                        \n",
       "suggested_helpfulness           66            61  \n",
       "web_search_helpfulness          63            61  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_cols = [\"suggested_helpfulness\", \"web_search_helpfulness\"]\n",
    "\n",
    "# Initialize lists to hold the statistics for each score column\n",
    "stats_data = []\n",
    "\n",
    "for score_col in score_cols:\n",
    "    n_suggested_solutions = df[score_col].notnull().sum()\n",
    "    n_tickets = df.shape[0]\n",
    "    percent_suggested_solutions = n_suggested_solutions/n_tickets * 100\n",
    "    mean_solution_score = df[score_col].mean()\n",
    "    median_solution_score = df[score_col].median()\n",
    "    \n",
    "    # Add the statistics to the list\n",
    "    stats_data.append({\n",
    "        \"score_type\": score_col,\n",
    "        \"solutions_count\": n_suggested_solutions,\n",
    "        \"tickets_count\": n_tickets,\n",
    "        \"coverage_percent\": round(percent_suggested_solutions),\n",
    "        \"mean_score\": round(mean_solution_score),\n",
    "        \"median_score\": round(median_solution_score)\n",
    "    })\n",
    "\n",
    "# Create the dataframe\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "\n",
    "# Display the dataframe\n",
    "print(\"\\nSolution Statistics:\")\n",
    "stats_df.set_index(\"score_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct median calculation: 61.0\n",
      "\n",
      "Value counts:\n",
      "web_search_helpfulness\n",
      "10      1\n",
      "21      1\n",
      "30      4\n",
      "41    187\n",
      "60      7\n",
      "61    663\n",
      "70     91\n",
      "75    117\n",
      "80    181\n",
      "81     19\n",
      "85      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Manually calculated median: 61\n"
     ]
    }
   ],
   "source": [
    "# Direct calculation of the median\n",
    "direct_median = df[\"web_search_helpfulness\"].median()\n",
    "print(f\"Direct median calculation: {direct_median}\")\n",
    "\n",
    "# Look at the value counts to understand the distribution\n",
    "value_counts = df[\"web_search_helpfulness\"].value_counts().sort_index()\n",
    "print(\"\\nValue counts:\")\n",
    "print(value_counts)\n",
    "\n",
    "# Calculate the median manually to verify\n",
    "sorted_values = df[\"web_search_helpfulness\"].dropna().sort_values()\n",
    "n = len(sorted_values)\n",
    "if n % 2 == 0:\n",
    "    manual_median = (sorted_values.iloc[n//2-1] + sorted_values.iloc[n//2])/2\n",
    "else:\n",
    "    manual_median = sorted_values.iloc[n//2]\n",
    "print(f\"\\nManually calculated median: {manual_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution scores\n",
    "\n",
    "There was a bug and the new solutions scores can't be trusted so we need to load the old ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ticket_id', 'user_history', 'user_similar_tickets', 'query',\n",
      "       'suggested_type', 'suggested_subtype', 'suggested_item',\n",
      "       'suggested_solution', 'actual_type', 'actual_subtype', 'actual_item',\n",
      "       'actual_solution', 'solution_score', 'solution_analysis'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>user_history</th>\n",
       "      <th>user_similar_tickets</th>\n",
       "      <th>query</th>\n",
       "      <th>suggested_type</th>\n",
       "      <th>suggested_subtype</th>\n",
       "      <th>suggested_item</th>\n",
       "      <th>suggested_solution</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>actual_subtype</th>\n",
       "      <th>actual_item</th>\n",
       "      <th>actual_solution</th>\n",
       "      <th>solution_score</th>\n",
       "      <th>solution_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Worxhub Cache In History - Hoping There Is A...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>Update</td>\n",
       "      <td>Suggested steps: Implement a scheduled task or...</td>\n",
       "      <td>Application</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The issue involved users experiencing problems...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>The suggested solution of implementing a sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978181</td>\n",
       "      <td>Sally Ali typically experiences issues related...</td>\n",
       "      <td>[791485, 718599, 631756, 626917]</td>\n",
       "      <td># Black screen</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>OS</td>\n",
       "      <td>Problem</td>\n",
       "      <td>Suggested steps: Attempt to restart the workst...</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The issue reported was a black screen on the u...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>The suggested solution provided a reasonable a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978183</td>\n",
       "      <td>Gabriel Mutch typically encounters issues rela...</td>\n",
       "      <td>[974891, 968771, 961682, 910891, 875428]</td>\n",
       "      <td># Update dsstaff@ Mailing List\\n\\n## On 2024-0...</td>\n",
       "      <td>User</td>\n",
       "      <td>Group Membership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suggested steps: The IT team can update the ds...</td>\n",
       "      <td>Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The actual problem was a request to update the...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>The suggested solution effectively identifies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978201</td>\n",
       "      <td>Lynnelle Friesen typically experiences issues ...</td>\n",
       "      <td>[929129, 843615, 914729, 854533, 811986]</td>\n",
       "      <td># Check If This Is Legit - Scout Request For A...</td>\n",
       "      <td>Application</td>\n",
       "      <td>MS - Teams (No Voice)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Network</td>\n",
       "      <td>E-mail/Spam</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>The actual problem was a request from the Scou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannot evaluate due to missing solution data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978204</td>\n",
       "      <td>Judy Slutsky typically experiences issues rela...</td>\n",
       "      <td>[951475, 951473, 928456, 916379, 953596]</td>\n",
       "      <td># Regarding Urban Email</td>\n",
       "      <td>User</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suggested steps: The IT team should review the...</td>\n",
       "      <td>Application</td>\n",
       "      <td>MS - Outlook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The actual problem was related to the Multi-Fa...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>The suggested solution emphasizes the need for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                       user_history  \\\n",
       "0     978178                                                NaN   \n",
       "1     978181  Sally Ali typically experiences issues related...   \n",
       "2     978183  Gabriel Mutch typically encounters issues rela...   \n",
       "3     978201  Lynnelle Friesen typically experiences issues ...   \n",
       "4     978204  Judy Slutsky typically experiences issues rela...   \n",
       "\n",
       "                       user_similar_tickets  \\\n",
       "0                                       NaN   \n",
       "1          [791485, 718599, 631756, 626917]   \n",
       "2  [974891, 968771, 961682, 910891, 875428]   \n",
       "3  [929129, 843615, 914729, 854533, 811986]   \n",
       "4  [951475, 951473, 928456, 916379, 953596]   \n",
       "\n",
       "                                               query suggested_type  \\\n",
       "0  # Worxhub Cache In History - Hoping There Is A...    Application   \n",
       "1                                     # Black screen    Workstation   \n",
       "2  # Update dsstaff@ Mailing List\\n\\n## On 2024-0...           User   \n",
       "3  # Check If This Is Legit - Scout Request For A...    Application   \n",
       "4                            # Regarding Urban Email           User   \n",
       "\n",
       "       suggested_subtype suggested_item  \\\n",
       "0                  Other         Update   \n",
       "1                     OS        Problem   \n",
       "2       Group Membership            NaN   \n",
       "3  MS - Teams (No Voice)            NaN   \n",
       "4                    NaN            NaN   \n",
       "\n",
       "                                  suggested_solution  actual_type  \\\n",
       "0  Suggested steps: Implement a scheduled task or...  Application   \n",
       "1  Suggested steps: Attempt to restart the workst...  Workstation   \n",
       "2  Suggested steps: The IT team can update the ds...        Group   \n",
       "3                                                NaN      Network   \n",
       "4  Suggested steps: The IT team should review the...  Application   \n",
       "\n",
       "  actual_subtype actual_item  \\\n",
       "0          Other         NaN   \n",
       "1            NaN         NaN   \n",
       "2            NaN         NaN   \n",
       "3    E-mail/Spam    Phishing   \n",
       "4   MS - Outlook         NaN   \n",
       "\n",
       "                                     actual_solution  solution_score  \\\n",
       "0  The issue involved users experiencing problems...            50.0   \n",
       "1  The issue reported was a black screen on the u...            61.0   \n",
       "2  The actual problem was a request to update the...            81.0   \n",
       "3  The actual problem was a request from the Scou...             NaN   \n",
       "4  The actual problem was related to the Multi-Fa...            41.0   \n",
       "\n",
       "                                   solution_analysis  \n",
       "0  The suggested solution of implementing a sched...  \n",
       "1  The suggested solution provided a reasonable a...  \n",
       "2  The suggested solution effectively identifies ...  \n",
       "3       Cannot evaluate due to missing solution data  \n",
       "4  The suggested solution emphasizes the need for...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old = pd.read_csv(\"ticket_data/experiment_old.csv\")\n",
    "print(df_old.columns)\n",
    "df_old.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>web_search_helpfulness</th>\n",
       "      <th>solution_score</th>\n",
       "      <th>total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>986176</td>\n",
       "      <td>61</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007702</td>\n",
       "      <td>41</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007217</td>\n",
       "      <td>80</td>\n",
       "      <td>41.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000881</td>\n",
       "      <td>80</td>\n",
       "      <td>41.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003604</td>\n",
       "      <td>61</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>992008</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>993160</td>\n",
       "      <td>41</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>982634</td>\n",
       "      <td>61</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>990259</td>\n",
       "      <td>75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1010396</td>\n",
       "      <td>80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticket_id  web_search_helpfulness  solution_score  total_score\n",
       "0        986176                      61            75.0         75.0\n",
       "1       1007702                      41            30.0         41.0\n",
       "2       1007217                      80            41.0         80.0\n",
       "3       1000881                      80            41.0         80.0\n",
       "4       1003604                      61            70.0         70.0\n",
       "...         ...                     ...             ...          ...\n",
       "1270     992008                      41             NaN         41.0\n",
       "1271     993160                      41            20.0         41.0\n",
       "1272     982634                      61            61.0         61.0\n",
       "1273     990259                      75            75.0         75.0\n",
       "1274    1010396                      80            80.0         80.0\n",
       "\n",
       "[1275 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solutions = df[[\"ticket_id\", \"web_search_helpfulness\"]]\n",
    "df_solutions_old = df_old[[\"ticket_id\", \"solution_score\"]]\n",
    "df_merged = pd.merge(df_solutions, df_solutions_old, on=\"ticket_id\", how=\"left\")\n",
    "df_merged[\"total_score\"] = df_merged[[\"web_search_helpfulness\", \"solution_score\"]].max(axis=1)\n",
    "df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "variable=web_search_helpfulness<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "web_search_helpfulness",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "web_search_helpfulness",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": {
          "bdata": "PSlQUD0pSz09UD09KT09PVA9Sz09UD1QPT0pPT09UFA9PT09UD09KT09UCk9KT09PUZQPT09PT09PT1GPSk9PUtLKSk9PSk9PT09KT0pS1BQUSk9PT1GKVA9PUZQKT09KVE9PVApKVEpUD1LS0s9RkY9PT09KT0pS1A9KT1QKSkpPT09PVBGPUYpPT1QPUtQKVA9PUs9PVBGPUtLPVApPT09KT0pPUs9PVBQPVA9RlA9UT09PT09UEs9PVA9PSkpPT09PT1QPUY9PVA9KT1QPT0pRkspKT0pKUtRPT1QUD09Rik9KSk9PT0pSz0pUClQPT09PT09KUspSz1QPT09PT1LPSk9PT09PT09PT09PVE9Hj1QPSlGPT09UVA9UClLPVA9PUtQPSk9UD1LPT09PVA9PT09PUY9PT09PT1GKT1LPT09PUY9Sz09PUtQPT1QUD09PT0pPT0pPFBQS0s9PT09Sz09UD0pPT1GKT09PUs9PT09PUspPT09USkePVBQUCkpPT09Rik9Rj0pPT1QKT1VUD09Sz09PT09UD09KT09PVA9SylQPT09UD1QPT09UD1LKT1LPT0pUD09PUYpRj09PUspPT09PT09PT1GUEs9PUY9Rj0pPSkpKVA9PT1QS0tLPT1GUD1LPT1QPT09UD0pPT09KT08Rj1GUD1QPT1LPT1QPT1GKT09KUs9PD09UD09PSk9PVBRPT1QPSkpRj1QPT1RPT1QRj09KT1LPT09PSk9PUYpPT09PUYpUEZQKT0pUD09S0Y9PVApPT1QPUtQPT1GUD1QPT1LUD09UD09RktLPUZLKT1RKT1GPT09UD09S1A9PT09UVA9UD1GPT1LRj1VPSlLPT1QPSlQPT1QPSk9KT1LPUs9UD1GKT09PT0pPUs9PVBLKSkpRlApPT1QPT09KR5QKVA9PSk9PT1QUFApPUZQSz1GRj09PUZQRkYVRilLPT0pPSkpSz0ePSkpPSk9UD09UDwpRj0pPT0pSz1LKSlQSz09RlA9RkY9UD09UFA9PUs9KT0pPT09KT09Rj09KVA9PTwpS0s9PVA9PUtLRikpUT09PUYpUT09PVA9S0spKSkpPT09PT09KT09PT1QSz0pPT09UD09PVBGPUspPT09KT1LUEYpUEZLPVA9UCk9RikpUEs9KT1LRilLPSlRPT09UD0pKSlQPUs9PVA9S1A9S1A9PVU9UFBLPVA9KT09PT1LPVE9Rj09PT09KUs9KUtGSz1LCj1GUD1LKVA9UCk9PT1QPT09KSkpPT09RlE9PT1GPSlQPSk9PT1GPUtQPVApPUspUD1QUD09PT1QPVVLPT09KSlLPVA9PSkpUFBQKSk9Syk9PT09PT0pPT1QPD1QPT09PT09PUY9PUY9PSk9PUY9S0s9Sz1QSykpPT09PT0pPVApPUtLPT0pPT1LUEspKT1GPT09PUY9PUYpUFA9PT1GKT09PT09PVA9PTw9PSk9KVA9PT09PT09PT09PT09UEY9PVApPT09KT09PT1QUD1QUD1GPUs9PUZQPT09PUtLRkZLUD1QPSk9RkZQPT1GPUtLRj1QSz09PUZLSz09KT09Rj09PT1QUD1LKSk9Sz1RPUZLUUY9PT09UD09Rks9UFBQUEs9PT1QUCk9UFA9PT09PT1GPSk9PVA9Sz0pPSkpPT0pPT1QPT09PT09RikpPUtQ",
          "dtype": "i1"
         },
         "xaxis": "x",
         "xbins": {
          "end": 100,
          "size": 10,
          "start": 0
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Mean: 63",
          "x": 62.89019607843137,
          "xanchor": "left",
          "y": 1.05,
          "yref": "paper"
         },
         {
          "bgcolor": "rgba(255, 255, 255, 0.7)",
          "bordercolor": "black",
          "borderwidth": 1,
          "font": {
           "size": 12
          },
          "showarrow": false,
          "text": "≥ 60: 84.9%",
          "x": 10,
          "y": 0.95,
          "yref": "paper"
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dash",
           "width": 2
          },
          "type": "line",
          "x0": 62.89019607843137,
          "x1": 62.89019607843137,
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Distribution of Web Search Solution Scores"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          100
         ],
         "title": {
          "text": "Score"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "variable=total_score<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "total_score",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "total_score",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "xbins": {
          "end": 100,
          "size": 10,
          "start": 0
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Mean: 65",
          "x": 65.25882352941177,
          "xanchor": "left",
          "y": 1.05,
          "yref": "paper"
         },
         {
          "bgcolor": "rgba(255, 255, 255, 0.7)",
          "bordercolor": "black",
          "borderwidth": 1,
          "font": {
           "size": 12
          },
          "showarrow": false,
          "text": "≥ 60: 91.0%",
          "x": 10,
          "y": 0.95,
          "yref": "paper"
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dash",
           "width": 2
          },
          "type": "line",
          "x0": 65.25882352941177,
          "x1": 65.25882352941177,
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Distribution of Total (Maximum) Helpfulness Scores"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          100
         ],
         "title": {
          "text": "Score"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the score columns to visualize\n",
    "score_cols = [\"web_search_helpfulness\", \"total_score\"]\n",
    "nice_names = {\n",
    "    \"web_search_helpfulness\": \"Web Search Solution\", \n",
    "    \"total_score\": \"Total (Maximum) Helpfulness\"\n",
    "}\n",
    "\n",
    "for score_col in score_cols:\n",
    "    # Skip if no data\n",
    "    if df_merged[score_col].notnull().sum() == 0:\n",
    "        print(f\"No data for {nice_names[score_col]}\")\n",
    "        continue\n",
    "        \n",
    "    median_score = df_merged[score_col].median()\n",
    "    mean_score = df_merged[score_col].mean()\n",
    "    \n",
    "    # Define exact bin edges\n",
    "    bin_edges = list(range(0, 101, 10))  # 0, 10, 20, ... 100\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df_merged[score_col].dropna(),  # Drop NA values to avoid errors\n",
    "        title=f\"Distribution of {nice_names[score_col]} Scores\",\n",
    "        color_discrete_sequence=[COLORS[1]],\n",
    "        histnorm=None,  # Count values\n",
    "        nbins=None,  # We'll specify exact bins\n",
    "        range_x=[0, 100],  # Range of x-axis\n",
    "        **style_settings\n",
    "    )\n",
    "    \n",
    "    # Update the bin configuration for exact bin edges\n",
    "    fig.update_traces(xbins=dict(\n",
    "        start=0,  # Start at 0\n",
    "        end=100,  # End at 100\n",
    "        size=10   # Bin width of 10\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        xaxis_title=\"Score\",\n",
    "        yaxis_title=\"Count\"\n",
    "    )\n",
    "    \n",
    "    # Add vertical line for mean with improved visibility\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=mean_score,\n",
    "        y0=0,\n",
    "        x1=mean_score,\n",
    "        y1=1,\n",
    "        yref=\"paper\",\n",
    "        line=dict(\n",
    "            color=\"black\",\n",
    "            width=2,\n",
    "            dash=\"dash\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add annotation for mean\n",
    "    fig.add_annotation(\n",
    "        x=mean_score,\n",
    "        y=1.05,\n",
    "        yref=\"paper\",\n",
    "        text=f\"Mean: {mean_score:.0f}\",\n",
    "        showarrow=False,\n",
    "        xanchor=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Calculate and display percentage of tickets with score >= 60\n",
    "    high_score_count = (df_merged[score_col] >= 60).sum()\n",
    "    total_count = df_merged[score_col].notnull().sum()\n",
    "    high_score_percentage = (high_score_count / total_count * 100) if total_count > 0 else 0\n",
    "    \n",
    "    # Add annotation for percentage\n",
    "    fig.add_annotation(\n",
    "        x=10,  # Position at x=10\n",
    "        y=0.95,\n",
    "        yref=\"paper\",\n",
    "        text=f\"≥ 60: {high_score_percentage:.1f}%\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=12),\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(54.93050847457627)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"solution_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tickets with web_search_helpfulness >= 60: 84.9%\n",
      "Percentage of tickets with total_score >= 60: 91.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Type</th>\n",
       "      <th>Count ≥ 60</th>\n",
       "      <th>Total with Scores</th>\n",
       "      <th>Percentage ≥ 60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Search Solution</td>\n",
       "      <td>1082</td>\n",
       "      <td>1275</td>\n",
       "      <td>84.862745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total (Maximum) Score</td>\n",
       "      <td>1160</td>\n",
       "      <td>1275</td>\n",
       "      <td>90.980392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score Type  Count ≥ 60  Total with Scores  Percentage ≥ 60\n",
       "0    Web Search Solution        1082               1275        84.862745\n",
       "1  Total (Maximum) Score        1160               1275        90.980392"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For web_search_helpfulness\n",
    "web_high_scores = df_merged[df_merged['web_search_helpfulness'] >= 60].shape[0]\n",
    "total_with_web_scores = df_merged['web_search_helpfulness'].notnull().sum()\n",
    "web_high_percentage = (web_high_scores / total_with_web_scores * 100) if total_with_web_scores > 0 else 0\n",
    "\n",
    "# For total_score\n",
    "total_high_scores = df_merged[df_merged['total_score'] >= 60].shape[0]\n",
    "total_with_total_scores = df_merged['total_score'].notnull().sum()\n",
    "total_high_percentage = (total_high_scores / total_with_total_scores * 100) if total_with_total_scores > 0 else 0\n",
    "\n",
    "print(f\"Percentage of tickets with web_search_helpfulness >= 60: {web_high_percentage:.1f}%\")\n",
    "print(f\"Percentage of tickets with total_score >= 60: {total_high_percentage:.1f}%\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary_df = pd.DataFrame({\n",
    "    'Score Type': ['Web Search Solution', 'Total (Maximum) Score'],\n",
    "    'Count ≥ 60': [web_high_scores, total_high_scores],\n",
    "    'Total with Scores': [total_with_web_scores, total_with_total_scores],\n",
    "    'Percentage ≥ 60': [web_high_percentage, total_high_percentage]\n",
    "})\n",
    "\n",
    "# Display the summary with rounded percentages\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_suggested_helpfulness = df[\"suggested_helpfulness\"].mean()\n",
    "# median_suggested_helpfulness = df[\"suggested_helpfulness\"].median()\n",
    "# mean_web_search_helpfulness = df[\"web_search_helpfulness\"].mean()\n",
    "# median_web_search_helpfulness = df[\"web_search_helpfulness\"].median()\n",
    "\n",
    "# print(f\"Mean suggested helpfulness: {mean_suggested_helpfulness:.0f}\")\n",
    "# print(f\"Median suggested helpfulness: {median_suggested_helpfulness:.0f}\")\n",
    "# print(f\"Mean web search helpfulness: {mean_web_search_helpfulness:.0f}\")\n",
    "# print(f\"Median web search helpfulness: {median_web_search_helpfulness:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for score_col in score_cols:\n",
    "#     # Skip if no data\n",
    "#     if df[score_col].notnull().sum() == 0:\n",
    "#         print(f\"No data for {nice_names[score_col]}\")\n",
    "#         continue\n",
    "        \n",
    "#     median_score = df[score_col].median()\n",
    "#     mean_score = df[score_col].mean()\n",
    "    \n",
    "#     # Define exact bin edges\n",
    "#     bin_edges = list(range(0, 101, 10))  # 0, 10, 20, ... 100\n",
    "    \n",
    "#     fig = px.histogram(\n",
    "#         df[score_col].dropna(),  # Drop NA values to avoid errors\n",
    "#         title=f\"Distribution of {nice_names[score_col]} Helpfulness Scores\",\n",
    "#         color_discrete_sequence=[COLORS[1]],\n",
    "#         histnorm=None,  # Count values\n",
    "#         nbins=None,  # We'll specify exact bins\n",
    "#         range_x=[0, 100],  # Range of x-axis\n",
    "#         **style_settings\n",
    "#     )\n",
    "    \n",
    "#     # Update the bin configuration\n",
    "#     fig.update_traces(xbins=dict(\n",
    "#         start=10,  # Start at 0\n",
    "#         end=100,  # End at 100\n",
    "#         size=10   # Bin width of 10\n",
    "#     ))\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         showlegend=False,\n",
    "#         xaxis_title=\"Score\",\n",
    "#         yaxis_title=\"Count\"\n",
    "#     )\n",
    "    \n",
    "#     # Add vertical line for mean with improved visibility\n",
    "#     fig.add_shape(\n",
    "#         type=\"line\",\n",
    "#         x0=mean_score,\n",
    "#         y0=0,\n",
    "#         x1=mean_score,\n",
    "#         y1=1,\n",
    "#         yref=\"paper\",\n",
    "#         line=dict(\n",
    "#             color=\"black\",\n",
    "#             width=2,\n",
    "#             dash=\"dash\",\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     # Add annotation\n",
    "#     fig.add_annotation(\n",
    "#         x=mean_score,\n",
    "#         y=1.05,\n",
    "#         yref=\"paper\",\n",
    "#         text=f\"Mean: {mean_score:.0f}\",\n",
    "#         showarrow=False,\n",
    "#         xanchor=\"left\"\n",
    "#     )\n",
    "    \n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a scatter plot\n",
    "# fig = px.scatter(\n",
    "#     df.dropna(subset=['suggested_helpfulness', 'web_search_helpfulness']),\n",
    "#     x='suggested_helpfulness',\n",
    "#     y='web_search_helpfulness',\n",
    "#     title='Comparison of Solution Helpfulness Scores',\n",
    "#     color_discrete_sequence=[COLORS[0]],\n",
    "#     width=PLOT_HEIGHT,\n",
    "#     height=PLOT_HEIGHT,\n",
    "#     # **style_settings\n",
    "\n",
    "# )\n",
    "\n",
    "# # Add a diagonal reference line (y=x)\n",
    "# fig.add_shape(\n",
    "#     type=\"line\",\n",
    "#     x0=0, y0=0,\n",
    "#     x1=100, y1=100,\n",
    "#     line=dict(color=\"gray\", width=2, dash=\"dash\")\n",
    "# )\n",
    "\n",
    "# # Add annotation for the reference line\n",
    "# fig.add_annotation(\n",
    "#     x=90, y=90,\n",
    "#     text=\"equal scores\",\n",
    "#     showarrow=False,\n",
    "#     font=dict(color=\"gray\")\n",
    "# )\n",
    "\n",
    "# # Calculate and add correlation coefficient\n",
    "# correlation = df['suggested_helpfulness'].corr(df['web_search_helpfulness'])\n",
    "# fig.add_annotation(\n",
    "#     x=20, y=90,\n",
    "#     text=f\"Correlation: {correlation:.2f}\",\n",
    "#     showarrow=False,\n",
    "#     font=dict(color=\"black\")\n",
    "# )\n",
    "\n",
    "# # Improve layout\n",
    "# fig.update_layout(\n",
    "#     xaxis_title=\"Suggested Solution Helpfulness Score\",\n",
    "#     yaxis_title=\"Web Search Solution Helpfulness Score\",\n",
    "#     xaxis=dict(range=[0, 100]),\n",
    "#     yaxis=dict(range=[0, 100])\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tickets with suggested_helpfulness >= 60: 90.4%\n",
      "Percentage of tickets with web_search_helpfulness >= 60: 84.9%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Type</th>\n",
       "      <th>Percentage ≥ 60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suggested Solution</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Web Search Solution</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Score Type  Percentage ≥ 60\n",
       "0   Suggested Solution             90.4\n",
       "1  Web Search Solution             84.9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For suggested_helpfulness\n",
    "suggested_high_scores = df[df['suggested_helpfulness'] >= 60].shape[0]\n",
    "total_with_suggested_scores = df['suggested_helpfulness'].notnull().sum()\n",
    "suggested_high_percentage = (suggested_high_scores / total_with_suggested_scores * 100) if total_with_suggested_scores > 0 else 0\n",
    "\n",
    "# For web_search_helpfulness\n",
    "web_high_scores = df[df['web_search_helpfulness'] >= 60].shape[0]\n",
    "total_with_web_scores = df['web_search_helpfulness'].notnull().sum()\n",
    "web_high_percentage = (web_high_scores / total_with_web_scores * 100) if total_with_web_scores > 0 else 0\n",
    "\n",
    "print(f\"Percentage of tickets with suggested_helpfulness >= 60: {suggested_high_percentage:.1f}%\")\n",
    "print(f\"Percentage of tickets with web_search_helpfulness >= 60: {web_high_percentage:.1f}%\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary_df = pd.DataFrame({\n",
    "    'Score Type': ['Suggested Solution', 'Web Search Solution'],\n",
    "    'Percentage ≥ 60': [suggested_high_percentage, web_high_percentage]\n",
    "})\n",
    "\n",
    "summary_df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Suggested Priority: %{x}<br>Actual Priority: %{y}<br>Percentage: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.1f}",
         "type": "heatmap",
         "x": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "xaxis": "x",
         "y": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "tStRuxK1P0BkcD4G52MoQNWuRO1K1EpAg/MxOB+DA0BSSF/zVAoRQMYsR36umD1AbmDUmcYNT0AmAeFEvCQQQCD96Ec/+tE/f/SjH/3oFUBiDnOYw5xWQCYrWclKVg5AAAAAAAAAAABDeQ3lNZQPQF9DeQ3ltUVADeU1lNdQSkA=",
          "dtype": "f8",
          "shape": "4, 4"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Percentage"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "showscale": false
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Priorities Heatmap (% of actual)"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Suggested Priority"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Actual Priority"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority agreement rate: 65.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Source=suggested_priority<br>Priority=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "suggested_priority",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "suggested_priority",
         "offsetgroup": "suggested_priority",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P1",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P4",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P2",
          "P4",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P1",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P1",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P4",
          "P2",
          "P3",
          "P4",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3"
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Source=actual_priority<br>Priority=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "actual_priority",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "actual_priority",
         "offsetgroup": "actual_priority",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          "P1",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P4",
          "P2",
          "P3",
          "P2",
          "P3",
          "P1",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P4",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P2",
          "P3",
          "P2",
          "P2",
          "P1",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P4",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P1",
          "P4",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P4",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P4",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P4",
          "P4",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P4",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P1",
          "P4",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P2",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P1",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P1",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P4",
          "P4",
          "P2",
          "P2",
          "P3",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P4",
          "P2",
          "P2",
          "P4",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P1",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P4",
          "P2",
          "P1",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P2",
          "P1",
          "P2",
          "P2",
          "P4",
          "P2",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P1",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P2",
          "P2",
          "P3",
          "P2",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P1",
          "P2",
          "P4",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P4",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P3",
          "P1",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P1",
          "P3",
          "P4",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P4",
          "P2",
          "P3",
          "P4",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P1",
          "P2",
          "P2",
          "P2",
          "P4",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P4",
          "P4",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P4",
          "P3",
          "P1",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P4",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P1",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P2",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P3",
          "P2",
          "P2",
          "P3",
          "P3",
          "P3"
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 500,
        "legend": {
         "title": {
          "text": "Source"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Distribution of Priority Levels"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Priority Level"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a cross-tabulation of the priorities\n",
    "priority_comparison = pd.crosstab(\n",
    "    df['actual_priority'], \n",
    "    df['suggested_priority'],\n",
    "    normalize='index'  # Normalize by row to show percentages\n",
    ") * 100  # Convert to percentage\n",
    "\n",
    "# Create a heatmap\n",
    "fig = px.imshow(\n",
    "    priority_comparison,\n",
    "    text_auto='.1f',  # Show 1 decimal place\n",
    "    color_continuous_scale=px.colors.sequential.Blues,\n",
    "    title='Priorities Heatmap (% of actual)',\n",
    "    labels=dict(x=\"Suggested Priority\", y=\"Actual Priority\", color=\"Percentage\"),\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "# Update layout - hide the color scale legend\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Suggested Priority\",\n",
    "    yaxis_title=\"Actual Priority\",\n",
    "    coloraxis_showscale=False  # This line hides the color scale legend\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Additionally, create a simple agreement percentage\n",
    "agreement = (df['suggested_priority'] == df['actual_priority']).mean() * 100\n",
    "print(f\"Priority agreement rate: {agreement:.1f}%\")\n",
    "\n",
    "# Create a bar chart showing counts by priority level\n",
    "fig2 = px.histogram(\n",
    "    pd.melt(\n",
    "        df, \n",
    "        value_vars=['suggested_priority', 'actual_priority'],\n",
    "        var_name='Source',\n",
    "        value_name='Priority'\n",
    "    ),\n",
    "    x='Priority',\n",
    "    color='Source',\n",
    "    barmode='group',\n",
    "    title='Distribution of Priority Levels',\n",
    "    color_discrete_map={\n",
    "        'suggested_priority': COLORS[1],  # orange\n",
    "        'actual_priority': COLORS[0]      # blue\n",
    "    },\n",
    "    category_orders={'Priority': ['P1', 'P2', 'P3', 'P4']},  # Set the custom order here\n",
    "    \n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "fig2.update_layout(\n",
    "    xaxis_title=\"Priority Level\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Suggested Priority: %{x}<br>Actual Priority: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "xaxis": "x",
         "y": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "DQAFABYAAQATAIQAFQESAAIAJwCEAhsAAAADACEAKAA=",
          "dtype": "i2",
          "shape": "4, 4"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "showscale": false
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Comparison of Suggested vs Actual Priorities (counts)"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Suggested Priority"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Actual Priority"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a cross-tabulation of the priorities with raw counts\n",
    "priority_comparison = pd.crosstab(\n",
    "    df['actual_priority'], \n",
    "    df['suggested_priority']\n",
    ")\n",
    "\n",
    "# Create a heatmap with raw counts\n",
    "fig = px.imshow(\n",
    "    priority_comparison,\n",
    "    text_auto=True,  # Show the exact counts\n",
    "    color_continuous_scale=px.colors.sequential.Blues,\n",
    "    title='Comparison of Suggested vs Actual Priorities (counts)',\n",
    "    labels=dict(x=\"Suggested Priority\", y=\"Actual Priority\"),\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "# Update layout - hide the color scale legend\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Suggested Priority\",\n",
    "    yaxis_title=\"Actual Priority\",\n",
    "    coloraxis_showscale=False  # Hide the color scale legend\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted priorities: 829 out of 1275 (65.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Priority=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "P1",
         "marker": {
          "color": "rgb(76,114,176)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "P1",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "P1"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "tStRuxK1P0A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Priority=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "P2",
         "marker": {
          "color": "rgb(221,132,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "P2",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "P2"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "xixHfq6YPUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Priority=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "P3",
         "marker": {
          "color": "rgb(85,168,104)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "P3",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "P3"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "Yg5zmMOcVkA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Priority=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "P4",
         "marker": {
          "color": "rgb(196,78,82)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "P4",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "P4"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "DeU1lNdQSkA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "white"
          },
          "showarrow": false,
          "text": "n=41.0",
          "x": "P1",
          "y": 15.853658536585366
         },
         {
          "font": {
           "color": "black"
          },
          "showarrow": false,
          "text": "n=446.0",
          "x": "P2",
          "y": 14.798206278026907
         },
         {
          "font": {
           "color": "white"
          },
          "showarrow": false,
          "text": "n=712.0",
          "x": "P3",
          "y": 45.2247191011236
         },
         {
          "font": {
           "color": "white"
          },
          "showarrow": false,
          "text": "n=76.0",
          "x": "P4",
          "y": 26.31578947368421
         }
        ],
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Priority"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "title": {
         "text": "Priority Prediction Accuracy by Priority Level"
        },
        "width": 500,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "P1",
          "P2",
          "P3",
          "P4"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Priority Level"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          100
         ],
         "title": {
          "text": "Accuracy (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "Predicted  P1   P2   P3  P4\n",
      "Actual                     \n",
      "P1         13    5   22   1\n",
      "P2         19  132  277  18\n",
      "P3          2   39  644  27\n",
      "P4          0    3   33  40\n"
     ]
    }
   ],
   "source": [
    "# Calculate correctly predicted priorities\n",
    "df['priority_correct'] = df['suggested_priority'] == df['actual_priority']\n",
    "\n",
    "# Count total matches and calculate percentage\n",
    "correct_count = df['priority_correct'].sum()\n",
    "total_count = df['priority_correct'].count()\n",
    "correct_percent = (correct_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "print(f\"Correctly predicted priorities: {correct_count} out of {total_count} ({correct_percent:.1f}%)\")\n",
    "\n",
    "# Calculate accuracy for each priority level\n",
    "priority_accuracy = pd.DataFrame({\n",
    "    'Priority': [],\n",
    "    'Accuracy': [],\n",
    "    'Count': []\n",
    "})\n",
    "\n",
    "for priority in ['P1', 'P2', 'P3', 'P4']:\n",
    "    # Filter for this priority level in actual data\n",
    "    priority_df = df[df['actual_priority'] == priority]\n",
    "    if len(priority_df) > 0:\n",
    "        correct = priority_df['priority_correct'].sum()\n",
    "        total = len(priority_df)\n",
    "        accuracy = (correct / total) * 100\n",
    "        \n",
    "        # Append to results dataframe\n",
    "        priority_accuracy = pd.concat([\n",
    "            priority_accuracy,\n",
    "            pd.DataFrame({\n",
    "                'Priority': [priority],\n",
    "                'Accuracy': [accuracy],\n",
    "                'Count': [total]\n",
    "            })\n",
    "        ])\n",
    "\n",
    "# Sort by priority order\n",
    "priority_accuracy['Priority'] = pd.Categorical(\n",
    "    priority_accuracy['Priority'], \n",
    "    categories=['P1', 'P2', 'P3', 'P4'],\n",
    "    ordered=True\n",
    ")\n",
    "priority_accuracy = priority_accuracy.sort_values('Priority')\n",
    "\n",
    "# Create bar chart of accuracy by priority level\n",
    "fig = px.bar(\n",
    "    priority_accuracy,\n",
    "    x='Priority',\n",
    "    y='Accuracy',\n",
    "    title='Priority Prediction Accuracy by Priority Level',\n",
    "    # text_auto='.1f',\n",
    "    color='Priority',\n",
    "    color_discrete_sequence=[COLORS[0], COLORS[1], COLORS[2], COLORS[3]],\n",
    "    **style_settings\n",
    ")\n",
    "\n",
    "# Add count as text on bars\n",
    "for i, row in priority_accuracy.iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=row['Priority'],\n",
    "        y=row['Accuracy'] / 2,  # Middle of the bar\n",
    "        text=f\"n={row['Count']}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"white\" if row['Accuracy'] > 30 else \"black\")\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Priority Level\",\n",
    "    yaxis_title=\"Accuracy (%)\",\n",
    "    yaxis=dict(range=[0, 100]),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Optional: Create confusion matrix\n",
    "confusion = pd.crosstab(\n",
    "    df['actual_priority'], \n",
    "    df['suggested_priority'],\n",
    "    rownames=['Actual'], \n",
    "    colnames=['Predicted']\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No solutions\n",
    "what caused there to be no solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 queries with null suggested_helpfulness scores\n",
      "\n",
      "Examples:\n",
      "\n",
      "----------------------------------------------------\n",
      "# New Voicemail from 16472896599 - Charlie Steele\n",
      "\n",
      "## On 2024-09-30T13:26:56Z, Scout Voicemail wrote a note (2272054):\n",
      "You have received a new voice mail from \"16472896599 - Charlie Steele\"\n",
      "\n",
      "From: 16472896599 \n",
      "To: \"9798\" - \"Emergency\" \"VM\"\n",
      "Received:\"Monday, September 30, 2024 6:26:11 AM\"\n",
      "Duration:\"00:00:23\"\t\n",
      "File:\"vmail_16472896599_9798_20240930132611\"\n",
      "\n",
      "Transcription:\n",
      "Hello, my name is Charlie Steele calling from Excel battery company. I got a new laptop last week, and I'm having issues just doing some setup. Can you please give me a call? My phone number is 647-289-6599. Thank you very much. Bye.\n",
      "\n",
      "## On 2024-09-30T13:27:38Z, OpsGenie wrote a note (2272055):\n",
      "[OpsGenie] Kurtis Johnson acknowledged alert: \"Ticket#986176/Excell Battery Company/New Voicemail from 16472896599 - Charlie Steele\" (URL removed)\n",
      "\n",
      "----------------------------------------------------\n",
      "# Network connection getting disconnect\n",
      "\n",
      "## On 2024-09-09T20:40:00Z, Alberto Rincon wrote a time_entry (980314):\n",
      "-Get a call from Manjit\n",
      "-Her computer is connecting and disconnecting\n",
      "-Remote to her computer \n",
      "-She is connected by WiFi\n",
      "-Also missing a bunch of update\n",
      "-Running update\n",
      "-Login out and login back\n",
      "-Connecting is back\n",
      "-All good for now\n",
      "-Closing this ticket\n",
      "\n",
      "## On 2024-09-09T20:43:41Z, ARincon wrote a note (2255961):\n",
      "Network connection getting disconnect\n",
      "\n",
      "----------------------------------------------------\n",
      "# Ronnie Deol - Home Directory not Mapped After Reboot\n",
      "\n",
      "## On 2024-10-21T18:59:55Z, Michael McQuigge wrote a note (2287500):\n",
      "#### How many people is this affecting?\n",
      "* One user\n",
      "\n",
      "#### Tip: Common issues may be resolved by restarting your computer.\n",
      "\n",
      "#### Is this a recurring issue?\n",
      "* Yes, This Has Happened Before\n",
      "\n",
      "#### Specific details about the problem/question?\n",
      "Hello Support,\n",
      "Ronnie has rebooted Win-PC-056 and her home directories (Desktop) are no longer mapping correctly and appear empty. \n",
      "\n",
      "Thank you,\n",
      "Michael\n",
      "\n",
      "#### What is the best way to contact you about your issue?\n",
      "* Email\n",
      "\n",
      "## On 2024-10-21T19:17:28Z, Michael McQuigge wrote a note (2287515):\n",
      "Issue remedied itself according to user.\n",
      "\n",
      "----------\n",
      "Ticket was closed by Michael McQuigge(mmcquigge@aacb.com)\n",
      "\n",
      "... and 43 more\n",
      "Found 0 queries with null web_search_helpfulness scores\n"
     ]
    }
   ],
   "source": [
    "for score_col in score_cols:\n",
    "    # Get tickets with null scores\n",
    "    null_score_tickets = df[df[score_col].isna()]\n",
    "    \n",
    "    # Make sure we use the correct column name for the query\n",
    "    # In the new structure it's 'user_query' instead of 'query'\n",
    "    null_score_queries = null_score_tickets['user_query'].tolist()\n",
    "\n",
    "    # Print the number of queries found and display some examples\n",
    "    print(f\"Found {len(null_score_queries)} queries with null {score_col} scores\")\n",
    "    \n",
    "    if len(null_score_queries) > 0:\n",
    "        print(\"\\nExamples:\")\n",
    "        # Limit the number of examples to avoid overwhelming output\n",
    "        for query in null_score_queries[:3]:  \n",
    "            print(f\"\\n----------------------------------------------------\\n{query}\")\n",
    "        \n",
    "        if len(null_score_queries) > 3:\n",
    "            print(f\"\\n... and {len(null_score_queries) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ticket_id': {48: 980759},\n",
       " 'contact_name': {48: 'Karen West'},\n",
       " 'user_query': {48: '# Unable to Login to Computer\\n\\n## On 2024-09-11T16:53:00Z, Brian Garcia wrote a time_entry (982000):\\n* Received call from Karen\\n* Mentioned shes been having issues connecting into her workstation\\n* Reviewed\\n* Looks like shes using a laptop at the moment\\n* Unable to find computer\\n* Checked with Techs\\n* Alberto available\\n* Transferred call\\n\\n## On 2024-09-11T16:55:00Z, Alberto Rincon wrote a time_entry (982001):\\n-Get a call from Karen\\n-Login to the server and reset her password\\n-She is able to login\\n-All set now\\n-Closing the ticket\\n\\n## On 2024-09-11T17:04:49Z, BGarcia wrote a note (2259091):\\nAssigned / ARincon / Over to you, thanks!'},\n",
       " 'user_history_overview': {48: 'Karen West frequently encounters issues related to accessing her workstation, software applications, and account credentials. The user has 4 previous tickets.'},\n",
       " 'user_similar_tickets': {48: [980759, 913982]},\n",
       " 'recurring_issue': {48: True},\n",
       " 'recurring_issue_cause': {48: 'The recurring issue appears to be related to difficulties with account credentials and accessing systems, potentially due to password management challenges.'},\n",
       " 'suggested_type': {48: 'User'},\n",
       " 'suggested_subtype': {48: 'Password'},\n",
       " 'suggested_item': {48: 'Change'},\n",
       " 'suggested_priority': {48: 'P3'},\n",
       " 'suggested_solution': {48: \"Suggested steps: Reset the user's password and ensure they can log in successfully. (based on tickets: #968108)\"},\n",
       " 'suggested_helpfulness': {48: 80.0},\n",
       " 'suggested_analysis': {48: \"The suggested solution of resetting the user's password is indeed relevant and directly addresses the core issue of the user being unable to log in to her workstation. In the actual solution, the technician confirmed that resetting the password was the effective step taken to resolve the login issue. Therefore, the suggested solution would likely have resolved the same issue, as it aligns with the actions taken in the actual solution.\\n\\nHowever, the suggested solution lacks some context that was present in the actual solution. For instance, the actual solution involved logging into the server to reset the password, which may imply that there were additional steps or considerations involved in the process that were not mentioned in the suggested solution. This could be important for someone who might not have the necessary access or knowledge to perform the server login.\\n\\nOverall, the suggested solution is helpful and would have likely led to a successful resolution of the user's issue, but it does not encompass the full methodology used in the actual solution. Therefore, it is rated as a helpful solution with minor limitations.\"},\n",
       " 'web_search_solution': {48: 'Karen experienced login issues on her workstation, which were resolved by resetting her password. However, if similar issues arise in the future, the following steps can be taken:\\n\\n### Steps to try:\\n\\n1. **Restart the Computer**\\n   - A simple restart can often resolve login issues by refreshing system processes. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\\n\\n2. **Check Internet Connection**\\n   - Ensure the computer is connected to the internet, as some login issues can occur if the device cannot communicate with the domain controller. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\\n\\n3. **Verify Password Entry**\\n   - Confirm that Caps Lock is off and that the password is entered correctly. Using the on-screen keyboard can help rule out hardware issues. ([groovypost.com](https://www.groovypost.com/howto/fix-windows-not-accepting-password/?utm_source=openai))\\n\\n4. **Use Previous Password**\\n   - If the new password isn\\'t recognized, try logging in with the previous password. This can indicate if the password change has propagated through the system. ([bdwebit.com](https://bdwebit.com/blog/domain-user-cannot-login-to-computer-after-password-change/?utm_source=openai))\\n\\n5. **Connect to the Corporate Network**\\n   - If the computer is off the corporate network, connect it via Ethernet or VPN to ensure it can communicate with the domain controller and update credentials. ([bdwebit.com](https://bdwebit.com/blog/domain-user-cannot-login-to-computer-after-password-change/?utm_source=openai))\\n\\n6. **Boot into Safe Mode**\\n   - Starting the computer in Safe Mode can help identify if background processes are causing login issues. To do this, restart the computer and hold the Shift key while selecting \"Restart\" to access Advanced Startup Options. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\\n\\n7. **Run System File Checker (SFC) and DISM Scans**\\n   - Corrupted system files can cause login problems. Running SFC and DISM scans can repair these files. Open Command Prompt as an administrator and run `sfc /scannow` followed by `DISM /Online /Cleanup-Image /RestoreHealth`. ([minitool.com](https://www.minitool.com/data-recovery/troubleshoot-problems-signing-into-windows.html?utm_source=openai))\\n\\n8. **Create a New User Profile**\\n   - If the user profile is corrupted, creating a new one can resolve login issues. This involves creating a new local administrator account and transferring files from the old profile. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\\n\\nImplementing these steps can help diagnose and resolve login issues effectively. '},\n",
       " 'web_search_helpfulness': {48: 61},\n",
       " 'web_search_analysis': {48: \"The web search solution provides a comprehensive set of troubleshooting steps for login issues, which could be beneficial in a variety of scenarios. However, it does not directly address the specific issue Karen faced, which was a password-related problem that was resolved by resetting her password on the server. \\n\\n1. **Helpfulness of the Web Search Solution**: The web search solution would have been moderately helpful for resolving the user's issue. It offers a range of troubleshooting steps that could potentially help in diagnosing and fixing login problems, but it lacks the direct approach of resetting the password, which was the actual solution applied.\\n\\n2. **Likelihood of Resolving the Same Issue**: While the web search solution includes steps that might help in other login scenarios, it would not have resolved Karen's specific issue of being unable to log in due to a password problem. The steps provided could lead to a longer troubleshooting process without addressing the root cause directly.\\n\\n3. **Key Differences in Methodology or Effectiveness**: The actual solution was straightforward and effective, involving a direct password reset, which is often the quickest way to resolve login issues related to credentials. In contrast, the web search solution suggests multiple steps that may not be necessary if the password reset is the core issue. This could lead to unnecessary delays in resolving the user's problem.\\n\\n4. **Useful Information Not in the Actual Solution**: The web search solution does provide additional context and troubleshooting steps that could be useful for future reference, such as checking internet connectivity, verifying password entry, and booting into Safe Mode. These steps could be beneficial in cases where the login issue is not related to a password, thus adding value beyond the immediate solution.\\n\\nOverall, while the web search solution is informative and could help in various scenarios, it does not directly address the specific issue Karen faced, leading to a moderate helpfulness score.\"},\n",
       " 'actual_type': {48: 'Workstation'},\n",
       " 'actual_subtype': {48: None},\n",
       " 'actual_item': {48: None},\n",
       " 'actual_priority': {48: 'P3'},\n",
       " 'actual_solution': {48: \"The actual problem was that the user was unable to log in to her workstation. To resolve the issue, the technician logged into the server and reset the user's password. After the password reset, the user was able to successfully log in to her computer.\"},\n",
       " 'priority_correct': {48: True}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"ticket_id\"]== 980759].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details for ticket 980759:\n",
      "ticket_id: 980759\n",
      "contact_name: Karen West\n",
      "user_query: # Unable to Login to Computer\n",
      "\n",
      "## On 2024-09-11T16:53:00Z, Brian Garcia wrote a time_entry (982000):\n",
      "* Received call from Karen\n",
      "* Mentioned shes been having issues connecting into her workstation\n",
      "* Reviewed\n",
      "* Looks like shes using a laptop at the moment\n",
      "* Unable to find computer\n",
      "* Checked with Techs\n",
      "* Alberto available\n",
      "* Transferred call\n",
      "\n",
      "## On 2024-09-11T16:55:00Z, Alberto Rincon wrote a time_entry (982001):\n",
      "-Get a call from Karen\n",
      "-Login to the server and reset her password\n",
      "-She is able to login\n",
      "-All set now\n",
      "-Closing the ticket\n",
      "\n",
      "## On 2024-09-11T17:04:49Z, BGarcia wrote a note (2259091):\n",
      "Assigned / ARincon / Over to you, thanks!\n",
      "user_history_overview: Karen West frequently encounters issues related to accessing her workstation, software applications, and account credentials. The user has 4 previous tickets.\n",
      "user_similar_tickets: [980759, 913982]\n",
      "recurring_issue: True\n",
      "recurring_issue_cause: The recurring issue appears to be related to difficulties with account credentials and accessing systems, potentially due to password management challenges.\n",
      "suggested_type: User\n",
      "suggested_subtype: Password\n",
      "suggested_item: Change\n",
      "suggested_priority: P3\n",
      "suggested_solution: Suggested steps: Reset the user's password and ensure they can log in successfully. (based on tickets: #968108)\n",
      "suggested_helpfulness: 80.0\n",
      "suggested_analysis: The suggested solution of resetting the user's password is indeed relevant and directly addresses the core issue of the user being unable to log in to her workstation. In the actual solution, the technician confirmed that resetting the password was the effective step taken to resolve the login issue. Therefore, the suggested solution would likely have resolved the same issue, as it aligns with the actions taken in the actual solution.\n",
      "\n",
      "However, the suggested solution lacks some context that was present in the actual solution. For instance, the actual solution involved logging into the server to reset the password, which may imply that there were additional steps or considerations involved in the process that were not mentioned in the suggested solution. This could be important for someone who might not have the necessary access or knowledge to perform the server login.\n",
      "\n",
      "Overall, the suggested solution is helpful and would have likely led to a successful resolution of the user's issue, but it does not encompass the full methodology used in the actual solution. Therefore, it is rated as a helpful solution with minor limitations.\n",
      "web_search_solution: Karen experienced login issues on her workstation, which were resolved by resetting her password. However, if similar issues arise in the future, the following steps can be taken:\n",
      "\n",
      "### Steps to try:\n",
      "\n",
      "1. **Restart the Computer**\n",
      "   - A simple restart can often resolve login issues by refreshing system processes. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\n",
      "\n",
      "2. **Check Internet Connection**\n",
      "   - Ensure the computer is connected to the internet, as some login issues can occur if the device cannot communicate with the domain controller. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\n",
      "\n",
      "3. **Verify Password Entry**\n",
      "   - Confirm that Caps Lock is off and that the password is entered correctly. Using the on-screen keyboard can help rule out hardware issues. ([groovypost.com](https://www.groovypost.com/howto/fix-windows-not-accepting-password/?utm_source=openai))\n",
      "\n",
      "4. **Use Previous Password**\n",
      "   - If the new password isn't recognized, try logging in with the previous password. This can indicate if the password change has propagated through the system. ([bdwebit.com](https://bdwebit.com/blog/domain-user-cannot-login-to-computer-after-password-change/?utm_source=openai))\n",
      "\n",
      "5. **Connect to the Corporate Network**\n",
      "   - If the computer is off the corporate network, connect it via Ethernet or VPN to ensure it can communicate with the domain controller and update credentials. ([bdwebit.com](https://bdwebit.com/blog/domain-user-cannot-login-to-computer-after-password-change/?utm_source=openai))\n",
      "\n",
      "6. **Boot into Safe Mode**\n",
      "   - Starting the computer in Safe Mode can help identify if background processes are causing login issues. To do this, restart the computer and hold the Shift key while selecting \"Restart\" to access Advanced Startup Options. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\n",
      "\n",
      "7. **Run System File Checker (SFC) and DISM Scans**\n",
      "   - Corrupted system files can cause login problems. Running SFC and DISM scans can repair these files. Open Command Prompt as an administrator and run `sfc /scannow` followed by `DISM /Online /Cleanup-Image /RestoreHealth`. ([minitool.com](https://www.minitool.com/data-recovery/troubleshoot-problems-signing-into-windows.html?utm_source=openai))\n",
      "\n",
      "8. **Create a New User Profile**\n",
      "   - If the user profile is corrupted, creating a new one can resolve login issues. This involves creating a new local administrator account and transferring files from the old profile. ([support.microsoft.com](https://support.microsoft.com/en-us/windows/troubleshoot-problems-signing-in-to-windows-298cfd5f-df1f-c66b-36ad-f2a61a73baad?utm_source=openai))\n",
      "\n",
      "Implementing these steps can help diagnose and resolve login issues effectively. \n",
      "web_search_helpfulness: 61\n",
      "web_search_analysis: The web search solution provides a comprehensive set of troubleshooting steps for login issues, which could be beneficial in a variety of scenarios. However, it does not directly address the specific issue Karen faced, which was a password-related problem that was resolved by resetting her password on the server. \n",
      "\n",
      "1. **Helpfulness of the Web Search Solution**: The web search solution would have been moderately helpful for resolving the user's issue. It offers a range of troubleshooting steps that could potentially help in diagnosing and fixing login problems, but it lacks the direct approach of resetting the password, which was the actual solution applied.\n",
      "\n",
      "2. **Likelihood of Resolving the Same Issue**: While the web search solution includes steps that might help in other login scenarios, it would not have resolved Karen's specific issue of being unable to log in due to a password problem. The steps provided could lead to a longer troubleshooting process without addressing the root cause directly.\n",
      "\n",
      "3. **Key Differences in Methodology or Effectiveness**: The actual solution was straightforward and effective, involving a direct password reset, which is often the quickest way to resolve login issues related to credentials. In contrast, the web search solution suggests multiple steps that may not be necessary if the password reset is the core issue. This could lead to unnecessary delays in resolving the user's problem.\n",
      "\n",
      "4. **Useful Information Not in the Actual Solution**: The web search solution does provide additional context and troubleshooting steps that could be useful for future reference, such as checking internet connectivity, verifying password entry, and booting into Safe Mode. These steps could be beneficial in cases where the login issue is not related to a password, thus adding value beyond the immediate solution.\n",
      "\n",
      "Overall, while the web search solution is informative and could help in various scenarios, it does not directly address the specific issue Karen faced, leading to a moderate helpfulness score.\n",
      "actual_type: Workstation\n",
      "actual_subtype: None\n",
      "actual_item: None\n",
      "actual_priority: P3\n",
      "actual_solution: The actual problem was that the user was unable to log in to her workstation. To resolve the issue, the technician logged into the server and reset the user's password. After the password reset, the user was able to successfully log in to her computer.\n",
      "priority_correct: True\n"
     ]
    }
   ],
   "source": [
    "# For a single row by ticket ID\n",
    "ticket_id = 980759\n",
    "row = df.loc[df[\"ticket_id\"] == ticket_id]\n",
    "\n",
    "if not row.empty:\n",
    "    # Convert the first (and presumably only) row to a dictionary\n",
    "    row_dict = row.iloc[0].to_dict()\n",
    "    \n",
    "    # Print each key-value pair on its own line\n",
    "    print(f\"Details for ticket {ticket_id}:\")\n",
    "    for key, value in row_dict.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(f\"No ticket found with ID {ticket_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
```
## File: experiment/ticket_annotation_experiment.py
```python
import os
import logging
import json
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pydantic import BaseModel, Field

from database import AuthenticatedPostgresClient
from ticket_database import TicketDatabase
from app.ticket_annotator import TicketAnnotator
from llm import get_llm_provider

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set the log level for the ticket_annotator module to WARNING
logging.getLogger("app.ticket_annotator").setLevel(logging.WARNING)

# Constants
USERNAME = "helpdesk_agent"
SELECT_RELEVANT_MODEL_NAME = "gpt-4o-mini"
FAILED_SUGGESTED_SOLUTION = "Unable to generate solution due to classification error."

class TicketAnnotationExperiment:
    """
    Experiment to validate the ticket annotation system against actual solutions.
    
    This class:
    1. Retrieves tickets from a specific date range
    2. Processes them with the TicketAnnotator
    3. Retrieves actual solutions from closed tickets
    4. Compares suggested solutions with actual solutions using LLM evaluation
    5. Saves results to disk for analysis
    """
    
    def __init__(
        self,
        db_client: AuthenticatedPostgresClient = None,
        username: str = USERNAME,
        simultaneous_requests: int = 10,
        model_name: str = "gpt-4o-2024-11-20",
    ):
        """
        Initialize the TicketAnnotationExperiment.
        
        Args:
            db_client: Database client for retrieving ticket data
            username: Username for database operations
            simultaneous_requests: Maximum number of concurrent requests
            model_name: Model to use for evaluations
        """
        self.db_client = db_client
        self.username = username
        self.simultaneous_requests = simultaneous_requests
        self.ticket_db = None  # Will be initialized in create() method
        self.annotator = None  # Will be initialized in run_experiment
        self.save_folder = None  # Will be set in run_experiment
        self.llm_provider = get_llm_provider(model_name, database_client=self.db_client)
    
    @classmethod
    async def create(
        cls,
        db_client: AuthenticatedPostgresClient = None,
        username: str = USERNAME,
        simultaneous_requests: int = 10,
        model_name: str = "gpt-4o-2024-11-20",
    ):
        """
        Create and initialize a new TicketAnnotationExperiment.
        
        This factory method handles all asynchronous initialization.
        
        Args:
            db_client: Database client for retrieving ticket data
            username: Username for database operations
            simultaneous_requests: Maximum number of concurrent requests
            model_name: Model to use for evaluations
            
        Returns:
            TicketAnnotationExperiment: Initialized instance
        """
        # Create instance with default initialization
        instance = cls(db_client, username, simultaneous_requests, model_name)
        
        # Create and initialize the ticket database
        ticket_db = await TicketDatabase.create(instance.db_client, username)
        instance.ticket_db = ticket_db
        
        return instance

    async def _get_first_last_ticket_ids(self, start_date: str, end_date: str) -> tuple[int, int]:
        """
        Get the first and last ticket IDs within a date range.
        
        Args:
            start_date: Start date in format YYYY-MM-DD
            end_date: End date in format YYYY-MM-DD
            
        Returns:
            tuple[int, int]: First and last ticket IDs in the range
        """
        try:
            return await self.ticket_db.find_tickets_in_date_range(start_date, end_date)
        except Exception as e:
            logger.error(f"Error getting first/last ticket IDs: {str(e)}")
            return (0, 0)
            
    async def _get_ticket_ids(self, start_id: int, end_id: int) -> List[int]:
        """
        Get a list of ticket IDs between start_id and end_id.
        
        Args:
            start_id: Starting ticket ID
            end_id: Ending ticket ID
            
        Returns:
            List[int]: List of ticket IDs in the range
        """
        if start_id <= 0 or end_id <= 0 or start_id > end_id:
            logger.warning(f"Invalid ID range: {start_id} to {end_id}")
            return []
            
        try:
            return await self.ticket_db.get_ticket_ids_in_range(start_id, end_id)
        except Exception as e:
            logger.error(f"Error getting ticket IDs in range: {str(e)}")
            return []
            
    async def _get_ticket_with_content(self, ticket_id: int) -> Dict[str, Any]:
        """
        Get a ticket by ID with complete content.
        
        Args:
            ticket_id: ID of the ticket to retrieve
            
        Returns:
            Dict[str, Any]: Ticket data with full content
        """
        try:
            return await self.ticket_db.get_ticket_with_content(ticket_id)
        except Exception as e:
            logger.error(f"Error getting ticket {ticket_id}: {str(e)}")
            return None
        

    async def _evaluate_solution(self, 
                                 user_request: str, 
                                 suggested_solution: str, 
                                 actual_solution: str, 
                                 observability_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Evaluate how helpful the suggested solution would have been compared to the actual solution.
        
        Args:
            user_request (str): The original user request/query
            suggested_solution (str): The solution suggested by the classification model
            actual_solution (str): The actual solution that was applied to resolve the ticket
            observability_info (Dict[str, Any]): Observability information for logging
            
        Returns:
            Dict[str, Any]: Evaluation results including helpfulness score and analysis
        """
        if not suggested_solution or not actual_solution or suggested_solution == FAILED_SUGGESTED_SOLUTION:
            logger.debug("Cannot evaluate solutions: missing suggested or actual solution")
            return {
                "helpfulness_score": None,
                "analysis": "Cannot evaluate due to missing solution data"
            }
        
        # Prepare prompt for LLM
        prompt = f"""
You are an IT support expert evaluating the helpfulness of a suggested solution compared to the actual solution that was applied. Note that the suggested solution is based on the user's request and may not have complete information that was available at the time it was made. The actual solution might be based on more information that the IT team got from the user.  

<user_request>
{user_request}
</user_request>

<suggested_solution>
{suggested_solution}
</suggested_solution>

<actual_solution>
{actual_solution}
</actual_solution>

Analyze both solutions and evaluate:
1. How helpful the suggested solution would have been for resolving the user's issue
2. Whether the suggested solution would likely have resolved the same issue
3. Any key differences in methodology or effectiveness

Provide a detailed analysis and a helpfulness score from 1-5 where:
1. Completely Unhelpful:
- Addresses an entirely different issue
- Would mislead the tech or waste their time
- No overlap with the actual solution approach
2. Minimally Helpful:
- Identifies part of the problem but misses key aspects
- Contains some relevant information but wrong overall approach
- Would require the tech to largely discard and restart troubleshooting
3. Moderately Helpful:
- Correctly identifies the main problem
- Points the tech in the right general direction
- Would save time but still requires significant additional troubleshooting
4. Very Helpful:
- Covers most aspects of the actual solution
- Contains the key steps needed to resolve the issue
- Tech would need to make small adjustments or additions
5. Exceptional Match:
- Nearly identical to the actual solution in approach and content
- Would fully resolve the issue with minimal modification
- Any differences are minor variations that would achieve the same result

"""

        class SolutionEvaluation(BaseModel):
            helpfulness_score: int = Field(description="A score from 1-5 indicating how helpful the suggested solution would have been")
            analysis: str = Field(description="A short analysis explaining the helpfulness and limitations of the suggested solution compared to the actual solution (max 100 words)")
            actual_solution_complete: bool = Field(description="Whether the actual solution is complete and addresses the user's issue")
            
        try:
            # Use a smaller model for this evaluation task
            response = await self.llm_provider.get_response(
                prompt,
                config = {"temperature": 0.1, "model": SELECT_RELEVANT_MODEL_NAME},
                response_format = SolutionEvaluation,
                observability_info = observability_info
            )
            
            return {
                "helpfulness_score": response.helpfulness_score,
                "analysis": response.analysis,
                "actual_solution_complete": response.actual_solution_complete
            }
            
        except Exception as e:
            logger.error(f"Error evaluating solutions: {str(e)}")
            logger.exception("Full traceback:")
            return {
                "helpfulness_score": 0,
                "analysis": "Unable to evaluate the solutions due to an error."
            }

#     async def _evaluate_web_search_solution(self, user_request: str, web_search_solution: str, actual_solution: str, observability_info: Dict[str, Any]) -> Dict[str, Any]:
#         """
#         Evaluate how helpful the web search solution would have been compared to the actual solution.
        
#         Args:
#             user_request (str): The original user request/query
#             web_search_solution (str): The solution suggested by web search
#             actual_solution (str): The actual solution that was applied to resolve the ticket
#             observability_info (Dict[str, Any]): Observability information for logging
            
#         Returns:
#             Dict[str, Any]: Evaluation results including helpfulness score and analysis
#         """
#         if not web_search_solution or not actual_solution or web_search_solution == "No solution found":
#             logger.debug("Cannot evaluate web search solution: missing web search or actual solution")
#             return {
#                 "helpfulness_score": None,
#                 "analysis": "Cannot evaluate due to missing solution data"
#             }
        
#         # Prepare prompt for LLM - similar to the regular evaluation but focused on web search solution
#         prompt = f"""
# You are an IT support expert evaluating the helpfulness of a solution found through web search compared to the actual solution that was applied. The web search solution may not have complete information about the specific system or environment.

# <user_request>
# {user_request}
# </user_request>

# <web_search_solution>
# {web_search_solution}
# </web_search_solution>

# <actual_solution>
# {actual_solution}
# </actual_solution>

# Analyze both solutions and evaluate:
# 1. How helpful the web search solution would have been for resolving the user's issue
# 2. Whether the web search solution would likely have resolved the same issue
# 3. Any key differences in methodology or effectiveness
# 4. Whether the web search solution provided useful information not in the actual solution

# Provide a detailed analysis and a helpfulness score from 0-100 where:
# - 0-20: Completely different approaches that address different issues
# - 21-40: Different approaches that might partially address the same issue
# - 41-60: Moderately helpful solution with some key limitations
# - 61-80: Helpful solution with minor limitations
# - 81-100: Highly effective solution that addresses the core issue
# """

#         class WebSearchEvaluation(BaseModel):
#             helpfulness_score: int = Field(description="A score from 0-100 indicating how helpful the web search solution would have been")
#             analysis: str = Field(description="A detailed analysis explaining the helpfulness and limitations of the web search solution compared to the actual solution")
            
#         try:
#             # Use a smaller model for this evaluation task
#             response = await self.llm_provider.get_response(
#                 prompt,
#                 config = {"temperature": 0.1, "model": SELECT_RELEVANT_MODEL_NAME},
#                 response_format = WebSearchEvaluation,
#                 observability_info = observability_info
#             )
            
#             return {
#                 "helpfulness_score": response.helpfulness_score,
#                 "analysis": response.analysis
#             }
            
#         except Exception as e:
#             logger.error(f"Error evaluating web search solution: {str(e)}")
#             logger.exception("Full traceback:")
#             return {
#                 "helpfulness_score": 0,
#                 "analysis": "Unable to evaluate the web search solution due to an error."
#             }

    async def _process_annotation_result(self, annotation_result: Dict[str, Any], save_folder: str) -> Dict[str, Any]:
        """
        Process a ticket annotation result, adding actual solution and evaluation.
        
        Args:
            annotation_result (Dict[str, Any]): Result from TicketAnnotator
            save_folder (str): Folder to save results
            
        Returns:
            Dict[str, Any]: Processed result with evaluation
        """
        if not annotation_result.get("success", False):
            logger.warning(f"Skipping failed annotation result for ticket {annotation_result.get('ticket_id')}")
            return annotation_result
            
        ticket_id = annotation_result.get("ticket_id")
        observability_info = {"ticket_id": ticket_id, "experiment": "ticket_annotation_validation"}
        
        try:
            # Get the complete ticket with content - use all messages for actual solution
            ticket = await self._get_ticket_with_content(ticket_id)
            if not ticket:
                logger.warning(f"Could not retrieve ticket {ticket_id} for evaluation")
                return annotation_result
                
            # Extract the user query from the annotation result
            user_query = annotation_result.get("user_query", "")
                
            # Generate a summary of the actual solution using complete ticket (not just initial messages)
            # actual_solution = await self._summarize_actual_solution(ticket, observability_info)

            # Get the actual solution from the ticket summary
            actual_solution = ticket.get("summary", "")
            
            # Get metadata from the ticket
            metadata = ticket.get("metadata", {})
            contact_name = metadata.get("contact_name")
            
            # Extract user history
            user_history = annotation_result.get("user_history")
                
            # Get classification and suggested solution
            classification = annotation_result.get("classification", {})
            suggested_solution = classification.get("suggested_solution", "")
            
            # Initialize the restructured result
            processed_result = {
                "ticket_id": ticket_id,
                "contact_name": contact_name,
                "user_query": user_query,  
            }
                
            # Add user_history if available
            if user_history:
                processed_result["user_history"] = user_history
                
            # Initialize suggested section with classification
            suggested_classification = {
                "type": classification.get("service_type", "Unknown"),
                "subtype": classification.get("subtype", "Unknown"),
                "item": classification.get("item", "Unknown"),
                "priority": classification.get("priority", "Unknown")
            }
            
            # Initialize suggested section
            suggested = {
                "classification": suggested_classification
            }
            
            # Evaluate suggested solution if both are available
            if suggested_solution and actual_solution:
                evaluation = await self._evaluate_solution(
                    user_query, 
                    suggested_solution, 
                    actual_solution,
                    observability_info
                )
                
                # Add solution with helpfulness score and analysis
                suggested["solution"] = {
                    "solution": suggested_solution,
                    "relevant_tickets": annotation_result.get("relevant_tickets", []),
                    "helpfulness_score": evaluation.get("helpfulness_score"),
                    "analysis": evaluation.get("analysis"),
                    "actual_solution_complete": evaluation.get("actual_solution_complete")
                }
            
            # Evaluate web search solution if available
            web_search_solution = annotation_result.get("web_search_solution", "")
            if web_search_solution and actual_solution:
                web_search_evaluation = await self._evaluate_solution(
                    user_query,
                    web_search_solution,
                    actual_solution,
                    observability_info
                )
                
                # Add web search solution with evaluation
                suggested["web_search_solution"] = {
                    "solution": web_search_solution,
                    "helpfulness_score": web_search_evaluation.get("helpfulness_score"),
                    "analysis": web_search_evaluation.get("analysis"),
                    "actual_solution_complete": web_search_evaluation.get("actual_solution_complete")
                }
            
            # Add the suggested section to the result
            processed_result["suggested"] = suggested
            
            # Add actual section
            actual_classification = {
                "type": metadata.get("type", "Unknown"),
                "subtype": metadata.get("subtype"),
                "item": metadata.get("item"),
                "priority": metadata.get("priority", "Unknown"),
                "solution": actual_solution,
            }
            
            processed_result["actual"] = {
                "classification": actual_classification
            }
            
            # Save processed result (silently)
            filepath = self._save_result(processed_result, save_folder)
            processed_result["saved_to"] = filepath
                
            return processed_result
                
        except Exception as e:
            logger.error(f"Error processing annotation result for ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return annotation_result
    
    def _save_result(self, result: Dict[str, Any], folder: str) -> str:
        """
        Save a result to a JSON file.
        
        Args:
            result (Dict[str, Any]): Result to save
            folder (str): Folder to save to
            
        Returns:
            str: Path to the saved file
        """
        try:
            ticket_id = result.get("ticket_id", "unknown")
            # Create folder if it doesn't exist
            os.makedirs(folder, exist_ok=True)
            
            # Create filename
            filename = f"{ticket_id}.json"
            filepath = os.path.join(folder, filename)
            
            # Save to file
            with open(filepath, "w") as f:
                json.dump(result, f, indent=4)
                
            # Use debug level instead of info to reduce console output
            logger.debug(f"Saved result for ticket {ticket_id} to {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error saving result for ticket {result.get('ticket_id', 'unknown')}: {str(e)}")
            logger.exception("Full traceback:")
            return None

    
    def _get_processed_ticket_ids(self, save_folder: str) -> set:
        """
        Check the save folder for existing processed ticket files.
        
        Args:
            save_folder (str): Folder where results are saved
            
        Returns:
            set: Set of ticket IDs that have already been processed
        """
        processed_ids = set()
        
        try:
            # Ensure the folder exists
            if not os.path.exists(save_folder):
                return processed_ids
                
            # Get all JSON files in the folder
            json_files = [f for f in os.listdir(save_folder) if f.endswith('.json') and f != "experiment_config.json" and not f.startswith("batch_summary_")]
            
            # Extract ticket IDs from filenames
            for filename in json_files:
                try:
                    ticket_id = filename.split('.')[0]  # Remove .json extension
                    # Only add if it's a valid ticket ID (numeric)
                    if ticket_id.isdigit():
                        processed_ids.add(int(ticket_id))
                except Exception:
                    continue
                    
            logger.info(f"Found {len(processed_ids)} already processed tickets in {save_folder}")
            return processed_ids
            
        except Exception as e:
            logger.error(f"Error checking for processed tickets: {str(e)}")
            logger.exception("Full traceback:")
            return processed_ids
            
    async def _process_ticket_complete(self, ticket_id: str, current_count: int, total_count: int) -> Dict[str, Any]:
        """
        Process a single ticket completely (annotation + evaluation) and save results
        
        Args:
            ticket_id (str): Ticket ID to process
            current_count (int): Current counter for this ticket
            total_count (int): Total number of tickets being processed
            
        Returns:
            Dict[str, Any]: The processed result or None if failed
        """
        try:
            # Annotate ticket directly with the ticket_id
            # Setting initial_messages_only to True ensures we're just using the initial query messages
            result = await self.annotator.annotate_ticket(
                ticket_input=ticket_id,
                initial_messages_only=True,
                lookback_only=True
            )
            # Process annotation result
            processed_result = await self._process_annotation_result(result, self.save_folder)
            
            # Single line progress output with counter
            logger.info(f"Successfully processed ticket {ticket_id} ({current_count}/{total_count})")
            return processed_result
                
        except Exception as e:
            logger.error(f"Error processing ticket {ticket_id}: {str(e)}")
            logger.exception("Full traceback:")
            return None
            
    async def run_experiment(self, 
                             start_date: str, 
                             end_date: str, 
                             save_folder: str = "ticket_data/experiment", 
                             simultaneous_requests: int = None,
                             ticket_ids: List[int] = None,
                             limit: int = None) -> List[Dict[str, Any]]:
        """
        Run the entire annotation experiment.
        
        Args:
            start_date (str): Start date in format YYYY-MM-DD
            end_date (str): End date in format YYYY-MM-DD
            save_folder (str): Folder to save results
            simultaneous_requests (int, optional): Override the default simultaneous requests value
            ticket_ids (List[int], optional): List of ticket IDs to process, overrides start_date and end_date
            limit (int, optional): Limit the number of tickets to process
        Returns:
            List[Dict[str, Any]]: List of minimal result summaries (ticket_id and success status)
        """
        # Use the provided simultaneous_requests value if given, otherwise use the instance value
        if simultaneous_requests is not None:
            self.simultaneous_requests = simultaneous_requests
            
        logger.info(f"Running experiment for tickets from {start_date} to {end_date} with {self.simultaneous_requests} simultaneous requests")
        
        # Set save_folder as an instance variable so it can be accessed by _process_ticket_complete
        self.save_folder = save_folder
            
        if ticket_ids:
            all_ticket_ids = ticket_ids
        else:
            # Get range of ticket IDs to process
            start_id, end_id = await self._get_first_last_ticket_ids(start_date, end_date)
            if start_id == 0 or end_id == 0:
                logger.warning(f"No tickets found between {start_date} and {end_date}")
                return []
            
            # Get all ticket IDs in range
            all_ticket_ids = await self._get_ticket_ids(start_id, end_id)

        # Get already processed ticket IDs and filter them out
        processed_ticket_ids = self._get_processed_ticket_ids(save_folder)
        original_count = len(all_ticket_ids)
        all_ticket_ids = [tid for tid in all_ticket_ids if int(tid) not in processed_ticket_ids]

        if limit:
            all_ticket_ids = all_ticket_ids[:limit]
            logger.info(f"Limiting to {limit} tickets")
        
        if len(processed_ticket_ids) > 0:
            logger.info(f"Skipping {len(processed_ticket_ids)} already processed tickets")
            logger.info(f"Original ticket count: {original_count}")
            logger.info(f"New ticket count:      {len(all_ticket_ids)}")
        
        total_tickets = len(all_ticket_ids)
        logger.info(f"Processing {total_tickets} tickets with {self.simultaneous_requests} concurrent requests")
        
        if total_tickets == 0:
            logger.info("No new tickets to process, exiting.")
            return []
        
        # Create and initialize the ticket annotator
        self.annotator = await TicketAnnotator.create(
            db_client=self.db_client,
            username=self.username,
            simultaneous_requests=self.simultaneous_requests
        )
        
        # Use a lightweight results list with just IDs and success status
        results = []
        semaphore = asyncio.Semaphore(self.simultaneous_requests)
        
        # Initialize counter
        counter = {
            "processed": 0,  # Number of tickets processed
            "total": total_tickets  # Total tickets to process
        }
        
        # Save the experiment configuration
        experiment_config = {
            "timestamp": datetime.now().isoformat(),
            "start_date": start_date,
            "end_date": end_date,
            "total_tickets": total_tickets,
            "ticket_ids": all_ticket_ids,
            "simultaneous_requests": self.simultaneous_requests
        }
        with open(os.path.join(save_folder, "experiment_config.json"), "w") as f:
            json.dump(experiment_config, f, indent=4)
        
        
        # Process each ticket with semaphore control for concurrency
        async def process_with_semaphore(ticket_id):
            async with semaphore:
                counter["processed"] += 1
                result = await self._process_ticket_complete(ticket_id, counter["processed"], counter["total"])
                if result:
                    has_suggested = "suggested" in result and result["suggested"] is not None
                    return {"ticket_id": result["ticket_id"], "success": has_suggested}
                return {"ticket_id": ticket_id, "success": False}
        
        # Create tasks for all tickets
        tasks = [process_with_semaphore(ticket_id) for ticket_id in all_ticket_ids]
        results = await asyncio.gather(*tasks)
        
        # Calculate success statistics
        successful_count = sum(1 for r in results if r.get("success", False))
        
        # Save final summary
        experiment_summary = {
            "completed_at": datetime.now().isoformat(),
            "total_tickets": total_tickets,
            "processed_tickets": total_tickets,
            "successful_tickets": successful_count,
            "success_rate": f"{successful_count/total_tickets:.2%}" if total_tickets else "0%",
        }
        
        with open(os.path.join(save_folder, "experiment_summary.json"), "w") as f:
            json.dump(experiment_summary, f, indent=4)
        
        logger.info(f"Experiment complete: {successful_count}/{total_tickets} tickets processed successfully")
        logger.info(f"Final results saved to {save_folder}")
        
        return results

async def main():
    """Run the annotation experiment."""
    start_date = "2025-02-01"
    end_date = "2025-03-01"
    save_folder = "ticket_data/garbage_data"
    simultaneous_requests = 20
    limit = 15
    # ticket_ids = [978474]
    ticket_ids = None

    os.makedirs(save_folder, exist_ok=True)
    if ticket_ids:
        logger.info(f"Processing specific ticket IDs: {ticket_ids}")

    start_time = datetime.now()
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        # Create the experiment
        experiment = await TicketAnnotationExperiment.create(
            db_client=db_client,
            username=USERNAME,
            simultaneous_requests=simultaneous_requests
        )
        results = await experiment.run_experiment(
            start_date=start_date,
            end_date=end_date,
            save_folder=save_folder,
            simultaneous_requests=simultaneous_requests,
            ticket_ids=ticket_ids,
            limit=limit
        )
    
    if len(results) > 0:
        end_time = datetime.now()
        time_elapsed = (end_time - start_time).total_seconds()
        logger.info(f"Time elapsed: {time_elapsed} seconds")
        logger.info(f"Average time per ticket: {time_elapsed / len(results):.1f} seconds")
    
if __name__ == "__main__":
    asyncio.run(main())
```
## File: postgres_setup/init-db.sh
```bash
#!/bin/bash
# This script is run when the postgres container is first created to restore the database from a backup
# If a backup_folder is provided, it will restore from that backup (eg pgdump_2024-12-24)
# usage: ./init-db.sh [--backup_date]
set -e

echo "Starting initialization..."

echo "Getting backup folder date from argument, default to latest if not provided"

# Debug: List contents of /postgres_setup
echo "Contents of /postgres_setup:"
ls -la /postgres_setup

# Check if the first argument starts with "/docker-entrypoint" - if so, ignore it
if [[ "$1" == */docker-entrypoint* ]]; then
    BACKUP_DATE=""
else
    BACKUP_DATE="$1"
fi

# If no backup date provided, use the most recent backup folder
if [ -z "$BACKUP_DATE" ]; then
    BACKUP_DATE=$(cd /postgres_setup && ls -d pgdump_* 2>/dev/null | sort -r | head -n1 | sed 's/pgdump_//')
fi

if [ -z "$BACKUP_DATE" ]; then
    echo "Error: No backup folder date provided and no backup folders found"
    echo "Please run backup_db.sh first to create a backup"
    exit 1
fi

BACKUP_DIR="/postgres_setup/pgdump_${BACKUP_DATE}"

# Debug: Check if backup directory exists
if [ ! -d "$BACKUP_DIR" ]; then
    echo "Error: Backup directory not found: ${BACKUP_DIR}"
    echo "Available backup directories:"
    ls -d /postgres_setup/pgdump_* 2>/dev/null || echo "No backup directories found"
    exit 1
fi

echo "Starting initialization from backup: ${BACKUP_DIR}"
echo "Loading roles and permissions..."
psql -U postgres -d postgres -f "${BACKUP_DIR}/roles_permissions.sql"

echo "Loading schema..."
psql -U postgres -d postgres -f "${BACKUP_DIR}/schema.sql"

echo "Restoring essential data..."
psql -U postgres -d postgres -f "${BACKUP_DIR}/essential_data.sql"

# Check if non-essential dump exists and restore it
if [ -f "${BACKUP_DIR}/non_essential_data.dump" ]; then
    echo "Restoring non-essential data..."
    pg_restore -U postgres -d postgres "${BACKUP_DIR}/non_essential_data.dump"
fi

echo "Initialization complete!"
```
## File: postgres_setup/Dockerfile
```
FROM pgvector/pgvector:pg17

# Copy configuration and initialization files
COPY postgresql.conf /etc/postgresql/postgresql.conf
COPY init-db.sh /docker-entrypoint-initdb.d/
COPY pgdump_* /postgres_setup/

# Make sure postgres user owns everything inside container paths
RUN chown -R postgres:postgres /etc/postgresql/postgresql.conf /docker-entrypoint-initdb.d /postgres_setup && \
    chmod -R 755 /postgres_setup

# The official postgres image automatically runs scripts in docker-entrypoint-initdb.d
# during first container startup

CMD ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]


# FROM pgvector/pgvector:pg17

# # Create necessary directories
# RUN mkdir -p /etc/postgresql /postgres_setup

# # Copy configuration files
# COPY postgresql.conf /etc/postgresql/postgresql.conf
# COPY init-db.sh /docker-entrypoint-initdb.d/init-db.sh

# # Set up permissions
# RUN chown -R postgres:postgres /docker-entrypoint-initdb.d /postgres_setup \
#     && chmod -R 755 /docker-entrypoint-initdb.d

# CMD ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
```
## File: postgres_setup/README.md
```markdown
# Postgres Setup

The postgres database runs in a docker container that is managed with docker-compose.

- `docker-compose.yml` for production.

## Running/restoring the database

No special action is required to get the database up and running. Just run:

```bash
# run the entire application
docker compose up 

# run just the postgres container
docker compose up postgres
```

This will call the `init-db.sh` script, which handles all the setup the first time the container runs (may take a few minutes). It will then be ready to go on subsequet runs.

## Creating a backup

To backup the database, run the `backup_db.sh` script:

```bash
# for a full backup including past conversations, documents, etc.
./postgres_setup/backup_db.sh

# for a minimal backup including only essential tables
./postgres_setup/backup_db.sh --minimal
```

This will create a directory called `postgres_setup/pgdump_YYYYMMDD` containing:

- `schema.sql` - database schema
- `roles_permissions.sql` - roles and permissions needed for the application to run
- `essential_data.sql` - table data from tables needed for the application to run (users, groups, apps, etc.)
- `essential_data.dump` - table data from the rest of the tables (documents, parent_documents, llm_calls, etc) Not included is you used the `--minimal` flag.

## Restoring a backup

### Automatic Restore

The easiest way to rebuild the database from a backup by deleting the `postgres` volume then restarting it. The `docker-compose.yml` file will automatically call the `init-db.sh` script to restore the database from the most recent backup.

```bash
# stop the postgres container and delete volume
docker compose down postgres -v

# start the container (will initiate rebuild from most recent backup)
docker compose up postgres
```

### Manual Restore

Alternately, you can restore a backup, with the `init-db.sh` script:

```bash
# restore the database from the backup in the `postgres_setup/pgdump_YYYYMMDD` directory
./postgres_setup/init-db.sh [--<YYYYMMDD>]

# restore the database from themost recent backup directory
./postgres_setup/restore_db.sh
```
```
## File: postgres_setup/postgresql.conf
```
timezone='UTC'

# Essential connection settings
listen_addresses='*'          # Allow connections from any IP
port=5432                     # Default port
max_connections=100           # Reduced as per requirement
superuser_reserved_connections=1

# Memory Configuration
shared_buffers='1GB'          # ~12.5% of total RAM, conservative due to multiple instances
work_mem='64MB'               # Higher value for vector operations
maintenance_work_mem='256MB'  # Helpful for index creation
effective_cache_size='2GB'    # Estimate of available OS cache per instance

# Query Planner
random_page_cost=1.1          # Assuming SSD storage
effective_io_concurrency=200  # Higher for SSD
max_parallel_workers_per_gather=4
max_parallel_workers=8

# Vector Search Optimization
maintenance_io_concurrency=200
vacuum_cost_delay=2
autovacuum_vacuum_scale_factor=0.1
autovacuum_analyze_scale_factor=0.05

# WAL Settings
wal_buffers='16MB'
checkpoint_completion_target=0.9
```
## File: postgres_setup/backup_db.sh
```bash
#!/bin/bash
# This script is used to backup the database to a local directory
# usage: ./backup_db.sh [--minimal]
# --minimal: only backup essential tables
set -e

# Get current date for folder name
BACKUP_DATE=$(date +%Y%m%d)
BACKUP_DIR="//postgres_setup/pgdump_${BACKUP_DATE}" # note double slash for windows local path

# Check for minimal flag
MINIMAL=false
if [[ "$1" == "--minimal" ]]; then
    MINIMAL=true
    echo "Running minimal backup (essential tables only)"
fi

# Define essential and non-essential tables
ESSENTIAL_TABLES="users groups user_groups llms"  # Always backed up
NON_ESSENTIAL_TABLES="documents parent_documents llm_calls emails"  # Skipped if minimal

# Echo what we're doing
echo "Starting database backup to ${BACKUP_DIR}"

# Create backup directory and set permissions
echo "Creating backup directory..."
docker exec scout_postgres bash -c "mkdir -p ${BACKUP_DIR} && chown postgres:postgres ${BACKUP_DIR}"

# Dump schema (DDL) in human-readable format
echo "Backing up schema..."
docker exec -u postgres scout_postgres pg_dump -U postgres -F p -s \
    --no-owner \
    -f "${BACKUP_DIR}/schema.sql" postgres

# Create a separate roles and permissions file
echo "Backing up roles and permissions..."
docker exec -u postgres scout_postgres pg_dumpall -U postgres --roles-only \
    -f "${BACKUP_DIR}/roles_permissions.sql"

# Always backup essential tables in plain text format
echo "Backing up essential tables..."
docker exec -u postgres scout_postgres pg_dump -U postgres -F p -a \
    $(for table in $ESSENTIAL_TABLES; do echo "-t $table"; done) \
    -f "${BACKUP_DIR}/essential_data.sql" postgres

# Backup non-essential tables only if not minimal (in binary format)
if [ "$MINIMAL" = false ]; then
    echo "Backing up non-essential tables..."
    docker exec -u postgres scout_postgres pg_dump -U postgres -F c -a \
        $(for table in $NON_ESSENTIAL_TABLES; do echo "-t $table"; done) \
        -f "${BACKUP_DIR}/non_essential_data.dump" postgres
fi

echo "Backup complete! Files are in ${BACKUP_DIR}"
```
## File: llm/demo_function_calling/weather_report.py
```python
import json
import os
from llm import LLMFunctionExtractor
from llm import get_llm_provider
import asyncio
from dotenv import load_dotenv
import logging
from datetime import datetime
from typing import Dict, Any
from pydantic import BaseModel, Field
from llm.demo_function_calling.weather import Weather
from tools import MarkdownFormatter

logger = logging.getLogger(__name__)

load_dotenv(override=True)
os.environ["USE_AZURE_OPENAI"] = "False"
logging.basicConfig(level=logging.INFO)
MODEL = "gpt-4o"
WEATHER_CLASS_PATH = "llm/demo_function_calling/weather.py"

class WeatherReport:
    def __init__(self, output_folder: str):
        self.provider = get_llm_provider(MODEL)
        self.weather_data = None
        self.output_folder = output_folder

    def show_weather_data(self):
        """Show the weather data
        
        Returns:
            Dict[Any, Any]: Weather data
        """
        return self.weather_data
    
    async def get_weather_data(self, prompt: str) -> Dict[Any, Any]:
        """Get weather data based on a prompt
        
        Args:
            prompt (str): The prompt to use to fetch weather data

        Returns:
            bool: True if successful
        """
        weather_obj = Weather()
        functions = LLMFunctionExtractor(WEATHER_CLASS_PATH).get_functions(weather_obj)
        prompt = f"""Get weather data to allow for: {prompt}
The date is {datetime.now().strftime("%Y-%m-%d (%A)")}
- for a 1 day forecast use forecasts=["hourly"]
- for a 7 day forecast use forecasts=["daily"]
- use the units that are most appropriate for the location
Please return the weather data unaltered as a json string with no other text (including markdown code blocks).
"""
        response = await self.provider.get_response(
            prompt,
            config = {"temperature": 0.1},
            functions = functions,
            max_function_iterations=20,
        )   
        self.weather_data = self._load_dict(response)
        return True

    async def write_single_day_weather_report(self, prompt: str) -> str:
        """
        Write a 1-day weather report and save it to disk. Note: must call get_weather_data() first.


        Args:
            prompt (str): The prompt to use to fetch weather data

        Returns:
            str: The path to the saved weather report
        """
        if not self.weather_data:
            raise ValueError("Weather data not found. Call get_weather_data() first.")

        md_format = """
        # 1-Day Weather Report for <location>
        The 1 day outlook for <weekday, month, date, year> is <general qualitaty weather description without numbers>

        ## Alert
        <alert message if present, otherwise omit this section and heading>

        ## Hourly Forecast
        <markdown table with columns ("Time", "Weather","Temp (<temp_unit>)", "Precip %", "Rain(mm)") and rows for each hour for next 24 hours>
        """

        prompt = f"""
        Write a weather report in markdown format for {self.weather_data["location"]}.
        Here is the weather data: {self.weather_data}

        Use the following format: 
        <format>
        {md_format}
        </format>

        Notes:
        - Please round all temperatures to one decimal place (no need to point this out)
        - Align numeric table values to the right and text to the left
        - do not add any other text to the report
        """
        
        class MDtext(BaseModel):
            text: str = Field(description="The weather report in markdown format")
    
        response = await self.provider.get_response(
            prompt,
            config = {"temperature": 0.1},
            # functions=self.functions,
            response_format=MDtext,
            max_function_iterations=20,
        )
        report = response.text

        # save report to file
        location = self.weather_data["location"]
        pdf_path = f"{self.output_folder}/{location}_1day_report.pdf"
        pdf_report = self._convert_to_pdf(response.text)
        self._save_report(pdf_report, pdf_path)

        # return the path to the report
        return pdf_path
    
    async def write_multi_day_weather_report(self, prompt: str) -> str:
        """
        Write a multi-day weather report (up to 8 days)and save it to disk. Note: must call get_weather_data() first.

        Args:
            prompt (str): The prompt to use to fetch weather data

        Returns:
            str: The path to the saved weather report
        """
        if not self.weather_data:
            raise ValueError("Weather data not found. Call get_weather_data() first.")

        md_format = """# <#days>-Day Weather Report for <location>
        The <#days> day outlook for <weekday, month, date, year> is <general qualitaty weather description without numbers, refer to alerts if present>

        ## Alert

        <alert message if present, otherwise omit this section and heading>

        ## Daily Forecast

        <markdown table with columns ("Date", "Weather","High (<temp_unit>)", "Low (<temp_unit>)", "Precip %", "Rain(mm)") and rows for each of the next 7 days>
        """

        prompt = f"""
        Write a weather report in markdown format for {self.weather_data["location"]}.
        Here is the weather data: {self.weather_data}
        The user provided the following prompt: '{prompt}'
        You may modify the output to better suit the user's prompt if apropriate.

        Use the following format: 
        <format>
        {md_format}
        </format>

        Notes:
        - Please round all temperatures and rainfall to one decimal place (do not point this out in the report)
        - format dates in the table like <weekday(abbreviated), month(abbreviated), date>
        - Align numeric table values to the right and text to the left
        - do not add any other text to the report
        """

        class MDtext(BaseModel):
            text: str = Field(description="The weather report in markdown format")
        

        response = await self.provider.get_response(
            prompt,
            config = {"temperature": 0.1},
            response_format=MDtext,
            max_function_iterations=20,
        )

        # save report to file
        location = self.weather_data["location"]
        pdf_path = f"{self.output_folder}/{location}_multi_day_report.pdf"
        pdf_report = self._convert_to_pdf(response.text)
        self._save_report(pdf_report, pdf_path)

        # return the path to the report
        return pdf_path

    def _load_dict(self, json_string: str) -> dict:
        """Parse a JSON string into a dictionary, handling cases where JSON is embedded in markdown code blocks or preceded by explanatory text.
        
        Args:
            json_string: String containing JSON data
            
        Returns:
            Parsed dictionary or original string if parsing fails
            
        Note:
            Handles cases where JSON is embedded in markdown code blocks or
            preceded by explanatory text
        """
        # First try to find JSON within code blocks
        if "```" in json_string:
            # Extract content between code blocks, regardless of language identifier
            parts = json_string.split("```")
            # Take the content from within the code block
            if len(parts) >= 2:
                json_string = parts[1]
                # Remove potential language identifier (e.g., 'json')
                if 'json\n' in json_string:
                    json_string = json_string.split('json\n', 1)[1]

        # Try to find JSON object by looking for first '{' and last '}'
        try:
            start_idx = json_string.find('{')
            end_idx = json_string.rindex('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_string = json_string[start_idx:end_idx]
        except ValueError:
            logger.debug("Could not find JSON object markers {} {}")

        try:
            return json.loads(json_string.strip())
        except Exception as e:
            logger.error(f"Error parsing JSON response: {str(e)}")
            logger.debug(f"Failed JSON string: {json_string}")
            return json_string

    def _save_report(self, report: str, path: str):
        extension = path.split(".")[-1]
        if extension == "pdf":
            with open(path, "wb") as f:
                f.write(report)
        else:
            with open(path, "w") as f:
                f.write(report)

    def _convert_to_pdf(self, report: str) -> str:
        formatter = MarkdownFormatter()
        pdf_report = formatter.markdown_to_pdf(report)
        return pdf_report
```
## File: llm/demo_function_calling/weather_joker.py
```python
from llm.demo_function_calling.weather import Weather
from llm import LLMFunctionExtractor
from llm import get_llm_provider
from dotenv import load_dotenv
import logging
import os
import json
from typing import Dict, Union

load_dotenv()
logger = logging.getLogger(__name__)
MODEL = "gpt-4o"
# MODEL = "claude-3-5-sonnet-20241022"


class WeatherJoker:
    """A class that uses LLM function calling to get the current weather and then uses that weather 
    data to create a funny weather forecast."""
    def __init__(self):
        self.llm = get_llm_provider(MODEL)
        pass

    async def get_weather(self, user_prompt)->dict:
        """Gets the current weather for a given location
        
        Args:
            user_prompt (str): The prompt to use for the weather

        Returns:
            dict: The weather data
        """

        prompt = f"""
You are a weather assistant who helps retrieve the current weather for a comedy weather forecast.
Get the current weather in the location specified by this user prompt: {user_prompt}

Your reply should be a json string with no other text (including markdown tags), suitable for json.loads()"""

        # load the weather function
        script_path = os.path.join(os.path.dirname(__file__), "weather.py")
        functions = LLMFunctionExtractor(script_path).get_functions(Weather())

        response = await self.llm.get_response(
            prompt,
            config={"temperature": 0.1},
            functions=functions,
            max_function_iterations=20,
        )
        return response

    async def get_funny_forecast(self, 
                                #  weather_data: str|dict,
                                 weather_data: Union[str, dict],
                                 )->str:
        """Gives a funny weather forecast given weather data . get_weather() must be called first.
        
        Args:
            weather_data (str|dict): The weather data (dict or JSON string) to use for the joke

        Returns:
            str: The joke about the current weather
        """
        if isinstance(weather_data, str):
            weather_data = json.loads(weather_data)
        prompt = f"""
    Give a humorous weather forcast for this weather data.
    We want it to be funny and locally relevant.
    - poke fun at the city and/or people who live in the area
    - reference what residents should look out for (as a goof)
    - be as funny as possible for a general audience
    The forecast should 
    <weather_data>
    {weather_data}
    </weather_data>
    """
        response = await self.llm.get_response(
            prompt,
            config={"temperature": 0.8},
        )
        return response
    
    async def get_funny_comparative_forecast(self, weather_data: str | list[dict]) -> str:
        """Generate a funny comparative weather forecast for multiple locations.
        
        Args:
            weather_data (str | list[dict]): List of weather data for different locations.
                Each dict should contain:
                - location: str
                - weather: str
                - temperature: float
                - etc.
                
        Returns:
            str: A humorous comparison of the weather in different locations
        """
        prompt = f"""
        You are a funny meteorologist who compares the weather in multiple cities in a humorous way.
        Make the comparison funny and locally relevant, for a general audience.
        Here is the weather data for the cities to compare:
        {weather_data}
        """
        weather_data = json.loads(weather_data) if isinstance(weather_data, str) else weather_data

        response = await self.llm.get_response(
            prompt,
            config={"temperature": 0.8},
        )
        return response
```
## File: llm/demo_function_calling/demo_nested_function_calls.py
```python
from llm.demo_function_calling.weather_joker import WeatherJoker
from llm import LLMFunctionExtractor
from llm import get_llm_provider
from dotenv import load_dotenv
import asyncio
import logging
import os

load_dotenv()
logger = logging.getLogger(__name__)
MODEL = "gpt-4o"
# MODEL = "claude-3-5-sonnet-20241022"


async def main():
    """This demo shows how to use a nested LLM call that involves function calls
    
    In this script we use the `WeatherJoker` class to make a funny weather forecast.
    The `WeatherJoker` class uses the `Weather` class to get the current weather for a given location, then uses that weather data to create a funny weather forecast.

    Also notable is the use of arg types in the function definitions:
    - `WeatherJoker.get_weather` involves a call to `Weather.get_weather_data` which returns a dict
    - `WeatherJoker.get_funny_forecast` method uses this weather data. Its arg type is `str|dict`, allowing the llm to pass the JSON string which is loaded into a dict by the function. The LLM is not able to pass the dict directly because it works only with strings during its function calling phase.
    """

    prompt="Give me a funny weather forecast for New Westminster"
    # prompt = "Give me a funny comparison of the weather in Whitehorse and Honolulu"
# 
    prompt += "\nPlease return the weather forecast as is."

    script_path = os.path.join(os.path.dirname(__file__), "weather_joker.py")
    print(f"SCRIPT PATH: {script_path}")
    functions = LLMFunctionExtractor(script_path).get_functions(WeatherJoker())
    # LLMFunctionExtractor(script_path).print_function_defs(functions)
    
    llm = get_llm_provider(MODEL)
    response = await llm.get_response(
        prompt,
        config={"temperature": 0.1},
        functions=functions
    )
    print(f"\n\nFinal LLM Response:\n{response}")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/demo_function_calling/weather.py
```python
import requests
from typing import Dict, Any
from dotenv import load_dotenv
import os
import json
from datetime import datetime, timezone, timedelta
from llm import get_llm_provider

load_dotenv()
OWM_API_KEY = os.getenv("OWM_API_KEY")

MODEL = "gpt-4o"
# MODEL = "claude-3-5-sonnet-20241022"

WEATHER_REPORT_PATH = "llm/demo_function_calling/weather_report.py"

class Weather:
    def __init__(self):
        self.api_key = os.getenv("OWM_API_KEY")


    def _epoch_to_local_time(self, weather_data: Dict[Any, Any], timestamp: int) -> str:
        """
        Convert Unix timestamp to local ISO format string using the timezone from weather data
        
        Args:
            weather_data (Dict[Any, Any]): Weather data response containing timezone_offset
            timestamp (int): Unix timestamp (UTC) to convert
            
        Returns:
            str: Local time in ISO format
        """

        timezone_offset = weather_data.get('timezone_offset', 0)
        tz = timezone(timedelta(seconds=timezone_offset))
        dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
        local_dt = dt.astimezone(tz)
        return local_dt.isoformat()
    

    def _local_to_epoch_time(self, local_time: str) -> int:
        """
        Convert local ISO format string to Unix timestamp
        
        Args:
            local_time (str): Local time in ISO format to convert
            
        Returns:
            int: Unix timestamp (UTC)
        """        
        dt = datetime.fromisoformat(local_time)
        return int(dt.timestamp())


    def _convert_to_local_times(self, weather_data: Dict[Any, Any]) -> Dict[Any, Any]:
        """
        Convert all timestamp data in the weather response to local ISO format strings
        
        Args:
            weather_data (Dict[Any, Any]): Weather data response from API
            
        Returns:
            Dict[Any, Any]: Weather data with converted timestamp fields
        """
        # Define timestamp fields to convert
        time_fields = [
            "dt",
            "sunrise",
            "sunset",
            "moonrise",
            "moonset",
            "start",
            "end"
        ]
        
        # Define sections that contain timestamp data
        sections = {
            "current": None,  # None indicates it's a single object
            "hourly": "hour",  # String indicates it's a list of objects
            "daily": "day",
            "alerts": "alert"
        }
        
        # Process each section
        for section, item_name in sections.items():
            if section in weather_data:
                if item_name is None:
                    # Handle single objects (like 'current')
                    for field in time_fields:
                        if field in weather_data[section]:
                            weather_data[section][field] = self._epoch_to_local_time(
                                weather_data,
                                weather_data[section][field]
                            )
                else:
                    # Handle lists of objects (like 'hourly', 'daily', 'alerts')
                    for item in weather_data[section]:
                        for field in time_fields:
                            if field in item:
                                item[field] = self._epoch_to_local_time(
                                    weather_data,
                                    item[field]
                                )
        
        return weather_data

    async def get_location(self, prompt: str) -> dict[str, str]:
        """
        Get the location informatio (lat, lon, location name) from a text prompt
        
        Args:
            prompt (str): Text prompt to extract location information from
            
        Returns:
            dict[str, any]: Location information including latitude, longitude, and location name
        """
        response_format = {"location": "<name of city or area>"}
        prompt = f"""Get the location referred to in this string: {prompt} """

        provider = get_llm_provider(MODEL)
        response = await provider.get_response(
            prompt,
            config = {"temperature": 0.1},
            response_format=response_format
        )   
        lat, lon = self._get_coordinates(response["location"])
        response = {
            "lat": lat,
            "lon": lon,
            "location_name": response["location"]
        }

        return response
    
    def get_weather_data(self, 
                         lat: float,
                         lon: float,
                         location_name: str = None,
                         units: str = "metric", 
                         forecasts: list[str]|None = None,
                         forecast_fields: list[str] = None) -> Dict[str, Any]:
        """
        Get current weather data from OpenWeatherMap, with optional forecasts (daiy for next 8 days, hourly for next 48 hours, minutely for next 60 minutes). Call get_location() first to get the lat, lon, and location_name
        
        Args:
            lat (float): Latitude of the location
            lon (float): Longitude of the location
            location_name (str, optional): Name of the location (used only to enhance the response)
            units (str, optional): Units of measurement. Defaults to "metric".
            forecasts (list[str], optional): Types of forecasts to include, (any or all of ["minutely", "hourly", "daily"]) Defaults to None (show current weather only)
            forecast_fields (list[str], optional): Fields to keep in forecast entries.
                If None, defaults to ["dt", "summary", "temp", "pop", "weather", "rain"]
        
        Returns:
            Dict[Any, Any]: Weather data including current conditions and forecasts
        """

        base_url = "https://api.openweathermap.org/data/3.0/onecall"
        params = {
            "lat": lat,
            "lon": lon,
            "appid": self.api_key,
            "units": units
        }

        # only include forecasts if specified
        exclude = ["minutely", "hourly", "daily"]
        if forecasts:
            exclude = [f for f in exclude if f not in forecasts]
        params["exclude"] = ",".join(exclude)
        
        try:
            response = requests.get(base_url, params=params)
            response.raise_for_status()
            weather_data = response.json()

            # Convert timestamp fields to local ISO strings
            weather_data = self._convert_to_local_times(weather_data)
            
            # Filter forecast entries
            weather_data = self._filter_forecasts(weather_data, forecast_fields)
            
            # delete unwanted fields
            for field in ["lat", "lon", "timezone_offset", "timezone"]:
                if field in weather_data:
                    del weather_data[field]
            
            weather_data["location"] = location_name

            return weather_data
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Failed to get weather data: {str(e)}")

    def _get_coordinates(self, city_name: str, country_code: str = None, limit: int = 1) -> tuple[float, float]:
        """
        Convert city name to latitude and longitude using OpenWeather Geocoding API
        
        Args:
            city_name (str): Name of the city
            country_code (str, optional): Two-letter country code (ISO 3166-1 alpha-2) e.g., "US", "GB", "DE"
            limit (int, optional): Number of results to return. Defaults to 1.
        
        Returns:
            tuple[float, float]: Latitude and longitude of the city
        
        Raises:
            Exception: If the city is not found or API request fails
        """
        base_url = "http://api.openweathermap.org/geo/1.0/direct"
        
        # Add country code to query if provided
        q = f"{city_name},{country_code}" if country_code else city_name
        
        params = {
            "q": q,
            "limit": limit,
            "appid": self.api_key
        }
        
        try:
            response = requests.get(base_url, params=params)
            response.raise_for_status()
            
            results = response.json()
            if not results:
                raise Exception(f"City not found: {city_name}")


            location = results[0]
            return location["lat"], location["lon"]
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Failed to get coordinates: {str(e)}")

    def _filter_forecasts(self, weather_data: Dict[Any, Any], 
                         fields: list[str] = None) -> Dict[Any, Any]:
        """
        Filter forecast entries to only include selected fields
        
        Args:
            weather_data (Dict[Any, Any]): Weather data response from API
            fields (list[str], optional): Fields to keep in forecast entries.
                Defaults to ["dt", "summary", "temp", "pop"]
            
        Returns:
            Dict[Any, Any]: Weather data with filtered forecast entries
        """
        # load default fields if none are provided
        fields = ["dt", "summary", "temp", "pop", "weather", "rain"] if fields is None else fields
        # ensure dt is always included so we know when the forecast is for
        fields.append("dt") if "dt" not in fields else None
            
        # Define sections that contain forecast data
        forecast_sections = ["minutely","hourly", "daily"]
        
        # Process each forecast section
        for section in forecast_sections:
            if section in weather_data:
                filtered_items = []
                for item in weather_data[section]:
                    filtered_item = {}
                    for field in fields:
                        if field in item:
                            filtered_item[field] = item[field]
                    filtered_items.append(filtered_item)
                weather_data[section] = filtered_items
        return weather_data
    

def main():
    # Example usage
    weather = Weather()

    city_name = "Cameron"
    country_code = "US"
    limit = 1   

    try:
        lat, lon = weather._get_coordinates(city_name, country_code, limit=limit)
        print(f"Latitude: {lat}, Longitude: {lon}")
        weather_data = weather.get_weather_data(
            lat, 
            lon, 
            location_name=city_name,
            forecasts=None
        )
        print(f"Weather data: {json.dumps(weather_data, indent=2)}")
        
        # Access the data
        current_temp = weather_data["current"]["temp"]
        current_conditions = weather_data["current"]["weather"][0]["description"]
        
        print(f"Current temperature: {current_temp}°C")
        print(f"Conditions: {current_conditions}")
    except Exception as e:
        print(f"Error: {e}")




    

if __name__ == "__main__":
    main()
```
## File: llm/demo_function_calling/demo_simple_function_call.py
```python
from llm.demo_function_calling.weather import Weather
from llm import LLMFunctionExtractor
from llm import get_llm_provider
from dotenv import load_dotenv
import asyncio
import logging
import os
import json

load_dotenv()
logger = logging.getLogger(__name__)
MODEL = "gpt-4o"

async def main():
    """Answers any general questions about the weather, using an LLM call with function calling using the `Weather` class.
    """

    prompt = f"How should I dress for the weather in Whitehorse tomorrow?"
    # prompt = f"Time will it get dark, and what time will the temperature dip below -10C in Whitehorse tomorrow?"
    # prompt = f"What is coldest it will reach in Whitehorse in the next 48 hours?"
    # load llm functions from the Weather class
    script_path = os.path.join(os.path.dirname(__file__), "weather.py")
    functions = LLMFunctionExtractor(script_path).get_functions(Weather())
    LLMFunctionExtractor(script_path).print_function_defs(functions)

    # get llm response
    llm = get_llm_provider(MODEL)
    response = await llm.get_response(
        prompt,
        config={"temperature": 0.1},
        functions=functions
    )
    print(f"\n\nFinal LLM Response:\n{response}")

if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/demo_function_calling/demo_binary_objects.py
```python
import json
import os
from llm import LLMFunctionExtractor
from llm import get_llm_provider
import asyncio
from dotenv import load_dotenv
import logging
from llm.demo_function_calling.weather_report import WeatherReport
from datetime import datetime
from pydantic import BaseModel, Field
import tempfile
import shutil

load_dotenv(override=True)
os.environ["USE_AZURE_OPENAI"] = "False"
logging.basicConfig(level=logging.INFO)
MODEL = "gpt-4o"
    
async def create_weather_report_pdf(
        query: str,
        output_folder: str
    ):
    """Creates a pdf weather report based on the user query using the WeatherReport class using llm function calling.
    The report is saved to 'output_folder', and the path to the report is returned.
    We do it this way because the LLM function calling can't return a file object but can return a path string.

    Args:
        query (str): The user query, outlining the weather report to create
        output_folder (str): The folder to save the report to

    Returns:
        str: The path to the report
    """
    prompt = f"""Generate a weather report based on this query: 
    {query}
    The current date is: {datetime.now().strftime("%Y-%m-%d (%A)")}
    Save any output to the folder: {output_folder}
    """
    # add functions to llm call
    script_path = os.path.join(os.path.dirname(__file__), "weather_report.py")
    functions = LLMFunctionExtractor(script_path).get_functions(WeatherReport(output_folder))

    # Define the structured output format
    class FilePath(BaseModel):
        path: str = Field(description="The path to the file")

    # instantiate the llm
    llm = get_llm_provider(MODEL)

    # start the llm function calling chain that creates and saves the report to the output folder
    # the response will be the path to the report
    response = await llm.get_response(
        prompt, 
        config = {"temperature": 0.1},
        functions=functions,
        response_format=FilePath,
        max_function_iterations=20,
    )
    return response.path

async def main():
    """This is a demo of how to use function calling to save a file to a folder.
    The file is saved to a temporary directory, and then copied to the output folder.

    """
    query = "Please prepare a 7-day weather report document for Fort Worth TX"
    
    # the output folder is where the file ultimately will be saved
    output_folder = "_app_output"
    os.makedirs(output_folder, exist_ok=True)

    # Since we are saving a file, we need to use a temporary directory  
    # Pass the temp directory to the functions that will do the file saving
    # The function should return the path to the file, which we can then load for our purposes
    with tempfile.TemporaryDirectory() as temp_dir:

        # get the weather report
        temp_path = await create_weather_report_pdf(query, temp_dir)
        print(f"\nReport saved to temp folder: {temp_path}")
        print(f"Temp file exists: {os.path.exists(temp_path)}")

        # use the files in the temp folder before leaving the context manager block
        # (in this case we will just copy them to the output folder, but in an app we'd use them as attachments)
        print(f"Copying {temp_path} to {output_folder}")
        shutil.copy(temp_path, output_folder)

    print("Left context manager block")
    print(f"Temp file exists: {os.path.exists(temp_path)}")


if __name__ == "__main__":
    asyncio.run(main())
```
## File: llm/demo_function_calling/try_arg_types.py
```python
from llm import get_llm_provider
from dotenv import load_dotenv
import asyncio
import logging
import os
from datetime import datetime, timedelta
from pydantic import BaseModel, Field
from random import randint, choice
from llm import LLMFunctionExtractor
from typing import List
import json


load_dotenv()
logger = logging.getLogger(__name__)
MODEL = "gpt-4o"


class DummyWeather:
    def get_current_weather(self, location: str) -> dict:
        """Get the current weather for a given location
        
        Args:
            location: The city name, e.g. Boston
        Returns:
            A dictionary with the current weather for the given location
        """
        weather_info = {
            "location": location,
            "date": self.get_today_date(),
            "weather": choice(["sunny", "cloudy", "rainy", "snowy"]),
        }    
        if weather_info["weather"] == "snowy":
            weather_info["temperature"] = randint(-10, 0)
        else:
            weather_info["temperature"] = randint(10, 25)
        return weather_info

    def get_weather_forecast(self, location: str, dates: List[datetime|str]) -> List[dict]:
        """Get the weather forecast for a given location and dates
        
        Args:
            location(str): The city name, e.g. Boston
            dates(List[datetime|str]): List of datetime objects or ISO date strings to get forecast for
        Returns:
            List[dict]: A list of dictionaries with the weather forecast for the given location and dates
        """
        weather_forecast = []
        for date in dates:
            if isinstance(date, str):
                date = datetime.fromisoformat(date)
            day_info = self.get_current_weather(location)
            del day_info["location"]  # Remove location from individual forecasts
            day_info["date"] = date
            weather_forecast.append(day_info)

        return {"location": location, "forecast": weather_forecast}
    
    def format_forecast(self, forecast: dict|str) -> str:
        """Format the forecast object into a string
        
        Args:
            forecast: The forecast object or JSON string (must include location and forecast keys)
        Returns:
            A string with the formatted forecast
        """
        forecast = json.loads(forecast) if isinstance(forecast, str) else forecast
        location = forecast["location"]
        forecast = forecast["forecast"]
        
        forceast_strs = [f"On {day['date']}, it will be {day['weather']} and {day['temperature']}°C." for day in forecast]
        return f"The weather in {location} for the next 7 days is:\n{'\n'.join(forceast_strs)}"

    def get_today_date(self) -> datetime:
        """Get the current date

        Args:
            None
        
        Returns:
            datetime: The current date
        """
        return datetime.now()
    
    def get_date_range(self, start_date: datetime|str, end_date: datetime|str) -> List[datetime]:
        """Get a list of dates between start_date and end_date
        
        Args:
            start_date: The start datetime or ISO date string
            end_date: The end datetime or ISO date string
        Returns:
            List of datetime objects between start_date and end_date
        """
        if isinstance(start_date, str):
            start_date = datetime.fromisoformat(start_date)
        if isinstance(end_date, str):
            end_date = datetime.fromisoformat(end_date)
        n_days = (end_date - start_date).days + 1
        return [start_date + timedelta(days=i) for i in range(n_days)]
    
weather = DummyWeather()
extractor = LLMFunctionExtractor(__file__)  
functions = extractor.get_functions(weather)
extractor.print_function_defs(functions)


async def test_function_calling(prompt, provider):    
    
    print(f"\n\n{'-'*25}Using '{provider.default_model}' {'-'*25}")
    
    
    response = await provider.get_response(
        prompt,
        config={},
        functions=functions,
        function_call="auto",
        response_format=None,
        max_function_iterations=20
    )
    print(f"\nFinal Response:\n{response}\n")


async def main():
    prompt = "What is the weather in Boston for the next 7 days? Give me a formatted forecast."
    models = [
            "gpt-4o", 
            # "claude-3-5-sonnet-20241022"
        ]
    

    for model in models:
        print(f"\n\n\n{'#'*80}\nTesting with model: {model}\n{'#'*80}")
        provider = get_llm_provider(model, azure=os.environ.get("USE_AZURE_OPENAI"))
        await test_function_calling(prompt, provider)

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/utils/generate_annotation_examples.py
```python
from app.ticket_annotator import TicketAnnotator
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from dotenv import load_dotenv
from typing import List
import os
import asyncio
load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

USERNAME = "helpdesk_agent"
save_folder = "app/data/demo_annotations"
os.makedirs(save_folder, exist_ok=True)

async def get_recent_closed_tickets_ids(
        db_client: AuthenticatedPostgresClient, 
        n: int = 10) -> List[int]:
    query = """
    SELECT id FROM parent_documents
    WHERE summary is not null
    ORDER BY id DESC
    LIMIT $1
    """
    response = await db_client.raw_query(query, [n])
    return [row['id'] for row in response]



async def main():
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        annotator = await TicketAnnotator.create(db_client=db_client)

        ticket_ids = await get_recent_closed_tickets_ids(db_client, n=15)
        print(ticket_ids)
        for ticket_id in ticket_ids:
            print(f"Annotating ticket {ticket_id}")
            response = await annotator.annotate_ticket(
                ticket_id,
                add_note=False,
                save_folder=save_folder,
                n_matches=15,
                initial_messages_only=True,
                lookback_only=True,
                source="api"
            )

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/utils/generate_note_examples.py
```python
from app.ticket_database import TicketDatabase
from database.authenticated_postgres_client import AuthenticatedPostgresClient
from app.ticket_poller import TicketPoller
from dotenv import load_dotenv
from typing import List
import os
import asyncio
import json
load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

USERNAME = "helpdesk_agent"
annotations_folder = "app/data/demo_annotations"
notes_folder = "app/data/demo_annotations/notes"
os.makedirs(annotations_folder, exist_ok=True)
os.makedirs(notes_folder, exist_ok=True)

def load_json_file(file_path: str) -> dict:
    with open(file_path, 'r') as f:
        return json.load(f)

def save_json_file(data: dict, file_path: str):
    with open(file_path, 'w') as f:
        json.dump(data, f, indent = 4)


async def main():
    async with AuthenticatedPostgresClient(username=USERNAME) as db_client:
        ticket_db = TicketDatabase(db_client)
        ticket_poller = TicketPoller(company_identifiers = [],db_client=db_client)
        annotation_files = os.listdir(annotations_folder)
        annotation_files = [f for f in annotation_files if f.endswith(".json")]
        annotation_files.sort()
        notes = []
        for annotation_file in annotation_files:
            annotation = load_json_file(os.path.join(annotations_folder, annotation_file))
            ticket_id = annotation["ticket_id"]
            initial_classification = annotation["classification"]
            ticket = await ticket_db.get_ticket(ticket_id)
            metadata = ticket["metadata"]
            final_classification = {
                "type": metadata.get("type", "Unknown"),
                "subtype": metadata.get("subtype", "Unknown"),
                "item": metadata.get("item", "Unknown"),
                "priority": metadata.get("priority", "Unknown")
            }
            post_note_text = ticket_poller._compose_post_closure_note(
                initial_classification, 
                final_classification)
            ticket_notes = {
                "ticket_id": ticket_id,
                "initial": annotation["note_content"],
                "post_closure": post_note_text
            }
            save_json_file(ticket_notes, os.path.join(notes_folder, annotation_file))
            notes.append(ticket_notes)

    output = ""
    for note in notes: 
        output += "\n***********************************"
        output += f"\nTICKET ID: {note['ticket_id']}"
        output += f"\nINITIAL NOTE:\n{note['initial']}"
        output += f"\nPOST-CLOSURE NOTE:\n{note['post_closure']}"

    with open("app/data/demo_annotations/notes/notes.txt", "w") as f:
        f.write(output)
        

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/utils/aech_test_ticket_operations.py
```python
import asyncio
from datetime import datetime, timezone
from app.api import ConnectWiseAPI
from dotenv import load_dotenv
import json
import logging
import os
from database import AuthenticatedPostgresClient
# from ticket_ingester import TicketIngester
from dotenv import load_dotenv

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"


# Set up logging
logging.basicConfig(level=logging.INFO)

load_dotenv()


api = ConnectWiseAPI()

def load_json_file(file_path: str):
    with open(file_path, "r") as f:
        return json.load(f)

def save_json_file(data: dict, file_path: str):
    with open(file_path, "w") as f:
        json.dump(data, f, indent=4)

async def add_note_to_ticket(ticket_id: int, note: str):
    
    data = {
        "ticketId": ticket_id,
        "text": note,
        "detailDescriptionFlag": False,
        "internalAnalysisFlag": True,
        "resolutionFlag": False
    }
    response = await api.post(route=f"service/tickets/{ticket_id}/notes", data=data)
    print(f"Added note {response['id']} to ticket: {response['ticketId']}")
    return response

async def delete_note_from_ticket(ticket_id: int, note_id: int):
    data = {
        "id": note_id,
        "parentId": ticket_id,
    }
    response = await api.delete(route=f"service/tickets/{ticket_id}/notes/{note_id}", data=data)
    return response

async def delete_all_notes_from_ticket(ticket: dict):
    for message in ticket["messages"]:
        if message["type"] == "note":
            response = await delete_note_from_ticket(ticket["id"], message["id"])
            print(f"Deleted note: {message['id']} from ticket: {ticket['id']}")

async def refresh_ticket(ticket_id: int, notes: list[str]):
    ticket = await api.get_ticket_with_messages(ticket_id)
    await delete_all_notes_from_ticket(ticket)
    for note in notes:
        response = await add_note_to_ticket(ticket_id, note)

    return ticket

async def main():
   
    # TEST GETTING TICKET WITH MESSAGES
    ticket_id = 1033009 


    initial_note = """# Misspelled Name Of New ALW - Inderjeet Kaur to Inderjit Kaur

#### How many people is this affecting?
* One user

#### Tip: Common issues may be resolved by restarting your computer.

#### Is this a recurring issue?
* No, First Time This Has Happened

#### Specific details about the problem/question?
Please change Inderjeet Kaur to Inderjit Kaur.  I misspelled her name.
Thankyou
"""
    follow_up_note = """
> Information recorded by desktop portal client-portal/5.3.1.0.

- operation system: Win32NT/10.0.19045.0
- portal dir: C:\\WINDOWS\\system32
- user name: wreuser
- machine name: 21-002D
    - host name: 21-002D
    - address: fe80::d3a8:8aee:ecc0:e982%8; 10.10.10.115; fd8d:9a42:f22c:6e11:b99c:4312:4a4:fcf3; fd8d:9a42:f22c:6e11:9562:371e:b3f3:a396
"""

    aech_note = """
AgentAech's initial classification:
- Service type: Hardware
- Subtype: Other
- Item: Other
- Priority: P2
"""
    post_closure_note = """Post-closure analysis:
AgentAech's initial classification:
- Service type: Hardware
- Subtype: Other
- Item: Other
- Priority: P2

Actual classification:
- Service type: Hardware
- Subtype: Other
- Item: Other
- Priority: Low
"""
    html_note = """
<html>
<body>
<h1>Heading 1</h1>
<p>This note is to test if HTML formatting is rendered correctly.</p>
<h2>Heading 2</h2>
<p>This is another paragraph with <b>bold</b> and <i>italic</i> text.</p>
<h3>Heading 3</h3>
<p>This is a paragraph with a <a href="https://www.google.com">link</a>.</p>
<h4>Heading 4</h4>
<ul>
    <li>Bullet Item 1</li>
    <li>Bullet Item 2</li>
</ul>
<ol>
    <li>Numbered Item 1</li>
    <li>Numbered Item 2</li>
</ol>
</body>
</html>
"""
    markdown_note = """
# Heading 1

This note is to test if markdown formatting is rendered correctly.

## Heading 2

This is another paragraph with **bold** and *italic* text.

### Heading 3

This is a paragraph with a [link](https://www.google.com).

#### Heading 4

- Bullet Item 1
- Bullet Item 2

1. Numbered Item 1
2. Numbered Item 2
"""
    notes = [
        # initial_note,
        # follow_up_note,
        # aech_note,
        # post_closure_note,
        html_note,
        markdown_note,
    ]

    async with AuthenticatedPostgresClient("helpdesk_agent") as db_client:

        # ticket_ingester = await TicketIngester.create(db_client)

        ticket_with_notes = await refresh_ticket(ticket_id, notes)
        print(f"\n\nTicket with notes: {json.dumps(ticket_with_notes, indent=4)}")

        # get ticket with messages
        ticket_with_messages = await api.get_ticket_with_messages(ticket_id)
        print(f"\n\nInitial ticket: {json.dumps(ticket_with_messages, indent=4)}")

        # print(f"\n\n Filtering Aech messages")
        # messages = ticket_with_messages["messages"]
        # print(f"Before: {json.dumps(messages, indent=4)}")
        # filtered_messages = ticket_ingester.filter_aechai_messages(messages)
        # print(f"After: {json.dumps(filtered_messages, indent=4)}")

        
        # for note in notes:
        #     response = await add_note_to_ticket(ticket_id, note)
        #     print(f"add_note_to_ticket response: {response}")
            
        # # add notes to ticket
        # ticket_with_messages = await api.get_ticket_with_messages(ticket_id)
        # print(f"\n\nTicket messages after adding note: {json.dumps(ticket_with_messages['messages'], indent=4)}")

        # # delete all notes from ticket
        # print(f"\nDeleting all notes from ticket")
        # response = await delete_all_notes_from_ticket(ticket_with_messages)
        
        
        # # get ticket with messages again
        # ticket_with_messages = await api.get_ticket_with_messages(ticket_id)
        # print(f"\n\nTicket after deleting notes: {json.dumps(ticket_with_messages['messages'], indent=4)}")

    

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/utils/ingest_tickets.py
```python
from app.api import ConnectWiseAPI
import logging
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from dotenv import load_dotenv
import os
import asyncio
import json
from database import AuthenticatedPostgresClient
from app.ticket_ingester import TicketIngester
from typing import List
import argparse

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

load_dotenv()
os.environ["POSTGRES_HOST"] = "localhost"

USER_EMAIL = "helpdesk_agent"
INGESTION_MODEL = "gpt-4o-mini"
SUMMARY_INSTRUCTIONS = "This is an IT support ticket. Please summarize the issue, the steps taken to resolve the issue, and the outcome. Do not repeat dates and do not include a preamble, just say what the problem was and how it was closed. Be concise (max 200 words)."


def save_json(data, filename, folder):
    """Save data to a JSON file."""
    os.makedirs(folder, exist_ok=True)
    file_path = os.path.join(folder, filename)
    with open(file_path, "w") as f:
        json.dump(data, f, indent=4)
    logger.debug(f"Saved JSON file: {file_path}")
    return file_path

def load_json(filename, folder):
    """Load data from a JSON file."""
    file_path = os.path.join(folder, filename)
    with open(file_path, "r") as f:
        return json.load(f)

async def get_all_ticket_ids(
        connectwise_api: ConnectWiseAPI, 
        company_identifiers: List[str], 
        start_date: datetime,
        page_size = 1000,
        limit: int = None) -> List[int]:
    """
    Get all ticket ids for a given company after a specific start date.
    
    Args:
        connectwise_api: ConnectWiseAPI instance for retrieving tickets
        ingester: TicketIngester instance for processing tickets
        company_identifier: The company identifier string
        start_date: Start date for ticket retrieval
        page_size: Number of tickets to get per page
        limit: Maximum number of tickets to get per company (None for all)
        
    Returns:
        List of processed ticket data dictionaries
    """
    all_ticket_ids = []
    for company_identifier in company_identifiers:
        company_tickets = await connectwise_api.get_tickets(
            company=company_identifier, fields=['id', 'closedDate'],
            after_date=start_date, board_id = 17,
            page_size = page_size,
            limit = limit
        )
        company_ticket_ids = [ticket["id"] for ticket in company_tickets]
        logger.info(f"Retrieved {len(company_ticket_ids)} ticket_ids for {company_identifier} since {start_date}")
        all_ticket_ids.extend(company_ticket_ids)

    return all_ticket_ids

async def ingest_ticket(
        ticket_id,
        ingester, 
        save_folder: str|None = None):
    """Ingest a single ticket"""
    ticket = await ingester.preprocess_ticket(ticket_id)
    if save_folder:
        save_json(ticket, f"{ticket_id}.json", folder = save_folder)
    response = await ingester.ingest_ticket(ticket)
    return response

async def ingest_tickets(
        ticket_ids_to_ingest,
        db_client, 
        save_folder: str|None = None,
        max_concurrent: int = 5):
    """
    Ingest a batch of tickets concurrently with controlled concurrency.
    
    Args:
        ticket_ids_to_ingest: List of ticket IDs to ingest
        db_client: Database client for retrieving ticket data
        save_folder: Folder to save processed tickets (None to skip saving)
        max_concurrent: Maximum number of concurrent ingestion tasks
        
    Returns:
        List[Dict]: List of ingestion responses
    """
    logger.info(f"Ingesting batch of {len(ticket_ids_to_ingest)} tickets with max {max_concurrent} concurrent tasks")
    
    ingester = await TicketIngester.create(db_client)
    
    # Create a semaphore to limit concurrency
    semaphore = asyncio.Semaphore(max_concurrent)
    
    # Counter for tracking progress with a lock for thread safety
    counter_lock = asyncio.Lock()
    processed_count = 0
    total_count = len(ticket_ids_to_ingest)
    
    async def ingest_ticket_with_semaphore(ticket_id):
        """Ingest a single ticket with semaphore control."""
        nonlocal processed_count
        
        async with semaphore:
            async with counter_lock:
                task_number = processed_count + 1
            
            try:
                ticket = await ingester.preprocess_ticket(ticket_id)
                if save_folder and ticket:
                    save_json(ticket, f"{ticket_id}.json", folder=save_folder)
                if ticket:
                    response = await ingester.ingest_ticket(ticket)
                    
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count
                    
                    logger.info(f"Successfully ingested ticket {ticket_id} ({current_count}/{total_count})")
                    return response
                else:
                    async with counter_lock:
                        processed_count += 1
                        current_count = processed_count

                    logger.warning(f"No data returned for ticket {ticket_id} ({current_count}/{total_count})")
                    return {"ticket_id": ticket_id, "success": False, "error": "No ticket data returned"}
            except Exception as e:
                async with counter_lock:
                    processed_count += 1
                    current_count = processed_count
                    
                logger.error(f"Error ingesting ticket {ticket_id} ({current_count}/{total_count}): {str(e)}")
                logger.exception("Full traceback:")
                return {"ticket_id": ticket_id, "success": False, "error": str(e)}
    
    # Create tasks for each ticket
    tasks = [ingest_ticket_with_semaphore(ticket_id) for ticket_id in ticket_ids_to_ingest]
    
    # Execute all tasks concurrently and gather results
    results = await asyncio.gather(*tasks)
    
    # Filter out None values (failed tickets)
    successful_results = [result for result in results if result and result.get("success", False)]
    
    logger.info(f"Batch ingestion complete. Successfully ingested {len(successful_results)}/{total_count} tickets")
    return results

async def get_ingested_ticket_ids(db_client):
    response = await db_client.table("parent_documents").select("id").execute()
    ingested_ticket_ids = [r["id"] for r in response]
    return ingested_ticket_ids

async def get_company_id_group_ip_map(db_client):
    response = await db_client.table("groups").select("id", "name").execute()
    return {row["name"]: row["id"] for row in response}

async def get_ticket_ids_to_ingest(all_ticket_ids, ingested_ticket_ids):
    return [tid for tid in all_ticket_ids if tid not in ingested_ticket_ids]

async def main():
    
    

    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Bulk ingest historical tickets.")
    parser.add_argument("--start-date", type=str, required=False, default="2020-01-01", help="Start date for ticket retrieval (YYYY-MM-DD)")
    parser.add_argument("--max-concurrent", type=int, required=False, default=10, help="Maximum number of concurrent ingestion tasks")
    parser.add_argument("--data_folder", type=str, required=False, default="ticket_data/all", help="Folder to save processed tickets")
    parser.add_argument("--fetch", action="store_true", help="Fetch all ticket ids from the API (default: load from file)")

    # parse arguments
    args = parser.parse_args()
    try:
        start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
    except ValueError:
        raise ValueError("--start-date must be in YYYY-MM-DD format")
    max_concurrent = args.max_concurrent
    ticket_data_folder = args.data_folder
    fetch = args.fetch

    individual_ticket_folder = f"{ticket_data_folder}/individual_tickets/"
    
    # Read company identifiers from environment variable
    company_identifiers = os.getenv("COMPANY_IDENTIFIERS")
    company_identifiers = [c.strip() for c in company_identifiers.split(",") if c.strip()]
    logger.info(f"Ingesting tickets for {len(company_identifiers)} companies: {', '.join(company_identifiers)}")

    # Let's get started
    connectwise_api = ConnectWiseAPI()
    async with AuthenticatedPostgresClient(USER_EMAIL) as db_client:
        # fetching all tickets for a company after a specific start date
        if fetch:
            logger.info("Fetching all ticket ids from API")
            all_ticket_ids = await get_all_ticket_ids(
                connectwise_api,
                company_identifiers, 
                start_date,
                page_size = 1000,
                limit = None
            )
            data_dict = {"ticket_ids": all_ticket_ids}
            save_json(data_dict, "all_ticket_ids.json", folder = ticket_data_folder)
        else:
            logger.info("Loading all ticket ids from file")
            all_ticket_ids = load_json("all_ticket_ids.json", folder = ticket_data_folder)
            all_ticket_ids = all_ticket_ids["ticket_ids"]
            
        ingested_ticket_ids = await get_ingested_ticket_ids(db_client)
        ticket_ids_to_ingest = await get_ticket_ids_to_ingest(all_ticket_ids, ingested_ticket_ids)
        ticket_ids_to_ingest.sort()
        logger.info(f"{len(ticket_ids_to_ingest)} ticket_ids to ingest")

        # #########
        # # limit the number of tickets to ingest
        # ticket_ids_to_ingest = ticket_ids_to_ingest[:10]
        # ########

        start_time = datetime.now()
        # ingest tickets
        response = await ingest_tickets(
            ticket_ids_to_ingest, 
            db_client,
            save_folder = individual_ticket_folder,
            max_concurrent = max_concurrent
        )
        end_time = datetime.now()
        seconds_elapsed = (end_time - start_time).total_seconds()
        logger.info(f"Ingested {len(response)} tickets in {seconds_elapsed}s")
        logger.info(f"Average time per ticket: {seconds_elapsed / len(response):.2f}s")

        # print summary of ingestion results
        total_success = sum(1 for r in response if r["success"])
        total_failure = len(response) - total_success
        logger.info(f"Total tickets ingested: {total_success} / {len(response)}")
        if total_failure > 0:
            logger.info(f"Total tickets failed:   {total_failure} / {len(response)}")



    

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/utils/get_active_tsi_dict.py
```python
import asyncio
from datetime import datetime, timezone
from app.api import ConnectWiseAPI
from dotenv import load_dotenv
import json
import logging
import os
import pathlib

# Set up logging
logging.basicConfig(level=logging.INFO)

load_dotenv()


api = ConnectWiseAPI()

def load_json_file(file_path: str):
    with open(file_path, "r") as f:
        return json.load(f)

def save_json_file(data: dict, file_path: str):
    with open(file_path, "w") as f:
        json.dump(data, f, indent=4)


def count_dict_items(d: dict):
    n_types = len(d)
    n_subtypes = 0
    n_items = 0
    for type in d:
        n_subtypes += len(d[type])
        for subtype in d[type]:
            n_items += len(d[type][subtype])
    return n_types, n_subtypes, n_items

def sort_dict(d: dict):
    """Sort the items in the dictionary in alphabetical order for the types, subtypes, and items"""
    sorted_dict = {}
    
    # Sort the types
    types = sorted(d.keys())
    for type in types:
        sorted_dict[type] = {}
        # Sort the subtypes
        subtypes = sorted(d[type].keys())
        for subtype in subtypes:
            sorted_dict[type][subtype] = sorted(d[type][subtype])

    return sorted_dict

async def get_active_tsi_dict(full_tsi_dict: dict):
    # Get active type data
    print("Getting active types...")
    route = "service/boards/17/types"
    params = {
        "fields": ",".join(["id", "name"]),
        "conditions": ",".join(["inactiveFlag!=true"])
    }
    data = await api.get_all(route = route, params = params, page_size = 100)
    active_types = {d["name"]: d["id"] for d in data}
    # print(f"active_types ({len(active_types)}): {list(active_types.keys())}")

    # Get active subtype data
    print("Getting active subtypes...")
    route = "service/boards/17/subTypes"
    data = await api.get_all(route = route, params = params, page_size = 100)
    active_subtypes = {d["name"]: d["id"] for d in data}
    # print(f"active_subtypes ({len(active_subtypes)}): {list(active_subtypes.keys())}")
    
    # Get active item data
    print("Getting active items...")
    route = "service/boards/17/items"
    data = await api.get_all(route = route, params = params, page_size = 100)
    active_items = {d["name"]: d["id"] for d in data}
    # print(f"active_items ({len(active_items)}): {list(active_items.keys())}")

    # Merge with tsi_dict
    print("Merging with fulltsi_dict...")
    new_tsi_dict = full_tsi_dict.copy()
    all_types = full_tsi_dict.keys()
    # First remove non-active types
    for type in all_types:
        if type not in active_types:
            del new_tsi_dict[type]
        else:
            # Then remove non-active subtypes
            subtypes = full_tsi_dict[type].copy().keys()
            for subtype in subtypes:
                if subtype not in active_subtypes:
                    # print(f"subtype {subtype} not in active_subtypes")
                    del new_tsi_dict[type][subtype]
                else:
                    # Then remove non-active items
                    items = full_tsi_dict[type][subtype].copy()
                    for item in items:
                        if item not in active_items:
                            # print(f"item {item} not in active_items")
                            new_tsi_dict[type][subtype].remove(item)

    return new_tsi_dict


def clean_dict(d: dict):
    """Clean the dictionary by removing any special characters from keys"""
    clean_d = {}
    
    for key in d:
        # Replace non-breaking space (u00a0), en dash (u2013), and other whitespace characters with regular spaces
        clean_key = key.replace('\u00a0', ' ').replace('\u2013', '-').strip()
        
        if isinstance(d[key], dict):
            clean_d[clean_key] = clean_dict(d[key])
        elif isinstance(d[key], list):
            clean_d[clean_key] = [item.replace('\u00a0', ' ').replace('\u2013', '-').strip() if isinstance(item, str) else item for item in d[key]]
        else:
            clean_d[clean_key] = d[key]
    
    return clean_d

async def main():

    # get full tsi_dict including inactive types, subtypes, and items
    print("Getting full tsi_dict...")
    tsi_dict = await api.get_tsi_dict()
    tsi_dict = sort_dict(tsi_dict)
    tsi_dict = clean_dict(tsi_dict)
    tsi_dict_path = "app/data/tsi_dict.json"
    save_json_file(tsi_dict, tsi_dict_path)


    active_tsi_dict = await get_active_tsi_dict(tsi_dict)   
    active_tsi_dict = sort_dict(active_tsi_dict)
    active_tsi_dict = clean_dict(active_tsi_dict)
    # Save the new tsi_dict
    tsi_dict_path = "app/data/tsi_dict_active.json"
    save_json_file(active_tsi_dict, tsi_dict_path)


    n_types, n_subtypes, n_items = count_dict_items(tsi_dict)
    print(f"Old tsi_dict: {n_types} types, {n_subtypes} subtypes, {n_items} items")

    n_types, n_subtypes, n_items = count_dict_items(active_tsi_dict)
    print(f"New tsi_dict: {n_types} types, {n_subtypes} subtypes, {n_items} items")
    





    # # Get active subtyitempe data
    # route = "service/boards/17/items"
    # params = {
    #     # "fields": ",".join(["id", "name", "inactiveFlag"]),
    #     "conditions": ",".join(["inactiveFlag!=true"])
    # }
    # data = await api.get_all(route = route, params = params, page_size = 100)
    
    # print(f"data:\n{json.dumps(data, indent=4)}")
    # print(f"{len(data)} active subtypes found")

    
    # data = await api.get(route = route)
    # print(f"data:\n{json.dumps(data, indent=4)}")

    # # TEST GEdTTING TSI DATA
    # tsi_data = await api.get_tsi_data(board_id=17)
    # print(f"tsi_ata:\n{json.dumps(tsi_data, indent=4)}")

    # tsi_dict = await api.get_tsi_dict()
    # print(f"tsi_dict:\n{json.dumps(tsi_dict, indent=4)}")
    
    # TEST GETTING TICKET WITH MESSAGES
    # ticket_id = 1018108 # the first one we have from feb 2025
    # ticket_id = 1030209 
    # fields = [
    #         "id",
    #         # "company",
    #         # "type",
    #         # "subtype",
    #         # "item",
    #         "_info"
    #     ]

    # ticket = await api.get(
    #     route = f"service/tickets/{ticket_id}",
    #     params = {"fields": ",".join(fields)}
    # )
    # try:
    #     print(f"ticket: {json.dumps(ticket, indent=4)}")
    # except Exception as e:
    #     print(f"Error: {e}")
    #     print(f"ticket: {ticket}")


    # ticket_with_messages = await api.get_ticket_with_messages(ticket_id)
    # print(f"\n\nticket_with_messages: {json.dumps(ticket_with_messages, indent=4)}")


    

    

if __name__ == "__main__":
    asyncio.run(main())
```
## File: app/models/ticket.py
```python
from typing import Dict, List, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field

class TicketMetadata(BaseModel):
    contact_id: Optional[int] = None
    contact_name: Optional[str] = None
    type: Optional[str] = None
    subtype: Optional[str] = None
    item: Optional[str] = None
    date_entered: Optional[str] = None
    closed_date: Optional[str] = None

class Company(BaseModel):
    identifier: str
    name: str

class Classification(BaseModel):
    service_type: Optional[str] = None
    subtype: Optional[str] = None
    item: Optional[str] = None

class Contact(BaseModel):
    id: int
    name: str

class Message(BaseModel):
    id: int
    text: str
    date: str
    type: str  # 'note', 'time_entry', etc.
    from_user: str = Field(alias="from")  # Used alias to handle 'from' keyword
    
    class Config:
        populate_by_name = True  # Allow field population by either alias or field name

class Ticket(BaseModel):
    """
    Complete representation of a ticket throughout the processing pipeline.
    
    This class is used across all components of the system to ensure
    consistency in how tickets are represented and processed.
    """
    # Core ticket information
    id: int
    summary: Optional[str] = None  # The title of the ticket from API
    llm_summary: Optional[str] = None  # The generated summary of the entire ticket content
    company: Company
    contact: Contact
    group_id: Optional[str] = None
    classification: Classification
    priority: Optional[str] = None
    date_entered: Optional[str] = None
    closed_date: Optional[str] = None
    messages: List[Message] = []
    content: Optional[str] = None
    
    class Config:
        populate_by_name = True  # Allows using field aliases

    @staticmethod
    def format_messages_as_content(summary: str, messages: List[Message]) -> str:
        """
        Format a list of messages into the standard content string format.
        
        Args:
            summary: The ticket summary to use as the header
            messages: List of message objects to format
            
        Returns:
            Formatted content string with messages in markdown format
        """
        # Start with the ticket summary as a header
        content = f"# {summary}\n\n"
        
        # Add each message with a clear header
        for message in messages:
            # Access the from_user field
            from_user = message.from_user  
            header = f"## On {message.date}, {from_user} wrote a {message.type} ({message.id}):\n"
            content += header + message.text + "\n\n"
        
        return content.strip()
    
    @staticmethod
    def parse_messages_from_content(content: str) -> tuple[str, List[Message]]:
        """
        Parse a content string to extract the summary and messages.
        
        Args:
            content: Formatted content string from database
            
        Returns:
            (summary, messages) tuple containing the ticket summary and list of Message objects
        """
        import re
        
        summary = ""
        messages = []
        
        # Try to extract summary from the first # header
        summary_match = re.search(r"^# (.+?)$", content, re.MULTILINE)
        if summary_match:
            summary = summary_match.group(1)
        
        # Look for message patterns: "## On DATE, ANY_NAME wrote a TYPE (ID):"
        # The pattern handles names with any characters (including symbols, spaces, etc.)
        # Examples that will work:
        # - John Doe wrote a note (123):
        # - Jane.Doe@company.com wrote a time_entry (456):
        # - User <user@domain.com> wrote a note (789):
        # - Client-Care Agent (labtech) wrote a note (949322):
        
        # We need to handle cases where the from_user contains parentheses
        # Match structure: 
        # ## On [date], [from_user] wrote a [type] ([id]):
        # [text]
        
        # Try with a simpler but more robust approach - find all headers first
        header_pattern = r"## On ([\w\-:\.TZ]+), (.*?) wrote a (.*?) \((\d+)\):"
        headers = re.findall(header_pattern, content)
        
        # Process each header and extract text until next header or end
        for i, header in enumerate(headers):
            date, from_user, msg_type, msg_id = header
            
            # Find where this header appears in the content
            header_text = f"## On {date}, {from_user} wrote a {msg_type} ({msg_id}):"
            header_pos = content.find(header_text)
            
            if header_pos >= 0:
                # Find the start of the message text (after the header)
                text_start = header_pos + len(header_text)
                
                # Find the end of the message text (start of next header or end of content)
                if i < len(headers) - 1:
                    next_header = f"## On {headers[i+1][0]}, {headers[i+1][1]} wrote a {headers[i+1][2]} ({headers[i+1][3]}):"
                    next_header_pos = content.find(next_header)
                    text_end = next_header_pos
                else:
                    text_end = len(content)
                
                # Extract the message text
                text = content[text_start:text_end].strip()
                
                messages.append(Message(
                    id=int(msg_id),
                    text=text,
                    date=date,
                    type=msg_type,
                    from_user=from_user
                ))
        
        return summary, messages
            
    @classmethod
    def from_api_format(cls, ticket: Dict[str, Any]) -> 'Ticket':
        """
        Create a Ticket instance from an API response.
        
        The API ticket format looks like:
        {
            "id": 381487,
            "company_name": "Elim Housing Society",
            "company_identifier": "Elim",
            "contact_name": "Jenn Pook",
            "contact_id": 6242,
            "type": "User",
            "subtype": "User",
            "item": null,
            "date_entered": "2018-05-04T22:41:32Z",
            "closed_date": "2021-09-10T17:43:48Z",
            "summary": "Shannon Shefner Files",
            "priority": "P3",
            "messages": [...]
        }
        """
        # Create company object with proper error handling
        company_name = ticket.get("company_name", "Unknown")
        company_identifier = ticket.get("company_identifier", "Unknown")
        if not company_name or company_name == "Unknown":
            # Try alternative field names
            if "company" in ticket and isinstance(ticket["company"], dict):
                company_name = ticket["company"].get("name", "Unknown")
                company_identifier = ticket["company"].get("identifier", "Unknown")
                
        company = Company(
            identifier=company_identifier,
            name=company_name
        )
        
        # Create contact object with proper error handling
        contact_id = ticket.get("contact_id", 0)
        contact_name = ticket.get("contact_name", "Unknown")
        if not contact_name or contact_name == "Unknown":
            # Try alternative field names
            if "contact" in ticket and isinstance(ticket["contact"], dict):
                contact_id = ticket["contact"].get("id", 0)
                contact_name = ticket["contact"].get("name", "Unknown")
                
        contact = Contact(
            id=contact_id,
            name=contact_name
        )
        
        # Extract type, subtype, item from various possible locations
        type_val = ticket.get("type")
        subtype_val = ticket.get("subtype")
        item_val = ticket.get("item")
        
        # If type is a dict (nested structure), extract the name
        if isinstance(type_val, dict) and "name" in type_val:
            type_val = type_val.get("name")
            
        # If subType is a dict (nested structure), extract the name
        if "subType" in ticket and isinstance(ticket["subType"], dict):
            subtype_val = ticket["subType"].get("name")
        elif isinstance(subtype_val, dict) and "name" in subtype_val:
            subtype_val = subtype_val.get("name")
            
        # If item is a dict (nested structure), extract the name
        if isinstance(item_val, dict) and "name" in item_val:
            item_val = item_val.get("name")
        
        # Create classification object
        classification = Classification(
            service_type=type_val,
            subtype=subtype_val,
            item=item_val
        )
        
        # Handle dates
        date_entered = ticket.get("date_entered")
        if not date_entered and "_info" in ticket and isinstance(ticket["_info"], dict):
            date_entered = ticket["_info"].get("dateEntered")
            
        closed_date = ticket.get("closed_date")
        if not closed_date and "closedDate" in ticket:
            closed_date = ticket.get("closedDate")
            
        # Convert messages if they exist
        messages = []
        for msg in ticket.get("messages", []):
            # Extract message fields
            msg_id = msg.get("id", 0)
            msg_text = msg.get("text", "")
            msg_date = msg.get("date", "")
            msg_type = msg.get("type", "")
            
            # The critical part: API response has 'from' field - we need to parse this correctly 
            # but provide it to the Message constructor using the 'from' field name
            msg_from = msg.get("from", "Unknown")
            
            # Create the Message using the alias
            message = Message(
                id=msg_id,
                text=msg_text,
                date=msg_date,
                type=msg_type,
                **{"from": msg_from}  # This ensures the alias works correctly
            )
            messages.append(message)
        
        # Get content field or generate it from messages if not present
        content = ticket.get("content")
        if content is None and messages:
            # Generate content from messages
            summary = ticket.get("summary", "")
            content = cls.format_messages_as_content(summary, messages)
        
        # Extract summary (title) from API data - no LLM summary from API
        summary = ticket.get("summary", "")
        
        # Create ticket instance
        return cls(
            id=ticket.get("id", 0),
            summary=summary,  # API summary = title
            llm_summary=None,  # No LLM summary from API
            company=company,
            contact=contact,
            classification=classification,
            date_entered=date_entered,
            closed_date=closed_date,
            messages=messages,
            content=content,
            priority=ticket.get("priority"),
            group_id=ticket.get("group_id")
        )
    
    @classmethod
    def from_database_format(cls, ticket: Dict[str, Any]) -> 'Ticket':
        """
        Create a Ticket instance from a database record.
        
        The database ticket format looks like:
        {
            "id": 381487,
            "source": "6242",
            "group_id": "d0cfea2a-1756-49dd-a3df-e8d20fc796c3",
            "summary": "Shannon Shefner accidentally deleted files...",
            "metadata": {
                "item": null,
                "type": "User",
                "subtype": "User",
                "priority": "P3",
                "closed_date": "2021-09-10T17:43:48Z",
                "company_name": "Elim Housing Society",
                "contact_name": "Jenn Pook",
                "date_entered": "2018-05-04T22:41:32Z"
            },
            "content": "# Shannon Shefner Files\n\n## On 2018-05-04T22:41:32Z..."
        }
        """
        # Extract metadata safely
        metadata = ticket.get("metadata", {})
        
        # Create company object
        company = Company(
            identifier="",  # Database doesn't store company identifier
            name=metadata.get("company_name", "Unknown")
        )
        
        # Create contact object from source field
        source = ticket.get("source", "0")
        contact_id = int(source) if source and source.isdigit() else 0
        
        contact = Contact(
            id=contact_id,
            name=metadata.get("contact_name", "Unknown")
        )
        
        # Create classification object
        classification = Classification(
            service_type=metadata.get("type"),
            subtype=metadata.get("subtype"),
            item=metadata.get("item")
        )
        
        # Get content
        content = ticket.get("content", "")
        
        # Set LLM summary from database (the "summary" field in database is the LLM-generated summary)
        llm_summary = ticket.get("summary", "")
        
        # Parse title/summary and messages from content
        api_summary = ""  # Will be extracted from content if possible
        messages = []
        
        if content:
            # Try to parse summary and messages from content
            parsed_summary, parsed_messages = cls.parse_messages_from_content(content)
            
            # Use parsed summary as the API summary (title)
            if parsed_summary:
                api_summary = parsed_summary
                
            messages = parsed_messages
        
        # Create ticket instance
        return cls(
            id=ticket.get("id", 0),
            summary=api_summary,  # Title extracted from content
            llm_summary=llm_summary,  # LLM-generated summary from database
            company=company,
            contact=contact,
            group_id=ticket.get("group_id"),
            classification=classification,
            date_entered=metadata.get("date_entered"),
            closed_date=metadata.get("closed_date"),
            messages=messages,
            content=content,
            priority=metadata.get("priority")
        )
        
    def to_api_format(self) -> Dict[str, Any]:
        """
        Convert the standardized Ticket to the API format.
        """
        # Convert messages
        messages = []
        for msg in self.messages:
            # Create a dictionary with explicit mapping of from_user to "from" field
            message_dict = {
                "id": msg.id,
                "text": msg.text,
                "date": msg.date,
                "type": msg.type,
                "from": msg.from_user  # This becomes the "from" field in the API
            }
            messages.append(message_dict)
        
        # Build API format
        return {
            "id": self.id,
            "company_name": self.company.name,
            "company_identifier": self.company.identifier,
            "contact_name": self.contact.name,
            "contact_id": self.contact.id,
            "type": self.classification.service_type,
            "subtype": self.classification.subtype,
            "item": self.classification.item,
            "date_entered": self.date_entered,
            "closed_date": self.closed_date,
            "summary": self.summary,  # Use the title/API summary
            "priority": self.priority,
            "messages": messages,
            "content": self.content
        }
    
    def to_database_format(self) -> Dict[str, Any]:
        """
        Convert the standardized Ticket to the database format.
        """
        # Format messages into content if they exist
        if self.messages:
            content = self.format_messages_as_content(self.summary, self.messages)
        else:
            content = self.content or ""
            
        # Prepare metadata
        metadata = {
            "company_name": self.company.name if self.company else "",
            "contact_name": self.contact.name if self.contact else "",
            "type": self.classification.service_type if self.classification else None,
            "subtype": self.classification.subtype if self.classification else None,
            "item": self.classification.item if self.classification else None,
            "date_entered": self.date_entered,
            "closed_date": self.closed_date,
            "priority": self.priority
        }
        
        # Remove None values from metadata
        metadata = {k: v for k, v in metadata.items() if v is not None}
        
        # Prepare database record
        db_record = {
            "id": self.id,
            "source": str(self.contact.id),
            "group_id": self.group_id,
            "summary": self.llm_summary,  # Store LLM summary in the database's summary field
            "content": content,
            "metadata": metadata
        }
        
        # Remove None values from top level
        return {k: v for k, v in db_record.items() if v is not None}
```
## File: app/models/ticket_annotation.py
```python
from typing import Dict, List, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field, model_serializer


class ClassificationResult(BaseModel):
    """
    Contains the classification results for a ticket.
    """
    service_type: str = Field(default=None, description="The classified service type")
    subtype: str = Field(default=None, description="The classified subtype")
    item: str = Field(default=None, description="The classified item")
    priority: str = Field(default=None, description="The classified priority")

class Solutions(BaseModel):
    """
    Contains the solutions for a ticket.
    """
    historical: Optional[str] = Field(default=None, description="The suggested solution for the ticket based on past tickets")
    web_search: Optional[str] = Field(default=None, description="The solution found through web search")

class SimilarTicket(BaseModel):
    """
    A ticket that is similar to the current ticket.
    """
    id: int = Field(description="The ID of the ticket")
    summary: str = Field(description="The summary of the ticket")

class UserHistory(BaseModel):
    """
    Summary of a user's ticket history.
    """
    overview: str = Field(description="Brief overview of the user's typical issues")
    similar_ticket_ids: List[int] = Field(default_factory=list, description="A list of ticket IDs from the same user that are most similar to the current ticket, in order of relevance ")
    similar_tickets: List[SimilarTicket] = Field(default_factory=list, description="A list of fulltickets that are most similar to the current ticket, in order of relevance")
    recurring_issue: bool = Field(description="Is the current ticket related to a recurring issue that is present in the ticket history?")
    recurring_issue_cause: Optional[str] = Field(default=None, description="If there is a recurring issue related to the current ticket, what is its underlying cause? If not, return None.")

class RetrievalQuery(BaseModel):
    """
    The user's query for the ticket.
    """
    query: str = Field(description="The user's query for the ticket")
    system_information: Optional[str] = Field(default=None, description="Technical specifications about the user's system that are relevant to the ticket")

class TicketAnnotation(BaseModel):
    """
    Complete representation of a ticket annotation result.
    
    This class models the result returned by TicketAnnotator.annotate_ticket()
    and provides methods for formatting the annotation as a note.
    """

    ticket_id: int = Field(description="The ID of the ticket")
    success: bool = Field(default=False, description="Whether the annotation was successful")
    retrieval_query: Optional[RetrievalQuery] = Field(default=None, description="The extracted user query and system information")
    user_history: Optional[UserHistory] = Field(default=None, description="Summary of the user's ticket history")
    relevant_ticket_ids: List[int] = Field(default_factory=list, description="IDs of tickets found to be relevant")
    classification: Optional[ClassificationResult] = Field(default=None, description="The classification results")
    solutions: Optional[Solutions] = Field(default=None, description="The solutions for the ticket")
    saved_to: Optional[str] = Field(default=None, description="Path to which the annotation was saved")
    note_added: Optional[bool] = Field(default=None, description="Whether a note was added to the ticket")
    note_content: Optional[str] = Field(default=None, description="The content of the note added to the ticket")
    error: Optional[str] = Field(default=None, description="Error message if any")
    group_id: Optional[str] = Field(default=None, description="The group ID of the ticket")
    
    # Make model serializable to JSON
    @model_serializer
    def ser_model(self) -> Dict[str, Any]:
        """Serialize model to dict for JSON conversion"""
        return {
            "ticket_id": self.ticket_id,
            "success": self.success,
            "retrieval_query": self.retrieval_query.model_dump() if self.retrieval_query else None,
            "relevant_ticket_ids": self.relevant_ticket_ids,
            "classification": self.classification.model_dump() if self.classification else None,
            "user_history": self.user_history.model_dump() if self.user_history else None,
            "solutions": self.solutions.model_dump() if self.solutions else None,
            "group_id": self.group_id,
            "saved_to": self.saved_to,
            "note_added": self.note_added,
            "note_content": self.note_content,
            "error": self.error
        }
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert model to dictionary for JSON serialization"""
        return self.model_dump()
```
## File: app/models/__init__.py
```python
from app.models.ticket import (
    Ticket, 
)

from app.models.ticket_annotation import (
    TicketAnnotation,
    ClassificationResult,
    UserHistory,
)

__all__ = [
    'Ticket',
    'TicketAnnotation',
    'ClassificationResult',
    'UserHistory',
]
```
## File: app/data/tsi_dict.json
```json
{
    "!Reactive": {
        "!Grant New User FTP Access (Novacom)": []
    },
    "!Setup": {
        "!Grant New User FTP Access (Novacom)": [],
        "!New User": [],
        "!New User (Butterworth's)": [],
        "!New User (Relevention)": []
    },
    "!Vendor": {
        "!LabTech": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Microsoft": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ]
    },
    "AREV - A&A": {
        "*Triage": [
            "*Triage"
        ],
        "CBSA Communications": [
            "CBSA Communications"
        ],
        "Dev": [],
        "EDI": [],
        "Invoices": [
            "Invoices"
        ],
        "LPCO": [
            "LPCO"
        ],
        "Locked File": [
            "Locked File"
        ],
        "Lumber": [
            "Lumber"
        ],
        "Message Box": [
            "Line Error",
            "OK Box",
            "OK Box Loop"
        ],
        "PDF": [
            "Problem"
        ],
        "Performance": [
            "Problem"
        ],
        "Permissions": [
            "Problem",
            "Update"
        ],
        "Printing": [
            "Problem"
        ],
        "Scheduler": [
            "Error",
            "Locked File",
            "Not Responding"
        ],
        "Shortcut": [
            "Broken",
            "Missing"
        ]
    },
    "Application": {
        "!AppRiver-DUPLICATE": [
            "!Add",
            "!Password",
            "!Problem",
            "Change"
        ],
        "!Office 365": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ],
        "!VMWare-DUPLICATE": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Veeam": [
            "!Add",
            "!Problem",
            "!Renew",
            "!Warranty",
            "Change"
        ],
        "!Windows": [
            "!Add",
            "!Password",
            "!Problem",
            "!Recover",
            "Change"
        ],
        "AREV / Open Insight  (Select Item)": [
            "AREV/Open Insight  (A&A)"
        ],
        "Accounting - ADP": [
            "ADP (A&A) - Supported by Accounting",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Adagio": [
            "Adagio (Urban)",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Quickbooks": [
            "!Add",
            "!Password",
            "!Problem",
            "!Renew",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Sage": [
            "!Add",
            "!Password",
            "!Problem",
            "!Renew",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Ambiance/DormaKaba": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Antivirus": [
            "!Add",
            "!Password",
            "!Problem",
            "Change",
            "Enable",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Chrome": [
            "!Add",
            "!Problem",
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Edge": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Browser - Firefox": [
            "!Add",
            "!Problem",
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "CBDiets": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Chat": [
            "ChatBeacon",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Source Port Request",
            "Spark",
            "Update"
        ],
        "Cloud App": [
            "Install",
            "Performance",
            "Problem",
            "Remove",
            "Repair",
            "Scout Portal (Deskdirector)",
            "Update"
        ],
        "DialPad": [
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Dropbox": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "EDITrade  (Select Item)": [
            "EDITrade  (A&A)",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Front": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Google Workspace - Documents": [
            "Install",
            "Permissions",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Google Workspace - Email": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Google Workspace - Other": [
            "Admin",
            "Gmail",
            "Google Docs (A&A)",
            "Google Docs (Frozen)",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "IM/Chat - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "IM/Chat - Slack": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Slack (A&A)",
            "Slack (CREW)",
            "Slack (Frozen)",
            "Update"
        ],
        "IM/Chat \u2013 Univerge": [],
        "LastPass": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "LibraOffice": [
            "Install",
            "Update"
        ],
        "LibreOffice": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - Office": [
            "!Add",
            "!Password",
            "!Problem",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - OneDrive": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Setup",
            "Sync Issue"
        ],
        "MS - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "MS - Outlook": [
            "!Add",
            "!Password",
            "!Problem",
            "Change",
            "Install",
            "Problem",
            "Profile",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - SharePoint": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "MS - Teams (No Voice)": [
            "!Add",
            "!Problem",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "NetExtender": [],
        "Other": [
            "!Add",
            "!Password",
            "!Problem",
            "!Renew",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "PDF - Adobe": [
            "!Add",
            "!Password",
            "!Problem",
            "!Renew",
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "PDF - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "PDF - PDFelement/Wondershare": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Video Conferencing - Google Meet": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Video Conferencing - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Video Conferencing - Zoom": [
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "WordPerfect": [
            "!Add",
            "!Problem",
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ]
    },
    "Application - LOB": {
        "Amicus Attorney": [],
        "Arcline": [],
        "Comvida": [],
        "Copitrak/SAI": [],
        "Destiny": [],
        "Dolphin": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "EPass": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "ESI Law": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "Filemaker": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "GhostPractice": [],
        "ITMR4": [],
        "Maestro": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "PCC": [],
        "Salesforce": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "Syspro (Select Item)": [
            "Install",
            "Remove",
            "Repair",
            "Syspro (Excell)",
            "Update"
        ],
        "Tower (Select Item)": [
            "Install",
            "Remove",
            "Repair",
            "Tower (Urban)",
            "Update"
        ],
        "Worldox": [],
        "iCarol": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ]
    },
    "Credit-Card": {
        "Credit-Card": [
            "Purchase"
        ]
    },
    "Group": {
        "!Triage": [
            "!Triage"
        ],
        "Distribution Group": [
            "Add",
            "Change",
            "Remove"
        ],
        "File Share/Group Drive": [
            "Add",
            "Change",
            "Remove"
        ],
        "LP Shared Folder": [
            "Add",
            "Change",
            "Remove"
        ],
        "Security Group": [
            "Add",
            "Change",
            "Remove"
        ],
        "Shared Mailbox": [
            "Add",
            "Change",
            "Remove"
        ],
        "Teams/M365 Group": [
            "Add",
            "Change",
            "Remove"
        ]
    },
    "Information Request (Select Subtype)": {
        "Report (Select Item)": [
            "!Office365 Users Report - JRG",
            "AD Group Report - Elim",
            "Active AD Users Report",
            "KnowBe4",
            "Licensed Office365 Users Report",
            "OpenDNS"
        ]
    },
    "Meeting": {
        "Meeting": [
            "!Add",
            "Change"
        ]
    },
    "Mobile": {
        "Android": [
            "Error",
            "Setup"
        ],
        "MDM": [
            "App Deployment",
            "Change",
            "Enrollment",
            "Error",
            "Policy Change",
            "Setup"
        ],
        "Other": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Phone": [],
        "Tablet": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "iOS": [
            "Error",
            "Setup"
        ],
        "iPod": [
            "!Add",
            "!Password",
            "!Problem",
            "Change"
        ]
    },
    "Multi Factor Authentication": {
        "Enable": [],
        "LastPass Authenticator": [
            "New Phone"
        ],
        "Setup": []
    },
    "Network": {
        "!Drive": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!File": [
            "!Add",
            "!Problem",
            "!Recover",
            "Change"
        ],
        "!Restore": [],
        "AVD": [
            "Problem"
        ],
        "AppRiver": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Apple TV": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Azure": [],
        "Cabinet": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Cabling": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Camera/DVR": [
            "Change"
        ],
        "DNS/Host": [
            "!Add",
            "!Problem",
            "Change",
            "DMARC, SPF, DKIM"
        ],
        "Domain/Registrar": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "E-mail Compromise": [
            "Change",
            "Email Compromise",
            "Email Compromise - False Positive"
        ],
        "E-mail/Spam": [
            "!Add",
            "!Password",
            "!Problem",
            "!Spam",
            "Bounceback",
            "Change",
            "Phishing",
            "Remove",
            "Whitelist Request"
        ],
        "FTP": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Firewall": [
            "!Add",
            "!Password",
            "!Problem",
            "!Reboot",
            "Change",
            "Rule Request"
        ],
        "IP Address": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "IPSEC VPN": [],
        "Internet (Bonding)": [
            "Change",
            "Maintenance",
            "Outage",
            "Performance"
        ],
        "Internet (Home)": [
            "Change"
        ],
        "Internet (ISP)": [
            "!Add",
            "!Problem",
            "Change",
            "Maintenance",
            "Outage",
            "Performance"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Microsoft 365/SharePoint": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Modem": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "NAS/SAN": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Network Jack": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "OpenDNS": [
            "!Add",
            "!Bypass Request",
            "!Malware Detected",
            "!Problem",
            "Change",
            "Whitelist Request"
        ],
        "Performance": [
            "!Problem",
            "Change"
        ],
        "RDP": [
            "!Add",
            "!Problem",
            "Change",
            "Problem"
        ],
        "Router": [
            "!Add",
            "!Password",
            "!Problem",
            "!Reboot",
            "!Renew",
            "!Warranty",
            "Change"
        ],
        "Security": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Switch": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "UPS": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "VPN": [
            "!Add",
            "!Problem",
            "Change",
            "Problem",
            "Whitelist Request"
        ],
        "Website/Host": [
            "!Add",
            "!Password",
            "!Problem",
            "Change",
            "Whitelist Request"
        ],
        "Wireless": [
            "!Add",
            "!Password",
            "!Problem",
            "AP Problem",
            "AP Reboot",
            "Change",
            "Coverage"
        ]
    },
    "Offering": {
        "Addigy": [],
        "CW Automate": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "CW Control (ScreenConnect)": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "CW Manage": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "Client-Care": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "DSIT Tools (CW, SC ETC)": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "DeskDirector": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "OpenDNS": [
            "Change",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Security Awareness": [
            "Change",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Signature/Crossware": [
            "Problem",
            "Remove",
            "Setup"
        ]
    },
    "Print/Scan/eFax": {
        "!Colour": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Inkjet": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Monochrome": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Faxing": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "IP Address": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Performance": [
            "!Problem",
            "Change"
        ],
        "Printing": [
            "!Add",
            "!Problem",
            "Change",
            "Install",
            "Problem"
        ],
        "Scanning": [
            "!Add",
            "!Problem",
            "Change",
            "Problem"
        ],
        "Toner": [
            "!Add",
            "!Problem",
            "Change"
        ]
    },
    "Server": {
        "!File": [
            "!Recover"
        ],
        "!File Server": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "!Office 365": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!RAID": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Restore": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!SBS": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "!Veeam": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ],
        "!Warranty": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ],
        "!Windows": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Active Directory": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Azure": [],
        "BES": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "Backup/Restore": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Cabinet": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Certificate": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ],
        "DFS": [
            "Change"
        ],
        "DHCP": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "DNS/Host": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Disk/Drive": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Domain Controller": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "E-mail Compromise": [
            "Change",
            "Email Compromise"
        ],
        "E-mail/Spam": [
            "!Add",
            "!Problem",
            "!Spam",
            "Change"
        ],
        "Encryption": [
            "Change"
        ],
        "Exchange": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "FTP": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Fan": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Faxing": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "File/Folder (Select Item)": [
            "!Add",
            "!File Permissions (Accent)",
            "!Problem",
            "!Recover",
            "Change",
            "File Permissions (All)",
            "Restore"
        ],
        "Firewall": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Group Policy": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Hyper-V": [
            "Change"
        ],
        "IIS": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "IP Address": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "IPSEC VPN": [],
        "MS - Teams (No Voice)": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Memory": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Motherboard": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "NIC": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "OS": [
            "!Add",
            "!Password",
            "!Problem",
            "!Reboot",
            "!Recover",
            "Change"
        ],
        "Patching": [
            "Change"
        ],
        "Performance": [
            "!Problem",
            "Change"
        ],
        "Power": [
            "!Add",
            "!Interruption",
            "!Problem",
            "Change"
        ],
        "Profile": [
            "Change"
        ],
        "SQL": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change"
        ],
        "Terminal Services": [
            "!Add",
            "!Problem",
            "!Reboot",
            "Change",
            "Problem"
        ],
        "Time/NTP": [
            "Change"
        ],
        "UPS": [
            "!Add",
            "!Battery",
            "!Problem",
            "Change"
        ],
        "USB/Serial Port": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "VMware": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Video": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Virus/Spyware": [
            "!Add",
            "!Problem",
            "Change",
            "False Positive"
        ],
        "Website/Host": [
            "!Add",
            "!Problem",
            "Change"
        ]
    },
    "Telecom": {
        "!Analog": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Digital": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "3CX": [
            "Change",
            "Problem"
        ],
        "3CX Client": [
            "Education"
        ],
        "3CX Server": [],
        "Analog Line": [
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Cabling": [],
        "Call Logging": [],
        "Desk Phone": [
            "Change",
            "Education",
            "Phone A&A",
            "Programming"
        ],
        "IP Address": [
            "!Add",
            "!Problem",
            "Change",
            "Education"
        ],
        "MS - Teams Voice": [
            "Firmware",
            "Problem"
        ],
        "Mitel/Shoretel": [
            "Education"
        ],
        "NurseCall": [
            "Alarm",
            "Change",
            "Education",
            "Install"
        ],
        "PBX": [
            "3CX Server",
            "Avaya",
            "Call Logging",
            "Education",
            "NEC",
            "Norstar",
            "Other",
            "Ring Central",
            "Samsung"
        ],
        "PRI": [
            "Call Quality Issue",
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Phone/Fax Line": [
            "!Add",
            "!Problem",
            "Call Quality Issue",
            "Change",
            "Education",
            "Phone A&A",
            "Programming",
            "Update Entertainment Announcement"
        ],
        "RingCentral": [
            "Education"
        ],
        "VOIP Provider": [
            "Call Quality Issue",
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Voicemail": [
            "Education"
        ],
        "Wireless Bridge": [],
        "miLINK": [],
        "miLINK PBX": [
            "Change",
            "Problem"
        ]
    },
    "User": {
        "Change User": [
            "International Travel Request"
        ],
        "Desk Move": [],
        "Discussion": [],
        "Group Membership": [
            "Volunteer Role Change (CrisisCentre)"
        ],
        "Multi Factor Authentication": [
            "New Phone",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Password": [
            "!Add",
            "!Problem",
            "Change",
            "Expired"
        ],
        "Profile": [
            "Broken",
            "Missing",
            "Problem"
        ],
        "Signature": [
            "Broken",
            "Change"
        ],
        "Training": [],
        "User": [
            "!Change User (Accent Inns & Hotel Zed)",
            "!Change User (JRG)",
            "!Deactivate User (Accent Inns & Hotel Zed)",
            "!Deactivate User (Collabware)",
            "!Deactivate User (Rally)",
            "!New Accounting User (JRG)",
            "!New User (Accent Inns & Hotel Zed)",
            "!New User (Aggressive Transport Ltd.)",
            "!New User (Collabware)",
            "!New User (DMS)",
            "!New User (Kidzsmart)",
            "!New User (Maplewood Seniors Care Society)",
            "!New User (Paramount)",
            "!New User (Primex)",
            "!New User (Rally)",
            "!New User (Relevention)",
            "!New User Request (JRG)",
            "!Password",
            "Change",
            "Deactivate User (CREW)",
            "Deactivate User (Weststone Group)",
            "New User",
            "New User (A&A)",
            "New User (CREW)",
            "New User (Concord)",
            "New User (DMS Mechanical Ltd.)",
            "New User (Elim)",
            "New User (Foyer Maillard)",
            "New User (Frozen Mountain Software)",
            "New User (GBACAN)",
            "New User (Novacom)",
            "New User (SSR)",
            "New User (Sonic Enclosures)",
            "New User (SunSelect)",
            "New User (Urban Impact)",
            "New User (Vancouver Holocaust Education Centre)",
            "New User (Way to Grow)",
            "New User (Weststone Group)",
            "Remove"
        ]
    },
    "Workstation": {
        "!Backup-DUPLICATE": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Desktop": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Drive": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!File": [
            "!Add",
            "!Problem",
            "!Recover",
            "Change"
        ],
        "!Icon": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Laptop": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Restore": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "!Warranty": [
            "!Add",
            "!Problem",
            "!Renew",
            "Change"
        ],
        "Audio": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Backup/Restore": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Certificate": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Computer": [
            "!New Computer (Benchmark)",
            "!New Computer (Collabware)",
            "!New Computer (Maplewood Seniors Care Society)",
            "!Problem",
            "!Reboot",
            "Change",
            "Clock",
            "New Computer",
            "New Computer (AOTP)",
            "New Computer (CREW)",
            "New Computer (Excell)",
            "New Computer (Frozen Mountain)"
        ],
        "Desk Move": [
            "Change"
        ],
        "Disk/Drive": [
            "!Add",
            "!Problem",
            "Change",
            "Quoted Replacement"
        ],
        "Docking Station": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Encryption": [
            "BitLocker Recovery Key",
            "Change"
        ],
        "FTP": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Fan": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Faxing": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Firewall": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "IP Address": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Keyboard": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Memory": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Monitor": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Motherboard": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Mouse": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "NIC": [
            "!Add",
            "!Problem",
            "!Slow",
            "Change"
        ],
        "OS": [
            "!Add",
            "!Password",
            "!Problem",
            "!Reboot",
            "!Recover",
            "!Renew",
            "Change",
            "Problem",
            "Update",
            "Upgrade"
        ],
        "Patching": [
            "Change"
        ],
        "Performance": [
            "!Add",
            "!Problem",
            "!Slow",
            "Because of OS Updates",
            "Change",
            "Problem"
        ],
        "Power": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Profile": [
            "Change"
        ],
        "Time/NTP": [
            "Change"
        ],
        "UPS": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "USB/Serial Port": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Video": [
            "!Add",
            "!Problem",
            "Change"
        ],
        "Virus/Spyware": [
            "!Add",
            "!Problem",
            "Change",
            "False Positive",
            "Remove"
        ],
        "Wireless": [
            "!Add",
            "!Problem",
            "!Slow",
            "Change"
        ]
    }
}
```
## File: app/data/ticket_with_images.json
```json
{
    "id": 622356,
    "summary": "Ethernet not detecting on Dock ",
    "company": {
        "id": 3885,
        "identifier": "Elim",
        "name": "Elim Housing Society",
        "_info": {
            "company_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/companies/3885",
            "mobileGuid": "d7ebc854-1c28-473d-8dcf-d0d4f2ab8294"
        }
    },
    "type": {
        "id": 109,
        "name": "Network",
        "_info": {
            "type_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17/types/109"
        }
    },
    "closedDate": "2020-01-14T23:25:26Z",
    "dateResolved": "2020-01-14T23:25:26Z",
    "messages": [
        {
            "id": 469509,
            "date": "2020-01-14T17:06:00Z",
            "from": "Shane Garner",
            "type": "time_entry",
            "text": "Grace called in \nshe cannot connect to the network \ncan log in but cannot connect to wifi \nlogged on\ntraced cabled, moved connections, checked all connectors \nstill no dock present - no monitors, no ethernet \ndevices not listing dock \npower cycled dock, still no change \npossible cable to surface is faulty \nremoving dock from equation to get her working \nstill cannot connect to wifi \nthey use radius, ,suspected password issue \ngot her pass, cannot log into terminal \nreset password \ncan now connect to wifi \nshe has access to her files and can work again \nDayne will be dropping in this afternoon to check "
        },
        {
            "id": 1362709,
            "date": "2020-01-14T18:05:51Z",
            "from": "SGarner",
            "type": "note",
            "text": "Assigned / DCody / "
        },
        {
            "id": 469649,
            "date": "2020-01-14T22:10:00Z",
            "from": "Dayne Cody",
            "type": "time_entry",
            "text": "-Spoke to Grace\n-Took a look at her dock and setup\n-It seems like her cable isn't getting a good connection from the wall\n-Went and grabbed a new Ethernet cable from the Jeep\n-Connected and confirmed working\n-Wiggled cable and confirmed much better connection now and no disconnects\n-She was also having an issue with her monitor not connecting\n-Found that the cable end at the dock was busted and looks like it had been rolled over or something\n-Found a replacement cable and connected it\n-Still having an issue with getting a connection, keeps saying that It is unable to make changes\n-Did a search for new display drivers\n-Found and installed updated display drivers\n-Once those installed was able to get the monitor back working again\n-Confirmed all good and all finished"
        },
        {
            "id": 1363783,
            "date": "2020-01-15T22:54:36Z",
            "from": "Grace Vanderende gvanderende@elimvillage.com",
            "type": "note",
            "text": "My new schedule as Education Coordinator for 2020 will be as follows:\nTuesday 0800- 1600\nThurday 0800-1600\n\n\\*\\*Grace VanderEnde\\*\\*\n!\\[\\\\\\[image\\\\\\]\\]\\(data:image/png;base64,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\\)Education Coordinator\nHarrison Administration\n9025 160 Street Surrey, BC V4N 2X7\n\\*\\*T:\\*\\* 604.587.8999 ext. 4488 \\*\\*F:\\*\\* 604.587.8998\nwww.elimvillage.com\n\\[!\\[\\\\\\[image\\\\\\]\\]\\(data:image/gif;base64,R0lGODlhEAAQAOYAAPX//H6dr0lnmqWv0zdKd1l2ubjM4fv96JuqxSU3cGh9wjxapTxlqEZpt2J/q1NmtkVdmTtWc0NUqvn92zVJiHKU2iM9g2N6mubz/z5gl0xkiwkWTTRUlDxclAspaSlCekFhrkRYiW2SyS9SikVWecTN6UVjokVfgFJaiVFxrfr6/zlZjDtag4+n51lpnQsRakddjQklWSpJbe76/1Frmfj8/ixLjTtSgz1RlVJhnTJPjTZYmjJaiy9MlTlcnzVclS5Aj//5+fL38URsqUplqneN4Pr8+XmQ1tLj82iM2nGMz3GK3nSUz9Te6pSsrDJLau717jVToTFLlVFztTxXnFVvooGX0HOAqMjX9IKNrY2VvJOcpZacvP/79+Tg+UJonwQEQE5np0tqozZWgvTw/vL+8D5Ykeb//1Njl4CNnlVqlV5ul9/v/lVymp2l1LC4uj9Xf63Aw0BXjVRjjHCR1PPs9IF6rXyT2Tpctm6JziNGhiZIhS5Hhy9IgGB2pF1yqSH5BAAAAAAALAAAAAAQABAAAAf/gCVXGjR/Loc5OWhzaygoJRcOKVMFlSmTIAUPEgpqAlMgDQw/GQwMPjoxMQlmLGINeA0+X0MMURZPTnEIcGM0KaEZAj8MOjdsZQAYBGYaJgtUYRxEOAkINUFeSB9ycCYgUt9RD2AIUHVgGxA3Jx0+Jjo7C0BXcQdddld9IRErHB0rOuxJgAHAhAk1zshIAMffijE8RvTJ0uTAAS4BZBAgwKGHDR0jOOAAo8UImRceMmzk08PCBxsWgGxwU0PFCwt6KESo0sEMBHkSEgwQUsMCjy8UNFi5k4eJCBEV2hgAAECNkhYwBBwpsqQCnQpJ/BiYMcOPghYhDKwJAQOOBhhtCtO82UICBgEsgQAAOw==\\)\\]\\(https://www.facebook.com/Elim-Village-167942179908157/\\)\u00a0\\[!\\[\\\\\\[image\\\\\\]\\]\\(data:image/gif;base64,R0lGODlhEAAQAOYAAI601jmWxiFiijV7pZGwtzeHnrfX8+r+/gtnhTRriCt0mXq12hh4uU226AJqpgpYiBZ7qvr79Cyd0/b9/wd3mS+QyhmI06HQ2kyEmwFypvv9/zum0qnV7bTZ5pvE24fG4ySTzwiAv/386wFhsSWLvTaDsQBdgU6t3Cah1keFuCKFxQZVommmuyhsk9zo7St5ojR0iuT9/hx1ndf09iVmfzaX1gQ2fSCNvwJknA5/tA5zsDx0ljZ6lUWf2j58nAxmkUaSsS6Ftw5hjxRWezVvl0mgqkeDqEiAozFwkRmGxwpuolmIos7d/EyTpwyGwQiQxOnx/JzE5y6Nqz17tDSDqidthm3E+Sd8vd/z/C+a4D+ezH6fslCLwyiN1aW74tTx/9P//4PA0ySEtBd4xR6CuB+X00KQn06FrCCOxiWPySmHxSiHyTCHwQVvswh0vRyJzA16u0OEpFeKnUaPr1uQxE6KpLTi+jVwmBxyi/D17hSAyM328haPxPn0+gtSkgFjkCH5BAAAAAAALAAAAAAQABAAAAf/gB0DU0AFJSlHBUA+cT47dR1yVjUBDRINARsbPVpaJydNMBVpEDhJKiQ3ICoVIGsSCj5ZZCwGZyo3FWhqbHxdFT5INTIzExxKJEEkbEEoFj0JPCA6S3ZkOEJCDy0/ORZoPFVlbgseYgtfHgZMYQJsT3hEFkoHESweIiJYGn1bQig0quj5s2/OggN7hgCIAcaEkypI3vxx0cfMhwkEbACY4EIAnAQJGDyAoqFAmAgZvUTIM8RJiwRKhMw4UOTiBRtRYhx44CDBnTEjUnAZwYCODBxSzBTIkAMJDR0OTJhog+PBnww//KwYASEBhis6KFBoE6JNjgwIXoiFgMHAjhYvDqi8GDBAAV0FL14Y4RAIADs=\\)\\]\\(https://www.linkedin.com/in/elim-village-6b39b1161/\\)\n\nImportant: This material is intended for the use of the individual to whom it is addressed and may contain information that is privileged, proprietary, confidential and exempt from disclosure. If you are not the intended recipient or the person responsible for delivering the material to the recipient, you are notified that dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately via email and delete this message. E-mail transmission cannot be guaranteed to be secure or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission.\n\nPrivacy Commitment: Elim Housing Society & Elim Christian Care Society are committed to protecting the privacy, confidentiality and security of personal information of residents and staff, and have Privacy Policies in place."
        }
    ]
}
```
## File: app/data/statuses.json
```json
[
    {
        "id": 258,
        "name": "4. Cancelled",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 66,
        "displayOnBoard": false,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2018-05-01T18:33:35Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2017-01-25T17:22:46Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 259,
        "name": "2. Enter Time",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 28,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Responded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2012-12-28T18:25:53Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2012-12-28T18:25:53Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 261,
        "name": "2. Done yet?",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 28,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "Responded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2019-11-07T01:24:22Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2013-10-08T22:20:42Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 263,
        "name": "Waiting for More Info",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 54,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2013-01-08T17:15:20Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2013-01-08T17:15:20Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 264,
        "name": "Waiting for Response",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 55,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2013-01-08T17:15:32Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2013-01-08T17:15:32Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 266,
        "name": "On-Hold",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 59,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2014-04-07T15:21:53Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2014-04-07T15:21:53Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 269,
        "name": "Waiting for Repair*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 50,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 23,
            "identifier": "Ticket #[srnumber] - WAITING FOR REPAIR - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/23"
            }
        },
        "_info": {
            "lastUpdated": "2021-04-23T18:51:54Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2017-01-25T17:14:17Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 270,
        "name": "4. Closed",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 65,
        "displayOnBoard": false,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2017-01-25T17:25:20Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2017-01-25T17:25:20Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 271,
        "name": "4. Closed*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 64,
        "displayOnBoard": false,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 17,
            "identifier": "Ticket #[srnumber] - RESOLVED SURVEY - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/17"
            }
        },
        "_info": {
            "lastUpdated": "2018-05-01T18:33:18Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2016-12-21T15:04:23Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 273,
        "name": "2. Scheduled*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 24,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Responded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 20,
            "identifier": "Ticket #[srnumber] - SCHEDULED  - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/20"
            }
        },
        "_info": {
            "lastUpdated": "2019-05-24T15:59:50Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2015-11-16T23:32:41Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 383,
        "name": "4. Closed - No Response*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 62,
        "displayOnBoard": false,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 34,
            "identifier": "Ticket #[srnumber] - RESOLVED - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/34"
            }
        },
        "_info": {
            "lastUpdated": "2017-01-25T17:24:47Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2017-01-25T17:24:47Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 390,
        "name": "Purchase Requested",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 56,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2012-12-28T04:49:01Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2012-12-28T04:49:01Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 391,
        "name": "Purchase Approved",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 57,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 51,
            "identifier": "Purchase has been approved for Ticket #[srnumber] - \"[srsummary]\"",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/51"
            }
        },
        "_info": {
            "lastUpdated": "2012-12-28T04:49:07Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2012-12-28T04:49:07Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 501,
        "name": "4. Client Reopened",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 69,
        "displayOnBoard": false,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": true,
        "_info": {
            "lastUpdated": "2018-05-01T18:32:47Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2017-04-19T14:49:03Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 504,
        "name": "Waiting for Procurement*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 52,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 92,
            "identifier": "Ticket #[srnumber] \"[srsummary]\" is waiting for procurement",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/92"
            }
        },
        "_info": {
            "lastUpdated": "2019-11-29T19:01:55Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2015-11-16T23:33:34Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 505,
        "name": "3. Escalated*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 33,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "ResolutionPlan",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 91,
            "identifier": "Ticket #[srnumber] - ESCALATED - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/91"
            }
        },
        "_info": {
            "lastUpdated": "2015-11-16T23:33:05Z",
            "updatedBy": "PPeterson",
            "dateEntered": "2015-11-16T23:33:05Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 508,
        "name": "2. Assigned*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 22,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Responded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 88,
            "identifier": "A resource has been assigned to Ticket #[srnumber] \"[srsummary]\"",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/88"
            }
        },
        "_info": {
            "lastUpdated": "2020-03-04T23:03:07Z",
            "updatedBy": "PPeterson",
            "dateEntered": "2015-11-16T23:32:31Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 574,
        "name": "Child",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 58,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2014-04-07T15:22:05Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2014-04-07T15:22:05Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 575,
        "name": "Child*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 58,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NoEscalation",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 97,
            "identifier": "Ticket #[srnumber] - CHILD - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/97"
            }
        },
        "_info": {
            "lastUpdated": "2015-11-16T23:33:57Z",
            "updatedBy": "PPeterson",
            "dateEntered": "2015-11-16T23:33:57Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 582,
        "name": "4. Completed - Pending",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 61,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2016-05-02T18:59:45Z",
            "updatedBy": "PPeterson",
            "dateEntered": "2016-05-02T18:59:45Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 657,
        "name": "4. Completed",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 60,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": true,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "Resolved",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2015-09-29T16:26:35Z",
            "updatedBy": "MDryfhout",
            "dateEntered": "2015-09-29T16:26:35Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 690,
        "name": "2. Queued*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 20,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": false,
        "defaultFlag": false,
        "escalationStatus": "Responded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 117,
            "identifier": "Ticket #[srnumber] - QUEUED - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/117"
            }
        },
        "_info": {
            "lastUpdated": "2015-11-16T23:32:20Z",
            "updatedBy": "PPeterson",
            "dateEntered": "2015-11-16T23:32:20Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 691,
        "name": "1. New",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 10,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NotResponded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "_info": {
            "lastUpdated": "2014-04-16T22:37:30Z",
            "updatedBy": "mdryfhout",
            "dateEntered": "2014-04-16T22:37:30Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 693,
        "name": "1. New*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 3,
        "displayOnBoard": true,
        "inactive": false,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NotResponded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 116,
            "identifier": "Ticket #[srnumber] - RECEIVED - [srsummary]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/116"
            }
        },
        "_info": {
            "lastUpdated": "2020-04-01T20:11:04Z",
            "updatedBy": "KGarbet",
            "dateEntered": "2015-11-16T23:31:57Z",
            "enteredBy": "CONVERSION"
        }
    },
    {
        "id": 697,
        "name": "1. New (Helpdesk Reminder)*",
        "board": {
            "id": 17,
            "name": "Services - IT",
            "_info": {
                "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
            }
        },
        "sortOrder": 12,
        "displayOnBoard": true,
        "inactive": true,
        "closedStatus": false,
        "timeEntryNotAllowed": true,
        "defaultFlag": false,
        "escalationStatus": "NotResponded",
        "customerPortalDescription": "",
        "customerPortalFlag": false,
        "emailTemplate": {
            "id": 114,
            "identifier": "\"[srsummary]\" has been received and assigned the Ticket #[srnumber]",
            "_info": {
                "emailTemplate_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/emailTemplates/114"
            }
        },
        "_info": {
            "lastUpdated": "2020-03-31T06:05:51Z",
            "updatedBy": "MDryfhout",
            "dateEntered": "2015-11-16T23:32:08Z",
            "enteredBy": "CONVERSION"
        }
    }
]
```
## File: app/data/tsi_dict_active.json
```json
{
    "AREV - A&A": {
        "*Triage": [
            "*Triage"
        ],
        "CBSA Communications": [
            "CBSA Communications"
        ],
        "Dev": [],
        "EDI": [],
        "Invoices": [
            "Invoices"
        ],
        "LPCO": [
            "LPCO"
        ],
        "Locked File": [
            "Locked File"
        ],
        "Lumber": [
            "Lumber"
        ],
        "Message Box": [
            "Line Error",
            "OK Box",
            "OK Box Loop"
        ],
        "PDF": [
            "Problem"
        ],
        "Performance": [
            "Problem"
        ],
        "Permissions": [
            "Problem",
            "Update"
        ],
        "Printing": [
            "Problem"
        ],
        "Shortcut": [
            "Broken",
            "Missing"
        ]
    },
    "Application": {
        "Accounting - ADP": [
            "ADP (A&A) - Supported by Accounting",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Adagio": [
            "Adagio (Urban)",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Quickbooks": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Accounting - Sage": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Ambiance/DormaKaba": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Antivirus": [
            "Change",
            "Enable",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Chrome": [
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Edge": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Browser - Firefox": [
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Browser - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "CBDiets": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Chat": [
            "ChatBeacon",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Source Port Request",
            "Spark",
            "Update"
        ],
        "Cloud App": [
            "Install",
            "Performance",
            "Problem",
            "Remove",
            "Repair",
            "Scout Portal (Deskdirector)",
            "Update"
        ],
        "DialPad": [
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Dropbox": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "EDITrade  (Select Item)": [
            "EDITrade  (A&A)",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Front": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Google Workspace - Documents": [
            "Install",
            "Permissions",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Google Workspace - Email": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Google Workspace - Other": [
            "Admin",
            "Gmail",
            "Google Docs (A&A)",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "IM/Chat - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "IM/Chat - Slack": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Slack (A&A)",
            "Slack (CREW)",
            "Update"
        ],
        "IM/Chat \u2013 Univerge": [],
        "LastPass": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "LibreOffice": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - Office": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - OneDrive": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Setup",
            "Sync Issue"
        ],
        "MS - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "MS - Outlook": [
            "Change",
            "Install",
            "Problem",
            "Profile",
            "Remove",
            "Repair",
            "Update"
        ],
        "MS - SharePoint": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "MS - Teams (No Voice)": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "NetExtender": [],
        "Other": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "PDF - Adobe": [
            "Change",
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "PDF - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "PDF - PDFelement/Wondershare": [
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "Video Conferencing - Google Meet": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Video Conferencing - Other": [
            "Install",
            "Problem",
            "Remove",
            "Repair"
        ],
        "Video Conferencing - Zoom": [
            "Install",
            "License",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ],
        "WordPerfect": [
            "Change",
            "Install",
            "Problem",
            "Remove",
            "Repair",
            "Update"
        ]
    },
    "Application - LOB": {
        "Amicus Attorney": [],
        "Arcline": [],
        "Comvida": [],
        "Copitrak/SAI": [],
        "Destiny": [],
        "Dolphin": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "EPass": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "ESI Law": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "Filemaker": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "GhostPractice": [],
        "ITMR4": [],
        "Maestro": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "PCC": [],
        "Salesforce": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ],
        "Syspro (Select Item)": [
            "Install",
            "Remove",
            "Repair",
            "Syspro (Excell)",
            "Update"
        ],
        "Tower (Select Item)": [
            "Install",
            "Remove",
            "Repair",
            "Tower (Urban)",
            "Update"
        ],
        "Worldox": [],
        "iCarol": [
            "Install",
            "Remove",
            "Repair",
            "Update"
        ]
    },
    "Group": {
        "!Triage": [
            "!Triage"
        ],
        "Distribution Group": [
            "Add",
            "Change",
            "Remove"
        ],
        "File Share/Group Drive": [
            "Add",
            "Change",
            "Remove"
        ],
        "LP Shared Folder": [
            "Add",
            "Change",
            "Remove"
        ],
        "Security Group": [
            "Add",
            "Change",
            "Remove"
        ],
        "Shared Mailbox": [
            "Add",
            "Change",
            "Remove"
        ],
        "Teams/M365 Group": [
            "Add",
            "Change",
            "Remove"
        ]
    },
    "Mobile": {
        "Android": [
            "Error",
            "Setup"
        ],
        "MDM": [
            "App Deployment",
            "Change",
            "Enrollment",
            "Error",
            "Policy Change",
            "Setup"
        ],
        "Other": [
            "Change"
        ],
        "Phone": [],
        "Tablet": [
            "Change"
        ],
        "iOS": [
            "Error",
            "Setup"
        ],
        "iPod": [
            "Change"
        ]
    },
    "Network": {
        "AVD": [
            "Problem"
        ],
        "AppRiver": [
            "Change"
        ],
        "Apple TV": [
            "Change"
        ],
        "Azure": [],
        "Cabinet": [
            "Change"
        ],
        "Cabling": [
            "Change"
        ],
        "Camera/DVR": [
            "Change"
        ],
        "DNS/Host": [
            "Change",
            "DMARC, SPF, DKIM"
        ],
        "Domain/Registrar": [
            "Change"
        ],
        "E-mail Compromise": [
            "Change",
            "Email Compromise",
            "Email Compromise - False Positive"
        ],
        "E-mail/Spam": [
            "Bounceback",
            "Change",
            "Phishing",
            "Remove",
            "Whitelist Request"
        ],
        "FTP": [
            "Change"
        ],
        "Firewall": [
            "Change",
            "Rule Request"
        ],
        "IP Address": [
            "Change"
        ],
        "IPSEC VPN": [],
        "Internet (Bonding)": [
            "Change",
            "Maintenance",
            "Outage",
            "Performance"
        ],
        "Internet (Home)": [
            "Change"
        ],
        "Internet (ISP)": [
            "Change",
            "Maintenance",
            "Outage",
            "Performance"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Microsoft 365/SharePoint": [
            "Change"
        ],
        "Modem": [
            "Change"
        ],
        "NAS/SAN": [
            "Change"
        ],
        "Network Jack": [
            "Change"
        ],
        "OpenDNS": [
            "Change",
            "Whitelist Request"
        ],
        "Performance": [
            "Change"
        ],
        "RDP": [
            "Change",
            "Problem"
        ],
        "Router": [
            "Change"
        ],
        "Security": [
            "Change"
        ],
        "Switch": [
            "Change"
        ],
        "UPS": [
            "Change"
        ],
        "VPN": [
            "Change",
            "Problem",
            "Whitelist Request"
        ],
        "Website/Host": [
            "Change",
            "Whitelist Request"
        ],
        "Wireless": [
            "AP Problem",
            "AP Reboot",
            "Change",
            "Coverage"
        ]
    },
    "Offering": {
        "Addigy": [],
        "CW Automate": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "CW Control (ScreenConnect)": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "CW Manage": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "Client-Care": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "DSIT Tools (CW, SC ETC)": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "DeskDirector": [
            "Problem",
            "Remove",
            "Setup"
        ],
        "OpenDNS": [
            "Change",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Security Awareness": [
            "Change",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Signature/Crossware": [
            "Problem",
            "Remove",
            "Setup"
        ]
    },
    "Print/Scan/eFax": {
        "Faxing": [
            "Change"
        ],
        "IP Address": [
            "Change"
        ],
        "Performance": [
            "Change"
        ],
        "Printing": [
            "Change",
            "Install",
            "Problem"
        ],
        "Scanning": [
            "Change",
            "Problem"
        ],
        "Toner": [
            "Change"
        ]
    },
    "Server": {
        "Active Directory": [
            "Change"
        ],
        "Azure": [],
        "Backup/Restore": [
            "Change"
        ],
        "Cabinet": [
            "Change"
        ],
        "Certificate": [
            "Change"
        ],
        "DFS": [
            "Change"
        ],
        "DHCP": [
            "Change"
        ],
        "DNS/Host": [
            "Change"
        ],
        "Disk/Drive": [
            "Change"
        ],
        "Domain Controller": [
            "Change"
        ],
        "E-mail Compromise": [
            "Change",
            "Email Compromise"
        ],
        "E-mail/Spam": [
            "Change"
        ],
        "Encryption": [
            "Change"
        ],
        "Exchange": [
            "Change"
        ],
        "FTP": [
            "Change"
        ],
        "Fan": [
            "Change"
        ],
        "Faxing": [
            "Change"
        ],
        "File/Folder (Select Item)": [
            "Change",
            "File Permissions (All)",
            "Restore"
        ],
        "Firewall": [
            "Change"
        ],
        "Group Policy": [
            "Change"
        ],
        "Hyper-V": [
            "Change"
        ],
        "IIS": [
            "Change"
        ],
        "IP Address": [
            "Change"
        ],
        "IPSEC VPN": [],
        "MS - Teams (No Voice)": [
            "Change"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Memory": [
            "Change"
        ],
        "Motherboard": [
            "Change"
        ],
        "NIC": [
            "Change"
        ],
        "OS": [
            "Change"
        ],
        "Patching": [
            "Change"
        ],
        "Performance": [
            "Change"
        ],
        "Power": [
            "Change"
        ],
        "Profile": [
            "Change"
        ],
        "SQL": [
            "Change"
        ],
        "Terminal Services": [
            "Change",
            "Problem"
        ],
        "Time/NTP": [
            "Change"
        ],
        "UPS": [
            "Change"
        ],
        "USB/Serial Port": [
            "Change"
        ],
        "VMware": [
            "Change"
        ],
        "Video": [
            "Change"
        ],
        "Virus/Spyware": [
            "Change",
            "False Positive"
        ],
        "Website/Host": [
            "Change"
        ]
    },
    "Telecom": {
        "3CX": [
            "Change",
            "Problem"
        ],
        "3CX Client": [
            "Education"
        ],
        "Analog Line": [
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Cabling": [],
        "Call Logging": [],
        "Desk Phone": [
            "Change",
            "Education",
            "Phone A&A",
            "Programming"
        ],
        "IP Address": [
            "Change",
            "Education"
        ],
        "MS - Teams Voice": [
            "Firmware",
            "Problem"
        ],
        "Mitel/Shoretel": [
            "Education"
        ],
        "NurseCall": [
            "Alarm",
            "Change",
            "Education",
            "Install"
        ],
        "PBX": [
            "3CX Server",
            "Avaya",
            "Call Logging",
            "Education",
            "NEC",
            "Norstar",
            "Other",
            "Ring Central",
            "Samsung"
        ],
        "PRI": [
            "Call Quality Issue",
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Phone/Fax Line": [
            "Call Quality Issue",
            "Change",
            "Education",
            "Phone A&A",
            "Programming",
            "Update Entertainment Announcement"
        ],
        "RingCentral": [
            "Education"
        ],
        "VOIP Provider": [
            "Call Quality Issue",
            "Education",
            "Programming",
            "Spam Caller"
        ],
        "Voicemail": [
            "Education"
        ],
        "Wireless Bridge": [],
        "miLINK": [],
        "miLINK PBX": [
            "Change",
            "Problem"
        ]
    },
    "User": {
        "Change User": [
            "International Travel Request"
        ],
        "Desk Move": [],
        "Discussion": [],
        "Group Membership": [],
        "Multi Factor Authentication": [
            "New Phone",
            "Problem",
            "Remove",
            "Setup"
        ],
        "Password": [
            "Change",
            "Expired"
        ],
        "Profile": [
            "Broken",
            "Missing",
            "Problem"
        ],
        "Signature": [
            "Broken",
            "Change"
        ],
        "Training": [],
        "User": [
            "Change",
            "Remove"
        ]
    },
    "Workstation": {
        "Audio": [
            "Change"
        ],
        "Backup/Restore": [
            "Change"
        ],
        "Certificate": [
            "Change"
        ],
        "Computer": [
            "Change",
            "Clock",
            "New Computer",
            "New Computer (CREW)",
            "New Computer (Excell)"
        ],
        "Desk Move": [
            "Change"
        ],
        "Disk/Drive": [
            "Change",
            "Quoted Replacement"
        ],
        "Docking Station": [
            "Change"
        ],
        "Encryption": [
            "BitLocker Recovery Key",
            "Change"
        ],
        "FTP": [
            "Change"
        ],
        "Fan": [
            "Change"
        ],
        "Faxing": [
            "Change"
        ],
        "Firewall": [
            "Change"
        ],
        "IP Address": [
            "Change"
        ],
        "Keyboard": [
            "Change"
        ],
        "Mapped Drive": [
            "Change"
        ],
        "Memory": [
            "Change"
        ],
        "Monitor": [
            "Change"
        ],
        "Motherboard": [
            "Change"
        ],
        "Mouse": [
            "Change"
        ],
        "NIC": [
            "Change"
        ],
        "OS": [
            "Change",
            "Problem",
            "Update",
            "Upgrade"
        ],
        "Patching": [
            "Change"
        ],
        "Performance": [
            "Because of OS Updates",
            "Change",
            "Problem"
        ],
        "Power": [
            "Change"
        ],
        "Profile": [
            "Change"
        ],
        "Time/NTP": [
            "Change"
        ],
        "UPS": [
            "Change"
        ],
        "USB/Serial Port": [
            "Change"
        ],
        "Video": [
            "Change"
        ],
        "Virus/Spyware": [
            "Change",
            "False Positive",
            "Remove"
        ],
        "Wireless": [
            "Change"
        ]
    }
}
```
## File: app/data/tickets.json
```json
{
    "id": 1028064,
    "summary": "Chrome as Primary Web Browser",
    "recordType": "ServiceTicket",
    "board": {
        "id": 17,
        "name": "Services - IT",
        "_info": {
            "board_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17"
        }
    },
    "status": {
        "id": 657,
        "name": "4. Completed",
        "_info": {
            "status_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17/statuses/657"
        }
    },
    "company": {
        "id": 3885,
        "identifier": "Elim",
        "name": "Elim Housing Society",
        "_info": {
            "company_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/companies/3885",
            "mobileGuid": "d7ebc854-1c28-473d-8dcf-d0d4f2ab8294"
        }
    },
    "site": {
        "id": 8344,
        "name": "Chilliwack",
        "_info": {
            "site_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/companies/3885/sites/8344",
            "mobileGuid": "40a2595b-ea96-4b75-85db-94e3032a23a5"
        }
    },
    "siteName": "Chilliwack",
    "addressLine1": "45460 Chehalis Dr",
    "city": "Chilliwack",
    "stateIdentifier": "BC",
    "zip": "V2R 0Y9",
    "country": {
        "id": 3,
        "identifier": "1",
        "name": "Canada",
        "_info": {
            "country_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/countries/3"
        }
    },
    "contact": {
        "id": 35120,
        "name": "Conrad Nedelec",
        "_info": {
            "mobileGuid": "89cec9e9-944d-43ea-b8cd-d5be397b3918",
            "contact_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/contacts/35120"
        }
    },
    "contactName": "Conrad Nedelec",
    "contactPhoneNumber": "16044260438",
    "contactPhoneExtension": "7819",
    "contactEmailAddress": "cnedelec@elimvillage.com",
    "type": {
        "id": 132,
        "name": "User",
        "_info": {
            "type_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17/types/132"
        }
    },
    "team": {
        "id": 78,
        "name": "Services Reactive",
        "_info": {
            "team_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/boards/17/teams/78"
        }
    },
    "owner": {
        "id": 367,
        "identifier": "DGeorgeadis",
        "name": "Demetrios Georgeadis",
        "_info": {
            "member_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/367",
            "image_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/367/image?lm=2024-12-28T00:56:18Z"
        }
    },
    "priority": {
        "id": 1,
        "name": "P2-Quick",
        "sort": 4,
        "_info": {
            "priority_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/priorities/1",
            "image_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/priorities/1/image?lm=2020-03-04T19:06:01Z"
        }
    },
    "serviceLocation": {
        "id": 7,
        "name": "Remote",
        "_info": {
            "location_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/locations/7"
        }
    },
    "source": {
        "id": 2,
        "name": "Phone",
        "_info": {
            "source_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/sources/2"
        }
    },
    "agreement": {
        "id": 551,
        "name": "TEL T1 Managed Services:",
        "_info": {
            "agreement_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/agreements/551"
        }
    },
    "severity": "Medium",
    "impact": "High",
    "allowAllClientsPortalView": false,
    "customerUpdatedFlag": false,
    "automaticEmailContactFlag": false,
    "automaticEmailResourceFlag": false,
    "automaticEmailCcFlag": false,
    "closedDate": "2025-03-11T18:29:07Z",
    "closedBy": "DGeorgeadis",
    "closedFlag": true,
    "actualHours": 0.4,
    "approved": true,
    "estimatedExpenseCost": 0.0,
    "estimatedExpenseRevenue": 0.0,
    "estimatedProductCost": 0.0,
    "estimatedProductRevenue": 0.0,
    "estimatedTimeCost": 0.0,
    "estimatedTimeRevenue": 0.0,
    "billingMethod": "ActualRates",
    "subBillingMethod": "ActualRates",
    "dateResolved": "2025-03-11T18:29:07Z",
    "dateResplan": "2025-03-11T18:08:02Z",
    "dateResponded": "2025-03-11T18:08:02Z",
    "resolveMinutes": 21,
    "resPlanMinutes": 0,
    "respondMinutes": 0,
    "isInSla": true,
    "resources": "DGeorgeadis",
    "hasChildTicket": false,
    "hasMergedChildTicketFlag": false,
    "billTime": "NoDefault",
    "billExpenses": "NoDefault",
    "billProducts": "Billable",
    "location": {
        "id": 2,
        "name": "Scout",
        "_info": {
            "location_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/locations/2"
        }
    },
    "department": {
        "id": 10,
        "identifier": "Services-ITPRO",
        "name": "IT Pro Services",
        "_info": {
            "department_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/departments/10"
        }
    },
    "mobileGuid": "11d8cb85-b655-4cb4-92e8-89f6cda3bb29",
    "sla": {
        "id": 2,
        "name": "MS SLA",
        "_info": {
            "sla_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/SLAs/2"
        }
    },
    "slaStatus": "Resolved",
    "requestForChangeFlag": false,
    "currency": {
        "id": 1,
        "symbol": "$",
        "currencyCode": "CAD",
        "decimalSeparator": ".",
        "numberOfDecimals": 2,
        "thousandsSeparator": ",",
        "negativeParenthesesFlag": false,
        "displaySymbolFlag": false,
        "currencyIdentifier": "CAD",
        "displayIdFlag": false,
        "rightAlign": false,
        "name": "Canadian Dollars",
        "_info": {
            "currency_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/currencies/1"
        }
    },
    "_info": {
        "lastUpdated": "2025-03-11T18:29:07Z",
        "updatedBy": "DGeorgeadis",
        "dateEntered": "2025-03-11T18:08:01Z",
        "enteredBy": "BGarcia",
        "activities_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/sales/activities?conditions=ticket/id=1028064",
        "scheduleentries_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/schedule/entries?conditions=type/id=4 AND objectId=1028064",
        "documents_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/documents?recordType=Ticket&recordId=1028064",
        "configurations_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/tickets/1028064/configurations",
        "tasks_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/tickets/1028064/tasks",
        "notes_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/tickets/1028064/notes",
        "products_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/procurement/products?conditions=chargeToType='Ticket' AND chargeToId=1028064",
        "timeentries_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/entries?conditions=(chargeToType='ServiceTicket' OR chargeToType='ProjectTicket') AND chargeToId=1028064",
        "expenseEntries_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/expense/entries?conditions=(chargeToType='ServiceTicket' OR chargeToType='ProjectTicket') AND chargeToId=1028064"
    },
    "escalationStartDateUTC": "2025-03-11T18:29:07Z",
    "escalationLevel": 15,
    "minutesBeforeWaiting": 0,
    "respondedSkippedMinutes": 0,
    "resplanSkippedMinutes": 0,
    "customFields": [
        {
            "id": 21,
            "caption": "Automation Could Help",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 31,
            "caption": "New Computer Count",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 38,
            "caption": "CSAT Sentiment",
            "type": "Text",
            "entryMethod": "List",
            "numberOfDecimals": 0
        },
        {
            "id": 39,
            "caption": "CSAT Rating",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 40,
            "caption": "CSAT Comment",
            "type": "TextArea",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 41,
            "caption": "Reopen Sentiment",
            "type": "Text",
            "entryMethod": "List",
            "numberOfDecimals": 0
        },
        {
            "id": 43,
            "caption": "CSAT Tech",
            "type": "Text",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 44,
            "caption": "CSAT Percent",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 54,
            "caption": "CSAT Date",
            "type": "Date",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 58,
            "caption": "Issue Health",
            "type": "Text",
            "entryMethod": "List",
            "numberOfDecimals": 0
        },
        {
            "id": 62,
            "caption": "Critical Path",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 65,
            "caption": "RolledintoAH",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 85,
            "caption": "Queue Jumping",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0,
            "value": false
        },
        {
            "id": 90,
            "caption": "P1Ticket",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 127,
            "caption": "Survey Sent",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 135,
            "caption": "Efficiency Gain",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 136,
            "caption": "Annual Frequency of Occur",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 137,
            "caption": "Potential Security Harden",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 138,
            "caption": "Client Experience",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 139,
            "caption": "Clients Affected",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 140,
            "caption": "Scout Employees Affected",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 151,
            "caption": "Ignore Due Date",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 152,
            "caption": "Tech Type",
            "type": "Text",
            "entryMethod": "List",
            "numberOfDecimals": 0
        },
        {
            "id": 159,
            "caption": "Re-Open Date",
            "type": "Date",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 178,
            "caption": "Vendor Involvement",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0,
            "value": false
        },
        {
            "id": 180,
            "caption": "Closed No Config",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 184,
            "caption": "Time to Tech Prediction",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 2
        },
        {
            "id": 185,
            "caption": "Total Score",
            "type": "Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 192,
            "caption": "Sales Ticket Number",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 205,
            "caption": "Pia Successful",
            "type": "Checkbox",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        },
        {
            "id": 209,
            "caption": "ARO ID",
            "type": "Text",
            "entryMethod": "EntryField",
            "numberOfDecimals": 0
        }
    ]
}
```
## File: app/data/time_entries.json
```json
[
    {
        "id": 814117,
        "company": {
            "id": 7016,
            "identifier": "CrisisCentre",
            "name": "Crisis Intervention Centre of BC",
            "_info": {
                "company_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/companies/7016",
                "mobileGuid": "bd23d57e-c9e6-42b7-8a19-e3dcd59457ec"
            }
        },
        "chargeToId": 868338,
        "chargeToType": "ServiceTicket",
        "member": {
            "id": 318,
            "identifier": "BGarcia",
            "name": "Brian Garcia",
            "_info": {
                "member_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/318",
                "image_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/318/image?lm=2025-03-20T18:38:01Z"
            }
        },
        "locationId": 54,
        "businessUnitId": 14,
        "workType": {
            "id": 18,
            "name": "Remote",
            "_info": {
                "workType_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/workTypes/18"
            }
        },
        "workRole": {
            "id": 30,
            "name": "PST Exempt",
            "_info": {
                "workRole_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/workRoles/30"
            }
        },
        "agreement": {
            "id": 1053,
            "name": "TEL T1 Managed Services:",
            "_info": {
                "agreement_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/agreements/1053"
            }
        },
        "timeStart": "2023-02-22T22:00:00Z",
        "timeEnd": "2023-02-22T22:31:00Z",
        "hoursDeduct": 0.0,
        "actualHours": 0.52,
        "billableOption": "Billable",
        "notes": "* Received call from Max\n* Unable to login to workstation\n* Confirmed that he had recently reset his password\n* Tried new password - not working\n* Tested account on SERVER - sh
owing error when trying to connect remotely\n* Reached out for help to Kris\n* Tried to get user connected to VPN\n* Showing as password incorrect - did password reset\n* Tested - still showing erro
r\n* Sent User over to Kris - shadowing Kris through process\n* User able to login to Workstation",
        "addToDetailDescriptionFlag": true,
        "addToInternalAnalysisFlag": false,
        "addToResolutionFlag": false,
        "emailResourceFlag": false,
        "emailContactFlag": false,
        "emailCcFlag": false,
        "hoursBilled": 0.75,
        "invoiceHours": 0.75,
        "enteredBy": "BGarcia",
        "dateEntered": "2023-02-22T22:31:48Z",
        "invoice": {
            "id": 36256,
            "identifier": "45848",
            "_info": {
                "invoice_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/invoices/36256"
            }
        },
        "mobileGuid": "3c2e7999-af15-41a0-8dd9-3a2f0aaad9a6",
        "hourlyRate": 0.0,
        "agreementHours": 0.0,
        "agreementAmount": 0.0,
        "timeSheet": {
            "id": 17824,
            "name": "2023-02-18 to 2023-02-24",
            "_info": {
                "timeSheet_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/sheets/17824"
            }
        },
        "status": "Billed",
        "ticket": {
            "id": 868338,
            "summary": "Unable to Login to workstation",
            "_info": {
                "ticket_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/tickets/868338",
                "billingMethod": "A"
            }
        },
        "_info": {
            "lastUpdated": "2023-02-28T00:57:13Z",
            "updatedBy": "TTrott",
            "chargeToMobileGuid": "12f24973-a941-4249-8407-f65186715b53"
        },
        "customFields": [
            {
                "id": 24,
                "caption": "Flex Bank",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 25,
                "caption": "Overtime",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 183,
                "caption": "Broadcast to Teams",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 211,
                "caption": "Time Entry Corrected",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0
            }
        ]
    },
    {
        "id": 814121,
        "company": {
            "id": 7016,
            "identifier": "CrisisCentre",
            "name": "Crisis Intervention Centre of BC",
            "_info": {
                "company_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/company/companies/7016",
                "mobileGuid": "bd23d57e-c9e6-42b7-8a19-e3dcd59457ec"
            }
        },
        "chargeToId": 868338,
        "chargeToType": "ServiceTicket",
        "member": {
            "id": 205,
            "identifier": "KGarbet",
            "name": "Kris Garbet",
            "_info": {
                "member_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/205",
                "image_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/system/members/205/image?lm=2025-03-20T18:39:16Z"
            }
        },
        "locationId": 54,
        "businessUnitId": 14,
        "workType": {
            "id": 18,
            "name": "Remote",
            "_info": {
                "workType_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/workTypes/18"
            }
        },
        "workRole": {
            "id": 30,
            "name": "PST Exempt",
            "_info": {
                "workRole_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/workRoles/30"
            }
        },
        "agreement": {
            "id": 1053,
            "name": "TEL T1 Managed Services:",
            "_info": {
                "agreement_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/agreements/1053"
            }
        },
        "timeStart": "2023-02-22T22:25:00Z",
        "timeEnd": "2023-02-22T22:35:44Z",
        "hoursDeduct": 0.0,
        "actualHours": 0.17,
        "billableOption": "Billable",
        "notes": "Escalation from Brian - User unable to login into the VPN - Password incorrect\nReviewed and discovered eventhough he had NetExtender installed he wasn't part of the group\nAdded h
im to the group to allow him to connect to the VPN\nConfirmed this worked\nSwitched users and let max log in\nAfter he got logged in, had him try the RDS - Missing the RDS from his desktop\nCreated 
the RDS icon for him \\(per documentation\\) \nTested with him. Confirmed working\nGood to Close",
        "addToDetailDescriptionFlag": true,
        "addToInternalAnalysisFlag": false,
        "addToResolutionFlag": false,
        "emailResourceFlag": false,
        "emailContactFlag": false,
        "emailCcFlag": false,
        "hoursBilled": 0.25,
        "invoiceHours": 0.25,
        "enteredBy": "KGarbet",
        "dateEntered": "2023-02-22T22:35:44Z",
        "invoice": {
            "id": 36256,
            "identifier": "45848",
            "_info": {
                "invoice_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/finance/invoices/36256"
            }
        },
        "mobileGuid": "b5a0ec52-46a1-4943-aa28-2c3abb86a8a1",
        "hourlyRate": 0.0,
        "agreementHours": 0.0,
        "agreementAmount": 0.0,
        "timeSheet": {
            "id": 17807,
            "name": "2023-02-18 to 2023-02-24",
            "_info": {
                "timeSheet_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/time/sheets/17807"
            }
        },
        "status": "Billed",
        "ticket": {
            "id": 868338,
            "summary": "Unable to Login to workstation",
            "_info": {
                "ticket_href": "https://manage.scouttg.com/v4_6_release/apis/3.0/service/tickets/868338",
                "billingMethod": "A"
            }
        },
        "_info": {
            "lastUpdated": "2023-02-27T03:44:02Z",
            "updatedBy": "MTaccogna",
            "chargeToMobileGuid": "12f24973-a941-4249-8407-f65186715b53"
        },
        "customFields": [
            {
                "id": 24,
                "caption": "Flex Bank",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 25,
                "caption": "Overtime",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 183,
                "caption": "Broadcast to Teams",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0,
                "value": false
            },
            {
                "id": 211,
                "caption": "Time Entry Corrected",
                "type": "Checkbox",
                "entryMethod": "EntryField",
                "numberOfDecimals": 0
            }
        ]
    }
]
```
## File: app/data/test/1036301.json
```json
{
    "ticket_id": 1036301,
    "success": true,
    "retrieval_query": {
        "query": "Error 0x80070194 when copying file from shared folder in Windows File Explorer:\nUser encounters error code 0x80070194 ('The cloud file provider exited unexpectedly') when attempting to copy a PowerPoint file ('AI-2EXL1458-Rev-AB') from a company shared folder using Windows File Explorer. The error interrupts the file copy process and suggests searching the error code for help. The issue appears related to cloud file synchronization or access in Windows.",
        "system_information": null
    },
    "relevant_ticket_ids": [
        1025365
    ],
    "classification": {
        "service_type": "Application",
        "subtype": "MS - OneDrive",
        "item": "Sync Issue",
        "priority": "P3"
    },
    "user_history": {
        "overview": "Charlie Steele typically experiences issues related to password expirations and resets, VPN and remote server access problems, Surface Pro hardware and performance issues, Microsoft Teams and Outlook connectivity problems, file and shared drive access permissions, and occasional software setup and configuration challenges. There are recurring themes of authentication difficulties, device freezing or performance degradation, and cloud or network file access errors. The user has 42 previous tickets.",
        "similar_ticket_ids": [
            943504,
            874551,
            862525,
            843653,
            926809,
            874550,
            874551
        ],
        "similar_tickets": [
            {
                "id": 943504,
                "summary": "The issue was that Charlie Steele could not access the T: Drive, which was marked as inaccessible. After receiving the support request, the IT team identified it as a permissions issue. They checked the folder permissions on the server and found that the necessary read permissions were not assigned. After signing Charlie out and restarting his computer, they scheduled a follow-up. When Charlie was available, the technician connected to his computer via VPN, reassigned the correct permissions, and confirmed that the T: Drive was now accessible. The technician followed up to ensure the permissions remained intact, and Charlie confirmed that the issue was resolved, allowing the ticket to be closed."
            },
            {
                "id": 874551,
                "summary": "The issue was that Charlie Steele from Excel Battery Company was unable to access shared drives on the server while working from home. He attempted to disconnect and reconnect but was unsuccessful. IT support, represented by Noah Wilkie, confirmed that all servers were online and that Charlie was connected to the VPN. Upon checking, only the P drive was visible, and no errors were found in the mapping. After running a gpupdate /force command, all shared drives became accessible. The issue was resolved, and Charlie was able to access the necessary documents."
            }
        ],
        "recurring_issue": true,
        "recurring_issue_cause": "Recurring authentication and access issues primarily caused by password expirations, VPN connectivity problems, and cloud synchronization errors affecting file access and remote resources."
    },
    "solutions": {
        "historical": "Steps: \n- Contact the user to review the OneDrive sync issue, as the error 0x80070194 indicates a problem with the cloud file provider. \n- Attempt to resolve by checking OneDrive status, restarting the OneDrive client, and ensuring the user is signed in and connected to the internet. \n- If the issue persists, escalate for further troubleshooting.\n\n(based on tickets: #1025365)",
        "web_search": "The error message \"Error 0x80070194: The cloud file provider exited unexpectedly\" typically indicates a synchronization issue with OneDrive, often related to the Files On-Demand feature or a corrupted application cache.\n\n1. **Disable Files On-Demand Feature Temporarily**\n    - Right-click the OneDrive icon in the taskbar and select 'Settings'.\n    - In the 'Settings' tab, under 'Files On-Demand', uncheck 'Save space and download files as you use them'.\n    - Click 'OK' to apply the changes.\n    - Restart OneDrive and check if the issue persists.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)\n\n2. **Reset OneDrive**\n    - Press 'Win + R' to open the Run dialog box.\n    - Enter the following command:\n        ```\n        %localappdata%\\Microsoft\\OneDrive\\onedrive.exe /reset\n        ```\n    - Click 'OK'. This will reset OneDrive.\n    - If the OneDrive icon doesn't reappear in the taskbar after a few minutes, open the Run dialog box again, enter:\n        ```\n        %localappdata%\\Microsoft\\OneDrive\\onedrive.exe\n        ```\n    - Click 'OK' to restart OneDrive.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)\n\n3. **Uninstall and Reinstall OneDrive**\n    - Press 'Win + I' to open 'Settings'.\n    - Navigate to 'Apps' > 'Apps & features'.\n    - Locate 'Microsoft OneDrive' in the list, click on it, and select 'Uninstall'.\n    - After uninstallation, download the latest version of OneDrive from the [official website](https://www.microsoft.com/en-us/microsoft-365/onedrive/download).\n    - Install OneDrive and set it up again.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116) "
    },
    "group_id": "b7b15529-8aae-4aec-bcd9-b859906e3708",
    "saved_to": null,
    "note_added": null,
    "note_content": "**Suggested Classification:**\n\n- Type: Application\n- Subtype: MS - OneDrive\n- Item: Sync Issue\n- Priority: P3\n\n**User Information:** Charlie Steele\n\nCharlie Steele typically experiences issues related to password expirations and resets, VPN and remote server access problems, Surface Pro hardware and performance issues, Microsoft Teams and Outlook connectivity problems, file and shared drive access permissions, and occasional software setup and configuration challenges. There are recurring themes of authentication difficulties, device freezing or performance degradation, and cloud or network file access errors. The user has 42 previous tickets.\n\n*Possible recurring issue:* Recurring authentication and access issues primarily caused by password expirations, VPN connectivity problems, and cloud synchronization errors affecting file access and remote resources.\n\n\n*Similar tickets from this user:* \n- #943504: The issue was that Charlie Steele could not access the T: Drive, which was marked as inaccessible. After receiving the support request, the IT team identified it as a permissions issue. They checked the folder permissions on the server and found that the necessary read permissions were not assigned. After signing Charlie out and restarting his computer, they scheduled a follow-up. When Charlie was available, the technician connected to his computer via VPN, reassigned the correct permissions, and confirmed that the T: Drive was now accessible. The technician followed up to ensure the permissions remained intact, and Charlie confirmed that the issue was resolved, allowing the ticket to be closed.\n- #874551: The issue was that Charlie Steele from Excel Battery Company was unable to access shared drives on the server while working from home. He attempted to disconnect and reconnect but was unsuccessful. IT support, represented by Noah Wilkie, confirmed that all servers were online and that Charlie was connected to the VPN. Upon checking, only the P drive was visible, and no errors were found in the mapping. After running a gpupdate /force command, all shared drives became accessible. The issue was resolved, and Charlie was able to access the necessary documents.\n\n\n*Other related tickets from Charlie Steele:* #862525, #843653, #926809, #874550\n\n**Suggested Solution based on historical tickets:**\n\nSteps: \n- Contact the user to review the OneDrive sync issue, as the error 0x80070194 indicates a problem with the cloud file provider. \n- Attempt to resolve by checking OneDrive status, restarting the OneDrive client, and ensuring the user is signed in and connected to the internet. \n- If the issue persists, escalate for further troubleshooting.\n\n(based on tickets: #1025365)\n\n\n\n*Similar tickets from other users at Excell Battery Company:* #1025365\n\n\n**Suggested Solution based on web search:**\n\nThe error message \"Error 0x80070194: The cloud file provider exited unexpectedly\" typically indicates a synchronization issue with OneDrive, often related to the Files On-Demand feature or a corrupted application cache.\n\n1. **Disable Files On-Demand Feature Temporarily**\n    - Right-click the OneDrive icon in the taskbar and select 'Settings'.\n    - In the 'Settings' tab, under 'Files On-Demand', uncheck 'Save space and download files as you use them'.\n    - Click 'OK' to apply the changes.\n    - Restart OneDrive and check if the issue persists.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)\n\n2. **Reset OneDrive**\n    - Press 'Win + R' to open the Run dialog box.\n    - Enter the following command:\n        ```\n        %localappdata%\\Microsoft\\OneDrive\\onedrive.exe /reset\n        ```\n    - Click 'OK'. This will reset OneDrive.\n    - If the OneDrive icon doesn't reappear in the taskbar after a few minutes, open the Run dialog box again, enter:\n        ```\n        %localappdata%\\Microsoft\\OneDrive\\onedrive.exe\n        ```\n    - Click 'OK' to restart OneDrive.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)\n\n3. **Uninstall and Reinstall OneDrive**\n    - Press 'Win + I' to open 'Settings'.\n    - Navigate to 'Apps' > 'Apps & features'.\n    - Locate 'Microsoft OneDrive' in the list, click on it, and select 'Uninstall'.\n    - After uninstallation, download the latest version of OneDrive from the [official website](https://www.microsoft.com/en-us/microsoft-365/onedrive/download).\n    - Install OneDrive and set it up again.\n    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116) ",
    "error": null
}
```
## File: app/data/test/1036301.md
```markdown
**Suggested Classification:**

- Type: Application
- Subtype: MS - OneDrive
- Item: Sync Issue
- Priority: P3

**User Information:** Charlie Steele

Charlie Steele typically experiences issues related to password expirations and resets, VPN and remote server access problems, Surface Pro hardware and performance issues, Microsoft Teams and Outlook connectivity problems, file and shared drive access permissions, and occasional software setup and configuration challenges. There are recurring themes of authentication difficulties, device freezing or performance degradation, and cloud or network file access errors. The user has 42 previous tickets.

*Possible recurring issue:* Recurring authentication and access issues primarily caused by password expirations, VPN connectivity problems, and cloud synchronization errors affecting file access and remote resources.


*Similar tickets from this user:* 
- #943504: The issue was that Charlie Steele could not access the T: Drive, which was marked as inaccessible. After receiving the support request, the IT team identified it as a permissions issue. They checked the folder permissions on the server and found that the necessary read permissions were not assigned. After signing Charlie out and restarting his computer, they scheduled a follow-up. When Charlie was available, the technician connected to his computer via VPN, reassigned the correct permissions, and confirmed that the T: Drive was now accessible. The technician followed up to ensure the permissions remained intact, and Charlie confirmed that the issue was resolved, allowing the ticket to be closed.
- #874551: The issue was that Charlie Steele from Excel Battery Company was unable to access shared drives on the server while working from home. He attempted to disconnect and reconnect but was unsuccessful. IT support, represented by Noah Wilkie, confirmed that all servers were online and that Charlie was connected to the VPN. Upon checking, only the P drive was visible, and no errors were found in the mapping. After running a gpupdate /force command, all shared drives became accessible. The issue was resolved, and Charlie was able to access the necessary documents.


*Other related tickets from Charlie Steele:* #862525, #843653, #926809, #874550

**Suggested Solution based on historical tickets:**

Steps: 
- Contact the user to review the OneDrive sync issue, as the error 0x80070194 indicates a problem with the cloud file provider. 
- Attempt to resolve by checking OneDrive status, restarting the OneDrive client, and ensuring the user is signed in and connected to the internet. 
- If the issue persists, escalate for further troubleshooting.

(based on tickets: #1025365)



*Similar tickets from other users at Excell Battery Company:* #1025365


**Suggested Solution based on web search:**

The error message "Error 0x80070194: The cloud file provider exited unexpectedly" typically indicates a synchronization issue with OneDrive, often related to the Files On-Demand feature or a corrupted application cache.

1. **Disable Files On-Demand Feature Temporarily**
    - Right-click the OneDrive icon in the taskbar and select 'Settings'.
    - In the 'Settings' tab, under 'Files On-Demand', uncheck 'Save space and download files as you use them'.
    - Click 'OK' to apply the changes.
    - Restart OneDrive and check if the issue persists.
    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)

2. **Reset OneDrive**
    - Press 'Win + R' to open the Run dialog box.
    - Enter the following command:
        ```
        %localappdata%\Microsoft\OneDrive\onedrive.exe /reset
        ```
    - Click 'OK'. This will reset OneDrive.
    - If the OneDrive icon doesn't reappear in the taskbar after a few minutes, open the Run dialog box again, enter:
        ```
        %localappdata%\Microsoft\OneDrive\onedrive.exe
        ```
    - Click 'OK' to restart OneDrive.
    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)

3. **Uninstall and Reinstall OneDrive**
    - Press 'Win + I' to open 'Settings'.
    - Navigate to 'Apps' > 'Apps & features'.
    - Locate 'Microsoft OneDrive' in the list, click on it, and select 'Uninstall'.
    - After uninstallation, download the latest version of OneDrive from the [official website](https://www.microsoft.com/en-us/microsoft-365/onedrive/download).
    - Install OneDrive and set it up again.
    - [Source](https://answers.microsoft.com/en-us/windows/forum/all/error-code-0x80070194-the-cloud-file-provider/56bb2a8b-ab12-4915-b225-4fd09595e116)
```
## File: postgres_setup/pgdump_20250409/essential_data.sql
```
--
-- PostgreSQL database dump
--

-- Dumped from database version 17.4 (Debian 17.4-1.pgdg120+2)
-- Dumped by pg_dump version 17.4 (Debian 17.4-1.pgdg120+2)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Data for Name: groups; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.groups (id, name, description) FROM stdin;
17dd16eb-3f2d-4fff-a398-bce997273ed6	admins	Members have full access to all groups
84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b	users	Default group that all users belong to
e8c90ae7-2773-4ef0-9e36-32faca879c8f	Protec	Protec Dental Laboratories (2021) Inc
115f1e95-43b7-4a0e-a0dc-686d2969c29f	CrisisCentre	Crisis Intervention Centre of BC
0ed65bb9-3a58-41b3-a16c-9a8b379ce18c	UrbanImpact	Urban Impact
b7b15529-8aae-4aec-bcd9-b859906e3708	Excell	Excell Battery Company
d0cfea2a-1756-49dd-a3df-e8d20fc796c3	Elim	Elim Housing Society
3a0c8c35-afbc-40a9-a732-98fd64739270	AACB	A&A Contract Customs Brokers Ltd
\.


--
-- Data for Name: llms; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.llms (id, name, input_token_cost, output_token_cost, created_at) FROM stdin;
22a5baaf-17ac-4d83-835c-7bcf3b156ddc	gpt-4o	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
03cc6952-8f18-4311-a7cf-4ff8bc227b25	gpt-4o-2024-11-20	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
b8f8566e-ecad-4cae-8b7c-0b809f92ab07	gpt-4o-2024-08-06	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
dff63ab7-8093-4667-ba10-11c0df21f393	gpt-4o-mini	0.000000150000000000000000	0.000000600000000000000000	2025-03-13 05:33:56.555649+00
1def3f96-4e7d-4b38-a2ef-26bbd294ce93	gpt-4o-mini-2024-07-18	0.000000150000000000000000	0.000000600000000000000000	2025-03-13 05:33:56.555649+00
ddb219af-7fc0-4e5f-a7d2-cadf9c4b4878	o1-mini-2024-09-12	0.000003000000000000000000	0.000012000000000000000000	2025-03-13 05:33:56.555649+00
738d7099-2598-4542-a550-eb48d13edd5f	o1-preview	0.000015000000000000000000	0.000060000000000000000000	2025-03-13 05:33:56.555649+00
cb03e4a3-8588-4402-ac78-6f7195e05164	o1-preview-2024-09-12	0.000015000000000000000000	0.000060000000000000000000	2025-03-13 05:33:56.555649+00
884ca97e-1133-490f-a7a1-c27355e77d74	claude-3-5-haiku-20241022	0.000000250000000000000000	0.000001250000000000000000	2025-03-13 05:33:56.555649+00
aeb0487e-ae18-4929-9e01-670db67500c3	claude-3-5-sonnet-20240620	0.000003000000000000000000	0.000015000000000000000000	2025-03-13 05:33:56.555649+00
73dcaf8a-3b7f-43bd-83ac-fc77cb6f8311	claude-3-5-sonnet-20241022	0.000003000000000000000000	0.000015000000000000000000	2025-03-13 05:33:56.555649+00
9cfc9638-4a46-4d93-b4de-123a1e004aef	llama3.1-8b	0.000000000000000000000000	0.000000000000000000000000	2025-03-13 05:33:56.555649+00
f0290647-1736-4d42-bc4c-b128c322e785	llama3.1-70b	0.000000000000000000000000	0.000000000000000000000000	2025-03-13 05:33:56.555649+00
ab367d0f-4e81-4302-b870-345c37c18633	llama3.1-405b	0.000006000000000000000000	0.000012000000000000000000	2025-03-13 05:33:56.555649+00
f07134c4-ddfb-44af-b9f9-3ad7707234f3	o1-mini	0.0000011000000000000000000	0.0000044000000000000000000	2025-03-13 05:33:56.555649+00
5cf909cf-f4a6-4f76-8317-7e205ab08a16	o3-mini	0.000001100000000000000000	0.000004400000000000000000	2025-03-13 05:33:56.555649+00
\.


--
-- Data for Name: users; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.users (id, username, first_name, last_name, settings) FROM stdin;
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	victor@aech.ai	Victor	Marquez	{}
e862146c-8b79-4408-8a84-b8e6315b66a0	steven@aech.ai	Steven	Moon	{}
88a28dd0-3294-4780-b9c7-874cd4e4654d	trevor@aech.ai	Trevor	Kinsey	{}
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	helpdesk_agent	Ingestion	Agent	{}
\.


--
-- Data for Name: user_groups; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.user_groups (user_id, group_id) FROM stdin;
88a28dd0-3294-4780-b9c7-874cd4e4654d	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
e862146c-8b79-4408-8a84-b8e6315b66a0	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
88a28dd0-3294-4780-b9c7-874cd4e4654d	17dd16eb-3f2d-4fff-a398-bce997273ed6
e862146c-8b79-4408-8a84-b8e6315b66a0	17dd16eb-3f2d-4fff-a398-bce997273ed6
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	17dd16eb-3f2d-4fff-a398-bce997273ed6
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	17dd16eb-3f2d-4fff-a398-bce997273ed6
\.


--
-- PostgreSQL database dump complete
--
```
## File: postgres_setup/pgdump_20250409/schema.sql
```
--
-- PostgreSQL database dump
--

-- Dumped from database version 17.4 (Debian 17.4-1.pgdg120+2)
-- Dumped by pg_dump version 17.4 (Debian 17.4-1.pgdg120+2)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Name: auth; Type: SCHEMA; Schema: -; Owner: -
--

CREATE SCHEMA auth;


--
-- Name: pg_trgm; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS pg_trgm WITH SCHEMA public;


--
-- Name: EXTENSION pg_trgm; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION pg_trgm IS 'text similarity measurement and index searching based on trigrams';


--
-- Name: uuid-ossp; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS "uuid-ossp" WITH SCHEMA public;


--
-- Name: EXTENSION "uuid-ossp"; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION "uuid-ossp" IS 'generate universally unique identifiers (UUIDs)';


--
-- Name: vector; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA public;


--
-- Name: EXTENSION vector; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION vector IS 'vector data type and ivfflat and hnsw access methods';


--
-- Name: uid(); Type: FUNCTION; Schema: auth; Owner: -
--

CREATE FUNCTION auth.uid() RETURNS uuid
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    RETURN current_setting('app.current_user_id', TRUE)::UUID;
EXCEPTION
    WHEN OTHERS THEN
        RETURN NULL;
END;
$$;


--
-- Name: add_user_to_groups(text, text[]); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.add_user_to_groups(p_username text, p_group_names text[]) RETURNS TABLE(username text, group_names text[])
    LANGUAGE plpgsql
    AS $$
BEGIN
  -- Insert the user-group relationships
  INSERT INTO public.user_groups (user_id, group_id)
  SELECT u.id AS user_id, g.id AS group_id
  FROM public.users u
  CROSS JOIN UNNEST(p_group_names) AS gn(name)
  JOIN public.groups g ON g.name = gn.name
  WHERE u.username = p_username
  ON CONFLICT ON CONSTRAINT user_groups_pkey DO NOTHING;
  
  -- Return the username and array of group names
  RETURN QUERY
  SELECT 
    p_username AS username,
    ARRAY_AGG(g.name) AS group_names
  FROM public.groups g
  WHERE g.name = ANY(p_group_names)
  GROUP BY p_username;
END;
$$;


--
-- Name: calculate_llm_call_cost(text, integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) RETURNS numeric
    LANGUAGE plpgsql STABLE
    AS $$
DECLARE
    input_cost numeric;
    output_cost numeric;
BEGIN
    -- Get the costs from the llms table
    SELECT 
        input_token_cost,
        output_token_cost
    INTO 
        input_cost,
        output_cost
    FROM public.llms
    WHERE name = p_model_name;

    -- If model not found, return null
    IF NOT FOUND THEN
        RETURN NULL;
    END IF;

    -- Calculate total cost
    RETURN (p_input_tokens * input_cost) + (p_output_tokens * output_cost);
END;
$$;


--
-- Name: connect_as_user(text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.connect_as_user(p_username text) RETURNS void
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
DECLARE
    v_user_id UUID;
BEGIN
    -- Get the user ID
    SELECT id INTO v_user_id
    FROM public.users
    WHERE username = p_username;
    
    IF v_user_id IS NULL THEN
        RAISE EXCEPTION 'User not found';
    END IF;
    
    -- Set the user context
    PERFORM set_authenticated_user(v_user_id);
END;
$$;


--
-- Name: document_fts_search(text, integer, double precision, uuid[], timestamp with time zone, timestamp with time zone, integer, jsonb, text[], integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.document_fts_search(p_query_text text, p_match_count integer DEFAULT 10, p_similarity_threshold double precision DEFAULT 0.0, p_group_ids uuid[] DEFAULT NULL::uuid[], p_created_before timestamp with time zone DEFAULT NULL::timestamp with time zone, p_created_after timestamp with time zone DEFAULT NULL::timestamp with time zone, p_max_terms integer DEFAULT 50, p_parent_metadata jsonb DEFAULT NULL::jsonb, p_non_null_parent_metadata_keys text[] DEFAULT NULL::text[], p_min_parent_id integer DEFAULT NULL::integer, p_max_parent_id integer DEFAULT NULL::integer) RETURNS TABLE(id uuid, content text, parent_document_id integer, group_id uuid, prev_id uuid, next_id uuid, similarity double precision, parent_metadata jsonb)
    LANGUAGE plpgsql
    AS $$
DECLARE
    v_query_tsv tsquery;
BEGIN
    v_query_tsv := plainto_tsquery_smart_prefix(p_query_text, p_max_terms);

    RETURN QUERY
    SELECT 
        d.id,
        d.content,
        d.parent_document_id,
        d.group_id,
        d.prev_id,
        d.next_id,
        ts_rank(to_tsvector('english', d.content), v_query_tsv)::float as similarity,
        pd.metadata as parent_metadata
    FROM documents d
    LEFT JOIN parent_documents pd ON d.parent_document_id = pd.id
    WHERE (
        p_group_ids IS NULL 
        OR d.group_id = ANY(p_group_ids)
    )
    AND (
        p_created_before IS NULL 
        OR d.created_at <= p_created_before
    )
    AND (
        p_created_after IS NULL 
        OR d.created_at >= p_created_after
    )
    AND (
        p_parent_metadata IS NULL
        OR pd.metadata @> p_parent_metadata
    )
    AND (
        p_non_null_parent_metadata_keys IS NULL
        OR NOT EXISTS (
            SELECT 1 
            FROM unnest(p_non_null_parent_metadata_keys) AS key 
            WHERE pd.metadata->>key IS NULL
        )
    )
    AND (
        to_tsvector('english', d.content) @@ v_query_tsv
    )
    AND (
        ts_rank(to_tsvector('english', d.content), v_query_tsv)::float >= p_similarity_threshold
    )
    AND (
    p_min_parent_id IS NULL
    OR d.parent_document_id >= p_min_parent_id
    )
    AND (
        p_max_parent_id IS NULL
        OR d.parent_document_id <= p_max_parent_id
    )
    ORDER BY similarity DESC
    LIMIT p_match_count;
END;
$$;


--
-- Name: document_semantic_search(public.vector, integer, double precision, uuid[], timestamp with time zone, timestamp with time zone, jsonb, text[], integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.document_semantic_search(p_query_embedding public.vector, p_match_count integer DEFAULT 10, p_similarity_threshold double precision DEFAULT 0.0, p_group_ids uuid[] DEFAULT NULL::uuid[], p_created_before timestamp with time zone DEFAULT NULL::timestamp with time zone, p_created_after timestamp with time zone DEFAULT NULL::timestamp with time zone, p_parent_metadata jsonb DEFAULT NULL::jsonb, p_non_null_parent_metadata_keys text[] DEFAULT NULL::text[], p_min_parent_id integer DEFAULT NULL::integer, p_max_parent_id integer DEFAULT NULL::integer) RETURNS TABLE(id uuid, content text, parent_document_id integer, group_id uuid, prev_id uuid, next_id uuid, similarity double precision, parent_metadata jsonb)
    LANGUAGE plpgsql
    AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.id,
        d.content,
        d.parent_document_id,
        d.group_id,
        d.prev_id,
        d.next_id,
        1 - (d.embedding <=> p_query_embedding) as similarity,
        pd.metadata as parent_metadata
    FROM documents d
    LEFT JOIN parent_documents pd ON d.parent_document_id = pd.id
    WHERE (
        p_group_ids IS NULL 
        OR d.group_id = ANY(p_group_ids)
    )
    AND (
        p_created_before IS NULL 
        OR d.created_at <= p_created_before
    )
    AND (
        p_created_after IS NULL 
        OR d.created_at >= p_created_after
    )
    AND (
        p_parent_metadata IS NULL
        OR pd.metadata @> p_parent_metadata
    )
    AND (
        p_non_null_parent_metadata_keys IS NULL
        OR NOT EXISTS (
            SELECT 1 
            FROM unnest(p_non_null_parent_metadata_keys) AS key 
            WHERE pd.metadata->>key IS NULL
        )
    )
    AND (
        1 - (d.embedding <=> p_query_embedding) >= p_similarity_threshold
    )
    AND (
        p_min_parent_id IS NULL
        OR d.parent_document_id >= p_min_parent_id
    )
    AND (
        p_max_parent_id IS NULL
        OR d.parent_document_id <= p_max_parent_id
    )
    ORDER BY similarity DESC
    LIMIT p_match_count;
END;
$$;


--
-- Name: get_admins_group_id(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_admins_group_id() RETURNS uuid
    LANGUAGE plpgsql IMMUTABLE SECURITY DEFINER
    AS $$
BEGIN
    -- Replace this UUID with your actual admins group ID
    RETURN '17dd16eb-3f2d-4fff-a398-bce997273ed6'::UUID;
END;
$$;


--
-- Name: get_group_id(text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_group_id(p_group_name text) RETURNS uuid
    LANGUAGE plpgsql STABLE
    AS $$
DECLARE
    group_id UUID;
BEGIN
    SELECT id INTO group_id FROM public.groups WHERE name = p_group_name LIMIT 1;
    RETURN group_id;
END;
$$;


--
-- Name: get_user_groups(uuid, text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_user_groups(p_user_id uuid DEFAULT NULL::uuid, p_username text DEFAULT NULL::text) RETURNS TABLE(group_id uuid, group_name text)
    LANGUAGE plpgsql
    AS $$
BEGIN
  IF p_user_id IS NULL AND p_username IS NULL THEN
    RAISE EXCEPTION 'Either p_user_id or p_username must be provided';
  END IF;

  RETURN QUERY
  SELECT g.id as group_id, g.name AS group_name
  FROM public.users u
  JOIN public.user_groups ug ON u.id = ug.user_id
  JOIN public.groups g ON ug.group_id = g.id
  WHERE (p_user_id IS NOT NULL AND u.id = p_user_id)
     OR (p_username IS NOT NULL AND u.username = p_username);
END;
$$;


--
-- Name: get_users_in_group(uuid, text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_users_in_group(p_group_id uuid DEFAULT NULL::uuid, p_group_name text DEFAULT NULL::text) RETURNS TABLE(id uuid, username text, first_name text, last_name text)
    LANGUAGE plpgsql
    SET search_path TO 'public'
    AS $$
BEGIN
  IF p_group_id IS NULL AND p_group_name IS NULL THEN
    RAISE EXCEPTION 'Either p_group_id or p_group_name must be provided';
  END IF;

  RETURN QUERY
  SELECT u.id, u.username, u.first_name, u.last_name
  FROM users u
  JOIN user_groups ug ON u.id = ug.user_id
  JOIN groups g ON g.id = ug.group_id
  WHERE (p_group_id IS NOT NULL AND g.id = p_group_id)
     OR (p_group_name IS NOT NULL AND g.name = p_group_name);
END;
$$;


--
-- Name: is_authenticated(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.is_authenticated() RETURNS boolean
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    RETURN current_setting('app.current_user_id', TRUE) IS NOT NULL;
END;
$$;


--
-- Name: plainto_tsquery_smart(text, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.plainto_tsquery_smart(p_query_text text, p_max_terms integer DEFAULT 8) RETURNS tsquery
    LANGUAGE plpgsql STABLE PARALLEL SAFE
    AS $_$
DECLARE
    words text[];
    num_words int;
    important_terms text[];
    result_query tsquery;
BEGIN
    -- Split query into words
    words := regexp_split_to_array(lower(p_query_text), '\s+');
    num_words := array_length(words, 1);
    
    -- For short queries, use OR logic between all words with prefix matching
    IF num_words <= p_max_terms THEN
        RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
                FROM unnest(tsvector_to_array(to_tsvector('english', p_query_text))) lexeme);
    END IF;
    
    -- For long queries, extract important terms (same as before)
    SELECT ARRAY(
        SELECT word
        FROM (
            SELECT unnest(words) as word
        ) t
        WHERE length(word) > 2
        AND word !~ '^(the|and|or|in|on|at|to|for|of|with|by|as|but|if|from|when|where|how|all|been|have|has|had|may|what|about|than|then|them|these|this|that|into|unto|not|there|their|they|some|will|would|could|should|your|which|who|whom|whose|why|yes|no)$'
        GROUP BY word
        ORDER BY length(word) DESC
        LIMIT p_max_terms
    ) INTO important_terms;
    
    -- Combine important terms with OR logic and add prefix matching
    result_query := plainto_tsquery(array_to_string(important_terms, ' '));
    RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
            FROM unnest(tsvector_to_array(to_tsvector('english', replace(result_query::text, ' & ', ' | ')))) lexeme);
END;
$_$;


--
-- Name: plainto_tsquery_smart_prefix(text, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer DEFAULT 20) RETURNS tsquery
    LANGUAGE plpgsql STABLE PARALLEL SAFE
    AS $_$
DECLARE
    words text[];
    num_words int;
    important_terms text[];
    result_query tsquery;
BEGIN
    -- Split query into words
    words := regexp_split_to_array(lower(p_query_text), '\s+');
    num_words := array_length(words, 1);
    
    -- For short queries, use OR logic between all words with prefix matching
    IF num_words <= p_max_terms THEN
        RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
                FROM unnest(tsvector_to_array(to_tsvector('english', p_query_text))) lexeme);
    END IF;
    
    -- For long queries, extract important terms (same as before)
    SELECT ARRAY(
        SELECT word
        FROM (
            SELECT unnest(words) as word
        ) t
        WHERE length(word) > 2
        AND word !~ '^(the|and|or|in|on|at|to|for|of|with|by|as|but|if|from|when|where|how|all|been|have|has|had|may|what|about|than|then|them|these|this|that|into|unto|not|there|their|they|some|will|would|could|should|your|which|who|whom|whose|why|yes|no)$'
        GROUP BY word
        ORDER BY length(word) DESC
        LIMIT p_max_terms
    ) INTO important_terms;
    
    -- Combine important terms with OR logic and add prefix matching
    result_query := plainto_tsquery(array_to_string(important_terms, ' '));
    RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
            FROM unnest(tsvector_to_array(to_tsvector('english', replace(result_query::text, ' & ', ' | ')))) lexeme);
END;
$_$;


--
-- Name: remove_user_from_groups(text, text[]); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.remove_user_from_groups(p_username text, p_group_names text[]) RETURNS TABLE(group_id uuid, group_name text, group_description text)
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
DECLARE
  v_removed_groups uuid[];
BEGIN
  -- Store the group IDs that will be removed
  SELECT ARRAY_AGG(g.id)
  INTO v_removed_groups
  FROM public.users u
  CROSS JOIN UNNEST(p_group_names) AS gn(name)
  JOIN public.groups g ON g.name = gn.name
  JOIN public.user_groups ug ON ug.group_id = g.id AND ug.user_id = u.id
  WHERE u.username = p_username;

  -- Remove the user from the groups
  DELETE FROM public.user_groups
  WHERE (user_id, group_id) IN (
    SELECT u.id AS user_id, g.id AS group_id
    FROM public.users u
    CROSS JOIN UNNEST(p_group_names) AS gn(name)
    JOIN public.groups g ON g.name = gn.name
    WHERE u.username = p_username
  );
  
  -- Return information about the groups that were removed
  RETURN QUERY
  SELECT g.id, g.name, g.description
  FROM public.groups g
  WHERE g.id = ANY(v_removed_groups);
END;
$$;


--
-- Name: set_authenticated_user(uuid); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.set_authenticated_user(user_id uuid) RETURNS void
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    PERFORM set_config('app.current_user_id', user_id::TEXT, FALSE);
END;
$$;


--
-- Name: update_llm_call_cost(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.update_llm_call_cost() RETURNS trigger
    LANGUAGE plpgsql
    AS $$
BEGIN
    NEW.cost := calculate_llm_call_cost(
        NEW.model,
        NEW.input_tokens,
        NEW.output_tokens
    );
    RETURN NEW;
END;
$$;


--
-- Name: user_in_group(uuid, uuid); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) RETURNS boolean
    LANGUAGE sql SECURITY DEFINER
    AS $$
SELECT EXISTS (
  SELECT 1
  FROM user_groups ug
  WHERE ug.group_id = p_group_id
  AND ug.user_id = p_user_id
);
$$;


SET default_tablespace = '';

SET default_table_access_method = heap;

--
-- Name: documents; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.documents (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    content text NOT NULL,
    prev_id uuid,
    next_id uuid,
    parent_document_id integer NOT NULL,
    group_id uuid NOT NULL,
    metadata jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    fts tsvector GENERATED ALWAYS AS (to_tsvector('english'::regconfig, content)) STORED,
    embedding public.vector(1536) NOT NULL
);


--
-- Name: groups; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.groups (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    name text NOT NULL,
    description text
);


--
-- Name: llm_calls; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.llm_calls (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    prompt text NOT NULL,
    response text NOT NULL,
    ticket_id integer,
    model text NOT NULL,
    input_tokens integer NOT NULL,
    output_tokens integer NOT NULL,
    cost numeric(12,7),
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


--
-- Name: llms; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.llms (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    name text NOT NULL,
    input_token_cost numeric NOT NULL,
    output_token_cost numeric NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


--
-- Name: parent_documents; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.parent_documents (
    id integer NOT NULL,
    summary text,
    source text,
    group_id uuid NOT NULL,
    metadata jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    created_by uuid NOT NULL
);


--
-- Name: user_groups; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.user_groups (
    user_id uuid NOT NULL,
    group_id uuid NOT NULL
);


--
-- Name: users; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.users (
    id uuid DEFAULT gen_random_uuid() NOT NULL,
    username text NOT NULL,
    first_name text NOT NULL,
    last_name text NOT NULL,
    settings jsonb
);


--
-- Name: documents documents_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_pkey PRIMARY KEY (id);


--
-- Name: groups groups_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.groups
    ADD CONSTRAINT groups_pkey PRIMARY KEY (id);


--
-- Name: llm_calls llm_calls_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.llm_calls
    ADD CONSTRAINT llm_calls_pkey PRIMARY KEY (id);


--
-- Name: llms models_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.llms
    ADD CONSTRAINT models_pkey PRIMARY KEY (id);


--
-- Name: parent_documents parent_documents_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_pkey PRIMARY KEY (id);


--
-- Name: user_groups user_groups_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_pkey PRIMARY KEY (user_id, group_id);


--
-- Name: users users_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_pkey PRIMARY KEY (id);


--
-- Name: users users_username_key; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_username_key UNIQUE (username);


--
-- Name: idx_documents_fts; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_documents_fts ON public.documents USING gin (fts);


--
-- Name: idx_documents_group_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_documents_group_id ON public.documents USING btree (group_id);


--
-- Name: idx_hnsw_documents_embedding; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_hnsw_documents_embedding ON public.documents USING hnsw (embedding public.vector_ip_ops);


--
-- Name: idx_llm_calls_ticket_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_llm_calls_ticket_id ON public.llm_calls USING btree (ticket_id);


--
-- Name: idx_parent_documents_source; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_parent_documents_source ON public.parent_documents USING btree (source);


--
-- Name: idx_user_groups_user_id_group_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_user_groups_user_id_group_id ON public.user_groups USING btree (user_id, group_id);


--
-- Name: llm_calls before_insert_llm_call; Type: TRIGGER; Schema: public; Owner: -
--

CREATE TRIGGER before_insert_llm_call BEFORE INSERT ON public.llm_calls FOR EACH ROW EXECUTE FUNCTION public.update_llm_call_cost();


--
-- Name: documents documents_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id);


--
-- Name: documents documents_parent_document_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_parent_document_id_fkey FOREIGN KEY (parent_document_id) REFERENCES public.parent_documents(id) ON DELETE CASCADE;


--
-- Name: parent_documents parent_documents_created_by_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_created_by_fkey FOREIGN KEY (created_by) REFERENCES public.users(id);


--
-- Name: parent_documents parent_documents_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id);


--
-- Name: user_groups user_groups_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id) ON DELETE CASCADE;


--
-- Name: user_groups user_groups_user_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_user_id_fkey FOREIGN KEY (user_id) REFERENCES public.users(id) ON DELETE CASCADE;


--
-- Name: documents; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.documents ENABLE ROW LEVEL SECURITY;

--
-- Name: documents documents_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY documents_group_access ON public.documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.groups
  WHERE (groups.id = documents.group_id))));


--
-- Name: groups; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.groups ENABLE ROW LEVEL SECURITY;

--
-- Name: groups groups_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY groups_admin_access ON public.groups TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.user_id = auth.uid()) AND (ug.group_id = public.get_admins_group_id())))));


--
-- Name: groups groups_member_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY groups_member_access ON public.groups FOR SELECT TO authenticated USING ((id IN ( SELECT user_groups.group_id
   FROM public.user_groups
  WHERE (user_groups.user_id = auth.uid()))));


--
-- Name: parent_documents parent_docs_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_docs_admin_access ON public.parent_documents TO authenticated USING ((auth.uid() IN ( SELECT user_groups.user_id
   FROM public.user_groups
  WHERE (user_groups.group_id = public.get_admins_group_id()))));


--
-- Name: parent_documents parent_docs_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_docs_group_access ON public.parent_documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.group_id = parent_documents.group_id) AND (ug.user_id = auth.uid())))));


--
-- Name: parent_documents; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.parent_documents ENABLE ROW LEVEL SECURITY;

--
-- Name: parent_documents parent_documents_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_documents_group_access ON public.parent_documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.groups
  WHERE (groups.id = parent_documents.group_id))));


--
-- Name: user_groups; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.user_groups ENABLE ROW LEVEL SECURITY;

--
-- Name: user_groups user_groups_self_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY user_groups_self_access ON public.user_groups FOR SELECT TO authenticated USING ((user_id = auth.uid()));


--
-- Name: users; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.users ENABLE ROW LEVEL SECURITY;

--
-- Name: users users_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY users_admin_access ON public.users TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.user_id = auth.uid()) AND (ug.group_id = public.get_admins_group_id())))));


--
-- Name: users users_self_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY users_self_access ON public.users FOR SELECT TO authenticated USING ((id = auth.uid()));


--
-- Name: SCHEMA auth; Type: ACL; Schema: -; Owner: -
--

GRANT USAGE ON SCHEMA auth TO authenticated;
GRANT USAGE ON SCHEMA auth TO service_role;


--
-- Name: SCHEMA public; Type: ACL; Schema: -; Owner: -
--

GRANT USAGE ON SCHEMA public TO authenticated;
GRANT USAGE ON SCHEMA public TO service_role;


--
-- Name: FUNCTION gtrgm_in(cstring); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_in(cstring) TO authenticated;


--
-- Name: FUNCTION gtrgm_out(public.gtrgm); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_out(public.gtrgm) TO authenticated;


--
-- Name: FUNCTION halfvec_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION halfvec_out(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_out(public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION halfvec_send(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_send(public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION sparsevec_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION sparsevec_out(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_out(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION sparsevec_send(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_send(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION vector_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION vector_out(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_out(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION vector_send(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_send(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(real[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(real[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(real[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(real[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(double precision[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(double precision[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(double precision[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(double precision[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(integer[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(integer[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(integer[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(integer[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(numeric[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(numeric[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(numeric[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(numeric[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_float4(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_float4(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_sparsevec(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_sparsevec(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_vector(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_vector(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec_to_halfvec(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_to_halfvec(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec_to_vector(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_to_vector(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_float4(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_float4(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_halfvec(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_halfvec(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_sparsevec(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_sparsevec(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION add_user_to_groups(p_username text, p_group_names text[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.add_user_to_groups(p_username text, p_group_names text[]) TO authenticated;


--
-- Name: FUNCTION binary_quantize(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.binary_quantize(public.halfvec) TO authenticated;


--
-- Name: FUNCTION binary_quantize(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.binary_quantize(public.vector) TO authenticated;


--
-- Name: FUNCTION calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) TO authenticated;
GRANT ALL ON FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) TO service_role;


--
-- Name: FUNCTION connect_as_user(p_username text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.connect_as_user(p_username text) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION document_fts_search(p_query_text text, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_max_terms integer, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.document_fts_search(p_query_text text, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_max_terms integer, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer) TO authenticated;


--
-- Name: FUNCTION document_semantic_search(p_query_embedding public.vector, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.document_semantic_search(p_query_embedding public.vector, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer) TO authenticated;


--
-- Name: FUNCTION get_admins_group_id(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_admins_group_id() TO authenticated;


--
-- Name: FUNCTION get_group_id(p_group_name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_group_id(p_group_name text) TO authenticated;
GRANT ALL ON FUNCTION public.get_group_id(p_group_name text) TO service_role;


--
-- Name: FUNCTION get_user_groups(p_user_id uuid, p_username text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_user_groups(p_user_id uuid, p_username text) TO authenticated;


--
-- Name: FUNCTION get_users_in_group(p_group_id uuid, p_group_name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_users_in_group(p_group_id uuid, p_group_name text) TO authenticated;


--
-- Name: FUNCTION gin_extract_query_trgm(text, internal, smallint, internal, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_extract_query_trgm(text, internal, smallint, internal, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gin_extract_value_trgm(text, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_extract_value_trgm(text, internal) TO authenticated;


--
-- Name: FUNCTION gin_trgm_consistent(internal, smallint, text, integer, internal, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_trgm_consistent(internal, smallint, text, integer, internal, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gin_trgm_triconsistent(internal, smallint, text, integer, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_trgm_triconsistent(internal, smallint, text, integer, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_compress(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_compress(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_consistent(internal, text, smallint, oid, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_consistent(internal, text, smallint, oid, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_decompress(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_decompress(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_distance(internal, text, smallint, oid, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_distance(internal, text, smallint, oid, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_options(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_options(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_penalty(internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_penalty(internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_picksplit(internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_picksplit(internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_same(public.gtrgm, public.gtrgm, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_same(public.gtrgm, public.gtrgm, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_union(internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_union(internal, internal) TO authenticated;


--
-- Name: FUNCTION halfvec_accum(double precision[], public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_accum(double precision[], public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_add(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_add(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_avg(double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_avg(double precision[]) TO authenticated;


--
-- Name: FUNCTION halfvec_cmp(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_cmp(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_combine(double precision[], double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_combine(double precision[], double precision[]) TO authenticated;


--
-- Name: FUNCTION halfvec_concat(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_concat(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_eq(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_eq(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_ge(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_ge(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_gt(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_gt(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_l2_squared_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_l2_squared_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_le(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_le(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_lt(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_lt(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_mul(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_mul(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_ne(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_ne(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_negative_inner_product(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_negative_inner_product(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_spherical_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_spherical_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_sub(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_sub(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION hamming_distance(bit, bit); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hamming_distance(bit, bit) TO authenticated;


--
-- Name: FUNCTION hnsw_bit_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_bit_support(internal) TO authenticated;


--
-- Name: FUNCTION hnsw_halfvec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_halfvec_support(internal) TO authenticated;


--
-- Name: FUNCTION hnsw_sparsevec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_sparsevec_support(internal) TO authenticated;


--
-- Name: FUNCTION hnswhandler(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnswhandler(internal) TO authenticated;


--
-- Name: FUNCTION inner_product(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION inner_product(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION inner_product(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION is_authenticated(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.is_authenticated() TO authenticated;


--
-- Name: FUNCTION ivfflat_bit_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflat_bit_support(internal) TO authenticated;


--
-- Name: FUNCTION ivfflat_halfvec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflat_halfvec_support(internal) TO authenticated;


--
-- Name: FUNCTION ivfflathandler(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflathandler(internal) TO authenticated;


--
-- Name: FUNCTION jaccard_distance(bit, bit); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.jaccard_distance(bit, bit) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION l2_norm(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_norm(public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_norm(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_norm(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.vector) TO authenticated;


--
-- Name: FUNCTION plainto_tsquery_smart(p_query_text text, p_max_terms integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.plainto_tsquery_smart(p_query_text text, p_max_terms integer) TO authenticated;


--
-- Name: FUNCTION plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer) TO authenticated;


--
-- Name: FUNCTION remove_user_from_groups(p_username text, p_group_names text[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.remove_user_from_groups(p_username text, p_group_names text[]) TO authenticated;


--
-- Name: FUNCTION set_authenticated_user(user_id uuid); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.set_authenticated_user(user_id uuid) TO authenticated;


--
-- Name: FUNCTION set_limit(real); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.set_limit(real) TO authenticated;


--
-- Name: FUNCTION show_limit(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.show_limit() TO authenticated;


--
-- Name: FUNCTION show_trgm(text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.show_trgm(text) TO authenticated;


--
-- Name: FUNCTION similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity(text, text) TO authenticated;


--
-- Name: FUNCTION similarity_dist(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity_dist(text, text) TO authenticated;


--
-- Name: FUNCTION similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION sparsevec_cmp(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_cmp(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_eq(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_eq(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_ge(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_ge(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_gt(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_gt(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_l2_squared_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_l2_squared_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_le(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_le(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_lt(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_lt(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_ne(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_ne(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_negative_inner_product(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_negative_inner_product(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_dist_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_dist_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_dist_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_dist_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION subvector(public.halfvec, integer, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.subvector(public.halfvec, integer, integer) TO authenticated;


--
-- Name: FUNCTION subvector(public.vector, integer, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.subvector(public.vector, integer, integer) TO authenticated;


--
-- Name: FUNCTION update_llm_call_cost(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.update_llm_call_cost() TO authenticated;


--
-- Name: FUNCTION user_in_group(p_user_id uuid, p_group_id uuid); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) TO authenticated;
GRANT ALL ON FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) TO service_role;


--
-- Name: FUNCTION uuid_generate_v1(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v1() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v1mc(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v1mc() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v3(namespace uuid, name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v3(namespace uuid, name text) TO authenticated;


--
-- Name: FUNCTION uuid_generate_v4(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v4() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v5(namespace uuid, name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v5(namespace uuid, name text) TO authenticated;


--
-- Name: FUNCTION uuid_nil(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_nil() TO authenticated;


--
-- Name: FUNCTION uuid_ns_dns(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_dns() TO authenticated;


--
-- Name: FUNCTION uuid_ns_oid(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_oid() TO authenticated;


--
-- Name: FUNCTION uuid_ns_url(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_url() TO authenticated;


--
-- Name: FUNCTION uuid_ns_x500(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_x500() TO authenticated;


--
-- Name: FUNCTION vector_accum(double precision[], public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_accum(double precision[], public.vector) TO authenticated;


--
-- Name: FUNCTION vector_add(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_add(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_avg(double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_avg(double precision[]) TO authenticated;


--
-- Name: FUNCTION vector_cmp(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_cmp(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_combine(double precision[], double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_combine(double precision[], double precision[]) TO authenticated;


--
-- Name: FUNCTION vector_concat(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_concat(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_dims(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_dims(public.halfvec) TO authenticated;


--
-- Name: FUNCTION vector_dims(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_dims(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_eq(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_eq(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_ge(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_ge(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_gt(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_gt(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_l2_squared_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_l2_squared_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_le(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_le(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_lt(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_lt(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_mul(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_mul(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_ne(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_ne(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_negative_inner_product(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_negative_inner_product(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_norm(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_norm(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_spherical_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_spherical_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_sub(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_sub(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION word_similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_dist_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_dist_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_dist_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_dist_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION avg(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.avg(public.halfvec) TO authenticated;


--
-- Name: FUNCTION avg(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.avg(public.vector) TO authenticated;


--
-- Name: FUNCTION sum(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sum(public.halfvec) TO authenticated;


--
-- Name: FUNCTION sum(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sum(public.vector) TO authenticated;


--
-- Name: TABLE documents; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.documents TO authenticated;
GRANT ALL ON TABLE public.documents TO service_role;


--
-- Name: TABLE groups; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.groups TO authenticated;
GRANT ALL ON TABLE public.groups TO service_role;


--
-- Name: TABLE llm_calls; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.llm_calls TO authenticated;


--
-- Name: TABLE llms; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.llms TO authenticated;
GRANT ALL ON TABLE public.llms TO service_role;


--
-- Name: TABLE parent_documents; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.parent_documents TO authenticated;
GRANT ALL ON TABLE public.parent_documents TO service_role;


--
-- Name: TABLE user_groups; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.user_groups TO authenticated;
GRANT ALL ON TABLE public.user_groups TO service_role;


--
-- Name: TABLE users; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.users TO authenticated;
GRANT ALL ON TABLE public.users TO service_role;


--
-- Name: DEFAULT PRIVILEGES FOR SEQUENCES; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT SELECT,USAGE ON SEQUENCES TO authenticated;


--
-- Name: DEFAULT PRIVILEGES FOR FUNCTIONS; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT ALL ON FUNCTIONS TO authenticated;


--
-- Name: DEFAULT PRIVILEGES FOR TABLES; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT SELECT,INSERT,DELETE,UPDATE ON TABLES TO authenticated;


--
-- PostgreSQL database dump complete
--
```
## File: postgres_setup/pgdump_20250409/roles_permissions.sql
```
--
-- PostgreSQL database cluster dump
--

SET default_transaction_read_only = off;

SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;

--
-- Roles
--

CREATE ROLE app_user;
ALTER ROLE app_user WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB LOGIN NOREPLICATION NOBYPASSRLS PASSWORD 'SCRAM-SHA-256$4096:G2BO2gAsm3AdaLwV3wU0IA==$BMAEMs1jTrGZIjuCWpDhjPniAbhJGGwxafh1QvLV3y4=:gwjM7XDhlMg7JdRlSS/kyXriK/5IZAJjKJ61SPyGkXw=';
CREATE ROLE authenticated;
ALTER ROLE authenticated WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB NOLOGIN NOREPLICATION NOBYPASSRLS;
CREATE ROLE postgres;
ALTER ROLE postgres WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN REPLICATION BYPASSRLS PASSWORD 'SCRAM-SHA-256$4096:25CvqijMAQlsEMjZ6AVPYA==$KDpWN7skjchyfZ57d7SN/z1r+2AIJhrF7oLBbhLTjZY=:sOYF7UwVdt39fQzydGRNCbB43p5Ty2WNWVEQnXF6wnY=';
CREATE ROLE service_role;
ALTER ROLE service_role WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB NOLOGIN NOREPLICATION NOBYPASSRLS;

--
-- User Configurations
--


--
-- Role memberships
--

GRANT authenticated TO app_user WITH INHERIT TRUE GRANTED BY postgres;




--
-- PostgreSQL database cluster dump complete
--
```
## File: postgres_setup/pgdump_20250415/essential_data.sql
```
--
-- PostgreSQL database dump
--

-- Dumped from database version 17.4 (Debian 17.4-1.pgdg120+2)
-- Dumped by pg_dump version 17.4 (Debian 17.4-1.pgdg120+2)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Data for Name: groups; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.groups (id, name, description) FROM stdin;
17dd16eb-3f2d-4fff-a398-bce997273ed6	admins	Members have full access to all groups
84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b	users	Default group that all users belong to
e8c90ae7-2773-4ef0-9e36-32faca879c8f	Protec	Protec Dental Laboratories (2021) Inc
115f1e95-43b7-4a0e-a0dc-686d2969c29f	CrisisCentre	Crisis Intervention Centre of BC
0ed65bb9-3a58-41b3-a16c-9a8b379ce18c	UrbanImpact	Urban Impact
b7b15529-8aae-4aec-bcd9-b859906e3708	Excell	Excell Battery Company
d0cfea2a-1756-49dd-a3df-e8d20fc796c3	Elim	Elim Housing Society
3a0c8c35-afbc-40a9-a732-98fd64739270	AACB	A&A Contract Customs Brokers Ltd
\.


--
-- Data for Name: llms; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.llms (id, name, input_token_cost, output_token_cost, created_at) FROM stdin;
22a5baaf-17ac-4d83-835c-7bcf3b156ddc	gpt-4o	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
03cc6952-8f18-4311-a7cf-4ff8bc227b25	gpt-4o-2024-11-20	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
b8f8566e-ecad-4cae-8b7c-0b809f92ab07	gpt-4o-2024-08-06	0.000002500000000000000000	0.000010000000000000000000	2025-03-13 05:33:56.555649+00
dff63ab7-8093-4667-ba10-11c0df21f393	gpt-4o-mini	0.000000150000000000000000	0.000000600000000000000000	2025-03-13 05:33:56.555649+00
1def3f96-4e7d-4b38-a2ef-26bbd294ce93	gpt-4o-mini-2024-07-18	0.000000150000000000000000	0.000000600000000000000000	2025-03-13 05:33:56.555649+00
ddb219af-7fc0-4e5f-a7d2-cadf9c4b4878	o1-mini-2024-09-12	0.000003000000000000000000	0.000012000000000000000000	2025-03-13 05:33:56.555649+00
738d7099-2598-4542-a550-eb48d13edd5f	o1-preview	0.000015000000000000000000	0.000060000000000000000000	2025-03-13 05:33:56.555649+00
cb03e4a3-8588-4402-ac78-6f7195e05164	o1-preview-2024-09-12	0.000015000000000000000000	0.000060000000000000000000	2025-03-13 05:33:56.555649+00
884ca97e-1133-490f-a7a1-c27355e77d74	claude-3-5-haiku-20241022	0.000000250000000000000000	0.000001250000000000000000	2025-03-13 05:33:56.555649+00
aeb0487e-ae18-4929-9e01-670db67500c3	claude-3-5-sonnet-20240620	0.000003000000000000000000	0.000015000000000000000000	2025-03-13 05:33:56.555649+00
73dcaf8a-3b7f-43bd-83ac-fc77cb6f8311	claude-3-5-sonnet-20241022	0.000003000000000000000000	0.000015000000000000000000	2025-03-13 05:33:56.555649+00
9cfc9638-4a46-4d93-b4de-123a1e004aef	llama3.1-8b	0.000000000000000000000000	0.000000000000000000000000	2025-03-13 05:33:56.555649+00
f0290647-1736-4d42-bc4c-b128c322e785	llama3.1-70b	0.000000000000000000000000	0.000000000000000000000000	2025-03-13 05:33:56.555649+00
ab367d0f-4e81-4302-b870-345c37c18633	llama3.1-405b	0.000006000000000000000000	0.000012000000000000000000	2025-03-13 05:33:56.555649+00
f07134c4-ddfb-44af-b9f9-3ad7707234f3	o1-mini	0.0000011000000000000000000	0.0000044000000000000000000	2025-03-13 05:33:56.555649+00
5cf909cf-f4a6-4f76-8317-7e205ab08a16	o3-mini	0.000001100000000000000000	0.000004400000000000000000	2025-03-13 05:33:56.555649+00
8ca6b027-1c1a-409f-8774-28942b2b463f	gpt-4.1-2025-04-14	0.00000199999999999999990949622365177251737122787744738161563873291015625	0.000007999999999999999637984894607090069484911509789526462554931640625	2025-04-14 19:18:08.864805+00
0cfa31a2-66e7-4208-988f-352dede32e7a	gpt-4.1	0.00000199999999999999990949622365177251737122787744738161563873291015625	0.000007999999999999999637984894607090069484911509789526462554931640625	2025-04-14 19:20:05.241161+00
efa47d1d-cd65-4481-8c5b-e74fcebb96d5	gpt-4.1-mini-2025-04-14	0.00000040000000000000003483880393374827466601573178195394575595855712890625	0.000001600000000000000139355215734993098664062927127815783023834228515625	2025-04-14 19:20:56.175231+00
d55cfa7e-d6db-4dab-8515-4bf9f1605b57	gpt-4.1-mini	0.00000040000000000000003483880393374827466601573178195394575595855712890625	0.000001600000000000000139355215734993098664062927127815783023834228515625	2025-04-14 19:21:08.860804+00
ee2be457-8b33-4fb3-9e4f-fab5df8658f5	gpt-4.1-nano-2025-04-14	0.0000001000000000000000087097009834370686665039329454884864389896392822265625	0.00000040000000000000003483880393374827466601573178195394575595855712890625	2025-04-14 19:21:32.805453+00
9dbc231b-fa3e-4443-a186-45dd64766697	gpt-4.1-nano	0.0000001000000000000000087097009834370686665039329454884864389896392822265625	0.00000040000000000000003483880393374827466601573178195394575595855712890625	2025-04-14 19:21:41.217079+00
\.


--
-- Data for Name: users; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.users (id, username, first_name, last_name, settings) FROM stdin;
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	victor@aech.ai	Victor	Marquez	{}
e862146c-8b79-4408-8a84-b8e6315b66a0	steven@aech.ai	Steven	Moon	{}
88a28dd0-3294-4780-b9c7-874cd4e4654d	trevor@aech.ai	Trevor	Kinsey	{}
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	helpdesk_agent	Helpdesk	Agent	{}
\.


--
-- Data for Name: user_groups; Type: TABLE DATA; Schema: public; Owner: postgres
--

COPY public.user_groups (user_id, group_id) FROM stdin;
88a28dd0-3294-4780-b9c7-874cd4e4654d	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
e862146c-8b79-4408-8a84-b8e6315b66a0	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
88a28dd0-3294-4780-b9c7-874cd4e4654d	17dd16eb-3f2d-4fff-a398-bce997273ed6
e862146c-8b79-4408-8a84-b8e6315b66a0	17dd16eb-3f2d-4fff-a398-bce997273ed6
9d5b3c96-1c96-4ddf-9e3c-d131f8190bec	17dd16eb-3f2d-4fff-a398-bce997273ed6
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	84ac0210-b4e4-4d34-9ba0-b2ec7ad3c03b
baa90098-5bc6-452b-aa9f-e2de1cf02eaf	17dd16eb-3f2d-4fff-a398-bce997273ed6
\.


--
-- PostgreSQL database dump complete
--
```
## File: postgres_setup/pgdump_20250415/schema.sql
```
--
-- PostgreSQL database dump
--

-- Dumped from database version 17.4 (Debian 17.4-1.pgdg120+2)
-- Dumped by pg_dump version 17.4 (Debian 17.4-1.pgdg120+2)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Name: auth; Type: SCHEMA; Schema: -; Owner: -
--

CREATE SCHEMA auth;


--
-- Name: pg_trgm; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS pg_trgm WITH SCHEMA public;


--
-- Name: EXTENSION pg_trgm; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION pg_trgm IS 'text similarity measurement and index searching based on trigrams';


--
-- Name: uuid-ossp; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS "uuid-ossp" WITH SCHEMA public;


--
-- Name: EXTENSION "uuid-ossp"; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION "uuid-ossp" IS 'generate universally unique identifiers (UUIDs)';


--
-- Name: vector; Type: EXTENSION; Schema: -; Owner: -
--

CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA public;


--
-- Name: EXTENSION vector; Type: COMMENT; Schema: -; Owner: -
--

COMMENT ON EXTENSION vector IS 'vector data type and ivfflat and hnsw access methods';


--
-- Name: uid(); Type: FUNCTION; Schema: auth; Owner: -
--

CREATE FUNCTION auth.uid() RETURNS uuid
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    RETURN current_setting('app.current_user_id', TRUE)::UUID;
EXCEPTION
    WHEN OTHERS THEN
        RETURN NULL;
END;
$$;


--
-- Name: add_user_to_groups(text, text[]); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.add_user_to_groups(p_username text, p_group_names text[]) RETURNS TABLE(username text, group_names text[])
    LANGUAGE plpgsql
    AS $$
BEGIN
  -- Insert the user-group relationships
  INSERT INTO public.user_groups (user_id, group_id)
  SELECT u.id AS user_id, g.id AS group_id
  FROM public.users u
  CROSS JOIN UNNEST(p_group_names) AS gn(name)
  JOIN public.groups g ON g.name = gn.name
  WHERE u.username = p_username
  ON CONFLICT ON CONSTRAINT user_groups_pkey DO NOTHING;
  
  -- Return the username and array of group names
  RETURN QUERY
  SELECT 
    p_username AS username,
    ARRAY_AGG(g.name) AS group_names
  FROM public.groups g
  WHERE g.name = ANY(p_group_names)
  GROUP BY p_username;
END;
$$;


--
-- Name: calculate_llm_call_cost(text, integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) RETURNS numeric
    LANGUAGE plpgsql STABLE
    AS $$
DECLARE
    input_cost numeric;
    output_cost numeric;
BEGIN
    -- Get the costs from the llms table
    SELECT 
        input_token_cost,
        output_token_cost
    INTO 
        input_cost,
        output_cost
    FROM public.llms
    WHERE name = p_model_name;

    -- If model not found, return null
    IF NOT FOUND THEN
        RETURN NULL;
    END IF;

    -- Calculate total cost
    RETURN (p_input_tokens * input_cost) + (p_output_tokens * output_cost);
END;
$$;


--
-- Name: connect_as_user(text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.connect_as_user(p_username text) RETURNS void
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
DECLARE
    v_user_id UUID;
BEGIN
    -- Get the user ID
    SELECT id INTO v_user_id
    FROM public.users
    WHERE username = p_username;
    
    IF v_user_id IS NULL THEN
        RAISE EXCEPTION 'User not found';
    END IF;
    
    -- Set the user context
    PERFORM set_authenticated_user(v_user_id);
END;
$$;


--
-- Name: document_fts_search(text, integer, double precision, uuid[], timestamp with time zone, timestamp with time zone, integer, jsonb, text[], integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.document_fts_search(p_query_text text, p_match_count integer DEFAULT 10, p_similarity_threshold double precision DEFAULT 0.0, p_group_ids uuid[] DEFAULT NULL::uuid[], p_created_before timestamp with time zone DEFAULT NULL::timestamp with time zone, p_created_after timestamp with time zone DEFAULT NULL::timestamp with time zone, p_max_terms integer DEFAULT 50, p_parent_metadata jsonb DEFAULT NULL::jsonb, p_non_null_parent_metadata_keys text[] DEFAULT NULL::text[], p_min_parent_id integer DEFAULT NULL::integer, p_max_parent_id integer DEFAULT NULL::integer) RETURNS TABLE(id uuid, content text, parent_document_id integer, group_id uuid, prev_id uuid, next_id uuid, similarity double precision, parent_metadata jsonb)
    LANGUAGE plpgsql
    AS $$
DECLARE
    v_query_tsv tsquery;
BEGIN
    v_query_tsv := plainto_tsquery_smart_prefix(p_query_text, p_max_terms);

    RETURN QUERY
    SELECT 
        d.id,
        d.content,
        d.parent_document_id,
        d.group_id,
        d.prev_id,
        d.next_id,
        ts_rank(to_tsvector('english', d.content), v_query_tsv)::float as similarity,
        pd.metadata as parent_metadata
    FROM documents d
    LEFT JOIN parent_documents pd ON d.parent_document_id = pd.id
    WHERE (
        p_group_ids IS NULL 
        OR d.group_id = ANY(p_group_ids)
    )
    AND (
        p_created_before IS NULL 
        OR d.created_at <= p_created_before
    )
    AND (
        p_created_after IS NULL 
        OR d.created_at >= p_created_after
    )
    AND (
        p_parent_metadata IS NULL
        OR pd.metadata @> p_parent_metadata
    )
    AND (
        p_non_null_parent_metadata_keys IS NULL
        OR NOT EXISTS (
            SELECT 1 
            FROM unnest(p_non_null_parent_metadata_keys) AS key 
            WHERE pd.metadata->>key IS NULL
        )
    )
    AND (
        to_tsvector('english', d.content) @@ v_query_tsv
    )
    AND (
        ts_rank(to_tsvector('english', d.content), v_query_tsv)::float >= p_similarity_threshold
    )
    AND (
    p_min_parent_id IS NULL
    OR d.parent_document_id >= p_min_parent_id
    )
    AND (
        p_max_parent_id IS NULL
        OR d.parent_document_id <= p_max_parent_id
    )
    ORDER BY similarity DESC
    LIMIT p_match_count;
END;
$$;


--
-- Name: document_semantic_search(public.vector, integer, double precision, uuid[], timestamp with time zone, timestamp with time zone, jsonb, text[], integer, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.document_semantic_search(p_query_embedding public.vector, p_match_count integer DEFAULT 10, p_similarity_threshold double precision DEFAULT 0.0, p_group_ids uuid[] DEFAULT NULL::uuid[], p_created_before timestamp with time zone DEFAULT NULL::timestamp with time zone, p_created_after timestamp with time zone DEFAULT NULL::timestamp with time zone, p_parent_metadata jsonb DEFAULT NULL::jsonb, p_non_null_parent_metadata_keys text[] DEFAULT NULL::text[], p_min_parent_id integer DEFAULT NULL::integer, p_max_parent_id integer DEFAULT NULL::integer) RETURNS TABLE(id uuid, content text, parent_document_id integer, group_id uuid, prev_id uuid, next_id uuid, similarity double precision, parent_metadata jsonb)
    LANGUAGE plpgsql
    AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.id,
        d.content,
        d.parent_document_id,
        d.group_id,
        d.prev_id,
        d.next_id,
        1 - (d.embedding <=> p_query_embedding) as similarity,
        pd.metadata as parent_metadata
    FROM documents d
    LEFT JOIN parent_documents pd ON d.parent_document_id = pd.id
    WHERE (
        p_group_ids IS NULL 
        OR d.group_id = ANY(p_group_ids)
    )
    AND (
        p_created_before IS NULL 
        OR d.created_at <= p_created_before
    )
    AND (
        p_created_after IS NULL 
        OR d.created_at >= p_created_after
    )
    AND (
        p_parent_metadata IS NULL
        OR pd.metadata @> p_parent_metadata
    )
    AND (
        p_non_null_parent_metadata_keys IS NULL
        OR NOT EXISTS (
            SELECT 1 
            FROM unnest(p_non_null_parent_metadata_keys) AS key 
            WHERE pd.metadata->>key IS NULL
        )
    )
    AND (
        1 - (d.embedding <=> p_query_embedding) >= p_similarity_threshold
    )
    AND (
        p_min_parent_id IS NULL
        OR d.parent_document_id >= p_min_parent_id
    )
    AND (
        p_max_parent_id IS NULL
        OR d.parent_document_id <= p_max_parent_id
    )
    ORDER BY similarity DESC
    LIMIT p_match_count;
END;
$$;


--
-- Name: get_admins_group_id(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_admins_group_id() RETURNS uuid
    LANGUAGE plpgsql IMMUTABLE SECURITY DEFINER
    AS $$
BEGIN
    -- Replace this UUID with your actual admins group ID
    RETURN '17dd16eb-3f2d-4fff-a398-bce997273ed6'::UUID;
END;
$$;


--
-- Name: get_group_id(text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_group_id(p_group_name text) RETURNS uuid
    LANGUAGE plpgsql STABLE
    AS $$
DECLARE
    group_id UUID;
BEGIN
    SELECT id INTO group_id FROM public.groups WHERE name = p_group_name LIMIT 1;
    RETURN group_id;
END;
$$;


--
-- Name: get_user_groups(uuid, text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_user_groups(p_user_id uuid DEFAULT NULL::uuid, p_username text DEFAULT NULL::text) RETURNS TABLE(group_id uuid, group_name text)
    LANGUAGE plpgsql
    AS $$
BEGIN
  IF p_user_id IS NULL AND p_username IS NULL THEN
    RAISE EXCEPTION 'Either p_user_id or p_username must be provided';
  END IF;

  RETURN QUERY
  SELECT g.id as group_id, g.name AS group_name
  FROM public.users u
  JOIN public.user_groups ug ON u.id = ug.user_id
  JOIN public.groups g ON ug.group_id = g.id
  WHERE (p_user_id IS NOT NULL AND u.id = p_user_id)
     OR (p_username IS NOT NULL AND u.username = p_username);
END;
$$;


--
-- Name: get_users_in_group(uuid, text); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.get_users_in_group(p_group_id uuid DEFAULT NULL::uuid, p_group_name text DEFAULT NULL::text) RETURNS TABLE(id uuid, username text, first_name text, last_name text)
    LANGUAGE plpgsql
    SET search_path TO 'public'
    AS $$
BEGIN
  IF p_group_id IS NULL AND p_group_name IS NULL THEN
    RAISE EXCEPTION 'Either p_group_id or p_group_name must be provided';
  END IF;

  RETURN QUERY
  SELECT u.id, u.username, u.first_name, u.last_name
  FROM users u
  JOIN user_groups ug ON u.id = ug.user_id
  JOIN groups g ON g.id = ug.group_id
  WHERE (p_group_id IS NOT NULL AND g.id = p_group_id)
     OR (p_group_name IS NOT NULL AND g.name = p_group_name);
END;
$$;


--
-- Name: is_authenticated(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.is_authenticated() RETURNS boolean
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    RETURN current_setting('app.current_user_id', TRUE) IS NOT NULL;
END;
$$;


--
-- Name: plainto_tsquery_smart(text, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.plainto_tsquery_smart(p_query_text text, p_max_terms integer DEFAULT 8) RETURNS tsquery
    LANGUAGE plpgsql STABLE PARALLEL SAFE
    AS $_$
DECLARE
    words text[];
    num_words int;
    important_terms text[];
    result_query tsquery;
BEGIN
    -- Split query into words
    words := regexp_split_to_array(lower(p_query_text), '\s+');
    num_words := array_length(words, 1);
    
    -- For short queries, use OR logic between all words with prefix matching
    IF num_words <= p_max_terms THEN
        RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
                FROM unnest(tsvector_to_array(to_tsvector('english', p_query_text))) lexeme);
    END IF;
    
    -- For long queries, extract important terms (same as before)
    SELECT ARRAY(
        SELECT word
        FROM (
            SELECT unnest(words) as word
        ) t
        WHERE length(word) > 2
        AND word !~ '^(the|and|or|in|on|at|to|for|of|with|by|as|but|if|from|when|where|how|all|been|have|has|had|may|what|about|than|then|them|these|this|that|into|unto|not|there|their|they|some|will|would|could|should|your|which|who|whom|whose|why|yes|no)$'
        GROUP BY word
        ORDER BY length(word) DESC
        LIMIT p_max_terms
    ) INTO important_terms;
    
    -- Combine important terms with OR logic and add prefix matching
    result_query := plainto_tsquery(array_to_string(important_terms, ' '));
    RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
            FROM unnest(tsvector_to_array(to_tsvector('english', replace(result_query::text, ' & ', ' | ')))) lexeme);
END;
$_$;


--
-- Name: plainto_tsquery_smart_prefix(text, integer); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer DEFAULT 20) RETURNS tsquery
    LANGUAGE plpgsql STABLE PARALLEL SAFE
    AS $_$
DECLARE
    words text[];
    num_words int;
    important_terms text[];
    result_query tsquery;
BEGIN
    -- Split query into words
    words := regexp_split_to_array(lower(p_query_text), '\s+');
    num_words := array_length(words, 1);
    
    -- For short queries, use OR logic between all words with prefix matching
    IF num_words <= p_max_terms THEN
        RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
                FROM unnest(tsvector_to_array(to_tsvector('english', p_query_text))) lexeme);
    END IF;
    
    -- For long queries, extract important terms (same as before)
    SELECT ARRAY(
        SELECT word
        FROM (
            SELECT unnest(words) as word
        ) t
        WHERE length(word) > 2
        AND word !~ '^(the|and|or|in|on|at|to|for|of|with|by|as|but|if|from|when|where|how|all|been|have|has|had|may|what|about|than|then|them|these|this|that|into|unto|not|there|their|they|some|will|would|could|should|your|which|who|whom|whose|why|yes|no)$'
        GROUP BY word
        ORDER BY length(word) DESC
        LIMIT p_max_terms
    ) INTO important_terms;
    
    -- Combine important terms with OR logic and add prefix matching
    result_query := plainto_tsquery(array_to_string(important_terms, ' '));
    RETURN (SELECT string_agg(lexeme || ':*', ' | ')::tsquery 
            FROM unnest(tsvector_to_array(to_tsvector('english', replace(result_query::text, ' & ', ' | ')))) lexeme);
END;
$_$;


--
-- Name: remove_user_from_groups(text, text[]); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.remove_user_from_groups(p_username text, p_group_names text[]) RETURNS TABLE(group_id uuid, group_name text, group_description text)
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
DECLARE
  v_removed_groups uuid[];
BEGIN
  -- Store the group IDs that will be removed
  SELECT ARRAY_AGG(g.id)
  INTO v_removed_groups
  FROM public.users u
  CROSS JOIN UNNEST(p_group_names) AS gn(name)
  JOIN public.groups g ON g.name = gn.name
  JOIN public.user_groups ug ON ug.group_id = g.id AND ug.user_id = u.id
  WHERE u.username = p_username;

  -- Remove the user from the groups
  DELETE FROM public.user_groups
  WHERE (user_id, group_id) IN (
    SELECT u.id AS user_id, g.id AS group_id
    FROM public.users u
    CROSS JOIN UNNEST(p_group_names) AS gn(name)
    JOIN public.groups g ON g.name = gn.name
    WHERE u.username = p_username
  );
  
  -- Return information about the groups that were removed
  RETURN QUERY
  SELECT g.id, g.name, g.description
  FROM public.groups g
  WHERE g.id = ANY(v_removed_groups);
END;
$$;


--
-- Name: set_authenticated_user(uuid); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.set_authenticated_user(user_id uuid) RETURNS void
    LANGUAGE plpgsql SECURITY DEFINER
    AS $$
BEGIN
    PERFORM set_config('app.current_user_id', user_id::TEXT, FALSE);
END;
$$;


--
-- Name: update_llm_call_cost(); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.update_llm_call_cost() RETURNS trigger
    LANGUAGE plpgsql
    AS $$
BEGIN
    NEW.cost := calculate_llm_call_cost(
        NEW.model,
        NEW.input_tokens,
        NEW.output_tokens
    );
    RETURN NEW;
END;
$$;


--
-- Name: user_in_group(uuid, uuid); Type: FUNCTION; Schema: public; Owner: -
--

CREATE FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) RETURNS boolean
    LANGUAGE sql SECURITY DEFINER
    AS $$
SELECT EXISTS (
  SELECT 1
  FROM user_groups ug
  WHERE ug.group_id = p_group_id
  AND ug.user_id = p_user_id
);
$$;


SET default_tablespace = '';

SET default_table_access_method = heap;

--
-- Name: documents; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.documents (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    content text NOT NULL,
    prev_id uuid,
    next_id uuid,
    parent_document_id integer NOT NULL,
    group_id uuid NOT NULL,
    metadata jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    fts tsvector GENERATED ALWAYS AS (to_tsvector('english'::regconfig, content)) STORED,
    embedding public.vector(1536) NOT NULL
);


--
-- Name: groups; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.groups (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    name text NOT NULL,
    description text
);


--
-- Name: llm_calls; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.llm_calls (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    prompt text NOT NULL,
    response text NOT NULL,
    ticket_id integer,
    model text NOT NULL,
    input_tokens integer NOT NULL,
    output_tokens integer NOT NULL,
    cost numeric(12,7),
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


--
-- Name: llms; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.llms (
    id uuid DEFAULT public.uuid_generate_v4() NOT NULL,
    name text NOT NULL,
    input_token_cost numeric NOT NULL,
    output_token_cost numeric NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);


--
-- Name: parent_documents; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.parent_documents (
    id integer NOT NULL,
    summary text,
    source text,
    group_id uuid NOT NULL,
    metadata jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    created_by uuid NOT NULL
);


--
-- Name: user_groups; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.user_groups (
    user_id uuid NOT NULL,
    group_id uuid NOT NULL
);


--
-- Name: users; Type: TABLE; Schema: public; Owner: -
--

CREATE TABLE public.users (
    id uuid DEFAULT gen_random_uuid() NOT NULL,
    username text NOT NULL,
    first_name text NOT NULL,
    last_name text NOT NULL,
    settings jsonb
);


--
-- Name: documents documents_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_pkey PRIMARY KEY (id);


--
-- Name: groups groups_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.groups
    ADD CONSTRAINT groups_pkey PRIMARY KEY (id);


--
-- Name: llm_calls llm_calls_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.llm_calls
    ADD CONSTRAINT llm_calls_pkey PRIMARY KEY (id);


--
-- Name: llms models_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.llms
    ADD CONSTRAINT models_pkey PRIMARY KEY (id);


--
-- Name: parent_documents parent_documents_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_pkey PRIMARY KEY (id);


--
-- Name: user_groups user_groups_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_pkey PRIMARY KEY (user_id, group_id);


--
-- Name: users users_pkey; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_pkey PRIMARY KEY (id);


--
-- Name: users users_username_key; Type: CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.users
    ADD CONSTRAINT users_username_key UNIQUE (username);


--
-- Name: idx_documents_fts; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_documents_fts ON public.documents USING gin (fts);


--
-- Name: idx_documents_group_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_documents_group_id ON public.documents USING btree (group_id);


--
-- Name: idx_hnsw_documents_embedding; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_hnsw_documents_embedding ON public.documents USING hnsw (embedding public.vector_ip_ops);


--
-- Name: idx_llm_calls_ticket_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_llm_calls_ticket_id ON public.llm_calls USING btree (ticket_id);


--
-- Name: idx_parent_documents_source; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_parent_documents_source ON public.parent_documents USING btree (source);


--
-- Name: idx_user_groups_user_id_group_id; Type: INDEX; Schema: public; Owner: -
--

CREATE INDEX idx_user_groups_user_id_group_id ON public.user_groups USING btree (user_id, group_id);


--
-- Name: llm_calls before_insert_llm_call; Type: TRIGGER; Schema: public; Owner: -
--

CREATE TRIGGER before_insert_llm_call BEFORE INSERT ON public.llm_calls FOR EACH ROW EXECUTE FUNCTION public.update_llm_call_cost();


--
-- Name: documents documents_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id);


--
-- Name: documents documents_parent_document_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.documents
    ADD CONSTRAINT documents_parent_document_id_fkey FOREIGN KEY (parent_document_id) REFERENCES public.parent_documents(id) ON DELETE CASCADE;


--
-- Name: parent_documents parent_documents_created_by_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_created_by_fkey FOREIGN KEY (created_by) REFERENCES public.users(id);


--
-- Name: parent_documents parent_documents_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.parent_documents
    ADD CONSTRAINT parent_documents_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id);


--
-- Name: user_groups user_groups_group_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_group_id_fkey FOREIGN KEY (group_id) REFERENCES public.groups(id) ON DELETE CASCADE;


--
-- Name: user_groups user_groups_user_id_fkey; Type: FK CONSTRAINT; Schema: public; Owner: -
--

ALTER TABLE ONLY public.user_groups
    ADD CONSTRAINT user_groups_user_id_fkey FOREIGN KEY (user_id) REFERENCES public.users(id) ON DELETE CASCADE;


--
-- Name: documents; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.documents ENABLE ROW LEVEL SECURITY;

--
-- Name: documents documents_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY documents_group_access ON public.documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.groups
  WHERE (groups.id = documents.group_id))));


--
-- Name: groups; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.groups ENABLE ROW LEVEL SECURITY;

--
-- Name: groups groups_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY groups_admin_access ON public.groups TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.user_id = auth.uid()) AND (ug.group_id = public.get_admins_group_id())))));


--
-- Name: groups groups_member_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY groups_member_access ON public.groups FOR SELECT TO authenticated USING ((id IN ( SELECT user_groups.group_id
   FROM public.user_groups
  WHERE (user_groups.user_id = auth.uid()))));


--
-- Name: parent_documents parent_docs_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_docs_admin_access ON public.parent_documents TO authenticated USING ((auth.uid() IN ( SELECT user_groups.user_id
   FROM public.user_groups
  WHERE (user_groups.group_id = public.get_admins_group_id()))));


--
-- Name: parent_documents parent_docs_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_docs_group_access ON public.parent_documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.group_id = parent_documents.group_id) AND (ug.user_id = auth.uid())))));


--
-- Name: parent_documents; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.parent_documents ENABLE ROW LEVEL SECURITY;

--
-- Name: parent_documents parent_documents_group_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY parent_documents_group_access ON public.parent_documents TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.groups
  WHERE (groups.id = parent_documents.group_id))));


--
-- Name: user_groups; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.user_groups ENABLE ROW LEVEL SECURITY;

--
-- Name: user_groups user_groups_self_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY user_groups_self_access ON public.user_groups FOR SELECT TO authenticated USING ((user_id = auth.uid()));


--
-- Name: users; Type: ROW SECURITY; Schema: public; Owner: -
--

ALTER TABLE public.users ENABLE ROW LEVEL SECURITY;

--
-- Name: users users_admin_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY users_admin_access ON public.users TO authenticated USING ((EXISTS ( SELECT 1
   FROM public.user_groups ug
  WHERE ((ug.user_id = auth.uid()) AND (ug.group_id = public.get_admins_group_id())))));


--
-- Name: users users_self_access; Type: POLICY; Schema: public; Owner: -
--

CREATE POLICY users_self_access ON public.users FOR SELECT TO authenticated USING ((id = auth.uid()));


--
-- Name: SCHEMA auth; Type: ACL; Schema: -; Owner: -
--

GRANT USAGE ON SCHEMA auth TO authenticated;
GRANT USAGE ON SCHEMA auth TO service_role;


--
-- Name: SCHEMA public; Type: ACL; Schema: -; Owner: -
--

GRANT USAGE ON SCHEMA public TO authenticated;
GRANT USAGE ON SCHEMA public TO service_role;


--
-- Name: FUNCTION gtrgm_in(cstring); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_in(cstring) TO authenticated;


--
-- Name: FUNCTION gtrgm_out(public.gtrgm); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_out(public.gtrgm) TO authenticated;


--
-- Name: FUNCTION halfvec_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION halfvec_out(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_out(public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION halfvec_send(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_send(public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION sparsevec_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION sparsevec_out(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_out(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION sparsevec_send(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_send(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION vector_in(cstring, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_in(cstring, oid, integer) TO authenticated;


--
-- Name: FUNCTION vector_out(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_out(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_recv(internal, oid, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_recv(internal, oid, integer) TO authenticated;


--
-- Name: FUNCTION vector_send(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_send(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_typmod_in(cstring[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_typmod_in(cstring[]) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(real[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(real[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(real[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(real[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(double precision[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(double precision[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(double precision[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(double precision[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(integer[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(integer[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(integer[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(integer[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_halfvec(numeric[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_halfvec(numeric[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION array_to_vector(numeric[], integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.array_to_vector(numeric[], integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_float4(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_float4(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_sparsevec(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_sparsevec(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION halfvec_to_vector(public.halfvec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_to_vector(public.halfvec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec_to_halfvec(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_to_halfvec(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION sparsevec_to_vector(public.sparsevec, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_to_vector(public.sparsevec, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_float4(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_float4(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_halfvec(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_halfvec(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector_to_sparsevec(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_to_sparsevec(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION vector(public.vector, integer, boolean); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector(public.vector, integer, boolean) TO authenticated;


--
-- Name: FUNCTION add_user_to_groups(p_username text, p_group_names text[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.add_user_to_groups(p_username text, p_group_names text[]) TO authenticated;


--
-- Name: FUNCTION binary_quantize(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.binary_quantize(public.halfvec) TO authenticated;


--
-- Name: FUNCTION binary_quantize(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.binary_quantize(public.vector) TO authenticated;


--
-- Name: FUNCTION calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) TO authenticated;
GRANT ALL ON FUNCTION public.calculate_llm_call_cost(p_model_name text, p_input_tokens integer, p_output_tokens integer) TO service_role;


--
-- Name: FUNCTION connect_as_user(p_username text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.connect_as_user(p_username text) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION cosine_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.cosine_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION document_fts_search(p_query_text text, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_max_terms integer, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.document_fts_search(p_query_text text, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_max_terms integer, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer) TO authenticated;


--
-- Name: FUNCTION document_semantic_search(p_query_embedding public.vector, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.document_semantic_search(p_query_embedding public.vector, p_match_count integer, p_similarity_threshold double precision, p_group_ids uuid[], p_created_before timestamp with time zone, p_created_after timestamp with time zone, p_parent_metadata jsonb, p_non_null_parent_metadata_keys text[], p_min_parent_id integer, p_max_parent_id integer) TO authenticated;


--
-- Name: FUNCTION get_admins_group_id(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_admins_group_id() TO authenticated;


--
-- Name: FUNCTION get_group_id(p_group_name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_group_id(p_group_name text) TO authenticated;
GRANT ALL ON FUNCTION public.get_group_id(p_group_name text) TO service_role;


--
-- Name: FUNCTION get_user_groups(p_user_id uuid, p_username text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_user_groups(p_user_id uuid, p_username text) TO authenticated;


--
-- Name: FUNCTION get_users_in_group(p_group_id uuid, p_group_name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.get_users_in_group(p_group_id uuid, p_group_name text) TO authenticated;


--
-- Name: FUNCTION gin_extract_query_trgm(text, internal, smallint, internal, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_extract_query_trgm(text, internal, smallint, internal, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gin_extract_value_trgm(text, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_extract_value_trgm(text, internal) TO authenticated;


--
-- Name: FUNCTION gin_trgm_consistent(internal, smallint, text, integer, internal, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_trgm_consistent(internal, smallint, text, integer, internal, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gin_trgm_triconsistent(internal, smallint, text, integer, internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gin_trgm_triconsistent(internal, smallint, text, integer, internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_compress(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_compress(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_consistent(internal, text, smallint, oid, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_consistent(internal, text, smallint, oid, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_decompress(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_decompress(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_distance(internal, text, smallint, oid, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_distance(internal, text, smallint, oid, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_options(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_options(internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_penalty(internal, internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_penalty(internal, internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_picksplit(internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_picksplit(internal, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_same(public.gtrgm, public.gtrgm, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_same(public.gtrgm, public.gtrgm, internal) TO authenticated;


--
-- Name: FUNCTION gtrgm_union(internal, internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.gtrgm_union(internal, internal) TO authenticated;


--
-- Name: FUNCTION halfvec_accum(double precision[], public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_accum(double precision[], public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_add(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_add(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_avg(double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_avg(double precision[]) TO authenticated;


--
-- Name: FUNCTION halfvec_cmp(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_cmp(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_combine(double precision[], double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_combine(double precision[], double precision[]) TO authenticated;


--
-- Name: FUNCTION halfvec_concat(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_concat(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_eq(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_eq(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_ge(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_ge(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_gt(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_gt(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_l2_squared_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_l2_squared_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_le(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_le(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_lt(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_lt(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_mul(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_mul(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_ne(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_ne(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_negative_inner_product(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_negative_inner_product(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_spherical_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_spherical_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION halfvec_sub(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.halfvec_sub(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION hamming_distance(bit, bit); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hamming_distance(bit, bit) TO authenticated;


--
-- Name: FUNCTION hnsw_bit_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_bit_support(internal) TO authenticated;


--
-- Name: FUNCTION hnsw_halfvec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_halfvec_support(internal) TO authenticated;


--
-- Name: FUNCTION hnsw_sparsevec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnsw_sparsevec_support(internal) TO authenticated;


--
-- Name: FUNCTION hnswhandler(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.hnswhandler(internal) TO authenticated;


--
-- Name: FUNCTION inner_product(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION inner_product(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION inner_product(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.inner_product(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION is_authenticated(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.is_authenticated() TO authenticated;


--
-- Name: FUNCTION ivfflat_bit_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflat_bit_support(internal) TO authenticated;


--
-- Name: FUNCTION ivfflat_halfvec_support(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflat_halfvec_support(internal) TO authenticated;


--
-- Name: FUNCTION ivfflathandler(internal); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.ivfflathandler(internal) TO authenticated;


--
-- Name: FUNCTION jaccard_distance(bit, bit); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.jaccard_distance(bit, bit) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l1_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l1_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.halfvec, public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.halfvec, public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION l2_norm(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_norm(public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_norm(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_norm(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.halfvec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.sparsevec) TO authenticated;


--
-- Name: FUNCTION l2_normalize(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.l2_normalize(public.vector) TO authenticated;


--
-- Name: FUNCTION plainto_tsquery_smart(p_query_text text, p_max_terms integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.plainto_tsquery_smart(p_query_text text, p_max_terms integer) TO authenticated;


--
-- Name: FUNCTION plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.plainto_tsquery_smart_prefix(p_query_text text, p_max_terms integer) TO authenticated;


--
-- Name: FUNCTION remove_user_from_groups(p_username text, p_group_names text[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.remove_user_from_groups(p_username text, p_group_names text[]) TO authenticated;


--
-- Name: FUNCTION set_authenticated_user(user_id uuid); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.set_authenticated_user(user_id uuid) TO authenticated;


--
-- Name: FUNCTION set_limit(real); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.set_limit(real) TO authenticated;


--
-- Name: FUNCTION show_limit(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.show_limit() TO authenticated;


--
-- Name: FUNCTION show_trgm(text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.show_trgm(text) TO authenticated;


--
-- Name: FUNCTION similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity(text, text) TO authenticated;


--
-- Name: FUNCTION similarity_dist(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity_dist(text, text) TO authenticated;


--
-- Name: FUNCTION similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION sparsevec_cmp(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_cmp(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_eq(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_eq(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_ge(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_ge(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_gt(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_gt(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_l2_squared_distance(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_l2_squared_distance(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_le(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_le(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_lt(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_lt(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_ne(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_ne(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION sparsevec_negative_inner_product(public.sparsevec, public.sparsevec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sparsevec_negative_inner_product(public.sparsevec, public.sparsevec) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_dist_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_dist_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_dist_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_dist_op(text, text) TO authenticated;


--
-- Name: FUNCTION strict_word_similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.strict_word_similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION subvector(public.halfvec, integer, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.subvector(public.halfvec, integer, integer) TO authenticated;


--
-- Name: FUNCTION subvector(public.vector, integer, integer); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.subvector(public.vector, integer, integer) TO authenticated;


--
-- Name: FUNCTION update_llm_call_cost(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.update_llm_call_cost() TO authenticated;


--
-- Name: FUNCTION user_in_group(p_user_id uuid, p_group_id uuid); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) TO authenticated;
GRANT ALL ON FUNCTION public.user_in_group(p_user_id uuid, p_group_id uuid) TO service_role;


--
-- Name: FUNCTION uuid_generate_v1(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v1() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v1mc(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v1mc() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v3(namespace uuid, name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v3(namespace uuid, name text) TO authenticated;


--
-- Name: FUNCTION uuid_generate_v4(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v4() TO authenticated;


--
-- Name: FUNCTION uuid_generate_v5(namespace uuid, name text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_generate_v5(namespace uuid, name text) TO authenticated;


--
-- Name: FUNCTION uuid_nil(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_nil() TO authenticated;


--
-- Name: FUNCTION uuid_ns_dns(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_dns() TO authenticated;


--
-- Name: FUNCTION uuid_ns_oid(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_oid() TO authenticated;


--
-- Name: FUNCTION uuid_ns_url(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_url() TO authenticated;


--
-- Name: FUNCTION uuid_ns_x500(); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.uuid_ns_x500() TO authenticated;


--
-- Name: FUNCTION vector_accum(double precision[], public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_accum(double precision[], public.vector) TO authenticated;


--
-- Name: FUNCTION vector_add(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_add(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_avg(double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_avg(double precision[]) TO authenticated;


--
-- Name: FUNCTION vector_cmp(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_cmp(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_combine(double precision[], double precision[]); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_combine(double precision[], double precision[]) TO authenticated;


--
-- Name: FUNCTION vector_concat(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_concat(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_dims(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_dims(public.halfvec) TO authenticated;


--
-- Name: FUNCTION vector_dims(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_dims(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_eq(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_eq(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_ge(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_ge(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_gt(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_gt(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_l2_squared_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_l2_squared_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_le(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_le(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_lt(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_lt(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_mul(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_mul(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_ne(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_ne(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_negative_inner_product(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_negative_inner_product(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_norm(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_norm(public.vector) TO authenticated;


--
-- Name: FUNCTION vector_spherical_distance(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_spherical_distance(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION vector_sub(public.vector, public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.vector_sub(public.vector, public.vector) TO authenticated;


--
-- Name: FUNCTION word_similarity(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_dist_commutator_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_dist_commutator_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_dist_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_dist_op(text, text) TO authenticated;


--
-- Name: FUNCTION word_similarity_op(text, text); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.word_similarity_op(text, text) TO authenticated;


--
-- Name: FUNCTION avg(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.avg(public.halfvec) TO authenticated;


--
-- Name: FUNCTION avg(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.avg(public.vector) TO authenticated;


--
-- Name: FUNCTION sum(public.halfvec); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sum(public.halfvec) TO authenticated;


--
-- Name: FUNCTION sum(public.vector); Type: ACL; Schema: public; Owner: -
--

GRANT ALL ON FUNCTION public.sum(public.vector) TO authenticated;


--
-- Name: TABLE documents; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.documents TO authenticated;
GRANT ALL ON TABLE public.documents TO service_role;


--
-- Name: TABLE groups; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.groups TO authenticated;
GRANT ALL ON TABLE public.groups TO service_role;


--
-- Name: TABLE llm_calls; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.llm_calls TO authenticated;


--
-- Name: TABLE llms; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.llms TO authenticated;
GRANT ALL ON TABLE public.llms TO service_role;


--
-- Name: TABLE parent_documents; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.parent_documents TO authenticated;
GRANT ALL ON TABLE public.parent_documents TO service_role;


--
-- Name: TABLE user_groups; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.user_groups TO authenticated;
GRANT ALL ON TABLE public.user_groups TO service_role;


--
-- Name: TABLE users; Type: ACL; Schema: public; Owner: -
--

GRANT SELECT,INSERT,DELETE,UPDATE ON TABLE public.users TO authenticated;
GRANT ALL ON TABLE public.users TO service_role;


--
-- Name: DEFAULT PRIVILEGES FOR SEQUENCES; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT SELECT,USAGE ON SEQUENCES TO authenticated;


--
-- Name: DEFAULT PRIVILEGES FOR FUNCTIONS; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT ALL ON FUNCTIONS TO authenticated;


--
-- Name: DEFAULT PRIVILEGES FOR TABLES; Type: DEFAULT ACL; Schema: public; Owner: -
--

ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA public GRANT SELECT,INSERT,DELETE,UPDATE ON TABLES TO authenticated;


--
-- PostgreSQL database dump complete
--
```
## File: postgres_setup/pgdump_20250415/roles_permissions.sql
```
--
-- PostgreSQL database cluster dump
--

SET default_transaction_read_only = off;

SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;

--
-- Roles
--

CREATE ROLE app_user;
ALTER ROLE app_user WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB LOGIN NOREPLICATION NOBYPASSRLS PASSWORD 'SCRAM-SHA-256$4096:G2BO2gAsm3AdaLwV3wU0IA==$BMAEMs1jTrGZIjuCWpDhjPniAbhJGGwxafh1QvLV3y4=:gwjM7XDhlMg7JdRlSS/kyXriK/5IZAJjKJ61SPyGkXw=';
CREATE ROLE authenticated;
ALTER ROLE authenticated WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB NOLOGIN NOREPLICATION NOBYPASSRLS;
CREATE ROLE postgres;
ALTER ROLE postgres WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN REPLICATION BYPASSRLS PASSWORD 'SCRAM-SHA-256$4096:25CvqijMAQlsEMjZ6AVPYA==$KDpWN7skjchyfZ57d7SN/z1r+2AIJhrF7oLBbhLTjZY=:sOYF7UwVdt39fQzydGRNCbB43p5Ty2WNWVEQnXF6wnY=';
CREATE ROLE service_role;
ALTER ROLE service_role WITH NOSUPERUSER INHERIT NOCREATEROLE NOCREATEDB NOLOGIN NOREPLICATION NOBYPASSRLS;

--
-- User Configurations
--


--
-- Role memberships
--

GRANT authenticated TO app_user WITH INHERIT TRUE GRANTED BY postgres;




--
-- PostgreSQL database cluster dump complete
--
```
